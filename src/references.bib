
@InProceedings{	  abadi89:dynamic,
  title		= {Dynamic Typing in a Statically-Typed Language},
  booktitle	= {Proceedings of the 16th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Abadi, M. and Cardelli, L. and Pierce, B. and Plotkin,
		  G.},
  year		= {1989},
  month		= jan,
  series	= {{{POPL}} '89},
  pages		= {213--227},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/75277.75296},
  urldate	= {2023-10-20},
  abstract	= {Statically-typed programming languages allow earlier error
		  checking, better enforcement of disciplined programming
		  styles, and generation of more efficient object code than
		  languages where all type-consistency checks are performed
		  at runtime. However, even in statically-type languages,
		  there is often the need to deal with data whose type cannot
		  be known at compile time. To handle such situations safely,
		  we propose to add a type Dynamic whose values are pairs of
		  a value v and a type tag T where v has the type denoted by
		  T. Instances of Dynamic are built with an explicit tagging
		  construct and inspected with a type-safe typecase
		  construct. This paper is an exploration of the syntax,
		  operational semantics, and denotational semantics of a
		  simple language with the type Dynamic. We give examples of
		  how dynamically-typed values might be used in programming.
		  Then we discuss an operational semantics for our language
		  and obtain a soundness theorem. We present two formulations
		  of the denotational semantics of this language and relate
		  them to the operational semantics. Finally, we consider the
		  implications of polymorphism and some implementation
		  issues.},
  isbn		= {978-0-89791-294-5}
}

@InProceedings{	  adjih15:fit-iot-lab,
  title		= {{{FIT IoT-LAB}}: {{A}} Large Scale Open Experimental
		  {{IoT}} Testbed},
  shorttitle	= {{{FIT IoT-LAB}}},
  booktitle	= {{{IEEE World Forum}} on {{Internet}} of {{Things}},
		  {{WF-IoT}} 2015 - {{Proceedings}}},
  author	= {Adjih, C. and Baccelli, E. and Fleury, E. and Harter, G.
		  and Mitton, N. and Noel, T. and {Pissard-Gibollet}, R. and
		  {Saint-Marcel}, F. and Schreiner, G. and Vandaele, J. and
		  Watteyne, T.},
  year		= {2015},
  pages		= {459--464},
  doi		= {10.1109/WF-IoT.2015.7389098},
  abstract	= {This paper introduces the FIT IoT-LAB testbed, an open
		  testbed composed of 2728 low-power wireless nodes and 117
		  mobile robots available for experimenting with large-scale
		  wireless IoT technologies, ranging from low-level protocols
		  to advanced Internet services. IoT-LAB is built to
		  accelerate the development of tomorrow's IoT technology by
		  offering an accurate open-access and open-source multi-user
		  scientific tool. The IoT-LAB testbed is deployed in 6 sites
		  across France. Each site features different node and
		  hardware capabilities, but all sites are interconnected and
		  available through the same web portal, common REST
		  interfaces and consistent CLI tools. The result is a
		  heterogeneous testing environment, which covers a large
		  spectrum of IoT use cases and applications. IoT-LAB is a
		  one-of-a-kind facility, allowing anyone to test their
		  solution at scale, experiment and fine-tune new networking
		  concept. {\copyright} 2015 IEEE.},
  keywords	= {IoT,Large Scale,Low Power Wireless Sensor
		  Network,Mobility,Open Platform,Robot,Testbed}
}

@Article{	  agrawal91:execution-backtracking,
  title		= {An Execution-Backtracking Approach to Debugging},
  author	= {Agrawal, H. and De Millo, R.A. and Spafford, E.H.},
  year		= {1991},
  month		= may,
  journal	= {IEEE Software},
  volume	= {8},
  number	= {3},
  pages		= {21--26},
  issn		= {1937-4194},
  doi		= {10.1109/52.88940},
  urldate	= {2024-11-11},
  abstract	= {Spyder, a system for selective checkpointing of
		  computational sequences, is presented. It lets users
		  backtrack from checkpoints without the need to reexecute
		  the program to reach recent prior states. In contrast to
		  more comprehensive (and storage-intensive) checkpointing
		  schemes, backtracking in this approach is constrained to
		  limit storage requirements. The resulting debugger offers a
		  structured view of dynamic events, similar to lexical scope
		  rules' effect on static visibility. The debugger also
		  speeds backtracking to statements before loops and provides
		  what-if capabilities.{$<>$}},
  keywords	= {Debugging,Displays,Prototypes,Testing}
}

@Article{	  agrawal93:debugging,
  title		= {Debugging with Dynamic Slicing and Backtracking},
  author	= {Agrawal, Hiralal and Demillo, Richard A. and Spafford,
		  Eugene H.},
  year		= {1993},
  journal	= {Software: Practice and Experience},
  volume	= {23},
  number	= {6},
  pages		= {589--616},
  issn		= {1097-024X},
  doi		= {10.1002/spe.4380230603},
  urldate	= {2023-11-07},
  abstract	= {Programmers spend considerable time debugging code.
		  Symbolic debuggers provide some help but the task remains
		  complex and difficult. Other than breakpoints and tracing,
		  these tools provide little high-level help. Programmers
		  must perform many tasks manually that the tools could
		  perform automatically, such as finding which statements in
		  the program affect the value of an output variable for a
		  given test case, and what was the value of a given variable
		  when the control last reached a given program location. If
		  debugging tools provided explicit support for these tasks,
		  the debugging process could be automated to a significant
		  extent. In this paper we present a debugging model, based
		  on dynamic program slicing and execution backtracking
		  techniques, that easily lends itself to automation. This
		  model is based on experience with using these techniques to
		  debug software. We also present a prototype debugging tool,
		  SPYDER, that explicitly supports the proposed model, and
		  with which we are performing further debugging research.},
  langid	= {english},
  keywords	= {Dynamic program slicing,Execution backtracking,Program
		  debugging,Program slicing,Reverse program execution}
}

@InProceedings{	  aguzzi21:scafi-web,
  title		= {{{ScaFi-Web}}: {{A Web-Based Application}} for
		  {{Field-Based Coordination Programming}}},
  shorttitle	= {{{ScaFi-Web}}},
  booktitle	= {Coordination {{Models}} and {{Languages}}},
  author	= {Aguzzi, Gianluca and Casadei, Roberto and Maltoni,
		  Niccol{\`o} and Pianini, Danilo and Viroli, Mirko},
  editor	= {Damiani, Ferruccio and Dardha, Ornela},
  year		= {2021},
  pages		= {285--299},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-78142-2_18},
  abstract	= {Field-based coordination is a model for expressing the
		  coordination logic of large-scale adaptive systems,
		  composing functional blocks from a global perspective. As
		  for any coordination model, a proper toolchain must be
		  developed to support its adoption across all development
		  phases. Under this point of view, the ScaFi toolkit
		  provides a coordination language (field calculus) as a DSL
		  internal in the Scala language, a library of reusable
		  building blocks, and an infrastructure for simulation of
		  distributed deployments. In this work, we enrich such a
		  toolchain by introducing ScaFi-Web, a web-based application
		  allowing in-browser editing, execution, and visualisation
		  of ScaFi programs. ScaFi-Web facilitates access to the
		  ScaFi coordination technology by flattening the learning
		  curve and simplifying configuration and requirements, thus
		  promoting agile prototyping of field-based coordination
		  specifications. In turn, this opens the door to easier
		  demonstrations and experimentation, and also constitutes a
		  stepping stone towards monitoring and control of
		  simulated/deployed systems.},
  isbn		= {978-3-030-78142-2},
  langid	= {english}
}

@InProceedings{	  aguzzi23:macroswarm,
  title		= {{{MacroSwarm}}: {{A~Field-Based Compositional Framework}}
		  for~{{Swarm Programming}}},
  shorttitle	= {{{MacroSwarm}}},
  booktitle	= {Coordination {{Models}} and {{Languages}}},
  author	= {Aguzzi, Gianluca and Casadei, Roberto and Viroli, Mirko},
  editor	= {Jongmans, Sung-Shik and Lopes, Ant{\'o}nia},
  year		= {2023},
  pages		= {31--51},
  publisher	= {Springer Nature Switzerland},
  address	= {Cham},
  doi		= {10.1007/978-3-031-35361-1_2},
  abstract	= {Swarm behaviour engineering is an area of research that
		  seeks to investigate methods for coordinating computation
		  and action within groups of simple agents to achieve
		  complex global goals like collective movement, clustering,
		  and distributed sensing. Despite recent progress in the
		  study and engineering of swarms (of drones, robots,
		  vehicles), there is still need for general design and
		  implementation methods that can be used to define complex
		  swarm coordination in a principled way. To face this need,
		  this paper proposes a new field-based coordination
		  approach, called MacroSwarm, to design fully composable and
		  reusable blocks of swarm behaviour. Based on the
		  macroprogramming approach of aggregate computing, it roots
		  on the idea of modelling each block of swarm behaviour by a
		  purely functional transformation of sensing fields into
		  actuation description fields, typically including movement
		  vectors. We showcase the potential of MacroSwarm as a
		  framework for collective intelligence by simulation, in a
		  variety of scenarios including flocking, morphogenesis, and
		  collective decision-making.},
  isbn		= {978-3-031-35361-1},
  langid	= {english}
}

@InProceedings{	  ai20:novel-concolic-execution-approach,
  title		= {A {{Novel Concolic Execution Approach}} on {{Embedded
		  Device}}},
  booktitle	= {Proceedings of the 2020 4th {{International Conference}}
		  on {{Cryptography}}, {{Security}} and {{Privacy}}},
  author	= {Ai, Chengwei and Dong, Weiyu and Gao, Zicong},
  year		= {2020},
  month		= feb,
  series	= {{{ICCSP}} 2020},
  pages		= {47--52},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3377644.3377654},
  urldate	= {2024-03-28},
  abstract	= {With the widely use of embeded device, its security issues
		  cause high attention. As one of the popular program testing
		  techniques, symbolic execution tests a program by treating
		  the program's input as symbols and interpreting the program
		  over these inputs. Due to the complex environment and
		  lackage of computing resources, there is no efficient
		  symbolic execution approach in analyzing firmware running
		  on device. In this paper, we present a novel concolic
		  execution approach for firmware programs. The approach
		  adopts Dynamic Test Generation scheme to perform concrete
		  execution on multiple architectures Unix-like physical
		  device and symbolic execution on the debugging host. In
		  order to gain the complex environment info, the concrete
		  execution performs by gdb debugging method collects program
		  trace and runtime information. And to overcome the lackage
		  of computing resources, the symbolic execution extracts
		  relevant constraints and solves the collected constraints
		  to generate new test cases on a high perfomance host. We
		  implement the approach in various architectures, including
		  x86-64, arm and ppc. The availability and effectiveness of
		  our approach can be verified by evaluating some binutil
		  programs in our approach's framework.},
  isbn		= {978-1-4503-7744-7},
  keywords	= {Concolic execution,Firmware analysis,Test case
		  generation}
}

@InProceedings{	  allen83:conversion,
  title		= {Conversion of Control Dependence to Data Dependence},
  booktitle	= {Proceedings of the 10th {{ACM SIGACT-SIGPLAN}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Allen, J. R. and Kennedy, Ken and Porterfield, Carrie and
		  Warren, Joe},
  year		= {1983},
  month		= jan,
  series	= {{{POPL}} '83},
  pages		= {177--189},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/567067.567085},
  urldate	= {2024-03-18},
  abstract	= {Program analysis methods, especially those which support
		  automatic vectorization, are based on the concept of
		  interstatement dependence where a dependence holds between
		  two statements when one of the statements computes values
		  needed by the other. Powerful program transformation
		  systems that convert sequential programs to a form more
		  suitable for vector or parallel machines have been
		  developed using this concept [AllK 82, KKLW 80].The
		  dependence analysis in these systems is based on data
		  dependence. In the presence of complex control flow, data
		  dependence is not sufficient to transform programs because
		  of the introduction of control dependences. A control
		  dependence exists between two statements when the execution
		  of one statement can prevent the execution of the other.
		  Control dependences do not fit conveniently into
		  dependence-based program translators.One solution is to
		  convert all control dependences to data dependences by
		  eliminating goto statements and introducing logical
		  variables to control the execution of statements in the
		  program. In this scheme, action statements are converted to
		  IF statements. The variables in the conditional expression
		  of an IF statement can be viewed as inputs to the statement
		  being controlled. The result is that control dependences
		  between statements become explicit data dependences
		  expressed through the definitions and uses of the
		  controlling logical variables.This paper presents a method
		  for systematically converting control dependences to data
		  dependences in this fashion. The algorithms presented here
		  have been implemented in PFC, an experimental vectorizer
		  written at Rice University.},
  isbn		= {978-0-89791-090-3}
}

@Article{	  almatary22:compartos,
  title		= {{{CompartOS}}: {{CHERI Compartmentalization}} for
		  {{Embedded Systems}}},
  shorttitle	= {{{CompartOS}}},
  author	= {Almatary, Hesham and Dodson, Michael and Clarke, Jessica
		  and Rugg, Peter and Gomes, Ivan and Podhradsky, Michal and
		  Neumann, Peter G. and Moore, Simon W. and Watson, Robert N.
		  M.},
  year		= {2022},
  publisher	= {arXiv},
  doi		= {10.48550/ARXIV.2206.02852},
  urldate	= {2024-01-18},
  abstract	= {Existing high-end embedded systems face frequent security
		  attacks. Software compartmentalization is one technique to
		  limit the attacks' effects to the compromised compartment
		  and not the entire system. Unfortunately, the existing
		  state-of-the-art embedded hardware-software solutions do
		  not work well to enforce software compartmentalization for
		  high-end embedded systems. MPUs are not fine-grained and
		  suffer from significant scalability limitations as they can
		  only protect a small and fixed number of memory regions. On
		  the other hand, MMUs suffer from non-determinism and
		  coarse-grained protection. This paper introduces CompartOS
		  as a lightweight linkage-based compartmentalization model
		  for high-end, complex, mainstream embedded systems.
		  CompartOS builds on CHERI, a capability-based hardware
		  architecture, to meet scalability, availability,
		  compatibility, and fine-grained security goals.
		  Microbenchmarks show that CompartOS' protection-domain
		  crossing is 95\% faster than MPU-based IPC. We applied the
		  CompartOS model, with low effort, to complex existing
		  systems, including TCP servers and a safety-critical
		  automotive demo. CompartOS not only catches 10 out of 13
		  FreeRTOS-TCP published vulnerabilities that MPU-based
		  protection (e.g., uVisor) cannot catch but can also recover
		  from them. Further, our TCP throughput evaluations show
		  that our CompartOS prototype is 52\% faster than relevant
		  MPU-based compartmentalization models (e.g., ACES), with a
		  15\% overhead compared to an unprotected system. This comes
		  at an FPGA's LUTs overhead of 10.4\% to support CHERI for
		  an unprotected baseline RISC-V processor, compared to 7.6\%
		  to support MPU, while CHERI only incurs 1.3\% of the
		  registers area overhead compared to 2\% for MPU.},
  copyright	= {Creative Commons Attribution 4.0 International},
  keywords	= {Cryptography and Security (cs.CR),FOS: Computer and
		  information sciences}
}

@Article{	  almeida24:approaches,
  title		= {Approaches to {{Conflict-free Replicated Data Types}}},
  author	= {Almeida, Paulo S{\'e}rgio},
  year		= {2024},
  month		= nov,
  journal	= {ACM Comput. Surv.},
  volume	= {57},
  number	= {2},
  pages		= {51:1--51:36},
  issn		= {0360-0300},
  doi		= {10.1145/3695249},
  urldate	= {2025-03-04},
  abstract	= {Conflict-free Replicated Data Types (CRDTs) allow
		  optimistic replication in a principled way. Different
		  replicas can proceed independently, being available even
		  under network partitions and always converging
		  deterministically: Replicas that have received the same
		  updates will have equivalent state, even if received in
		  different orders. After a historical tour of the evolution
		  from sequential data types to CRDTs, we present in detail
		  the two main approaches to CRDTs, operation-based and
		  state-based, including two important variations, the pure
		  operation-based and the delta-state based. Intended for
		  prospective CRDT researchers and designers, this article
		  provides solid coverage of the essential concepts,
		  clarifying some misconceptions that frequently occur, but
		  also presents some novel insights gained from considerable
		  experience in designing both specific CRDTs and approaches
		  to CRDTs.}
}

@Article{	  alrabaee22:survey,
  title		= {A {{Survey}} of {{Binary Code Fingerprinting Approaches}}:
		  {{Taxonomy}}, {{Methodologies}}, and {{Features}}},
  shorttitle	= {A {{Survey}} of {{Binary Code Fingerprinting
		  Approaches}}},
  author	= {Alrabaee, Saed and Debbabi, Mourad and Wang, Lingyu},
  year		= {2022},
  month		= jan,
  journal	= {ACM Computing Surveys},
  volume	= {55},
  number	= {1},
  pages		= {19:1--19:41},
  issn		= {0360-0300},
  doi		= {10.1145/3486860},
  urldate	= {2024-03-18},
  abstract	= {Binary code fingerprinting is crucial in many security
		  applications. Examples include malware detection, software
		  infringement, vulnerability analysis, and digital
		  forensics. It is also useful for security researchers and
		  reverse engineers since it enables high fidelity reasoning
		  about the binary code such as revealing the functionality,
		  authorship, libraries used, and vulnerabilities. Numerous
		  studies have investigated binary code with the goal of
		  extracting fingerprints that can illuminate the semantics
		  of a target application. However, extracting fingerprints
		  is a challenging task since a substantial amount of
		  significant information will be lost during compilation,
		  notably, variable and function naming, the original data
		  and control flow structures, comments, semantic
		  information, and the code layout. This article provides the
		  first systematic review of existing binary code
		  fingerprinting approaches and the contexts in which they
		  are used. In addition, it discusses the applications that
		  rely on binary code fingerprints, the information that can
		  be captured during the fingerprinting process, and the
		  approaches used and their implementations. It also
		  addresses limitations and open questions related to the
		  fingerprinting process and proposes future directions.},
  keywords	= {Binary code analysis,reverse engineering,software
		  security}
}

@Misc{		  alter,
  title		= {Alter the Program's Execution Flow},
  year		= {2024},
  month		= nov,
  journal	= {IntelliJ~IDEA Help},
  urldate	= {2025-04-18},
  howpublished	= {https://www.jetbrains.com/help/idea/altering-the-program-s-execution-flow.html},
  langid	= {american}
}

@InProceedings{	  amar23:cheriot,
  title		= {{{CHERIoT}}: {{Complete Memory Safety}} for {{Embedded
		  Devices}}},
  shorttitle	= {{{CHERIoT}}},
  booktitle	= {Proceedings of the 56th {{Annual IEEE}}/{{ACM
		  International Symposium}} on {{Microarchitecture}}},
  author	= {Amar, Saar and Chisnall, David and Chen, Tony and Filardo,
		  Nathaniel Wesley and Laurie, Ben and Liu, Kunyan and
		  Norton, Robert and Moore, Simon W. and Tao, Yucong and
		  Watson, Robert N. M. and Xia, Hongyan},
  year		= {2023},
  month		= dec,
  series	= {{{MICRO}} '23},
  pages		= {641--653},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3613424.3614266},
  urldate	= {2024-01-18},
  abstract	= {The ubiquity of embedded devices is apparent. The desire
		  for increased functionality and connectivity drives ever
		  larger software stacks, with components from multiple
		  vendors and entities. These stacks should be replete with
		  isolation and memory safety technologies, but existing
		  solutions impinge upon development, unit cost, power,
		  scalability, and/or real-time constraints, limiting their
		  adoption and production-grade deployments. As memory safety
		  vulnerabilities mount, the situation is clearly not tenable
		  and a new approach is needed. To slake this need, we
		  present a novel adaptation of the CHERI capability
		  architecture, co-designed with a green-field,
		  security-centric RTOS. It is scaled for embedded systems,
		  is capable of fine-grained software compartmentalization,
		  and provides affordances for full inter-compartment memory
		  safety. We highlight central design decisions and offloads
		  and summarize how our prototype RTOS uses these to enable
		  memory-safe, compartmentalized applications. Unlike many
		  state-of-the-art schemes, our solution deterministically
		  (not probabilistically) eliminates memory safety
		  vulnerabilities while maintaining source-level
		  compatibility. We characterize the power, performance, and
		  area microarchitectural impacts, run microbenchmarks of key
		  facilities, and exhibit the practicality of an end-to-end
		  IoT application. The implementation shows that full memory
		  safety for compartmentalized embedded systems is achievable
		  without violating resource constraints or real-time
		  guarantees, and that hardware assists need not be
		  expensive, intrusive, or power-hungry.},
  isbn		= {9798400703294}
}

@InProceedings{	  annamaa15:introducing,
  title		= {Introducing {{Thonny}}, a {{Python IDE}} for Learning
		  Programming},
  booktitle	= {Proceedings of the 15th {{Koli Calling Conference}} on
		  {{Computing Education Research}}},
  author	= {Annamaa, Aivar},
  year		= {2015},
  month		= nov,
  series	= {Koli {{Calling}} '15},
  pages		= {117--121},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2828959.2828969},
  urldate	= {2025-01-14},
  abstract	= {Thonny is a new Python IDE for learning and teaching
		  programming that can make program visualization a natural
		  part of the beginners' workflow. Among its prominent
		  features are different ways of stepping through the code,
		  step-by-step expression evaluation, intuitive visualization
		  of the call stack and mode for explaining the concepts of
		  references and heap. It supports educational research by
		  logging user actions for replaying or analyzing the
		  programming process. It is free to use and open for
		  extension.},
  isbn		= {978-1-4503-4020-5}
}

@InCollection{	  answers,
  title		= {Answers to the {{Questions}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {327--329},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch9},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Answers to the end
		  of chapter questions Correct answers to the sample paper
		  questions},
  chapter	= {9},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@Misc{		  appoptics,
  title		= {{{AppOptics}} -- {{APM}} and {{Infrastructure Tool}}
		  {\textbar} {{SolarWinds AppOptics}}},
  urldate	= {2024-02-12},
  abstract	= {Get visibility into modern application and infrastructure
		  performance using one APM tool. Out-of-the-box dashboards,
		  metrics, and analytics. Try a free 14-day trial!},
  howpublished	= {https://www.solarwinds.com/appoptics},
  langid	= {american}
}

@Misc{		  aspencore23:embedded,
  title		= {Embedded Survey 2023: More {{IP}} Reuse as Workloads
		  Surge},
  author	= {{Aspencore}},
  year		= {2023}
}

@Article{	  atzori10:internet,
  title		= {The {{Internet}} of {{Things}}: {{A}} Survey},
  shorttitle	= {The {{Internet}} of {{Things}}},
  author	= {Atzori, Luigi and Iera, Antonio and Morabito, Giacomo},
  year		= {2010},
  month		= oct,
  journal	= {Computer Networks},
  volume	= {54},
  number	= {15},
  pages		= {2787--2805},
  issn		= {1389-1286},
  doi		= {10.1016/j.comnet.2010.05.010},
  urldate	= {2025-01-13},
  abstract	= {This paper addresses the Internet of Things. Main enabling
		  factor of this promising paradigm is the integration of
		  several technologies and communications solutions.
		  Identification and tracking technologies, wired and
		  wireless sensor and actuator networks, enhanced
		  communication protocols (shared with the Next Generation
		  Internet), and distributed intelligence for smart objects
		  are just the most relevant. As one can easily imagine, any
		  serious contribution to the advance of the Internet of
		  Things must necessarily be the result of synergetic
		  activities conducted in different fields of knowledge, such
		  as telecommunications, informatics, electronics and social
		  science. In such a complex scenario, this survey is
		  directed to those who want to approach this complex
		  discipline and contribute to its development. Different
		  visions of this Internet of Things paradigm are reported
		  and enabling technologies reviewed. What emerges is that
		  still major issues shall be faced by the research
		  community. The most relevant among them are addressed in
		  details.},
  keywords	= {Internet of Things,Pervasive computing,RFID systems}
}

@Article{	  auguston05:environment,
  title		= {Environment Behavior Models for Scenario Generation and
		  Testing Automation},
  author	= {Auguston, Mikhail and Michael, James Bret and Shing,
		  Man-Tak},
  year		= {2005},
  month		= may,
  journal	= {SIGSOFT Softw. Eng. Notes},
  volume	= {30},
  number	= {4},
  pages		= {1--6},
  issn		= {0163-5948},
  doi		= {10.1145/1082983.1083284},
  urldate	= {2025-03-03},
  abstract	= {This paper suggests an approach to automatic scenario
		  generation from environment models for testing of real-time
		  reactive systems. The behavior of the system is defined as
		  a set of events (event trace) with two basic relations:
		  precedence and inclusion. The attributed event grammar
		  (AEG) specifies possible event traces and provides a
		  uniform approach for automatically generating, executing,
		  and analyzing test cases. The environment model includes a
		  description of hazardous states in which the system may
		  arrive and makes it possible to gather statistics for
		  system safety assessment. The approach is supported by a
		  generator that creates test cases from the AEG models. We
		  demonstrate the approach with case studies of prototypes
		  for the safety-critical computer-assisted resuscitation
		  algorithm (CARA) software for a casualty intravenous fluid
		  infusion pump and the Paderborn Shuttle System.}
}

@InProceedings{	  aumayr18:efficient,
  title		= {Efficient and Deterministic Record \& Replay for Actor
		  Languages},
  booktitle	= {Proceedings of the 15th {{International Conference}} on
		  {{Managed Languages}} \& {{Runtimes}}},
  author	= {Aumayr, Dominik and Marr, Stefan and B{\'e}ra, Cl{\'e}ment
		  and Boix, Elisa Gonzalez and M{\"o}ssenb{\"o}ck, Hanspeter},
  year		= {2018},
  month		= sep,
  series	= {{{ManLang}} '18},
  pages		= {1--14},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3237009.3237015},
  urldate	= {2025-01-13},
  abstract	= {With the ubiquity of parallel commodity hardware,
		  developers turn to high-level concurrency models such as
		  the actor model to lower the complexity of concurrent
		  software. However, debugging concurrent software is hard,
		  especially for concurrency models with a limited set of
		  supporting tools. Such tools often deal only with the
		  underlying threads and locks, which obscures the view on
		  e.g. actors and messages and thereby introduces additional
		  complexity.To improve on this situation, we present a
		  low-overhead record \&amp; replay approach for actor
		  languages. It allows one to debug concurrency issues
		  deterministically based on a previously recorded trace. Our
		  evaluation shows that the average run-time overhead for
		  tracing on benchmarks from the Savina suite is 10\% (min.
		  0\%, max. 20\%). For Acme-Air, a modern web application, we
		  see a maximum increase of 1\% in latency for HTTP requests
		  and about 1.4 MB/s of trace data. These results are a first
		  step towards deterministic replay debugging of actor
		  systems in production.},
  isbn		= {978-1-4503-6424-9}
}

@Misc{		  automated,
  title		= {Automated {{System Verification}} - {{ScienceDirect}}},
  urldate	= {2024-08-29},
  howpublished	= {https://www.sciencedirect.com/science/article/pii/B978012372512700016X}
}

@Misc{		  automateda,
  title		= {Automated {{System Verification}} - {{ScienceDirect}}},
  urldate	= {2024-08-29},
  howpublished	= {https://www.sciencedirect.com/science/article/pii/B978012372512700016X}
}

@Misc{		  awaitility,
  title		= {Awaitility},
  author	= {Haleby, Johan},
  urldate	= {2024-02-09},
  abstract	= {Testing asynchronous systems is hard. Not only does it
		  require handling threads, timeouts and concurrency issues,
		  but the intent of the test code can be obscured by all
		  these details. Awaitility is a DSL that allows you to
		  express expectations of an asynchronous system in a concise
		  and easy to read manner.},
  howpublished	= {http://www.awaitility.org/}
}

@Article{	  axelsen16:on,
  title		= {On Reversible {{Turing}} Machines and Their Function
		  Universality},
  author	= {Axelsen, Holger Bock and Gl{\"u}ck, Robert},
  year		= {2016},
  month		= aug,
  journal	= {Acta Informatica},
  volume	= {53},
  number	= {5},
  pages		= {509--543},
  issn		= {1432-0525},
  doi		= {10.1007/s00236-015-0253-y},
  urldate	= {2024-11-09},
  abstract	= {We provide a treatment of the reversible Turing machines
		  (RTMs) under a strict function semantics. Unlike many
		  existing reversible computation models, we distinguish
		  strictly between computing the function
		  \$\${\textbackslash}lambda x.f(x)\$\$and computing the
		  function \$\${\textbackslash}lambda x. (x, f(x))\$\$, or
		  other injective embeddings of f. We reinterpret and adapt a
		  number of important foundational reversible computing
		  results under this semantics. Unifying the results in a
		  single model shows that, as expected (and previously
		  claimed), the RTMs are robust and can compute exactly all
		  injective computable functions. Because injectivity entails
		  that the RTMs are not strictly Turing-complete
		  w.r.t.~functions, we use an appropriate alternative
		  universality definition, and show how to derive universal
		  RTMs (URTMs) from existing irreversible universal machines.
		  We then proceed to construct a URTM from the ground up.
		  This resulting machine is the first URTM which does not
		  depend on a reversible simulation of an existing universal
		  machine. The new construction has the advantage that the
		  interpretive overhead of the URTM is limited to a (program
		  dependent) constant factor. Another novelty is that the
		  URTM can function as an inverse interpreter at no asymptotic cost.},
  langid	= {english},
  keywords	= {03D10,68Q05,68Q10}
}

@Article{	  aycock03:brief,
  title		= {A Brief History of Just-in-Time},
  author	= {Aycock, John},
  year		= {2003},
  month		= jun,
  journal	= {ACM Comput. Surv.},
  volume	= {35},
  number	= {2},
  pages		= {97--113},
  issn		= {0360-0300},
  doi		= {10.1145/857076.857077},
  urldate	= {2025-05-03},
  abstract	= {Software systems have been using "just-in-time"
		  compilation (JIT) techniques since the 1960s. Broadly, JIT
		  compilation includes any translation performed dynamically,
		  after a program has started execution. We examine the
		  motivation behind JIT compilation and constraints imposed
		  on JIT compilation systems, and present a classification
		  scheme for such systems. This classification emerges as we
		  survey forty years of JIT work, from 1960--2000.}
}

@InProceedings{	  baccelli18:reprogramming,
  title		= {Reprogramming {{Low-end IoT Devices}} from the {{Cloud}}},
  booktitle	= {2018 3rd {{Cloudification}} of the {{Internet}} of
		  {{Things}} ({{CIoT}})},
  author	= {Baccelli, Emmanuel and Doerr, Joerg and Jallouli, Ons and
		  Kikuchi, Shinji and Morgenstern, Andreas and Padilla,
		  Francisco Acosta and Schleiser, Kaspar and Thomas, Ian},
  year		= {2018},
  month		= jul,
  pages		= {1--6},
  doi		= {10.1109/CIOT.2018.8627129},
  urldate	= {2023-10-03},
  abstract	= {The Internet of Things (IoT) consists in a variety of
		  smart connected objects, among which a category of low-end
		  devices based on micro-controllers. The orchestration of
		  low-end IoT devices is not straightforward because of the
		  lack of generic and holistic solutions articulating
		  cloud-based tools on one hand, and low-end IoT device
		  software on the other hand. In this paper, we describe such
		  a solution, combining a cloud-based IDE, graphical
		  programming, and automatic JavaScript generation. Scripts
		  are pushed over the Internet and over-the-air for the last
		  hop, updating runtime containers hosted on heterogeneous
		  low-end IoT devices running RIOT. We demonstrate a
		  prototype working on common off-the-shelf low-end IoT
		  hardware with as little as 32kB of memory.}
}

@InProceedings{	  backus57:fortran,
  title		= {The {{FORTRAN}} Automatic Coding System},
  booktitle	= {Papers Presented at the {{February}} 26-28, 1957, Western
		  Joint Computer Conference: {{Techniques}} for Reliability},
  author	= {Backus, J. W. and Beeber, R. J. and Best, S. and Goldberg,
		  R. and Haibt, L. M. and Herrick, H. L. and Nelson, R. A.
		  and Sayre, D. and Sheridan, P. B. and Stern, H. and Ziller,
		  I. and Hughes, R. A. and Nutt, R.},
  year		= {1957},
  month		= feb,
  series	= {{{IRE-AIEE-ACM}} '57 ({{Western}})},
  pages		= {188--198},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1455567.1455599},
  urldate	= {2025-05-08},
  abstract	= {The FORTRAN project was begun in the summer of 1954. Its
		  purpose was to reduce by a large factor the task of
		  preparing scientific problems for IBM's next large
		  computer, the 704. If it were possible for the 704 to code
		  problems for itself and produce as good programs as human
		  coders (but without the errors), it was clear that large
		  benefits could be achieved. For it was known that about
		  two-thirds of the cost of solving most scientific and
		  engineering problems on large computers was that of problem
		  preparation. Furthermore, more than 90 per cent of the
		  elapsed time for a problem was usually devoted to planning,
		  writing, and debugging the program. In many cases the
		  development of a general plan for solving a problem was a
		  small job in comparison to the task of devising and coding
		  machine procedures to carry out the plan. The goal of the
		  FORTRAN project was to enable the programmer to specify a
		  numerical procedure using a concise language like that of
		  mathematics and obtain automatically from this
		  specification an efficient 704 program to carry out the
		  procedure. It was expected that such a system would reduce
		  the coding and debugging task to less than one-fifth of the
		  job it had been.},
  isbn		= {978-1-4503-7861-1}
}

@Article{	  bahlke86:psg,
  title		= {The {{PSG}} System: From Formal Language Definitions to
		  Interactive Programming Environments},
  shorttitle	= {The {{PSG}} System},
  author	= {Bahlke, Rolf and Snelting, Gregor},
  year		= {1986},
  month		= aug,
  journal	= {ACM Trans. Program. Lang. Syst.},
  volume	= {8},
  number	= {4},
  pages		= {547--576},
  issn		= {0164-0925},
  doi		= {10.1145/6465.20890},
  urldate	= {2025-04-06},
  abstract	= {The PSG programming system generator developed at the
		  Technical University of Darmstadt produces interactive,
		  language-specific programming environments from formal
		  language definitions. All language-dependent parts of the
		  environment are generated from an entirely nonprocedural
		  specification of the language's syntax, context conditions,
		  and dynamic semantics. The generated environment consists
		  of a language-based editor, supporting systematic program
		  development by named program fragments, an interpreter, and
		  a fragment library system. The major component of the
		  environment is a full-screen editor, which allows both
		  structure and text editing. In structure mode the editor
		  guarantees prevention of both syntactic and semantic
		  errors, whereas in textual mode it guarantees their
		  immediate recognition. PSG editors employ a novel algorithm
		  for incremental semantic analysis which is based on
		  unification. The algorithm will immediately detect semantic
		  errors even in incomplete program fragments. The dynamic
		  semantics of the language are defined in denotational style
		  using a functional language based on the lambda calculus.
		  Program fragments are compiled to terms of the functional
		  language which are executed by an interpreter. The PSG
		  generator has been used to produce environments for Pascal,
		  ALGOL 60, MODULA-2, and the formal language definition
		  language itself.}
}

@Article{	  baldoni18:survey,
  title		= {A {{Survey}} of {{Symbolic Execution Techniques}}},
  author	= {Baldoni, Roberto and Coppa, Emilio and D'elia, Daniele
		  Cono and Demetrescu, Camil and Finocchi, Irene},
  year		= {2018},
  month		= may,
  journal	= {ACM Comput. Surv.},
  volume	= {51},
  number	= {3},
  pages		= {50:1--50:39},
  issn		= {0360-0300},
  doi		= {10.1145/3182657},
  urldate	= {2025-03-11},
  abstract	= {Many security and software testing applications require
		  checking whether certain properties of a program hold for
		  any possible usage scenario. For instance, a tool for
		  identifying software vulnerabilities may need to rule out
		  the existence of any backdoor to bypass a program's
		  authentication. One approach would be to test the program
		  using different, possibly random inputs. As the backdoor
		  may only be hit for very specific program workloads,
		  automated exploration of the space of possible inputs is of
		  the essence. Symbolic execution provides an elegant
		  solution to the problem, by systematically exploring many
		  possible execution paths at the same time without
		  necessarily requiring concrete inputs. Rather than taking
		  on fully specified input values, the technique abstractly
		  represents them as symbols, resorting to constraint solvers
		  to construct actual instances that would cause property
		  violations. Symbolic execution has been incubated in dozens
		  of tools developed over the past four decades, leading to
		  major practical breakthroughs in a number of prominent
		  software reliability applications. The goal of this survey
		  is to provide an overview of the main ideas, challenges,
		  and solutions developed in the area, distilling them for a
		  broad audience.}
}

@InProceedings{	  balzer69:exdams,
  title		= {{{EXDAMS}}: Extendable Debugging and Monitoring System},
  shorttitle	= {{{EXDAMS}}},
  booktitle	= {Proceedings of the {{May}} 14-16, 1969, Spring Joint
		  Computer Conference},
  author	= {Balzer, R. M.},
  year		= {1969},
  month		= may,
  series	= {{{AFIPS}} '69 ({{Spring}})},
  pages		= {567--580},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1476793.1476881},
  urldate	= {2023-12-15},
  abstract	= {With the advent of the higher-level algebraic languages,
		  the computer industry expected to be relieved of the
		  detailed programming required at the assembly-language
		  level. This expectation has largely been realized. Many
		  systems are now being built in higher-level languages (most
		  notably MULTICS).},
  isbn		= {978-1-4503-7902-1}
}

@InProceedings{	  banken18:debugging,
  title		= {Debugging Data Flows in Reactive Programs},
  booktitle	= {Proceedings of the 40th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Banken, Herman and Meijer, Erik and Gousios, Georgios},
  year		= {2018},
  month		= may,
  series	= {{{ICSE}} '18},
  pages		= {752--763},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3180155.3180156},
  urldate	= {2025-03-03},
  abstract	= {Reactive Programming is a style of programming that
		  provides developers with a set of abstractions that
		  facilitate event handling and stream processing.
		  Traditional debug tools lack support for Reactive
		  Programming, leading developers to fallback to the most
		  rudimentary debug tool available: logging to the console.In
		  this paper, we present the design and implementation of
		  RxFiddle, a visualization and debugging tool targeted to
		  Rx, the most popular form of Reactive Programming. RxFiddle
		  visualizes the dependencies and structure of the data flow,
		  as well as the data inside the flow. We evaluate RxFiddle
		  with an experiment involving 111 developers. The results
		  show that RxFiddle can help developers finish debugging
		  tasks faster than with traditional debugging tools.},
  isbn		= {978-1-4503-5638-1}
}

@InProceedings{	  banken18:debugginga,
  title		= {Debugging Data Flows in Reactive Programs},
  booktitle	= {Proceedings of the 40th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Banken, Herman and Meijer, Erik and Gousios, Georgios},
  year		= {2018},
  month		= may,
  series	= {{{ICSE}} '18},
  pages		= {752--763},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3180155.3180156},
  urldate	= {2025-04-18},
  abstract	= {Reactive Programming is a style of programming that
		  provides developers with a set of abstractions that
		  facilitate event handling and stream processing.
		  Traditional debug tools lack support for Reactive
		  Programming, leading developers to fallback to the most
		  rudimentary debug tool available: logging to the console.In
		  this paper, we present the design and implementation of
		  RxFiddle, a visualization and debugging tool targeted to
		  Rx, the most popular form of Reactive Programming. RxFiddle
		  visualizes the dependencies and structure of the data flow,
		  as well as the data inside the flow. We evaluate RxFiddle
		  with an experiment involving 111 developers. The results
		  show that RxFiddle can help developers finish debugging
		  tasks faster than with traditional debugging tools.},
  isbn		= {978-1-4503-5638-1}
}

@Article{	  banks14:mqtt,
  title		= {{{MQTT}} Version 3.1. 1},
  author	= {Banks, Andrew and Gupta, Rahul},
  year		= {2014},
  journal	= {OASIS standard},
  volume	= {29}
}

@Book{		  banzi08:getting,
  title		= {Getting Started with Arduino},
  author	= {Banzi, Massimo},
  year		= {2008},
  edition	= {Ill},
  publisher	= {Make Books - Imprint of: O'Reilly Media},
  address	= {Sebastopol, CA},
  abstract	= {This valuable little book offers a thorough introduction
		  to the open-source electronics prototyping platform that's
		  taking the design and hobbyist world by storm. Getting
		  Started with Arduino gives you lots of ideas for Arduino
		  projects and helps you get going on them right away. From
		  getting organized to putting the final touches on your
		  prototype, all the information you need is right in the
		  book. Inside, you'll learn about:Interaction design and
		  physical computing The Arduino hardware and software
		  development environment Basics of electricity and
		  electronics Prototyping on a solderless breadboard Drawing
		  a schematic diagram And more. With inexpensive hardware and
		  open-source software components that you can download free,
		  getting started with Arduino is a snap. To use the
		  introductory examples in this book, all you need is a USB
		  Arduino, USB A-B cable, and an LED.Join the tens of
		  thousands of hobbyists who have discovered this incredible
		  (and educational) platform. Written by the co-founder of
		  the Arduino project, with illustrations by Elisa Canducci,
		  Getting Started with Arduino gets you in on the fun! This
		  128-page book is a greatly expanded follow-up to the
		  author's original short PDF that's available on the Arduino
		  website.},
  isbn		= {0-596-15551-4}
}

@Article{	  barik19:optimization,
  title		= {Optimization of Swift Protocols},
  author	= {Barik, Rajkishore and Sridharan, Manu and Ramanathan,
		  Murali Krishna and Chabbi, Milind},
  year		= {2019},
  month		= oct,
  journal	= {Optimization of Swift Protocols},
  volume	= {3},
  number	= {OOPSLA},
  pages		= {164:1--164:27},
  doi		= {10.1145/3360590},
  urldate	= {2024-12-17},
  abstract	= {Swift, an increasingly-popular programming language,
		  advocates the use of protocols, which define a set of
		  required methods and properties for conforming types.
		  Protocols are commonly used in Swift programs for
		  abstracting away implementation details; e.g., in a large
		  industrial app from Uber, they are heavily used to enable
		  mock objects for unit testing. Unfortunately, heavy use of
		  protocols can result in significant performance overhead.
		  Beyond the dynamic dispatch often associated with such a
		  feature, Swift allows for both value and reference types to
		  conform to a protocol, leading to significant boxing and
		  unboxing overheads. In this paper, we describe three new
		  optimizations and transformations to reduce the overhead of
		  Swift protocols. Within a procedure, we define LocalVar, a
		  dataflow analysis and transformation to remove both dynamic
		  dispatch and boxing overheads. We also describe Param,
		  which optimizes the case of protocol-typed method
		  parameters using specialization. Finally, we describe
		  SoleType, a transformation that injects casts when a global
		  analysis (like type-hierarchy analysis) discovers some
		  protocol variable must have some concrete type. We also
		  describe how these optimizations work fruitfully together
		  and with existing Swift optimizations to deliver further
		  speedups. We perform elaborate experimentation and
		  demonstrate that our optimizations deliver an average 1.56x
		  speedup on a suite of Swift benchmarks that use protocols.
		  Further, we applied the optimizations to a production iOS
		  Swift application from Uber used by millions of customers
		  daily. For a set of performance spans defined by the
		  developers of the application, the optimized version showed
		  speedups ranging from 6.9\% to 55.49\%. A version of our
		  optimizations has been accepted as part of the official
		  Swift compiler distribution.}
}

@InProceedings{	  barr14:tardis,
  title		= {Tardis: Affordable Time-Travel Debugging in Managed
		  Runtimes},
  shorttitle	= {Tardis},
  booktitle	= {Proceedings of the 2014 {{ACM International Conference}}
		  on {{Object Oriented Programming Systems Languages}} \&
		  {{Applications}}},
  author	= {Barr, Earl T. and Marron, Mark},
  year		= {2014},
  month		= oct,
  series	= {{{OOPSLA}} '14},
  pages		= {67--82},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2660193.2660209},
  urldate	= {2025-01-13},
  abstract	= {Developers who set a breakpoint a few statements too late
		  or who are trying to diagnose a subtle bug from a single
		  core dump often wish for a time-traveling debugger. The
		  ability to rewind time to see the exact sequence of
		  statements and program values leading to an error has great
		  intuitive appeal but, due to large time and space
		  overheads, time traveling debuggers have seen limited
		  adoption. A managed runtime, such as the Java JVM or a
		  JavaScript engine, has already paid much of the cost of
		  providing core features - type safety, memory management,
		  and virtual IO - that can be reused to implement a low
		  overhead time-traveling debugger. We leverage this insight
		  to design and build affordable time-traveling debuggers for
		  managed languages. Tardis realizes our design: it provides
		  affordable time-travel with an average overhead of only 7\%
		  during normal execution, a rate of 0.6MB/s of history
		  logging, and a worst-case 0.68s time-travel latency on our
		  benchmark applications. Tardis can also debug optimized
		  code using time-travel to reconstruct state. This
		  capability, coupled with its low overhead, makes Tardis
		  suitable for use as the default debugger for managed
		  languages, promising to bring time-traveling debugging into
		  the mainstream and transform the practice of debugging.},
  isbn		= {978-1-4503-2585-1}
}

@InProceedings{	  barthe14:system-level,
  title		= {System-Level {{Non-interference}} for {{Constant-time
		  Cryptography}}},
  booktitle	= {Proceedings of the 2014 {{ACM SIGSAC Conference}} on
		  {{Computer}} and {{Communications Security}}},
  author	= {Barthe, Gilles and Betarte, Gustavo and Campo, Juan and
		  Luna, Carlos and Pichardie, David},
  year		= {2014},
  month		= nov,
  series	= {{{CCS}} '14},
  pages		= {1267--1279},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2660267.2660283},
  urldate	= {2023-10-22},
  abstract	= {Cache-based attacks are a class of side-channel attacks
		  that are particularly effective in virtualized or
		  cloud-based environments, where they have been used to
		  recover secret keys from cryptographic implementations. One
		  common approach to thwart cache-based attacks is to use
		  constant-time implementations, i.e., which do not branch on
		  secrets and do not perform memory accesses that depend on
		  secrets. However, there is no rigorous proof that
		  constant-time implementations are protected against
		  concurrent cache-attacks in virtualization platforms with
		  shared cache; moreover, many prominent implementations are
		  not constant-time. An alternative approach is to rely on
		  system-level mechanisms. One recent such mechanism is
		  stealth memory, which provisions a small amount of private
		  cache for programs to carry potentially leaking
		  computations securely. Stealth memory induces a weak form
		  of constant-time, called S-constant-time, which encompasses
		  some widely used cryptographic implementations. However,
		  there is no rigorous analysis of stealth memory and
		  S-constant-time, and no tool support for checking if
		  applications are S-constant-time. We propose a new
		  information-flow analysis that checks if an x86 application
		  executes in constant-time, or in S-constant-time. Moreover,
		  we prove that constant-time (resp. S-constant-time)
		  programs do not leak confidential information through the
		  cache to other operating systems executing concurrently on
		  virtualization platforms (resp. platforms supporting
		  stealth memory). The soundness proofs are based on new
		  theorems of independent interest, including isolation
		  theorems for virtualization platforms (resp. platforms
		  supporting stealth memory), and proofs that constant-time
		  implementations (resp. S-constant-time implementations) are
		  non-interfering with respect to a strict information flow
		  policy which disallows that control flow and memory
		  accesses depend on secrets. We formalize our results using
		  the Coq proof assistant and we demonstrate the
		  effectiveness of our analyses on cryptographic
		  implementations, including PolarSSL AES, DES and RC4,
		  SHA256 and Salsa20.},
  isbn		= {978-1-4503-2957-6},
  keywords	= {cache-based attacks,constant-time
		  cryptography,coq,non-interference,stealth memory}
}

@Book{		  battagline21:art,
  title		= {The Art of {{WebAssembly}}: {{Build}} Secure, Portable,
		  High-Performance Applications},
  author	= {Battagline, R.},
  year		= {2021},
  publisher	= {No Starch Press},
  isbn		= {978-1-71850-144-7},
  lccn		= {2021930212}
}

@Article{	  bauman17:sound,
  title		= {Sound Gradual Typing: Only Mostly Dead},
  shorttitle	= {Sound Gradual Typing},
  author	= {Bauman, Spenser and {Bolz-Tereick}, Carl Friedrich and
		  Siek, Jeremy and {Tobin-Hochstadt}, Sam},
  year		= {2017},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {1},
  number	= {OOPSLA},
  pages		= {54:1--54:24},
  doi		= {10.1145/3133878},
  urldate	= {2024-01-05},
  abstract	= {While gradual typing has proven itself attractive to
		  programmers, many systems have avoided sound gradual typing
		  due to the run time overhead of enforcement. In the context
		  of sound gradual typing, both anecdotal and systematic
		  evidence has suggested that run time costs are quite high,
		  and often unacceptable, casting doubt on the viability of
		  soundness as an approach. We show that these overheads are
		  not fundamental, and that with appropriate improvements,
		  just-in-time compilers can greatly reduce the overhead of
		  sound gradual typing. Our study takes benchmarks published
		  in a recent paper on gradual typing performance in Typed
		  Racket (Takikawa et al., POPL 2016) and evaluates them
		  using a experimental tracing JIT compiler for Racket,
		  called Pycket. On typical benchmarks, Pycket is able to
		  eliminate more than 90\% of the gradual typing overhead.
		  While our current results are not the final word in
		  optimizing gradual typing, we show that the situation is
		  not dire, and where more work is needed. Pycket's
		  performance comes from several sources, which we detail and
		  measure individually. First, we apply a sophisticated
		  tracing JIT compiler and optimizer, automatically generated
		  in Pycket using the RPython framework originally created
		  for PyPy. Second, we focus our optimization efforts on the
		  challenges posed by run time checks, implemented in Racket
		  by chaperones and impersonators. We introduce
		  representation improvements, including a novel use of
		  hidden classes to optimize these data structures.},
  keywords	= {Gradual Typing,Just-in-Time compilation,Performance
		  Evaluation}
}

@Article{	  bauwens20:over-the-air-software-updates,
  title		= {Over-the-{{Air Software Updates}} in the {{Internet}} of
		  {{Things}}: {{An Overview}} of {{Key Principles}}},
  shorttitle	= {Over-the-{{Air Software Updates}} in the {{Internet}} of
		  {{Things}}},
  author	= {Bauwens, Jan and Ruckebusch, Peter and Giannoulis, Spilios
		  and Moerman, Ingrid and Poorter, Eli De},
  year		= {2020},
  month		= feb,
  journal	= {IEEE Communications Magazine},
  volume	= {58},
  number	= {2},
  pages		= {35--41},
  issn		= {1558-1896},
  doi		= {10.1109/MCOM.001.1900125},
  urldate	= {2023-10-25},
  abstract	= {Due to the fast pace at which IoT is evolving, there is an
		  increasing need to support over-theair software updates for
		  security updates, bug fixes, and software extensions. To
		  this end, multiple over-the-air techniques have been
		  proposed, each covering a specific aspect of the update
		  process, such as (partial) code updates, data
		  dissemination, and security. However, each technique
		  introduces overhead, especially in terms of energy
		  consumption, thereby impacting the operational lifetime of
		  the battery constrained devices. Until now, a comprehensive
		  overview describing the different update steps and
		  quantifying the impact of each step is missing in the
		  scientific literature, making it hard to assess the overall
		  feasibility of an over-the-air update. To remedy this, our
		  article analyzes which parts of an IoT operating system are
		  most updated after device deployment, proposes a
		  step-by-step approach to integrate software updates in IoT
		  solutions, and quantifies the energy cost of each of the
		  involved steps. The results show that besides the obvious
		  dissemination cost, other phases such as security also
		  introduce a significant overhead. For instance, a typical
		  firmware update requires 135.026 mJ, of which the main
		  portions are data dissemination (63.11 percent) and
		  encryption (5.29 percent). However, when modular updates
		  are used instead, the energy cost (e.g., for a MAC update)
		  is reduced to 26.743 mJ (48.69 percent for data
		  dissemination and 26.47 percent for encryption).}
}

@Misc{		  bechtold23:junit,
  title		= {{{JUnit}} 5 User Guide},
  author	= {Bechtold, Stefan and Brannen, Sam and Link, Johannes and
		  Merdes, Matthias and Philipp, Marc and {de Rancourt},
		  Juliette and Stein, Christian},
  year		= {2023},
  urldate	= {2023-01-10},
  lastaccessed	= {January 10, 2023}
}

@InProceedings{	  behnke19:hector,
  title		= {H{\'e}ctor: {{A Framework}} for {{Testing IoT Applications
		  Across Heterogeneous Edge}} and {{Cloud Testbeds}}},
  shorttitle	= {H{\'e}ctor},
  booktitle	= {Proceedings of the 12th {{IEEE}}/{{ACM International
		  Conference}} on {{Utility}} and {{Cloud Computing
		  Companion}}},
  author	= {Behnke, Ilja and Thamsen, Lauritz and Kao, Odej},
  year		= {2019},
  month		= dec,
  series	= {{{UCC}} '19 {{Companion}}},
  pages		= {15--20},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3368235.3368832},
  urldate	= {2025-05-04},
  abstract	= {As a result of the many technical advances in
		  microcomputers and mobile connectivity, the Internet of
		  Things (IoT) has been on the rise in the recent decade. Due
		  to the broad spectrum of applications, networks
		  facilitating IoT scenarios can be of very different scale
		  and complexity. Additionally, connected devices are
		  uncommonly heterogeneous, including micro controllers,
		  smartphones, fog nodes and server infrastructures.
		  Therefore, testing IoT applications is difficult,
		  motivating adequate tool support.In this paper, we present
		  H{\'e}ctor, a framework for the automatic testing of IoT
		  applications. H{\'e}ctor allows the automated execution of
		  user-defined experiments on agnostic IoT testbeds. To test
		  applications independently of the availability of required
		  devices, the framework is able to generate virtual testbeds
		  with adjustable network properties. Our evaluations show
		  that simple experiments can be easily automated across a
		  broad spectrum of testbeds. However, the results also
		  indicate that there is considerable interference in
		  experiments, in which many devices are emulated, due to the
		  high resource demand of system emulation.},
  isbn		= {978-1-4503-7044-8}
}

@InProceedings{	  beilharz22:continuously,
  title		= {Continuously {{Testing Distributed IoT Systems}}: {{An
		  Overview}} of~the~{{State}} of~the~{{Art}}},
  shorttitle	= {Continuously {{Testing Distributed IoT Systems}}},
  booktitle	= {Service-{{Oriented Computing}} -- {{ICSOC}} 2021
		  {{Workshops}}},
  author	= {Beilharz, Jossekin and Wiesner, Philipp and Boockmeyer,
		  Arne and Pirl, Lukas and Friedenberger, Dirk and
		  Brokhausen, Florian and Behnke, Ilja and Polze, Andreas and
		  Thamsen, Lauritz},
  editor	= {Hacid, Hakim and Aldwairi, Monther and Bouadjenek, Mohamed
		  Reda and Petrocchi, Marinella and Faci, Noura and Outay,
		  Fatma and Beheshti, Amin and Thamsen, Lauritz and Dong,
		  Hai},
  year		= {2022},
  pages		= {336--350},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-031-14135-5_30},
  abstract	= {The continuous testing of small changes to systems has
		  proven to be useful and is widely adopted in the
		  development of software systems. For this, software is
		  tested in environments that are as close as possible to the
		  production environments. When testing IoT systems, this
		  approach is met with unique challenges that stem from the
		  typically large scale of the deployments, heterogeneity of
		  nodes, challenging network characteristics, and tight
		  integration with the environment among others. IoT test
		  environments present a possible solution to these
		  challenges by emulating the nodes, networks, and possibly
		  domain environments in which IoT applications can be
		  executed. This paper gives an overview of the state of the
		  art in IoT testing. We derive desirable characteristics of
		  IoT test environments, compare 18 tools that can be used in
		  this respect, and give a research outlook of future trends
		  in this area.},
  isbn		= {978-3-031-14135-5},
  langid	= {english}
}

@InProceedings{	  bell18:deflaker,
  title		= {{{DeFlaker}}: {{Automatically Detecting Flaky Tests}}},
  shorttitle	= {{{DeFlaker}}},
  booktitle	= {2018 {{IEEE}}/{{ACM}} 40th {{International Conference}} on
		  {{Software Engineering}} ({{ICSE}})},
  author	= {Bell, Jonathan and Legunsen, Owolabi and Hilton, Michael
		  and Eloussi, Lamyaa and Yung, Tifany and Marinov, Darko},
  year		= {2018},
  month		= may,
  pages		= {433--444},
  issn		= {1558-1225},
  doi		= {10.1145/3180155.3180164},
  urldate	= {2025-05-04},
  abstract	= {Developers often run tests to check that their latest
		  changes to a code repository did not break any previously
		  working functionality. Ideally, any new test failures would
		  indicate regressions caused by the latest changes. However,
		  some test failures may not be due to the latest changes but
		  due to non-determinism in the tests, popularly called flaky
		  tests. The typical way to detect flaky tests is to rerun
		  failing tests repeatedly. Unfortunately, rerunning failing
		  tests can be costly and can slow down the development
		  cycle. We present the first extensive evaluation of
		  rerunning failing tests and propose a new technique, called
		  DeFlaker, that detects if a test failure is due to a flaky
		  test without rerunning and with very low runtime overhead.
		  DeFlaker monitors the coverage of latest code changes and
		  marks as flaky any newly failing test that did not execute
		  any of the changes. We deployed DeFlaker live, in the build
		  process of 96 Java projects on TravisCI, and found 87
		  previously unknown flaky tests in 10 of these projects. We
		  also ran experiments on project histories, where DeFlaker
		  detected 1,874 flaky tests from 4,846 failures, with a low
		  false alarm rate (1.5\%). DeFlaker had a higher recall
		  (95.5\% vs. 23\%) of confirmed flaky tests than Maven's
		  default flaky test detector.},
  keywords	= {code coverage,Detectors,flaky
		  tests,Java,Monitoring,Software,software
		  testing,Syntactics,Testing,Tools}
}

@InProceedings{	  beller18:on,
  title		= {On the Dichotomy of Debugging Behavior among Programmers},
  booktitle	= {Proceedings of the 40th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Beller, Moritz and Spruit, Niels and Spinellis, Diomidis
		  and Zaidman, Andy},
  year		= {2018},
  month		= may,
  series	= {{{ICSE}} '18},
  pages		= {572--583},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3180155.3180175},
  urldate	= {2025-05-07},
  abstract	= {Debugging is an inevitable activity in most software
		  projects, often difficult and more time-consuming than
		  expected, giving it the nickname the "dirty little secret
		  of computer science." Surprisingly, we have little
		  knowledge on how software engineers debug software problems
		  in the real world, whether they use dedicated debugging
		  tools, and how knowledgeable they are about debugging. This
		  study aims to shed light on these aspects by following a
		  mixed-methods research approach. We conduct an online
		  survey capturing how 176 developers reflect on debugging.
		  We augment this subjective survey data with objective
		  observations on how 458 developers use the debugger
		  included in their integrated development environments
		  (IDEs) by instrumenting the popular Eclipse and IntelliJ
		  IDEs with the purpose-built plugin WatchDog 2.0. To clarify
		  the insights and discrepancies observed in the previous
		  steps, we followed up by conducting interviews with
		  debugging experts and regular debugging users. Our results
		  indicate that IDE-provided debuggers are not used as often
		  as expected, as "printf debugging" remains a feasible
		  choice for many programmers. Furthermore, both knowledge
		  and use of advanced debugging features are low. These
		  results call to strengthen hands-on debugging experience in
		  computer science curricula and have already refined the
		  implementation of modern IDE debuggers.},
  isbn		= {978-1-4503-5638-1}
}

@Article{	  bennett13:characterising,
  title		= {Characterising Performance of Environmental Models},
  author	= {Bennett, Neil D. and Croke, Barry F. W. and Guariso,
		  Giorgio and Guillaume, Joseph H. A. and Hamilton, Serena H.
		  and Jakeman, Anthony J. and {Marsili-Libelli}, Stefano and
		  Newham, Lachlan T. H. and Norton, John P. and Perrin,
		  Charles and Pierce, Suzanne A. and Robson, Barbara and
		  Seppelt, Ralf and Voinov, Alexey A. and Fath, Brian D. and
		  Andreassian, Vazken},
  year		= {2013},
  month		= feb,
  journal	= {Environmental Modelling \& Software},
  volume	= {40},
  pages		= {1--20},
  issn		= {1364-8152},
  doi		= {10.1016/j.envsoft.2012.09.011},
  urldate	= {2025-03-03},
  abstract	= {In order to use environmental models effectively for
		  management and decision-making, it is vital to establish an
		  appropriate level of confidence in their performance. This
		  paper reviews techniques available across various fields
		  for characterising the performance of environmental models
		  with focus on numerical, graphical and qualitative methods.
		  General classes of direct value comparison, coupling real
		  and modelled values, preserving data patterns, indirect
		  metrics based on parameter values, and data transformations
		  are discussed. In practice environmental modelling requires
		  the use and implementation of workflows that combine
		  several methods, tailored to the model purpose and
		  dependent upon the data and information available. A
		  five-step procedure for performance evaluation of models is
		  suggested, with the key elements including: (i)
		  (re)assessment of the model's aim, scale and scope; (ii)
		  characterisation of the data for calibration and testing;
		  (iii) visual and other analysis to detect under- or
		  non-modelled behaviour and to gain an overview of overall
		  performance; (iv) selection of basic performance criteria;
		  and (v) consideration of more advanced methods to handle
		  problems such as systematic divergence between modelled and
		  observed values.},
  keywords	= {Model development,Model evaluation,Model
		  testing,Performance indicators,Sensitivity analysis}
}

@Article{	  bennett88:notes,
  title		= {Notes on the History of Reversible Computation},
  author	= {Bennett, Charles H.},
  year		= {1988},
  month		= jan,
  journal	= {IBM Journal of Research and Development},
  volume	= {32},
  number	= {1},
  pages		= {16--23},
  issn		= {0018-8646},
  doi		= {10.1147/rd.321.0016},
  urldate	= {2024-11-09},
  abstract	= {We review the history of the thermodynamics of information
		  processing, beginning with the paradox of Maxwell's demon;
		  continuing through the efforts of Szilard, Brillouin, and
		  others to demonstrate a thermodynamic cost of information
		  acquisition; the discovery by Landauer of the thermodynamic
		  cost of information destruction; the development of the
		  theory of and classical models for reversible computation;
		  and ending with a brief survey of recent work on quantum
		  reversible computation.}
}

@InProceedings{	  benton02:monads,
  title		= {Monads and {{Effects}}},
  booktitle	= {Applied {{Semantics}}},
  author	= {Benton, Nick and Hughes, John and Moggi, Eugenio},
  editor	= {Barthe, Gilles and Dybjer, Peter and Pinto, Lu{\'i}s and
		  Saraiva, Jo{\~a}o},
  year		= {2002},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {42--122},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-45699-6_2},
  abstract	= {A tension in language design has been between simple
		  semantics on the one hand, and rich possibilities for
		  side-effects, exception handling and so on on the other.
		  The introduction of monads has made a large step towards
		  reconciling these alternatives. First proposed by Moggi as
		  a way of structuring semantic descriptions, they were
		  adopted by Wadler to structure Haskell programs. Monads
		  have been used to solve long-standing problems such as
		  adding pointers and assignment, inter-language working, and
		  exception handling to Haskell, without compromising its
		  purely functional semantics. The course introduces monads,
		  effects, and exemplifies their applications in programming
		  (Haskell) and in compilation (MLj). The course presents
		  typed metalanguages for monads and related categorical
		  notions, and then describes how they can be further refined
		  by introducing effects.},
  isbn		= {978-3-540-45699-5},
  langid	= {english},
  keywords	= {Denotational Semantic,Functional Semantic,Intermediate
		  Language,Operational Semantic,Source Language}
}

@InProceedings{	  bernardo23:causal,
  title		= {Causal {{Reversibility Implies Time Reversibility}}},
  booktitle	= {Quantitative {{Evaluation}} of {{Systems}}},
  author	= {Bernardo, Marco and Lanese, Ivan and Marin, Andrea and
		  Mezzina, Claudio A. and Rossi, Sabina and Sacerdoti Coen,
		  Claudio},
  editor	= {Jansen, Nils and Tribastone, Mirco},
  year		= {2023},
  pages		= {270--287},
  publisher	= {Springer Nature Switzerland},
  address	= {Cham},
  doi		= {10.1007/978-3-031-43835-6_19},
  abstract	= {Several notions of reversibility exist in the literature.
		  On the one hand, causal reversibility establishes that an
		  action can be undone provided that all of its consequences
		  have been undone already, thereby making it possible to
		  bring a system back to a past consistent state. On the
		  other hand, time reversibility stipulates that the
		  stochastic behavior of a system remains the same when the
		  direction of time is reversed, which supports efficient
		  performance evaluation. In this paper we show that causal
		  reversibility is a sufficient condition for time
		  reversibility. The study is conducted on extended labeled
		  transition systems. Firstly, they include a forward and a
		  backward transition relations obeying the loop property.
		  Secondly, their transitions feature an independence
		  relation as well as rates for their exponentially
		  distributed random durations. Our result can thus be
		  smoothly applied to concurrent and distributed models,
		  calculi, and languages that account for performance
		  aspects.},
  isbn		= {978-3-031-43835-6},
  langid	= {english}
}

@InProceedings{	  bernstein95:formally,
  title		= {Formally {{Defining Debuggers}}: {{A Comparison}} of
		  {{Three Approaches}}},
  shorttitle	= {Formally {{Defining Debuggers}}},
  booktitle	= {Automated and {{Algorithmic Debugging}}},
  author	= {Bernstein, Karen L. and Stark, E. W.},
  year		= {1995},
  urldate	= {2025-03-05},
  abstract	= {Although there is a large body of literature on formal
		  deenitions of programming languages, relatively little work
		  has been done in applying formal techniques to deening
		  debuggers. Natural operational semantics, denotational
		  semantics and transitional operational semantics are all
		  proven techniques for formally deening programming
		  languages. In this paper we present techniques for formally
		  deening debuggers based on each of these three styles of
		  deenitions. We will investigate each style of deenition by
		  demonstrating how a simple debugger might be deened in each
		  framework.}
}

@Article{	  bernstein95:operational,
  title		= {Operational {{Semantics}} of a {{Focusing Debugger}}},
  author	= {Bernstein, Karen L. and Stark, Eugene W.},
  year		= {1995},
  month		= jan,
  journal	= {Electronic Notes in Theoretical Computer Science},
  series	= {{{MFPS XI}}, {{Mathematical Foundations}} of {{Programming
		  Semantics}}, {{Eleventh Annual Conference}}},
  volume	= {1},
  pages		= {13--31},
  issn		= {1571-0661},
  doi		= {10.1016/S1571-0661(04)80002-1},
  urldate	= {2025-03-05},
  abstract	= {This paper explores two main ideas: (1) a debugger for a
		  programming language ought to have a formal semantic
		  definition that is closely allied to the formal definition
		  of the language itself; and (2) a debugger for very high
		  level programming language ought to provide support for
		  exposing hidden information in a controlled fashion. We
		  investigate these ideas by giving formal semantic
		  definitions for a simple functional programming language
		  and an associated debugger for the language. The formal
		  definitions are accomplished using structured operational
		  semantics, and they demonstrate one way in which the formal
		  definition of a debugger might be built ``on top of'' the
		  formal definition of the underlying language. The debugger
		  itself provides the novel capability of allowing the
		  programmer to ``focus'' or shift the scope of attention in
		  a syntax-directed fashion to a specific subexpression
		  within the program, and to view the execution of the
		  program from that vantage. The main formal result about the
		  debugger is that ``focusing preserves meaning,'' in the
		  sense that a program being debugged exhibits equivalent
		  (bisimilar) operational behavior regardless of the
		  subexpression to which the focus has been shifted.}
}

@Article{	  besnard21:unified,
  title		= {Unified Verification and Monitoring of Executable {{UML}}
		  Specifications},
  author	= {Besnard, Valentin and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Dhaussy, Philippe},
  year		= {2021},
  month		= dec,
  journal	= {Software and Systems Modeling},
  volume	= {20},
  number	= {6},
  pages		= {1825--1855},
  issn		= {1619-1374},
  doi		= {10.1007/s10270-021-00923-9},
  urldate	= {2023-09-26},
  abstract	= {The increasing complexity of embedded systems renders
		  software verification more complex, requiring monitoring
		  and formal techniques, like model-checking. However, to use
		  such techniques, system engineers usually need formal
		  expertise to express the software requirements in a formal
		  language. To facilitate the use of model-checking tools by
		  system engineers, our approach uses a UML model interpreter
		  through which the software requirements can directly be
		  expressed in UML as well. Formal requirements are encoded
		  as UML state machines with the transition guards written in
		  a specific observation language, which expresses predicates
		  on the execution of the system model. Each such executable
		  UML specification can model either a B{\"u}chi automaton or
		  an observer automaton, and is synchronously composed with
		  the system, to follow its execution during model-checking.
		  Formal verification can continue at runtime for all
		  deterministic observer automata used during offline
		  verification by deploying them on real embedded systems.
		  Our approach has been evaluated on multiple case studies
		  and is illustrated, in this paper, through the user
		  interface model of a cruise-control system. The
		  automata-based verification results are in line with the
		  verification of the equivalent LTL properties. The runtime
		  overhead during monitoring is proportional to the number of
		  monitors.},
  langid	= {english},
  keywords	= {Embedded software,Embedded systems,Interpreters,Model
		  checking,Model interpretation,Model-checking,Model-driven
		  software engineering,Monitoring,Observation
		  Language,Software verification,Synchronous Composition}
}

@Misc{		  beyer23:bandit,
  title		= {Bandit. {{Human-friendly}} Unit Testing for {{C}}++11},
  author	= {Beyer, Stephan and Karlsson, Joakim},
  year		= {2023},
  urldate	= {2023-02-15},
  lastaccessed	= {February 15, 2023}
}

@InCollection{	  bibliography,
  title		= {Bibliography},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {331--333},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.biblio},
  urldate	= {2024-12-04},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InProceedings{	  bichhawat21:gradual,
  title		= {Gradual {{Security Types}} and {{Gradual Guarantees}}},
  booktitle	= {2021 {{IEEE}} 34th {{Computer Security Foundations
		  Symposium}} ({{CSF}})},
  author	= {Bichhawat, Abhishek and McCall, McKenna and Jia, Limin},
  year		= {2021},
  month		= jun,
  pages		= {1--16},
  issn		= {2374-8303},
  doi		= {10.1109/CSF51468.2021.00015},
  urldate	= {2024-12-18},
  abstract	= {Information flow type systems enforce the security
		  property of noninterference by detecting unauthorized data
		  flows at compile-time. However, they require precise type
		  annotations, making them difficult to use in practice as
		  much of the legacy infrastructure is written in untyped or
		  dynamically-typed languages. Gradual typing seamlessly
		  integrates static and dynamic typing, providing the best of
		  both approaches, and has been applied to information flow
		  control, where information flow monitors are derived from
		  gradual security types. Prior work on gradual information
		  flow typing uncovered tensions between noninterference and
		  the dynamic gradual guarantee--- the property that less
		  precise security type annotations in a program should not
		  cause more runtime errors.This paper re-examines the
		  connection between gradual information flow types and
		  information flow monitors to identify the root cause of the
		  tension between the gradual guarantees and noninterference.
		  We develop runtime semantics for a simple imperative
		  language with gradual information flow types that provides
		  both noninterference and gradual guarantees. We leverage a
		  proof technique developed for FlowML and reduce
		  noninterference proofs to preservation proofs.},
  keywords	= {Annotations,Computer security,gradual guarantees,gradual
		  typing,Information flow
		  control,Monitoring,noninterference,Refining,Runtime,Semantics}
}

@InProceedings{	  binder22:structural,
  title		= {Structural Refinement Types},
  booktitle	= {Proceedings of the 7th {{ACM SIGPLAN International
		  Workshop}} on {{Type-Driven Development}}},
  author	= {Binder, David and Skupin, Ingo and L{\"a}wen, David and
		  Ostermann, Klaus},
  year		= {2022},
  month		= sep,
  series	= {{{TyDe}} 2022},
  pages		= {15--27},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3546196.3550163},
  urldate	= {2023-09-26},
  abstract	= {Static types are a great form of lightweight static
		  analysis. But sometimes a type like List is too coarse --
		  we would also like to work with its refinements like
		  non-empty lists, or lists containing exactly 42 elements.
		  Dependent types allow for this, but they impose a heavy
		  proof burden on the programmer. We want the checking and
		  inference of refinements to be fully automatic. In this
		  article we present a simple refinement type system and
		  inference algorithm which uses only variants of familiar
		  concepts from constraint-based type inference. Concretely,
		  we build on the algebraic subtyping approach and extend it
		  with typing rules which combine properties of nominal and
		  structural type systems in a novel way. Despite the
		  simplicity of our approach, the resulting type system is
		  very expressive and allows to specify and infer non-trivial
		  properties of programs.},
  isbn		= {978-1-4503-9439-0},
  keywords	= {Algebraic Subtyping,Nominal Types,Refinement
		  Types,Structural Types}
}

@InCollection{	  binkley04:survey,
  title		= {A {{Survey}} of {{Empirical Results}} on {{Program
		  Slicing}}},
  booktitle	= {Advances in {{Computers}}},
  author	= {Binkley, David and Harman, Mark},
  year		= {2004},
  month		= jan,
  volume	= {62},
  pages		= {105--178},
  publisher	= {Elsevier},
  doi		= {10.1016/S0065-2458(03)62003-6},
  urldate	= {2023-11-30},
  abstract	= {A program slice extracts a semantically meaningful portion
		  of a program, based upon a user-selected slicing criterion.
		  As the study of program slicing has matured, a growing body
		  of empirical data has been gathered on the size of slices,
		  slicing tools and techniques, the applications of slicing,
		  and the beneficial psychological effects of slices on the
		  programmers who use them. Empirical work on these topics is
		  surveyed, highlighting trends and areas where additional
		  empirical investigation is desirable, either because of
		  contradictory findings or scarcity of results in the
		  existing body of empirical knowledge.}
}

@InProceedings{	  binkley14:orbs,
  title		= {{{ORBS}}: Language-Independent Program Slicing},
  shorttitle	= {{{ORBS}}},
  booktitle	= {Proceedings of the 22nd {{ACM SIGSOFT International
		  Symposium}} on {{Foundations}} of {{Software
		  Engineering}}},
  author	= {Binkley, David and Gold, Nicolas and Harman, Mark and
		  Islam, Syed and Krinke, Jens and Yoo, Shin},
  year		= {2014},
  month		= nov,
  series	= {{{FSE}} 2014},
  pages		= {109--120},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2635868.2635893},
  urldate	= {2023-11-29},
  abstract	= {Current slicing techniques cannot handle systems written
		  in multiple programming languages. Observation-Based
		  Slicing (ORBS) is a language-independent slicing technique
		  capable of slicing multi-language systems, including
		  systems which contain (third party) binary components. A
		  potential slice obtained through repeated statement
		  deletion is validated by observing the behaviour of the
		  program: if the slice and original program behave the same
		  under the slicing criterion, the deletion is accepted. The
		  resulting slice is similar to a dynamic slice. We evaluate
		  five variants of ORBS on ten programs of different sizes
		  and languages showing that it is less expensive than
		  similar existing techniques. We also evaluate it on bash
		  and four other systems to demonstrate feasible large-scale
		  operation in which a parallelised ORBS needs up to 82\%
		  less time when using four threads. The results show that an
		  ORBS slicer is simple to construct, effective at slicing,
		  and able to handle systems written in multiple languages
		  without specialist analysis tools.},
  isbn		= {978-1-4503-3056-5}
}

@Article{	  binkley19:comparison,
  title		= {A Comparison of Tree- and Line-Oriented Observational
		  Slicing},
  author	= {Binkley, David and Gold, Nicolas and Islam, Syed and
		  Krinke, Jens and Yoo, Shin},
  year		= {2019},
  month		= oct,
  journal	= {Empirical Software Engineering},
  volume	= {24},
  number	= {5},
  pages		= {3077--3113},
  issn		= {1573-7616},
  doi		= {10.1007/s10664-018-9675-9},
  urldate	= {2024-03-18},
  abstract	= {Observation-based slicing and its generalization
		  observational slicing are recently-introduced,
		  language-independent dynamic slicing techniques. They both
		  construct slices based on the dependencies observed during
		  program execution, rather than static or dynamic dependence
		  analysis. The original implementation of the
		  observation-based slicing algorithm used lines of source
		  code as its program representation. A recent variation,
		  developed to slice modelling languages (such as Simulink),
		  used an XML representation of an executable model. We
		  ported the XML slicer to source code by constructing a tree
		  representation of traditional source code through the use
		  of srcML. This work compares the tree- and line-based
		  slicers using four experiments involving twenty different
		  programs, ranging from classic benchmarks to million-line
		  production systems. The resulting slices are essentially
		  the same size for the majority of the programs and are
		  often identical. However, structural constraints imposed by
		  the tree representation sometimes force the slicer to
		  retain enclosing control structures. It can also ``bog
		  down'' trying to delete single-token subtrees. This
		  occasionally makes the tree-based slices larger and the
		  tree-based slicer slower than a parallelised version of the
		  line-based slicer. In addition, a Java versus C comparison
		  finds that the two languages lead to similar slices, but
		  Java code takes noticeably longer to slice. The initial
		  experiments suggest two improvements to the tree-based
		  slicer: the addition of a size threshold, for ignoring
		  small subtrees, and subtree replacement. The former enables
		  the slicer to run 3.4 times faster while producing slices
		  that are only about 9\% larger. At the same time the
		  subtree replacement reduces size by about 8--12\% and
		  allows the tree-based slicer to produce more natural
		  slices.},
  langid	= {english},
  keywords	= {Observational slicing,ORBS,Program slicing,XML}
}

@Book{		  black10:pharo,
  title		= {Pharo by Example},
  author	= {Black, Andrew P and Nierstrasz, Oscar and Ducasse,
		  St{\'e}phane and Pollet, Damien},
  year		= {2010},
  publisher	= {Lulu. com}
}

@InProceedings{	  blackburn98:using,
  title		= {Using Models for Test Generation and Analysis},
  booktitle	= {17th {{DASC}}. {{AIAA}}/{{IEEE}}/{{SAE}}. {{Digital
		  Avionics Systems Conference}}. {{Proceedings}} ({{Cat}}.
		  {{No}}.{{98CH36267}})},
  author	= {Blackburn, M.R.},
  year		= {1998},
  month		= oct,
  volume	= {1},
  pages		= {C45/1-C45/8 vol.1},
  doi		= {10.1109/DASC.1998.741501},
  urldate	= {2025-03-04},
  abstract	= {Software testing will play a role in the development of
		  software systems for some time to come. Although testing
		  can account for 40 to 75 percent of the lifetime
		  development and maintenance costs, the results summarized
		  in this paper provide promising evidence that the use of
		  test automation to support the manually intensive test
		  generation and model-based analysis is feasible and
		  practical. There is a great need to demonstrate and
		  integrate new and advanced technologies. This paper
		  describes an environment developed to validate the use of
		  model-based translators on real-world applications. The
		  environment integrates model-based development tools with a
		  specification-based test vector generator and
		  specification-based coverage analyzer.},
  keywords	= {Analytical models,Automatic testing,Costs,Formal
		  specifications,Object oriented modeling,Performance
		  evaluation,Productivity,Software testing,Software
		  tools,System testing}
}

@Article{	  blanvillain22:type-level,
  title		= {Type-Level Programming with Match Types},
  author	= {Blanvillain, Olivier and Brachth{\"a}user, Jonathan
		  Immanuel and Kjaer, Maxime and Odersky, Martin},
  year		= {2022},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {POPL},
  pages		= {37:1--37:24},
  doi		= {10.1145/3498698},
  urldate	= {2023-09-26},
  abstract	= {Type-level programming is becoming more and more popular
		  in the realm of functional programming. However, the
		  combination of type-level programming and subtyping remains
		  largely unexplored in practical programming languages. This
		  paper presents match types, a type-level equivalent of
		  pattern matching. Match types integrate seamlessly into
		  programming languages with subtyping and, despite their
		  simplicity, offer significant additional expressiveness. We
		  formalize the feature of match types in a calculus based on
		  System F sub and prove its soundness. We practically
		  evaluate our system by implementing match types in the
		  Scala 3 reference compiler, thus making type-level
		  programming readily available to a broad audience of
		  programmers.},
  keywords	= {Match types,Scala}
}

@InProceedings{	  bocchi22:reversible-temporal-process-language,
  title		= {The {{Reversible Temporal Process Language}}},
  booktitle	= {Formal {{Techniques}} for {{Distributed Objects}},
		  {{Components}}, and {{Systems}}},
  author	= {Bocchi, Laura and Lanese, Ivan and Mezzina, Claudio
		  Antares and Yuen, Shoji},
  editor	= {Mousavi, Mohammad Reza and Philippou, Anna},
  year		= {2022},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {31--49},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-031-08679-3_3},
  abstract	= {Reversible debuggers help programmers to quickly find the
		  causes of misbehaviours in concurrent programs. These
		  debuggers can be founded on the well-studied theory of
		  causal-consistent reversibility, which allows one to undo
		  any action provided that its consequences are undone
		  beforehand. Till now, causal-consistent reversibility never
		  considered time, a key aspect in real world applications.
		  Here, we study the interplay between reversibility and time
		  in concurrent systems via a process algebra. The Temporal
		  Process Language (TPL) by Hennessy and Regan is a
		  well-understood extension of CCS with discrete-time and a
		  timeout operator. We define \$\${\textbackslash}mathtt
		  \{revTPL\}\$\$revTPL, a reversible extension of TPL, and we
		  show that it satisfies the properties expected from a
		  causal-consistent reversible calculus. We show that,
		  alternatively, \$\${\textbackslash}mathtt
		  \{revTPL\}\$\$revTPLcan be interpreted as an extension of
		  reversible CCS with time.},
  isbn		= {978-3-031-08679-3},
  langid	= {english}
}

@InProceedings{	  bojanova21:classifying,
  title		= {Classifying {{Memory Bugs Using Bugs Framework
		  Approach}}},
  booktitle	= {2021 {{IEEE}} 45th {{Annual Computers}}, {{Software}}, and
		  {{Applications Conference}} ({{COMPSAC}})},
  author	= {Bojanova, Irena and Eduardo Galhardo, Carlos},
  year		= {2021},
  month		= jul,
  pages		= {1157--1164},
  issn		= {0730-3157},
  doi		= {10.1109/COMPSAC51774.2021.00159},
  urldate	= {2025-05-06},
  abstract	= {In this work, we present an orthogonal classification of
		  memory corruption bugs, allowing precise structured
		  descriptions of related software vulnerabilities. The
		  Common Weakness Enumeration (CWE) is a well-known and used
		  list of software weaknesses. However, it's exhaustive list
		  approach is prone to gaps and overlaps in coverage.
		  Instead, we utilize the Bugs Framework (BF) approach to
		  define language-independent classes that cover all possible
		  kinds of memory corruption bugs. Each class is a taxonomic
		  category of a weakness type, defined by sets of operations,
		  cause{$\rightarrow$}consequence relations, and attributes.
		  A BF description of a bug or a weakness is an instance of a
		  taxonomic BF class, with one operation, one cause, one
		  consequence, and their attributes. Any memory vulnerability
		  then can be described as a chain of such instances and
		  their consequence--cause transitions. We showcase that BF
		  is a classification system that extends the CWE, providing
		  a structured way to precisely describe real world
		  vulnerabilities. It allows clear communication about
		  software bugs and weaknesses and can help identify exploit
		  mitigation techniques.},
  keywords	= {Bug classification,bug taxonomy,Computer
		  bugs,Conferences,memory corruption,Resource
		  management,Software,software vulnerability,software
		  weakness,Taxonomy,Tools}
}

@Misc{		  boost-test-team23:what,
  title		= {What Is {{Boost}}.{{Test}}?},
  author	= {{Boost.Test team}},
  year		= {2023},
  urldate	= {2023-02-15},
  lastaccessed	= {February 15, 2023}
}

@Misc{		  boosting,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}} {\textbar} {{Proceedings}} of the {{ACM}} on
		  {{Programming Languages}}},
  urldate	= {2024-08-20},
  howpublished	= {https://dl.acm.org/doi/10.1145/3656386}
}

@InProceedings{	  boothe00:efficient,
  title		= {Efficient Algorithms for Bidirectional Debugging},
  booktitle	= {Proceedings of the {{ACM SIGPLAN}} 2000 Conference on
		  {{Programming}} Language Design and Implementation},
  author	= {Boothe, Bob},
  year		= {2000},
  month		= may,
  series	= {{{PLDI}} '00},
  pages		= {299--310},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/349299.349339},
  urldate	= {2023-12-13},
  abstract	= {This paper discusses our research into algorithms for
		  creating an efficient bidirectional debugger in which all
		  traditional forward movement commands can be performed with
		  equal ease in the reverse direction. We expect that adding
		  these backwards movement capabilities to a debugger will
		  greatly increase its efficacy as a programming tool. The
		  efficiency of our methods arises from our use of event
		  counters that are embedded into the program being debugged.
		  These counters are used to precisely identify the desired
		  target event on the fly as the target program executes.
		  This is in contrast to traditional debuggers that may trap
		  back to the debugger many times for some movements. For
		  reverse movements we re-execute the program (possibly using
		  two passes) to identify and stop at the desired earlier
		  point. Our counter based techniques are essential for these
		  reverse movements because they allow us to efficiently
		  execute through the millions of events encountered during
		  re-execution. Two other important components of this
		  debugger are its I/O logging and checkpointing. We log and
		  later replay the results of system calls to ensure
		  deterministic re-execution, and we use checkpointing to
		  bound the amount of re-execution used for reverse
		  movements. Short movements generally appear instantaneous,
		  and the time for longer movements is usually bounded within
		  a small constant factor of the temporal distance moved
		  back.},
  isbn		= {978-1-58113-199-4}
}

@Article{	  boruch-gruszecki23:capturing,
  title		= {Capturing {{Types}}},
  author	= {{Boruch-Gruszecki}, Aleksander and Odersky, Martin and
		  Lee, Edward and Lhot{\'a}k, Ond{\v r}ej and
		  Brachth{\"a}user, Jonathan},
  year		= {2023},
  month		= nov,
  journal	= {ACM Trans. Program. Lang. Syst.},
  volume	= {45},
  number	= {4},
  pages		= {21:1--21:52},
  issn		= {0164-0925},
  doi		= {10.1145/3618003},
  urldate	= {2024-12-18},
  abstract	= {Type systems usually characterize the shape of values but
		  not their free variables. However, many desirable safety
		  properties could be guaranteed if one knew the free
		  variables captured by values. We describe CC\&lt; :◻, a
		  calculus where such captured variables are succinctly
		  represented in types, and show it can be used to safely
		  implement effects and effect polymorphism via scoped
		  capabilities. We discuss how the decision to track captured
		  variables guides key aspects of the calculus, and show that
		  CC\&lt; :◻\&nbsp; admits simple and intuitive types for
		  common data structures and their typical usage patterns. We
		  demonstrate how these ideas can be used to guide the
		  implementation of capture checking in a practical
		  programming language.}
}

@InProceedings{	  bosamiya22:provably-safe,
  title		= {\{\vphantom\}{{Provably-Safe}}\vphantom\{\} {{Multilingual
		  Software Sandboxing}} Using \{\vphantom\}{{WebAssembly}}\vphantom\{\}},
  booktitle	= {31st {{USENIX Security Symposium}} ({{USENIX Security}}
		  22)},
  author	= {Bosamiya, Jay and Lim, Wen Shih and Parno, Bryan},
  year		= {2022},
  pages		= {1975--1992},
  urldate	= {2024-01-18},
  isbn		= {978-1-939133-31-1},
  langid	= {english}
}

@InProceedings{	  brus87:clean,
  title		= {Clean --- {{A}} Language for Functional Graph Rewriting},
  booktitle	= {Functional {{Programming Languages}} and {{Computer
		  Architecture}}},
  author	= {Brus, T. H. and {van Eekelen}, M. C. J. D. and {van Leer},
		  M. O. and Plasmeijer, M. J.},
  editor	= {Kahn, Gilles},
  year		= {1987},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {364--384},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-18317-5_20},
  abstract	= {Clean is an experimental language for specifying
		  functional computations in terms of graph rewriting. It is
		  based on an extension of Term Rewriting Systems (TRS) in
		  which the terms are replaced by graphs. Such a Graph
		  Rewriting System (GRS) consists of a, possibly cyclic,
		  directed graph, called the data graph and graph rewrite
		  rules which specify how this data graph may be rewritten.
		  Clean is designed to provide a firm base for functional
		  programming. In particular, Clean is suitable as an
		  intermediate language between functional languages and
		  (parallel) target machine architectures. A sequential
		  implementation of Clean on a conventional machine is
		  described and its performance is compared with other
		  systems. The results show that Clean can be efficiently
		  implemented.},
  isbn		= {978-3-540-47879-9},
  langid	= {english},
  keywords	= {Data Graph,Function Symbol,Functional Language,Functional
		  Strategy,Normal Form}
}

@Article{	  bull72:dynamic,
  title		= {Dynamic {{Debugging}} in {{BASIC}}},
  author	= {Bull, G. M.},
  year		= {1972},
  month		= feb,
  journal	= {The Computer Journal},
  volume	= {15},
  number	= {1},
  pages		= {21--24},
  issn		= {0010-4620},
  doi		= {10.1093/comjnl/15.1.21},
  urldate	= {2025-05-07},
  abstract	= {One of the main advantages that on-line working provides
		  is the ability to interact with a running program.
		  Interaction at run-time is important from two standpoints.
		  Firstly, it enables the programmer to control the action of
		  the program by providing suitable data as the execution
		  progresses. Secondly, and most importantly, given the right
		  facilities, it enables a programmer dynamically to debug
		  the program. One of the most popular languages designed
		  explicitly for on-line working is BASIC. Although one is
		  able to interact in the first sense, most implementations
		  fail to give any run-time debugging facilities to the BASIC
		  user. This paper describes the range of run-time debugging
		  facilities provided on an implementation of BASIC at
		  Hatfield Polytechnic on an ICL 803.}
}

@InProceedings{	  burchell23:dont,
  title		= {Don't {{Trust Your Profiler}}: {{An Empirical Study}} on
		  the {{Precision}} and {{Accuracy}} of {{Java Profilers}}},
  shorttitle	= {Don't {{Trust Your Profiler}}},
  booktitle	= {Proceedings of the 20th {{ACM SIGPLAN International
		  Conference}} on {{Managed Programming Languages}} and
		  {{Runtimes}}},
  author	= {Burchell, Humphrey and Larose, Octave and Kaleba, Sophie
		  and Marr, Stefan},
  year		= {2023},
  month		= oct,
  series	= {{{MPLR}} 2023},
  pages		= {100--113},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3617651.3622985},
  urldate	= {2023-10-27},
  abstract	= {To identify optimisation opportunities, Java developers
		  often use sampling profilers that attribute a percentage of
		  run time to the methods of a program. Even so these
		  profilers use sampling, are probabilistic in nature, and
		  may suffer for instance from safepoint bias, they are
		  normally considered to be relatively reliable. However,
		  unreliable or inaccurate profiles may misdirect developers
		  in their quest to resolve performance issues by not
		  correctly identifying the program parts that would benefit
		  most from optimisations. With the wider adoption of
		  profilers such as async-profiler and Honest Profiler, which
		  are designed to avoid the safepoint bias, we wanted to
		  investigate how precise and accurate Java sampling
		  profilers are today. We investigate the precision,
		  reliability, accuracy, and overhead of async-profiler,
		  Honest Profiler, Java Flight Recorder, JProfiler, perf, and
		  YourKit, which are all actively maintained. We assess them
		  on the fully deterministic Are We Fast Yet benchmarks to
		  have a stable foundation for the probabilistic profilers.
		  We find that profilers are relatively reliable over 30 runs
		  and normally report the same hottest method. Unfortunately,
		  this is not true for all benchmarks, which suggests their
		  reliability may be application-specific. Different
		  profilers also report different methods as hottest and
		  cannot reliably agree on the set of top 5 hottest methods.
		  On the positive side, the average run time overhead is in
		  the range of 1\% to 5.4\% for the different profilers.
		  Future work should investigate how results can become more
		  reliable, perhaps by reducing the observer effect of
		  profilers by using optimisation decisions of unprofiled
		  runs or by developing a principled approach of combining
		  multiple profiles that explore different dynamic
		  optimisations.},
  isbn		= {9798400703805},
  keywords	= {Analysis tools,CPU sampling,Profiler comparison,Profiler
		  precision,Profiling}
}

@InProceedings{	  bures20:interoperability,
  title		= {Interoperability and Integration Testing Methods for
		  {{IoT}} Systems: A Systematic Mapping Study},
  booktitle	= {Software Engineering and Formal Methods},
  author	= {Bures, Miroslav and Klima, Matej and Rechtberger, Vaclav
		  and Bellekens, Xavier and Tachtatzis, Christos and
		  Atkinson, Robert and Ahmed, Bestoun S.},
  editor	= {{de Boer}, Frank and Cerone, Antonio},
  year		= {2020},
  pages		= {93--112},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  abstract	= {The recent active development of Internet of Things (IoT)
		  solutions in various domains has led to an increased demand
		  for security, safety, and reliability of these systems.
		  Security and data privacy are currently the most frequently
		  discussed topics; however, other reliability aspects also
		  need to be focused on to maintain smooth and safe operation
		  of IoT systems. Until now, there has been no systematic
		  mapping study dedicated to the topic of interoperability
		  and integration testing of IoT systems specifically;
		  therefore, we present such an overview in this study. We
		  analyze 803 papers from four major primary databases and
		  perform detailed assessment and quality check to find 115
		  relevant papers. In addition, recently published testing
		  techniques and approaches are analyzed and classified; the
		  challenges and limitations in the field are also identified
		  and discussed. Research trends related to publication time,
		  active researchers, and publication media are presented in
		  this study. The results suggest that studies mainly focus
		  only on general testing methods, which can be applied to
		  integration and interoperability testing of IoT systems;
		  thus, there are research opportunities to develop
		  additional testing methods focused specifically on IoT
		  systems, so that they are more effective in the IoT
		  context.},
  isbn		= {978-3-030-58768-0}
}

@InProceedings{	  burg13:interactive,
  title		= {Interactive Record/Replay for Web Application Debugging},
  booktitle	= {Proceedings of the 26th Annual {{ACM}} Symposium on
		  {{User}} Interface Software and Technology},
  author	= {Burg, Brian and Bailey, Richard and Ko, Amy J. and Ernst,
		  Michael D.},
  year		= {2013},
  month		= oct,
  series	= {{{UIST}} '13},
  pages		= {473--484},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2501988.2502050},
  urldate	= {2024-02-28},
  abstract	= {During debugging, a developer must repeatedly and manually
		  reproduce faulty behavior in order to inspect different
		  facets of the program's execution. Existing tools for
		  reproducing such behaviors prevent the use of debugging
		  aids such as breakpoints and logging, and are not designed
		  for interactive, random-access exploration of recorded
		  behavior. This paper presents Timelapse, a tool for quickly
		  recording, reproducing, and debugging interactive behaviors
		  in web applications. Developers can use Timelapse to
		  browse, visualize, and seek within recorded program
		  executions while simultaneously using familiar debugging
		  tools such as breakpoints and logging. Testers and
		  end-users can use Timelapse to demonstrate failures in situ
		  and share recorded behaviors with developers, improving bug
		  report quality by obviating the need for detailed
		  reproduction steps. Timelapse is built on Dolos, a novel
		  record/replay infrastructure that ensures deterministic
		  execution by capturing and reusing program inputs both from
		  the user and from external sources such as the network.
		  Dolos introduces negligible overhead and does not interfere
		  with breakpoints and logging. In a small user evaluation,
		  participants used Timelapse to accelerate existing
		  reproduction activities, but were not significantly faster
		  or more successful in completing the larger tasks at hand.
		  Together, the Dolos infrastructure and Timelapse developer
		  tool support systematic bug reporting and debugging
		  practices.},
  isbn		= {978-1-4503-2268-3},
  keywords	= {debugging,deterministic replay,web applications}
}

@Article{	  burin12:senslab,
  title		= {{{SensLAB}}: {{Very}} Large Scale Open Wireless Sensor
		  Network Testbed},
  shorttitle	= {{{SensLAB}}},
  author	= {Burin Des Rosiers, C. and Chelius, G. and Fleury, E. and
		  Fraboulet, A. and Gallais, A. and Mitton, N. and No{\"e}l,
		  T.},
  year		= {2012},
  journal	= {Lecture Notes of the Institute for Computer Sciences,
		  Social-Informatics and Telecommunications Engineering},
  volume	= {90 LNICST},
  pages		= {239--254},
  doi		= {10.1007/978-3-642-29273-6_19},
  abstract	= {This paper presents a precise description of SensLAB: Very
		  Large Scale Open Wireless Sensor Network Testbed that has
		  been developed and deployed in order to allow the
		  evaluation of scalable wireless sensor network protocols
		  and applications. SensLAB's main and most important goal is
		  to offer an accurate open access multi-users scientific
		  tool to support the design, development, tuning, and
		  experimentation of real large-scale sensor network
		  applications. The SensLAB testbed is composed of 1024 nodes
		  and it is distributed among 4 sites. Each location hosts
		  256 sensor nodes with specific characteristics in order to
		  offer a wide spectrum of possibilities and heterogeneity.
		  Two sites offer access to mobile nodes. Within a given
		  site, each one of the 256 nodes is able to communicate via
		  its radio interface to its neighbors. Furthermore, every
		  sensor node is also able to be configured as a sink node
		  and can exchange data with any other sink node of the whole
		  SensLAB testbed or any computer on the Internet. The
		  hardware designed on purpose and software architectures
		  that allow to reserve, configure, deploy embedded software,
		  boot wireless sensor nodes and gather experimental data and
		  monitoring information are described in detail. We also
		  present short demonstration examples to illustrate the use
		  of the SensLAB testbed: http://www.senslab.info.
		  {\copyright} 2012 ICST Institute for Computer Science,
		  Social Informatics and Telecommunications Engineering.},
  keywords	= {Monitoring,Network,Radio,Testbed,Wireless Sensor Network}
}

@Article{	  burow17:control-flow-integrity,
  title		= {Control-{{Flow Integrity}}: {{Precision}}, {{Security}},
		  and {{Performance}}},
  shorttitle	= {Control-{{Flow Integrity}}},
  author	= {Burow, Nathan and Carr, Scott A. and Nash, Joseph and
		  Larsen, Per and Franz, Michael and Brunthaler, Stefan and
		  Payer, Mathias},
  year		= {2017},
  month		= apr,
  journal	= {ACM Comput. Surv.},
  volume	= {50},
  number	= {1},
  pages		= {16:1--16:33},
  issn		= {0360-0300},
  doi		= {10.1145/3054924},
  urldate	= {2025-01-15},
  abstract	= {Memory corruption errors in C/C++ programs remain the most
		  common source of security vulnerabilities in today's
		  systems. Control-flow hijacking attacks exploit memory
		  corruption vulnerabilities to divert program execution away
		  from the intended control flow. Researchers have spent more
		  than a decade studying and refining defenses based on
		  Control-Flow Integrity (CFI); this technique is now
		  integrated into several production compilers. However, so
		  far, no study has systematically compared the various
		  proposed CFI mechanisms nor is there any protocol on how to
		  compare such mechanisms. We compare a broad range of CFI
		  mechanisms using a unified nomenclature based on (i) a
		  qualitative discussion of the conceptual security
		  guarantees, (ii) a quantitative security evaluation, and
		  (iii) an empirical evaluation of their performance in the
		  same test environment. For each mechanism, we evaluate (i)
		  protected types of control-flow transfers and (ii)
		  precision of the protection for forward and backward edges.
		  For open-source, compiler-based implementations, we also
		  evaluate (iii) generated equivalence classes and target
		  sets and (iv) runtime performance.}
}

@InProceedings{	  buskey06:protected,
  title		= {Protected {{JTAG}}},
  booktitle	= {2006 {{International Conference}} on {{Parallel Processing
		  Workshops}} ({{ICPPW}}'06)},
  author	= {Buskey, R.F. and Frosik, B.B.},
  year		= {2006},
  month		= aug,
  pages		= {8 pp.-414},
  issn		= {2332-5690},
  doi		= {10.1109/ICPPW.2006.65},
  urldate	= {2024-11-15},
  abstract	= {In this paper, we consider a particular aspect of an
		  effort to define trusted computing solutions. One of the
		  hardware features of an embedded device is the JTAG (joint
		  test action group) port that allows easy access to a
		  processor for debugging purposes. This access is a
		  potential security threat in a high assurance environment.
		  This paper presents a solution of a protected JTAG. The
		  purpose of providing protected JTAG, as part of the trusted
		  computing platform, is to prevent access to private and
		  confidential information by unauthorized users and yet
		  allow debugging functions. The presented solution
		  introduces different levels of access. The level of user's
		  access is based on the user's permissions.},
  keywords	= {Access protocols,Circuits,Debugging,Hardware,Information
		  security,Internet,Mathematical
		  model,Protection,Registers,Testing}
}

@InProceedings{	  cadar11:symbolic,
  title		= {Symbolic Execution for Software Testing in Practice:
		  Preliminary Assessment},
  shorttitle	= {Symbolic Execution for Software Testing in Practice},
  booktitle	= {Proceedings of the 33rd {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Cadar, Cristian and Godefroid, Patrice and Khurshid,
		  Sarfraz and P{\u a}s{\u a}reanu, Corina S. and Sen, Koushik
		  and Tillmann, Nikolai and Visser, Willem},
  year		= {2011},
  month		= may,
  series	= {{{ICSE}} '11},
  pages		= {1066--1071},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1985793.1985995},
  urldate	= {2025-03-11},
  abstract	= {We present results for the "Impact Project Focus Area" on
		  the topic of symbolic execution as used in software
		  testing. Symbolic execution is a program analysis technique
		  introduced in the 70s that has received renewed interest in
		  recent years, due to algorithmic advances and increased
		  availability of computational power and constraint solving
		  technology. We review classical symbolic execution and some
		  modern extensions such as generalized symbolic execution
		  and dynamic test generation. We also give a preliminary
		  assessment of the use in academia, research labs, and
		  industry.},
  isbn		= {978-1-4503-0445-0}
}

@InProceedings{	  calikli10:analysis,
  title		= {An Analysis of the Effects of Company Culture, Education
		  and Experience on Confirmation Bias Levels of Software
		  Developers and Testers},
  booktitle	= {Proceedings of the 32nd {{ACM}}/{{IEEE International
		  Conference}} on {{Software Engineering}} - {{Volume}} 2},
  author	= {Calikli, Gul and Bener, Ayse and Arslan, Berna},
  year		= {2010},
  month		= may,
  series	= {{{ICSE}} '10},
  pages		= {187--190},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1810295.1810326},
  urldate	= {2025-05-10},
  abstract	= {In this paper, we present a preliminary analysis of
		  factors such as company culture, education and experience,
		  on confirmation bias levels of software developers and
		  testers. Confirmation bias is defined as the tendency of
		  people to verify their hypotheses rather than refuting them
		  and thus it has an effect on all software testing.},
  isbn		= {978-1-60558-719-6}
}

@Article{	  campbell02:deep,
  title		= {Deep {{Blue}}},
  author	= {Campbell, Murray and Hoane, A. Joseph and Hsu,
		  Feng-hsiung},
  year		= {2002},
  month		= jan,
  journal	= {Artificial Intelligence},
  volume	= {134},
  number	= {1},
  pages		= {57--83},
  issn		= {0004-3702},
  doi		= {10.1016/S0004-3702(01)00129-1},
  urldate	= {2024-03-11},
  abstract	= {Deep Blue is the chess machine that defeated then-reigning
		  World Chess Champion Garry Kasparov in a six-game match in
		  1997. There were a number of factors that contributed to
		  this success, including: {$\bullet$}a single-chip chess
		  search engine,{$\bullet$}a massively parallel system with
		  multiple levels of parallelism,{$\bullet$}a strong emphasis
		  on search extensions,{$\bullet$}a complex evaluation
		  function, and{$\bullet$}effective use of a Grandmaster game
		  database. This paper describes the Deep Blue system, and
		  gives some of the rationale that went into the design
		  decisions behind Deep Blue.},
  keywords	= {Computer chess,Evaluation function,Game tree
		  search,Parallel search,Search extensions,Selective search}
}

@Article{	  cartwright91:soft,
  title		= {Soft Typing},
  author	= {Cartwright, Robert and Fagan, Mike},
  year		= {1991},
  month		= may,
  journal	= {ACM SIGPLAN Notices},
  volume	= {26},
  number	= {6},
  pages		= {278--292},
  issn		= {0362-1340},
  doi		= {10.1145/113446.113469},
  urldate	= {2023-10-20}
}

@Article{	  casadei22:scafi,
  title		= {{{ScaFi}}: {{A Scala DSL}} and {{Toolkit}} for {{Aggregate
		  Programming}}},
  shorttitle	= {{{ScaFi}}},
  author	= {Casadei, Roberto and Viroli, Mirko and Aguzzi, Gianluca
		  and Pianini, Danilo},
  year		= {2022},
  month		= dec,
  journal	= {SoftwareX},
  volume	= {20},
  pages		= {101248},
  issn		= {2352-7110},
  doi		= {10.1016/j.softx.2022.101248},
  urldate	= {2024-05-17},
  abstract	= {Supported by current socio-scientific trends, programming
		  the global behaviour of whole computational collectives
		  makes for great opportunities, but also significant
		  challenges. Recently, aggregate computing has emerged as a
		  prominent paradigm for so-called collective adaptive
		  systems programming. To shorten the gap between such
		  research endeavours and mainstream software development and
		  engineering, we present ScaFi, a Scala toolkit providing an
		  internal domain-specific language, libraries, a simulation
		  environment, and runtime support for practical aggregate
		  computing systems development.},
  keywords	= {Aggregate programming,Computational fields,Distributed
		  computing,Macro-level programming,Scala toolkit}
}

@Article{	  catolino19:not,
  title		= {Not All Bugs Are the Same: {{Understanding}},
		  Characterizing, and Classifying Bug Types},
  shorttitle	= {Not All Bugs Are the Same},
  author	= {Catolino, Gemma and Palomba, Fabio and Zaidman, Andy and
		  Ferrucci, Filomena},
  year		= {2019},
  month		= jun,
  journal	= {Journal of Systems and Software},
  volume	= {152},
  pages		= {165--181},
  issn		= {0164-1212},
  doi		= {10.1016/j.jss.2019.03.002},
  urldate	= {2025-05-06},
  abstract	= {Modern version control systems, e.g., GitHub, include bug
		  tracking mechanisms that developers can use to highlight
		  the presence of bugs. This is done by means of bug reports,
		  i.e., textual descriptions reporting the problem and the
		  steps that led to a failure. In past and recent years, the
		  research community deeply investigated methods for easing
		  bug triage, that is, the process of assigning the fixing of
		  a reported bug to the most qualified developer.
		  Nevertheless, only a few studies have reported on how to
		  support developers in the process of understanding the type
		  of a reported bug, which is the first and most
		  time-consuming step to perform before assigning a bug-fix
		  operation. In this paper, we target this problem in two
		  ways: first, we analyze 1280 bug reports of 119 popular
		  projects belonging to three ecosystems such as Mozilla,
		  Apache, and Eclipse, with the aim of building a taxonomy of
		  the types of reported bugs; then, we devise and evaluate an
		  automated classification model able to classify reported
		  bugs according to the defined taxonomy. As a result, we
		  found nine main common bug types over the considered
		  systems. Moreover, our model achieves high F-Measure and
		  AUC-ROC (64\% and 74\% on overall, respectively).},
  keywords	= {Bug classification,Empirical study,Taxonomy}
}

@InProceedings{	  chalupa21:fast,
  title		= {Fast {{Computation}} of {{Strong Control Dependencies}}},
  booktitle	= {Computer {{Aided Verification}}},
  author	= {Chalupa, Marek and Kla{\u s}ka, David and Strej{\v c}ek,
		  Jan and Tomovi{\u c}, Luk{\'a}{\u s}},
  editor	= {Silva, Alexandra and Leino, K. Rustan M.},
  year		= {2021},
  pages		= {887--910},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-81688-9_41},
  abstract	= {We introduce new algorithms for computing non-termination
		  sensitive control dependence (NTSCD) and decisive order
		  dependence (DOD). These relations on vertices of a control
		  flow graph have many applications including program slicing
		  and compiler optimizations. Our algorithms are
		  asymptotically faster than the current algorithms. We also
		  show that the original algorithms for computing NTSCD and
		  DOD may produce incorrect results. We implemented the new
		  as well as fixed versions of the original algorithms for
		  the computation of NTSCD and DOD. Experimental evaluation
		  shows that our algorithms dramatically outperform the
		  original ones.},
  isbn		= {978-3-030-81688-9},
  langid	= {english}
}

@Article{	  chappe23:choice,
  title		= {Choice {{Trees}}: {{Representing Nondeterministic}},
		  {{Recursive}}, and {{Impure Programs}} in {{Coq}}},
  shorttitle	= {Choice {{Trees}}},
  author	= {Chappe, Nicolas and He, Paul and Henrio, Ludovic and
		  Zakowski, Yannick and Zdancewic, Steve},
  year		= {2023},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {POPL},
  pages		= {61:1770--61:1800},
  doi		= {10.1145/3571254},
  urldate	= {2023-09-27},
  abstract	= {This paper introduces ctrees, a monad for modeling
		  nondeterministic, recursive, and impure programs in Coq.
		  Inspired by Xia et al.'s itrees, this novel data structure
		  embeds computations into coinductive trees with three kind
		  of nodes: external events, and two variants of
		  nondeterministic branching. This apparent redundancy allows
		  us to provide shallow embedding of denotational models with
		  internal choice in the style of CCS, while recovering an
		  inductive LTS view of the computation. ctrees inherit a
		  vast collection of bisimulation and refinement tools, with
		  respect to which we establish a rich equational theory. We
		  connect ctrees to the itree infrastructure by showing how a
		  monad morphism embedding the former into the latter permits
		  to use ctrees to implement nondeterministic effects. We
		  demonstrate the utility of ctrees by using them to model
		  concurrency semantics in two case studies: CCS and
		  cooperative multithreading.},
  keywords	= {Concurrency,Formal Semantics,Interaction
		  Trees,Nondeterminism}
}

@Article{	  chattopadhyay22:cognitive,
  title		= {Cognitive Biases in Software Development},
  author	= {Chattopadhyay, Souti and Nelson, Nicholas and Au, Audrey
		  and Morales, Natalia and Sanchez, Christopher and Pandita,
		  Rahul and Sarma, Anita},
  year		= {2022},
  month		= mar,
  journal	= {Commun. ACM},
  volume	= {65},
  number	= {4},
  pages		= {115--122},
  issn		= {0001-0782},
  doi		= {10.1145/3517217},
  urldate	= {2025-05-07},
  abstract	= {Cognitive biases are hardwired behaviors that influence
		  developer actions and can set them on an incorrect course
		  of action, necessitating backtracking. Although researchers
		  have found that cognitive biases occur in development tasks
		  in controlled lab studies, we still do not know how these
		  biases affect developers' everyday behavior. Without such
		  an understanding, development tools and practices remain
		  inadequate. To close this gap, we conducted a two-part
		  field study to examine the extent to which cognitive biases
		  occur, the consequences of these biases on developer
		  behavior, and the practices and tools that developers use
		  to deal with these biases. We found about 70\% of observed
		  actions were associated with at least one cognitive bias.
		  Even though developers recognized that biases frequently
		  occur, they are forced to deal with such issues with ad hoc
		  processes and suboptimal tool support. As one participant
		  (IP12) lamented: There is no salvation!}
}

@Article{	  chen01:reversible,
  title		= {Reversible Debugging Using Program Instrumentation},
  author	= {Chen, Shyh-Kwei and Fuchs, W.K. and Chung, Jen-Yao},
  year		= {2001},
  month		= aug,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {27},
  number	= {8},
  pages		= {715--727},
  issn		= {1939-3520},
  doi		= {10.1109/32.940726},
  urldate	= {2023-09-28},
  abstract	= {Reversible execution has not been fully exploited in
		  symbolic debuggers. Debuggers that can undo instructions
		  usually incur a significant performance penalty during a
		  debugging session. We describe an efficient reversible
		  debugging mechanism based on program instrumentation. The
		  approach enables repetitive debugging sessions with
		  selectable reversible routines and recording modes.
		  Experimental results indicate that the execution penalty
		  can be significantly reduced with moderate code growth.}
}

@Article{	  chen15:deterministic,
  title		= {Deterministic {{Replay}}: {{A Survey}}},
  shorttitle	= {Deterministic {{Replay}}},
  author	= {Chen, Yunji and Zhang, Shijin and Guo, Qi and Li, Ling and
		  Wu, Ruiyang and Chen, Tianshi},
  year		= {2015},
  month		= sep,
  journal	= {ACM Comput. Surv.},
  volume	= {48},
  number	= {2},
  pages		= {17:1--17:47},
  issn		= {0360-0300},
  doi		= {10.1145/2790077},
  urldate	= {2025-01-13},
  abstract	= {Deterministic replay is a type of emerging technique
		  dedicated to providing deterministic executions of computer
		  programs in the presence of nondeterministic factors. The
		  application scopes of deterministic replay are very broad,
		  making it an important research topic in domains such as
		  computer architecture, operating systems, parallel
		  computing, distributed computing, programming languages,
		  verification, and hardware testing.In this survey, we
		  comprehensively review existing studies on deterministic
		  replay by introducing a taxonomy. Basically, existing
		  deterministic replay schemes can be classified into two
		  categories, single-processor (SP) schemes and
		  multiprocessor (MP) schemes. By reviewing the details of
		  these two categories of schemes respectively, we summarize
		  and compare how existing schemes address technical issues
		  such as log size, record slowdown, replay slowdown,
		  implementation cost, and probe effect, which may shed some
		  light on future studies on deterministic replay.}
}

@Article{	  chen21:algebraic-information-effects,
  title		= {{{ALGEBRAIC INFORMATION EFFECTS}}},
  author	= {Chen, Chao-Hong},
  year		= {2021},
  month		= aug,
  publisher	= {[Bloomington, Ind.] : Indiana University},
  urldate	= {2023-09-29},
  abstract	= {From the informational perspective, programs that are
		  usually considered as pure have effects, for example, the
		  simply typed lambda calculus is considered as a pure
		  language. However, {$\beta$}--reduction does not preserve
		  information and embodies information effects. To capture
		  the idea about pure programs in the informational sense, a
		  new model of computation --- reversible computation was
		  proposed. This work focuses on type-theoretic approaches
		  for reversible effect handling. The main idea of this work
		  is inspired by compact closed categories. Compact closed
		  categories are categories equipped with a dual object for
		  every object. They are well-established as models of linear
		  logic, concurrency, and quantum computing. This work gives
		  computational interpretations of compact closed categories
		  for conventional product and sum types, where a negative
		  type represents a computational effect that ``reverses
		  execution flow'' and a fractional type represents a
		  computational effect that ``allocates/deallocates space''.},
  copyright	= {This work is under a CC-BY license. You are free to copy
		  and redistribute the material in any format, as well as
		  remix, transform, and build upon the material as long as
		  you give appropriate credit to the original creator,
		  provide a link to the license, and indicate any changes
		  made.},
  langid	= {english},
  annotation	= {Accepted: 2021-08-23T03:09:12Z}
}

@InProceedings{	  chern07:debugging,
  title		= {Debugging with Control-Flow Breakpoints},
  booktitle	= {Proceedings of the 6th International Conference on
		  {{Aspect-oriented}} Software Development},
  author	= {Chern, Rick and De Volder, Kris},
  year		= {2007},
  month		= mar,
  series	= {{{AOSD}} '07},
  pages		= {96--106},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1218563.1218575},
  urldate	= {2025-04-18},
  abstract	= {Modern source-level debuggers support dynamic breakpoints
		  that are guarded by conditions based on program state. Such
		  breakpoints address situations where a static breakpoint is
		  not sufficiently precise to characterise a point of
		  interest in program execution. However, we believe that
		  current IDE support for dynamic breakpoints are cumbersome
		  to use. Firstly, guard conditions formulated in
		  (non-aspect-oriented) source-languages cannot directly
		  express control-flow conditions, forcing developers to seek
		  alternative formulations. Secondly, guard-conditions can be
		  complex expressions and manually typing them is
		  cumbersome.We present the Control-flow Breakpoint Debugger
		  (CBD). CBD uses a dynamic pointcut language to characterise
		  control-flow breakpoints---dynamic breakpoints which are
		  conditional on the control-flow through which they were
		  reached. CBD provides a "point-and-click" GUI to specify
		  and incrementally refine control-flow breakpoints, thereby
		  avoiding the burden of manually editing the potentially
		  complex expressions that define them.We performed 20 case
		  studies debugging and fixing documented bugs in 3 existing
		  applications. Our results show that dynamic breakpoints in
		  general are useful in practice, and that CBD's GUI allows
		  specifying them adequately in the majority of cases.},
  isbn		= {978-1-59593-615-8}
}

@InProceedings{	  chowdhury18:safe,
  title		= {Safe and {{Secure Automotive Over-the-Air Updates}}},
  booktitle	= {Computer {{Safety}}, {{Reliability}}, and {{Security}}},
  author	= {Chowdhury, Thomas and Lesiuta, Eric and Rikley, Kerianne
		  and Lin, Chung-Wei and Kang, Eunsuk and Kim, BaekGyu and
		  Shiraishi, Shinichi and Lawford, Mark and Wassyng, Alan},
  editor	= {Gallina, Barbara and Skavhaug, Amund and Bitsch,
		  Friedemann},
  year		= {2018},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {172--187},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-99130-6_12},
  abstract	= {Over-the-air updates have been used for years in the
		  software industry, allowing bug fixes and enhancements to
		  desktop, laptop, and mobile operating systems and
		  applications. Automotive vehicles now depend on software to
		  the extent that manufacturers are turning to over-the-air
		  updates for critical vehicle functionality. History shows
		  that our software systems are most vulnerable to lapses in
		  safety and dependability when they undergo change, and
		  performing an update over a communication channel adds a
		  significant security concern. This paper presents our ideas
		  on assuring integrated safety and security of over-the-air
		  updates through assurance case templates that comply with
		  both ISO 26262 (functional safety) and SAE J3061
		  (cyber-security). Wisely, the authors of SAE J3061
		  structured the guidebook so that it meshes well with ISO
		  26262, and we have been able to use principles we developed
		  for deriving an assurance case template from ISO 26262, to
		  help include compliance with SAE J3061 in the template. The
		  paper also demonstrates how a specialization of the
		  template helps guide us to pre-emptively mitigate against
		  potential vulnerabilities in over-the-air update
		  implementations.},
  isbn		= {978-3-319-99130-6},
  langid	= {english}
}

@Article{	  church40:formulation,
  title		= {A Formulation of the Simple Theory of Types},
  author	= {Church, Alonzo},
  year		= {1940},
  journal	= {Journal of Symbolic Logic},
  volume	= {5},
  number	= {2},
  pages		= {56--68},
  doi		= {10.2307/2266170}
}

@Misc{		  clang-contributors21:clang,
  title		= {Clang: A {{C}} Language Family Frontend for {{LLVM}}},
  author	= {{Clang contributors}},
  year		= {2021},
  publisher	= {Online}
}

@Misc{		  codemagic-ltd-22:welcome,
  title		= {Welcome to Wokwi!},
  author	= {{CodeMagic LTD.}},
  year		= {2022-05-20, 2022}
}

@InProceedings{	  coetzee15:combining,
  title		= {Combining Reverse Debugging and Live Programming towards
		  Visual Thinking in Computer Programming},
  author	= {Coetzee, A.},
  year		= {2015},
  month		= mar,
  urldate	= {2023-09-26},
  abstract	= {Combining reverse debugging and live programming towards
		  visual thinking in computer programming}
}

@Article{	  cohen94:use,
  title		= {The Use of "Bug" in Computing},
  author	= {Cohen, I.B.},
  year		= {1994},
  journal	= {IEEE Annals of the History of Computing},
  volume	= {16},
  number	= {2},
  pages		= {54--55},
  issn		= {1934-1547},
  doi		= {10.1109/85.279235},
  urldate	= {2025-05-05},
  abstract	= {There has been much speculation concerning the early use
		  of the word "bug" in the language of computer science,
		  technology, and practice. The purpose of the article is to
		  indicate what may be the earliest application of "bug" in
		  the context of computers. When the IBM ASCC/Harvard Mark I
		  was installed at Harvard University, Robert V.D. Campbell
		  was in charge of the operation of the machine. Bob Campbell
		  supervised the testing and first runs of the machine and
		  remained in charge of the machine and its operation until
		  the spring of 1944. Campbell kept a detailed log book,
		  recording almost every aspect of the operation of the new
		  machine, including the preparation of the first programs
		  and the various kinds of difficulties that arose. On April
		  17 1944, Campbell recorded an entry in which reference was
		  made to "bugs" in the ASCC/Mark 1. This is thought to be
		  the first mention of the word "bug" in relation to a
		  computer.{$<>$}},
  keywords	= {Application software,Books,Computer
		  science,Laboratories,Lakes,Military
		  computing,Physics,Relays,Testing,Weapons}
}

@Book{		  cohn09:succeeding,
  title		= {Succeeding with Agile: {{Software}} Development Using
		  Scrum},
  author	= {Cohn, Mike},
  year		= {2009},
  edition	= {1th.},
  publisher	= {Addison-Wesley Professional},
  address	= {Boston, MA, USA},
  isbn		= {978-0-321-57936-2}
}

@Misc{		  control-flow-integrity,
  title		= {Control-{{Flow Integrity}}: {{Precision}}, {{Security}},
		  and {{Performance}}: {{ACM Computing Surveys}}: {{Vol}} 50,
		  {{No}} 1},
  urldate	= {2025-01-15},
  howpublished	= {https://dl.acm.org/doi/10.1145/3054924}
}

@InProceedings{	  cousot02:modular,
  title		= {Modular {{Static Program Analysis}}},
  booktitle	= {Compiler {{Construction}}},
  author	= {Cousot, Patrick and Cousot, Radhia},
  editor	= {Horspool, R. Nigel},
  year		= {2002},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {159--179},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-45937-5_13},
  abstract	= {The purpose of this paper is to present four basic methods
		  for compositional separate modular static analysis of
		  programs by abstract interpretation: - simplification-based
		  separate analysis; - worst-case separate analysis; -
		  separate analysis with (user-provided) interfaces; -
		  symbolic relational separate analysis; as well as a fifth
		  category which is essentially obtained by composition of
		  the above separate local analyses together with global
		  analysis methods.},
  isbn		= {978-3-540-45937-8},
  langid	= {english},
  keywords	= {Abstract Domain,Abstract Interpretation,Dependence
		  Graph,Logic Program,Program Part}
}

@InProceedings{	  crary99:typed,
  title		= {Typed Memory Management in a Calculus of Capabilities},
  booktitle	= {Proceedings of the 26th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Crary, Karl and Walker, David and Morrisett, Greg},
  year		= {1999},
  month		= jan,
  series	= {{{POPL}} '99},
  pages		= {262--275},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/292540.292564},
  urldate	= {2023-12-01},
  abstract	= {An increasing number of systems rely on programming
		  language technology to ensure safety and security of
		  low-level code. Unfortunately, these systems typically rely
		  on a complex, trusted garbage collector. Region-based type
		  systems provide an alternative to garbage collection by
		  making memory management explicit but verifiably safe.
		  However, it has not been clear how to use regions in
		  low-level, type-safe code.We present a compiler
		  intermediate language, called the Capability Calculus, that
		  supports region-based memory management, enjoys a provably
		  safe type system, and is straightforward to compile to a
		  typed assembly language. Source languages may be compiled
		  to our language using known region inference algorithms.
		  Furthermore, region lifetimes need not be lexically scoped
		  in our language, yet the language may be checked for safety
		  without complex analyses. Finally, our soundness proof is
		  relatively simple, employing only standard techniques.The
		  central novelty is the use of static capabilities to
		  specify the permissibility of various operations, such as
		  memory access and deallocation. In order to ensure
		  capabilities are relinquished properly, the type system
		  tracks aliasing information using a form of bounded
		  quantification.},
  isbn		= {978-1-58113-095-9}
}

@Article{	  crescenzi00:reversible,
  title		= {Reversible {{Execution}} and {{Visualization}} of
		  {{Programs}} with {{LEONARDO}}},
  author	= {Crescenzi, {\relax PIERLUIGI} and Demetrescu, {\relax
		  CAMIL} and Finocchi, {\relax IRENE} and Petreschi, {\relax
		  ROSSELLA}},
  year		= {2000},
  month		= apr,
  journal	= {Journal of Visual Languages \& Computing},
  volume	= {11},
  number	= {2},
  pages		= {125--150},
  issn		= {1045-926X},
  doi		= {10.1006/jvlc.1999.0143},
  urldate	= {2024-02-29},
  abstract	= {In this paper we present LEONARDO, an integrated
		  environment for software visualization that allows the user
		  to edit, compile, execute, and animate general-purpose C
		  programs. LEONARDO relies on a logic-based approach to
		  visualization: a mapping between concrete and abstract data
		  structures can be declared through a logic visualization
		  language and animations are conceived as reflecting formal
		  properties of algorithms. LEONARDO is able to automatically
		  detect visual events during the execution of programs and
		  simplifies the creation of visualizations according to an
		  incremental approach. Moreover, it guarantees the complete
		  reversibility of computations, bounded only by the
		  potentiality of the working machine, and appears simple to
		  be used. The latest version of LEONARDO is currently
		  available over the Internet at the URLhttp:
		  //www.dis.uniroma1.it/{\textasciitilde}demetres/Leonardo/.}
}

@Article{	  cutler24:stream,
  title		= {Stream {{Types}}},
  author	= {Cutler, Joseph W. and Watson, Christopher and Nkurumeh,
		  Emeka and Hilliard, Phillip and Goldstein, Harrison and
		  Stanford, Caleb and Pierce, Benjamin C.},
  year		= {2024},
  month		= jun,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {8},
  number	= {PLDI},
  pages		= {204:1412--204:1436},
  doi		= {10.1145/3656434},
  urldate	= {2024-12-18},
  abstract	= {We propose a rich foundational theory of typed data
		  streams and stream transformers, motivated by two
		  high-level goals. First, the type of a stream should be
		  able to express complex sequential patterns of events over
		  time. And second, it should describe the internal parallel
		  structure of the stream, to support deterministic stream
		  processing on parallel and distributed systems. To these
		  ends, we introduce stream types, with operators capturing
		  sequential composition, parallel composition, and
		  iteration, plus a core calculus {$\lambda$}ST of
		  transformers over typed streams that naturally supports a
		  number of common streaming idioms, including punctuation,
		  windowing, and parallel partitioning, as first-class
		  constructions. {$\lambda$}ST exploits a Curry-Howard-like
		  correspondence with an ordered variant of the Logic of
		  Bunched Implication to program with streams compositionally
		  and uses Brzozowski-style derivatives to enable an
		  incremental, prefix-based operational semantics. To
		  illustrate the programming style supported by the rich
		  types of {$\lambda$}ST, we present a number of examples
		  written in Delta, a prototype high-level language design
		  based on {$\lambda$}ST.}
}

@PhDThesis{	  da-silva92:correctness,
  title		= {Correctness Proofs of Compilers and Debuggers : An
		  Approach Based on Structural Operational Semantics},
  shorttitle	= {Correctness Proofs of Compilers and Debuggers},
  author	= {{da Silva}, Fabio Q. B.},
  year		= {1992},
  bibsource	= {dblp computer science bibliography, https://dblp.org},
  school	= {University of Edinburgh, UK},
  timestamp	= {Wed, 04 May 2022 12:59:16 +0200}
}

@InProceedings{	  dalal99:model-based,
  title		= {Model-Based Testing in Practice},
  booktitle	= {Proceedings of the 21st International Conference on
		  {{Software}} Engineering},
  author	= {Dalal, S. R. and Jain, A. and Karunanithi, N. and Leaton,
		  J. M. and Lott, C. M. and Patton, G. C. and Horowitz, B.
		  M.},
  year		= {1999},
  month		= may,
  series	= {{{ICSE}} '99},
  pages		= {285--294},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/302405.302640},
  urldate	= {2025-03-04},
  isbn		= {978-1-58113-074-4}
}

@Article{	  damiani16:type-sound,
  title		= {A Type-Sound Calculus of Computational Fields},
  author	= {Damiani, Ferruccio and Viroli, Mirko and Beal, Jacob},
  year		= {2016},
  month		= feb,
  journal	= {Science of Computer Programming},
  volume	= {117},
  pages		= {17--44},
  issn		= {0167-6423},
  doi		= {10.1016/j.scico.2015.11.005},
  urldate	= {2024-05-17},
  abstract	= {A number of recent works have investigated the notion of
		  ``computational fields'' as a means of coordinating systems
		  in distributed, dense and dynamic environments such as
		  pervasive computing, sensor networks, and robot swarms. We
		  introduce a minimal core calculus meant to capture the key
		  ingredients of languages that make use of computational
		  fields: functional composition of fields, functions over
		  fields, evolution of fields over time, construction of
		  fields of values from neighbours, and restriction of a
		  field computation to a sub-region of the network. We
		  formalise a notion of type soundness for the calculus that
		  encompasses the concept of domain alignment, and present a
		  sound static type inference system. This calculus and its
		  type inference system can act as a core for actual
		  implementation of coordination languages and models, as
		  well as to pave the way towards formal analysis of
		  properties concerning expressiveness, self-stabilisation,
		  topology independence, and relationships with the
		  continuous space--time semantics of spatial computations.},
  keywords	= {Computational field,Core calculus,Operational
		  semantics,Spatial computing,Type soundness}
}

@InProceedings{	  danos04:reversible,
  title		= {Reversible {{Communicating Systems}}},
  booktitle	= {{{CONCUR}} 2004 - {{Concurrency Theory}}},
  author	= {Danos, Vincent and Krivine, Jean},
  editor	= {Gardner, Philippa and Yoshida, Nobuko},
  year		= {2004},
  pages		= {292--307},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-540-28644-8_19},
  abstract	= {One obtains in this paper a process algebra RCCS, in the
		  style of CCS, where processes can backtrack. Backtrack,
		  just as plain forward computation, is seen as a
		  synchronization and incurs no additional cost on the
		  communication structure. It is shown that, given a past, a
		  computation step can be taken back if and only if it leads
		  to a causally equivalent past.},
  isbn		= {978-3-540-28644-8},
  langid	= {english}
}

@Article{	  dardinier24:hyper,
  title		= {Hyper {{Hoare Logic}}: ({{Dis-}}){{Proving Program
		  Hyperproperties}}},
  shorttitle	= {Hyper {{Hoare Logic}}},
  author	= {Dardinier, Thibault and M{\"u}ller, Peter},
  year		= {2024},
  month		= jun,
  journal	= {Hyper Hoare Logic: (Dis-)Proving Program Hyperproperties
		  (artifact)},
  volume	= {8},
  number	= {PLDI},
  pages		= {207:1485--207:1509},
  doi		= {10.1145/3656437},
  urldate	= {2024-12-13},
  abstract	= {Hoare logics are proof systems that allow one to formally
		  establish properties of computer programs. Traditional
		  Hoare logics prove properties of individual program
		  executions (such as functional correctness). Hoare logic
		  has been generalized to prove also properties of multiple
		  executions of a program (so-called hyperproperties, such as
		  determinism or non-interference). These program logics
		  prove the absence of (bad combinations of) executions. On
		  the other hand, program logics similar to Hoare logic have
		  been proposed to disprove program properties (e.g.,
		  Incorrectness Logic), by proving the existence of (bad
		  combinations of) executions. All of these logics have in
		  common that they specify program properties using
		  assertions over a fixed number of states, for instance, a
		  single pre- and post-state for functional properties or
		  pairs of pre- and post-states for non-interference. In this
		  paper, we present Hyper Hoare Logic, a generalization of
		  Hoare logic that lifts assertions to properties of
		  arbitrary sets of states. The resulting logic is simple yet
		  expressive: its judgments can express arbitrary program
		  hyperproperties, a particular class of hyperproperties over
		  the set of terminating executions of a program (including
		  properties of individual program executions). By allowing
		  assertions to reason about sets of states, Hyper Hoare
		  Logic can reason about both the absence and the existence
		  of (combinations of) executions, and, thereby, supports
		  both proving and disproving program (hyper-)properties
		  within the same logic, including (hyper-)properties that no
		  existing Hoare logic can express. We prove that Hyper Hoare
		  Logic is sound and complete, and demonstrate that it
		  captures important proof principles naturally. All our
		  technical results have been proved in Isabelle/HOL.}
}

@Article{	  dash23:affine,
  title		= {Affine {{Monads}} and {{Lazy Structures}} for {{Bayesian
		  Programming}}},
  author	= {Dash, Swaraj and Kaddar, Younesse and Paquet, Hugo and
		  Staton, Sam},
  year		= {2023},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {POPL},
  pages		= {46:1338--46:1368},
  doi		= {10.1145/3571239},
  urldate	= {2023-09-27},
  abstract	= {We show that streams and lazy data structures are a
		  natural idiom for programming with infinite-dimensional
		  Bayesian methods such as Poisson processes, Gaussian
		  processes, jump processes, Dirichlet processes, and Beta
		  processes. The crucial semantic idea, inspired by
		  developments in synthetic probability theory, is to work
		  with two separate monads: an affine monad of probability,
		  which supports laziness, and a commutative, non-affine
		  monad of measures, which does not. (Affine means that
		  T(1){$\cong$} 1.) We show that the separation is important
		  from a decidability perspective, and that the recent model
		  of quasi-Borel spaces supports these two monads. To perform
		  Bayesian inference with these examples, we introduce new
		  inference methods that are specially adapted to laziness;
		  they are proven correct by reference to the
		  Metropolis-Hastings-Green method. Our theoretical
		  development is implemented as a Haskell library, LazyPPL.},
  keywords	= {Bayesian inference,categorical semantics,commutative
		  monads,functional
		  programming,Haskell,laziness,nonparametric
		  statistics,probabilistic programming,quasi-Borel
		  spaces,synthetic measure theory}
}

@Misc{		  datadog00:end,
  title		= {End to {{End Testing Automation}}},
  author	= {Datadog},
  year		= {00:00:00 +0000 UTC},
  journal	= {Datadog},
  urldate	= {2024-02-12},
  abstract	= {Learn how to create and configure robust end-to-end tests
		  with ease using automation.},
  howpublished	= {https://www.datadoghq.com/synthetics/end-to-end-testing-automation/},
  langid	= {english}
}

@Misc{		  datadog24:end,
  title		= {End to {{End Testing Automation}}},
  author	= {{Datadog}},
  year		= {2024},
  urldate	= {2024-02-12},
  abstract	= {Learn how to create and configure robust end-to-end tests
		  with ease using automation.},
  langid	= {english}
}

@InCollection{	  de-boer20:sympaths,
  title		= {{{SymPaths}}: {{Symbolic Execution Meets Partial Order
		  Reduction}}},
  shorttitle	= {{{SymPaths}}},
  booktitle	= {Deductive {{Software Verification}}: {{Future
		  Perspectives}}: {{Reflections}} on the {{Occasion}} of 20
		  {{Years}} of {{KeY}}},
  author	= {{de Boer}, Frank S. and Bonsangue, Marcello and Johnsen,
		  Einar Broch and Pun, Violet Ka I. and Tapia Tarifa, S.
		  Lizeth and Tveito, Lars},
  editor	= {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard
		  and H{\"a}hnle, Reiner and Ulbrich, Mattias},
  year		= {2020},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {313--338},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-64354-6_13},
  urldate	= {2023-10-16},
  abstract	= {Symbolic execution is an important technique for software
		  analysis, which enables systematic model exploration by
		  following all possible execution paths for a given program.
		  For multithreaded shared variable programs, this technique
		  leads to a state space explosion. Partial order reduction
		  is a technique which allows equivalent execution paths to
		  be recognized, reducing the state space explosion problem.
		  This paper provides formal justifications for these
		  techniques in a multithreaded setting by proving the
		  correctness and completeness of symbolic execution for
		  multithreaded shared variable programs, with and without
		  the use of partial order reduction. We then show how these
		  formal justifications carry over to prove the soundness and
		  relative completeness of a proof system for such
		  multithreaded shared variable programs in dynamic logic,
		  such that partial order reduction can be used to simplify
		  the proof construction by mitigating the state space
		  explosion.},
  isbn		= {978-3-030-64354-6},
  langid	= {english}
}

@Article{	  de-boer21:symbolic,
  title		= {Symbolic Execution Formally Explained},
  author	= {{de Boer}, Frank S. and Bonsangue, Marcello},
  year		= {2021},
  month		= aug,
  journal	= {Formal Aspects of Computing},
  volume	= {33},
  number	= {4},
  pages		= {617--636},
  issn		= {1433-299X},
  doi		= {10.1007/s00165-020-00527-y},
  urldate	= {2023-10-16},
  abstract	= {In this paper, we provide a formal explanation of symbolic
		  execution in terms of a symbolic transition system and
		  prove its correctness and completeness with respect to an
		  operational semantics which models the execution on
		  concrete values.We first introduce a formalmodel for a
		  basic programming languagewith a statically fixed number of
		  programming variables. This model is extended to a
		  programming language with recursive procedures which are
		  called by a call-by-value parameter mechanism. Finally, we
		  present a more general formal framework for proving the
		  soundness and completeness of the symbolic execution of a
		  basic object-oriented language which features dynamically
		  allocated variables.},
  langid	= {english}
}

@InProceedings{	  de-troyer18:building,
  title		= {Building {{IoT Systems Using Distributed First-Class
		  Reactive Programming}}},
  booktitle	= {2018 {{IEEE International Conference}} on {{Cloud
		  Computing Technology}} and {{Science}} ({{CloudCom}})},
  author	= {{de Troyer}, Christophe and Nicolay, Jens and {de Meuter},
		  Wolfgang},
  year		= {2018},
  month		= dec,
  pages		= {185--192},
  issn		= {2330-2186},
  doi		= {10.1109/CloudCom2018.2018.00045},
  urldate	= {2023-10-03},
  abstract	= {Contemporary IoT systems are challenging to develop,
		  deploy, and maintain. This is because of their
		  ever-increasing scale, dynamic network topologies,
		  heterogeneity and resource constraints of the involved
		  devices, and failures that may occur as a result of these
		  characteristics. Existing approaches are either not at the
		  right level of abstraction, require developers to learn
		  specialized languages, or miss certain key features to
		  address all these challenges in a uniform manner. In this
		  paper we leverage reactive programming and code mobility to
		  support the entire life-cycle of large-scale IoT systems.
		  Our approach is based on existing programming technologies
		  and offers simple and composable abstractions to
		  developers. We implemented our approach in a middleware
		  called Potato and used it to develop and deploy an IoT
		  application on a Raspberry Pi cluster. We found that using
		  Potato reduces much of the accidental complexity associated
		  with developing and deploying IoT systems, resulting in
		  clean and maintainable programs.}
}

@Article{	  de23:evaluating,
  title		= {Evaluating Reliability against {{SEE}} of Embedded
		  Systems: {{A}} Comparison of {{RTOS}} and Bare-Metal
		  Approaches},
  shorttitle	= {Evaluating Reliability against {{SEE}} of Embedded
		  Systems},
  author	= {De Sio, C. and Azimi, S. and Sterpone, L.},
  year		= {2023},
  month		= oct,
  journal	= {Microelectronics Reliability},
  pages		= {115124},
  issn		= {0026-2714},
  doi		= {10.1016/j.microrel.2023.115124},
  urldate	= {2023-10-12},
  abstract	= {Embedded processors are widely used in critical
		  applications such as space missions, where reliability is
		  mandatory for the success of missions. Due to the
		  increasing application complexity, the number of systems
		  using Real-Time Operating Systems (RTOSs) is quickly
		  growing to manage the execution of multiple applications
		  and meet timing constraints. However, whether operating
		  systems or bare-metal applications provide higher
		  reliability is still being determined. We present a
		  comprehensive reliability analysis of software applications
		  running on a device with bare-metal and FreeRTOS against
		  the same faults based on fault models derived from a proton
		  test. Additionally, the FreeRTOS system has been evaluated
		  with a set of software applications dedicated to evaluating
		  specific RTOS functions, providing an additional evaluation
		  for operations crucial for a real-time operating system.},
  keywords	= {Baremetal,Embedded processors,Fault
		  injection,FreeRTOS,Multiple cell upset,Operating
		  system,Radiation effects,Reliability,RTOS,Single event
		  upset}
}

@Misc{		  debugging,
  title		= {Debugging the {{Internet}} of {{Things}}: {{The Case}} of
		  {{Wireless Sensor Networks}} {\textbar} {{IEEE Journals}}
		  \& {{Magazine}} {\textbar} {{IEEE Xplore}}},
  urldate	= {2024-02-29},
  howpublished	= {https://ieeexplore.ieee.org/abstract/document/6914470}
}

@InProceedings{	  decasse88:review,
  title		= {A Review of Automated Debugging Systems: Knowledge,
		  Strategies and Techniques},
  shorttitle	= {A Review of Automated Debugging Systems},
  booktitle	= {Proceedings. [1989] 11th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Decasse, M. and Emde, A.-M.},
  year		= {1988},
  month		= jan,
  pages		= {162,163,164,165,166,167,168,169,170,171--162,163,164,165,166,167,168,169,170,171},
  publisher	= {IEEE Computer Society},
  doi		= {10.1109/ICSE.1988.93698},
  urldate	= {2025-05-08},
  abstract	= {The authors propose a classification of debugging
		  knowledge, and a description of the corresponding knowledge
		  representation in the systems. Then they propose a
		  classification of global debugging strategies used in the
		  systems, and a description of the corresponding techniques.
		  They assess the identified strategies from a real-world
		  program development point of view. The knowledge types
		  identified are: (1) knowledge of the intended program; (2)
		  knowledge of the actual program; (3) understanding of the
		  programming language; (4) general programming expertise;
		  (5) knowledge of the application domain; (6) knowledge of
		  bugs; and (7) knowledge of debugging methods. The
		  strategies identified are: (1) filtering; (2) checking
		  computational equivalence of intended program and actual
		  one; (3) checking the well-formedness of actual program;
		  and (4) recognizing stereotyped errors.},
  langid	= {english}
}

@InProceedings{	  decker18:online,
  title		= {Online Analysis of Debug Trace Data for Embedded Systems},
  booktitle	= {2018 {{Design}}, {{Automation}} \& {{Test}} in {{Europe
		  Conference}} \& {{Exhibition}} ({{DATE}})},
  author	= {Decker, Normann and Dreyer, Boris and Gottschling, Philip
		  and Hochberger, Christian and Lange, Alexander and Leucker,
		  Martin and Scheffel, Torben and Wegener, Simon and Weiss,
		  Alexander},
  year		= {2018},
  month		= mar,
  pages		= {851--856},
  issn		= {1558-1101},
  doi		= {10.23919/DATE.2018.8342124},
  urldate	= {2024-06-04},
  abstract	= {Modern multi-core Systems-on-Chip (SoC) provide very high
		  computational power. On the downside, they are hard to
		  debug and it is often very difficult to understand what is
		  going on in these chips because of the limited
		  observability inside the SoC. Chip manufacturers try to
		  compensate this difficulty by providing highly compressed
		  trace data from the individual cores. In the past, the
		  common way to deal with this data was storing it for later
		  offline analysis, which severely limits the time span that
		  can be observed. In this contribution, we present an
		  FPGA-based solution that is able to process the trace data
		  in real-time, enabling continuous observation of the state
		  of a core. Moreover, we discuss applications enabled by
		  this technology.},
  keywords	= {Bandwidth,Field programmable gate
		  arrays,Hardware,Instruments,Monitoring,Runtime,Software}
}

@InProceedings{	  deiner24:nuzzlebug,
  title		= {{{NuzzleBug}}: {{Debugging Block-Based Programs}} in
		  {{Scratch}}},
  shorttitle	= {{{NuzzleBug}}},
  booktitle	= {Proceedings of the 46th {{IEEE}}/{{ACM International
		  Conference}} on {{Software Engineering}}},
  author	= {Deiner, Adina and Fraser, Gordon},
  year		= {2024},
  month		= feb,
  pages		= {1--13},
  publisher	= {ACM},
  address	= {Lisbon, Portugal},
  doi		= {10.1145/3597503.3623331},
  isbn		= {9798400702174},
  langid	= {english}
}

@Misc{		  dessouky18:when,
  title		= {When a {{Patch}} Is {{Not Enough}} - {{HardFails}}:
		  {{Software-Exploitable Hardware Bugs}}},
  shorttitle	= {When a {{Patch}} Is {{Not Enough}} - {{HardFails}}},
  author	= {Dessouky, Ghada and Gens, David and Haney, Patrick and
		  Persyn, Garrett and Kanuparthi, Arun and Khattri, Hareesh
		  and Fung, Jason M. and Sadeghi, Ahmad-Reza and Rajendran,
		  Jeyavijayan},
  year		= {2018},
  month		= dec,
  number	= {arXiv:1812.00197},
  eprint	= {1812.00197},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.1812.00197},
  urldate	= {2025-05-06},
  abstract	= {In this paper, we take a deep dive into microarchitectural
		  security from a hardware designer's perspective by
		  reviewing the existing approaches to detect hardware
		  vulnerabilities during the design phase. We show that a
		  protection gap currently exists in practice that leaves
		  chip designs vulnerable to software-based attacks. In
		  particular, existing verification approaches fail to detect
		  specific classes of vulnerabilities, which we call
		  HardFails: these bugs evade detection by current
		  verification techniques while being exploitable from
		  software. We demonstrate such vulnerabilities in real-world
		  SoCs using RISC-V to showcase and analyze concrete
		  instantiations of HardFails. Patching these hardware bugs
		  may not always be possible and can potentially result in a
		  product recall. We base our findings on two extensive case
		  studies: the recent Hack@DAC 2018 hardware security
		  competition, where 54 independent teams of researchers
		  competed world-wide over a period of 12 weeks to catch
		  inserted security bugs in SoC RTL designs, and an in-depth
		  systematic evaluation of state-of-the-art verification
		  approaches. Our findings indicate that even combinations of
		  techniques will miss high-impact bugs due to the large
		  number of modules with complex interdependencies and
		  fundamental limitations of current detection approaches. We
		  also craft a real-world software attack that exploits one
		  of the RTL bugs from Hack@DAC that evaded detection and
		  discuss novel approaches to mitigate the growing problem of
		  cross-layer bugs at design time.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Cryptography and Security}
}

@InProceedings{	  dessouky19:hardfails,
  title		= {\{\vphantom\}{{HardFails}}\vphantom\{\}: {{Insights}} into
		  \{\vphantom\}{{Software-Exploitable}}\vphantom\{\} {{Hardware Bugs}}},
  shorttitle	= {\{\vphantom\}{{HardFails}}\vphantom\{\}},
  booktitle	= {28th {{USENIX Security Symposium}} ({{USENIX Security}}
		  19)},
  author	= {Dessouky, Ghada and Gens, David and Haney, Patrick and
		  Persyn, Garrett and Kanuparthi, Arun and Khattri, Hareesh
		  and Fung, Jason M. and Sadeghi, Ahmad-Reza and Rajendran,
		  Jeyavijayan},
  year		= {2019},
  pages		= {213--230},
  urldate	= {2025-05-06},
  isbn		= {978-1-939133-06-9},
  langid	= {english}
}

@InProceedings{	  disselkoen19:position,
  title		= {Position {{Paper}}: {{Progressive Memory Safety}} for
		  {{WebAssembly}}},
  shorttitle	= {Position {{Paper}}},
  booktitle	= {Proceedings of the 8th {{International Workshop}} on
		  {{Hardware}} and {{Architectural Support}} for {{Security}}
		  and {{Privacy}}},
  author	= {Disselkoen, Craig and Renner, John and Watt, Conrad and
		  Garfinkel, Tal and Levy, Amit and Stefan, Deian},
  year		= {2019},
  month		= jun,
  series	= {{{HASP}} '19},
  pages		= {1--8},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3337167.3337171},
  urldate	= {2024-01-18},
  abstract	= {WebAssembly (Wasm) is a low-level platform-independent
		  bytecode language. Today, developers can compile C/C++ to
		  Wasm and run it everywhere, at almost native speeds.
		  Unfortunately, this compilation from C/C++ to Wasm also
		  preserves classic memory safety vulnerabilities, such as
		  buffer overflows and use-after-frees. New processor
		  features (e.g., tagged memory, pointer authentication, and
		  fine grain capabilities) are making it increasingly
		  possible to detect, mitigate, and prevent such
		  vulnerabilities with low overhead. Unfortunately, Wasm JITs
		  and compilers cannot exploit these features. Critical
		  high-level information---e.g., the size of an array---is
		  lost when lowering to Wasm. We present MS-Wasm, an
		  extension to Wasm that bridges this gap by allowing
		  developers to capture low-level C/C++ memory semantics such
		  as pointers and memory allocation in Wasm, at compile time.
		  At deployment time, Wasm compilers and JITs can leverage
		  these added semantics to enforce different models of memory
		  safety depending on user preferences and what hardware is
		  available on the target platform. This way, MS-Wasm offers
		  a range of security-performance trade-offs, and enables
		  users to move to progressively stronger models of memory
		  safety as hardware evolves.},
  isbn		= {978-1-4503-7226-8},
  keywords	= {memory safety,tagged memory,Wasm,WebAssembly}
}

@Misc{		  doctest,
  title		= {Doctest --- {{Test}} Interactive {{Python}} Examples},
  author	= {{Python Software Foundation}},
  journal	= {Python documentation},
  urldate	= {2024-02-09},
  abstract	= {Source code: Lib/doctest.py The doctest module searches
		  for pieces of text that look like interactive Python
		  sessions, and then executes those sessions to verify that
		  they work exactly as shown. Th...},
  howpublished	= {https://docs.python.org/3/library/doctest.html},
  langid	= {english}
}

@Article{	  dodd92:monitoring,
  title		= {Monitoring and Debugging Distributed Realtime Programs},
  author	= {Dodd, Paul S. and Ravishankar, Chinya V.},
  year		= {1992},
  journal	= {Software: Practice and Experience},
  volume	= {22},
  number	= {10},
  pages		= {863--877},
  issn		= {1097-024X},
  doi		= {10.1002/spe.4380221005},
  urldate	= {2025-03-03},
  abstract	= {In this paper we describe the design and implementation of
		  an integrated monitoring and debugging system for a
		  distributed real-time computer system. The monitor provides
		  continuous, transparent monitoring capabilities throughout
		  a real-time system's lifecycle with bounded, minimal,
		  predictable interference by using software support. The
		  monitor is flexible enough to observe both high-level
		  events that are operating system- and application-specific,
		  as well as low-level events such as shared variable
		  references. We present a novel approach to monitoring
		  shared variable references that provides transparent
		  monitoring with low overhead. The monitor is designed to
		  support tasks such as debugging realtime applications,
		  aiding real-time task scheduling, and measuring system
		  performance. Since debugging distributed real-time
		  applications is particularly difficult, we describe how the
		  monitor can be used to debug distributed and parallel
		  applications by deterministic execution replay.},
  langid	= {english},
  keywords	= {Debugging,Program monitoring,Real-time systems}
}

@Article{	  doderlein24:liverec,
  title		= {{{LiveRec}}: {{Prototyping Probes}} by {{Framing Debug
		  Protocols}}},
  shorttitle	= {{{LiveRec}}},
  author	= {D{\"o}derlein, Jean-Baptiste and van Rozen, Riemer and van
		  der Storm, Tijs},
  year		= {2024},
  month		= feb,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {8},
  number	= {3},
  pages		= {16:1-16:36},
  publisher	= {AOSA, Inc.},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2024/8/16},
  urldate	= {2024-03-13},
  abstract	= {Context: In the first part of his 2012 presentation
		  ``Inventing on Principle'', Bret Victor gives a demo of a
		  live code editor for Javascript which shows the dynamic
		  history of values of variables in real time. This form of
		  live programming has become known as ``probes''. Probes
		  provide the programme...},
  langid	= {english}
}

@Article{	  dsilva08:survey,
  title		= {A {{Survey}} of {{Automated Techniques}} for {{Formal
		  Software Verification}}},
  author	= {D'Silva, Vijay and Kroening, Daniel and Weissenbacher,
		  Georg},
  year		= {2008},
  month		= jul,
  journal	= {IEEE Transactions on Computer-Aided Design of Integrated
		  Circuits and Systems},
  volume	= {27},
  number	= {7},
  pages		= {1165--1178},
  issn		= {1937-4151},
  doi		= {10.1109/TCAD.2008.923410},
  urldate	= {2025-05-06},
  abstract	= {The quality and the correctness of software are often the
		  greatest concern in electronic systems. Formal verification
		  tools can provide a guarantee that a design is free of
		  specific flaws. This paper surveys algorithms that perform
		  automatic static analysis of software to detect programming
		  errors or prove their absence. The three techniques
		  considered are static analysis with abstract domains, model
		  checking, and bounded model checking. A short tutorial on
		  these techniques is provided, highlighting their
		  differences when applied to practical problems. This paper
		  also surveys tools implementing these techniques and
		  describes their merits and shortcomings.},
  keywords	= {Algorithm design and analysis,Automatic
		  programming,Automatic testing,Bounded model checking
		  (BMC),Formal verification,Hardware,model
		  checking,Performance analysis,predicate
		  abstraction,Software algorithms,Software
		  performance,Software quality,Software systems,software
		  verification,static analysis}
}

@InProceedings{	  dupriez17:analysis,
  title		= {Analysis and Exploration for New Generation Debuggers},
  booktitle	= {Proceedings of the 12th Edition of the {{International
		  Workshop}} on {{Smalltalk Technologies}}},
  author	= {Dupriez, Thomas and Polito, Guillermo and Ducasse,
		  St{\'e}phane},
  year		= {2017},
  month		= sep,
  series	= {{{IWST}} '17},
  pages		= {1--6},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3139903.3139910},
  urldate	= {2023-09-25},
  abstract	= {Locating and fixing bugs is well-known to be a time
		  consuming task. Advanced approaches such as object-centric
		  or back-in-time debuggers have been proposed in the
		  literature. still in many scenarios developers are left
		  alone with generic tools such as manual breakpoints and
		  execution stepping that, while usable, cannot adapt to
		  specific debugging scenarios to make the life of developers
		  easier. In this position paper we explore several advanced
		  on-line debugging techniques such as contextual breakpoints
		  and on-line execution comparison, that could help
		  developers solve complex debugging scenarios. We analyse
		  the open research challenges these techniques pose, as well
		  as the underlying mechanisms they require. We present early
		  but promising prototypes we built using the Pharo
		  programming language. We finally identify future research
		  paths by analysing existing research and connecting it to
		  the techniques we presented before.},
  isbn		= {978-1-4503-5554-4},
  keywords	= {Breakpoint,Debugger,Stack,Tool,Watchpoint}
}

@InProceedings{	  dupriez19:sindarin,
  title		= {Sindarin: A Versatile Scripting {{API}} for the {{Pharo}}
		  Debugger},
  shorttitle	= {Sindarin},
  booktitle	= {Proceedings of the 15th {{ACM SIGPLAN International
		  Symposium}} on {{Dynamic Languages}}},
  author	= {Dupriez, Thomas and Polito, Guillermo and Costiou, Steven
		  and Aranega, Vincent and Ducasse, St{\'e}phane},
  year		= {2019},
  month		= oct,
  series	= {{{DLS}} 2019},
  pages		= {67--79},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3359619.3359745},
  urldate	= {2025-05-04},
  abstract	= {Debugging is one of the most important and time consuming
		  activities in software maintenance, yet mainstream
		  debuggers are not well-adapted to several debugging
		  scenarios. This has led to the research of new techniques
		  covering specific families of complex bugs. Notably, recent
		  research proposes to empower developers with scripting
		  DSLs, plugin-based and moldable debuggers. However, these
		  solutions are tailored to specific use-cases, or too costly
		  for one-time-use scenarios. In this paper we argue that
		  exposing a debugging scripting interface in mainstream
		  debuggers helps in solving many challenging debugging
		  scenarios. For this purpose, we present Sindarin, a
		  scripting API that eases the expression and automation of
		  different strategies developers pursue during their
		  debugging sessions. Sindarin provides a GDB-like API,
		  augmented with AST-bytecode-source code mappings and
		  object-centric capabilities. To demonstrate the versatility
		  of Sindarin, we reproduce several advanced breakpoints and
		  non-trivial debugging mechanisms from the literature.},
  isbn		= {978-1-4503-6996-1}
}

@InCollection{	  edelkamp12:chapter,
  title		= {Chapter 16 - {{Automated System Verification}}},
  booktitle	= {Heuristic {{Search}}},
  author	= {Edelkamp, Stefan and Schr{\"o}dl, Stefan},
  editor	= {Edelkamp, Stefan and Schr{\"o}dl, Stefan},
  year		= {2012},
  month		= jan,
  pages		= {701--736},
  publisher	= {Morgan Kaufmann},
  address	= {San Francisco},
  doi		= {10.1016/B978-0-12-372512-7.00016-X},
  urldate	= {2024-08-29},
  abstract	= {This chapter gives an introduction to search problems in
		  model checking, Petri nets, and graph transition systems.
		  It also introduces automated theorem proving and discusses
		  state space search for proof state-based theorem proving
		  and diagnosis problems. The presence of a vast number of
		  computing devices in our environment imposes a challenge
		  for designers to produce reliable software. In medicine,
		  aviation, finance, transportation, space technology, and
		  communication, we are more and more aware of the critical
		  role correct hardware and software play. Failure leads to
		  financial and commercial disaster, human suffering, and
		  fatalities. However, systems are harder to verify than in
		  earlier days. Testing if a system works as intended becomes
		  increasingly difficult. Nowadays, design groups spend 50\%
		  to 70\% of the design time on verification. The cost of the
		  late discovery of bugs is enormous, justifying the fact
		  that, for a typical microprocessor design project, up to
		  half of the overall resources spent are devoted to its
		  verification. Most of the work in heuristic search for
		  automated system verification concentrates on accelerated
		  falsification. With directed automated theorem proving,
		  algorithms like A* and greedy best-first search are
		  integrated in a deductive system.},
  isbn		= {978-0-12-372512-7},
  keywords	= {automated theorem proving,communication
		  protocol,diagnosis,directed model checking,general
		  diagnostic engine,graph transition system,knowledge base
		  anomaly,model checking,Petri net,priced timed
		  automaton,program model checking,real-time system,temporal
		  logic,timed automaton,trail-directed
		  search,validation,verification}
}

@InProceedings{	  edwards05:subtext,
  title		= {Subtext: Uncovering the Simplicity of Programming},
  shorttitle	= {Subtext},
  booktitle	= {Proceedings of the 20th Annual {{ACM SIGPLAN}} Conference
		  on {{Object-oriented}} Programming, Systems, Languages, and
		  Applications},
  author	= {Edwards, Jonathan},
  year		= {2005},
  month		= oct,
  series	= {{{OOPSLA}} '05},
  pages		= {505--518},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1094811.1094851},
  urldate	= {2024-10-30},
  abstract	= {Representing programs as text strings makes programming
		  harder then it has to be. The source text of a program is
		  far removed from its behavior. Bridging this conceptual
		  gulf is what makes programming so inhumanly difficult -- we
		  are not compilers. Subtext is a new medium in which the
		  representation of a program is the same thing as its
		  execution. Like a spreadsheet, a program is visible and
		  alive, constantly executing even as it is edited. Program
		  edits are coherent semantic transformations.The essence of
		  this new medium is copying. Programs are constructed by
		  copying and executed by copy flow: the projection of
		  changes through copies. The simple idea of copying develops
		  into a rich theory of higher-order continual copying of
		  trees. Notably absent are symbolic names, the workhorse of
		  textual notation, replaced by immediately-bound explicit
		  relationships. Subtext unifies traditionally distinct
		  programming tools and concepts, and enables some novel
		  ones. Ancestral structures are a new primitive data type
		  that combines the features of lists and records, along with
		  unproblematic multiple inheritance. Adaptive conditionals
		  use first-class program edits to dynamically adapt
		  behavior.A prototype implementation shows promise, but
		  calls for much further research. Subtext suggests that we
		  can make programming radically easier, if we are willing to
		  be radical.},
  isbn		= {978-1-59593-031-6}
}

@InProceedings{	  elliott97:functional,
  title		= {Functional Reactive Animation},
  booktitle	= {Proceedings of the Second {{ACM SIGPLAN}} International
		  Conference on {{Functional}} Programming},
  author	= {Elliott, Conal and Hudak, Paul},
  year		= {1997},
  month		= aug,
  series	= {{{ICFP}} '97},
  pages		= {263--273},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/258948.258973},
  urldate	= {2024-04-02},
  abstract	= {Fran (Functional Reactive Animation) is a collection of
		  data types and functions for composing richly interactive,
		  multimedia animations. The key ideas in Fran are its
		  notions of behaviors and events. Behaviors are
		  time-varying, reactive values, while events are sets of
		  arbitrarily complex conditions, carrying possibly rich
		  information. Most traditional values can be treated as
		  behaviors, and when images are thus treated, they become
		  animations. Although these notions are captured as data
		  types rather than a programming language, we provide them
		  with a denotational semantics, including a proper treatment
		  of real time, to guide reasoning and implementation. A
		  method to effectively and efficiently perform event
		  detection using interval analysis is also described, which
		  relies on the partial information structure on the domain
		  of event times. Fran has been implemented in Hugs, yielding
		  surprisingly good performance for an interpreter-based
		  system. Several examples are given, including the ability
		  to describe physical phenomena involving gravity, springs,
		  velocity, acceleration, etc. using ordinary differential
		  equations.},
  isbn		= {978-0-89791-918-0}
}

@InProceedings{	  engblom12:review,
  title		= {A Review of Reverse Debugging},
  booktitle	= {Proceedings of the 2012 {{System}}, {{Software}}, {{SoC}}
		  and {{Silicon Debug Conference}}},
  author	= {Engblom, Jakob},
  year		= {2012},
  month		= sep,
  pages		= {1--6},
  issn		= {2114-3684},
  urldate	= {2023-12-13},
  abstract	= {Reverse debugging is the ability of a debugger to stop
		  after a failure in a program has been observed and go back
		  into the history of the execution to uncover the reason for
		  the failure. Long the dream of programmers, over the past
		  decade, reverse execution has become a practical technique
		  available in a number of free and commercial tools. This
		  article will review the history and techniques of reverse
		  debugging, as researched, implemented, and used from the
		  1970s until today. We will provide some personal insights
		  into reverse debugging, from our own practical use of one
		  such tool, Wind River Simics.}
}

@InProceedings{	  english19:exploiting,
  title		= {Exploiting {{Memory Corruption Vulnerabilities}} in
		  {{Connman}} for {{IoT Devices}}},
  booktitle	= {2019 49th {{Annual IEEE}}/{{IFIP International
		  Conference}} on {{Dependable Systems}} and {{Networks}}
		  ({{DSN}})},
  author	= {English, K. Virgil and Obaidat, Islam and Sridhar, Meera},
  year		= {2019},
  month		= jun,
  pages		= {247--255},
  issn		= {1530-0889},
  doi		= {10.1109/DSN.2019.00036},
  urldate	= {2025-01-13},
  abstract	= {In the recent past, there has been a rapid increase in
		  attacks on consumer Internet-of-Things (IoT) devices.
		  Several attacks currently focus on easy targets for
		  exploitation, such as weak configurations (weak default
		  passwords). However, with governments, industries, and
		  organizations proposing new laws and regulations to reduce
		  and prevent such easy targets in the IoT space, attackers
		  will move to more subtle exploits in these devices. Memory
		  corruption vulnerabilities are a significant class of
		  vulnerabilities in software security through which
		  attackers can gain control of the entire system. Numerous
		  memory corruption vulnerabilities have been found in IoT
		  firmware already deployed in the consumer market. This
		  paper presents an approach for exploiting stack-based
		  buffer-overflow attacks in IoT firmware, to hijack the
		  device remotely. To show the feasibility of this approach,
		  we demonstrate exploiting a common network software
		  application, Connman, used widely in IoT firmware such as
		  Samsung smart TVs. A series of experiments are reported on,
		  including: crashing and executing arbitrary code in the
		  targeted software application in a controlled environment,
		  adopting the attacks in uncontrolled environments (with
		  standard software defenses such as W{$\oplus$}X and ASLR
		  enabled), and installing publicly available IoT firmware
		  that uses this software application on a Raspberry Pi. The
		  presented exploits demonstrate the ease in which an
		  adversary can control IoT devices.},
  keywords	= {Password,Servers,Software,Standards,Tools,Wireless
		  fidelity}
}

@Misc{		  espressif-systems23:esp-idf,
  title		= {{{ESP-IDF}} Programming Guide},
  author	= {{Espressif Systems}},
  year		= {2023},
  urldate	= {2023-05},
  keywords	= {ESP-IDF,ESP32,reference}
}

@Misc{		  espressif-systems23:espressif,
  title		= {{{ESPRESSIF}}. {{Espressif}} Offers Integrated, Reliable
		  and Energy-Efficient Wireless {{SoCs}}},
  author	= {{Espressif Systems}},
  year		= {2023},
  urldate	= {2023-05-10},
  lastaccessed	= {May 10, 2023}
}

@Misc{		  espruino21:espruino,
  title		= {Espruino},
  author	= {{Espruino}},
  year		= {2021-12-16, 2021}
}

@Article{	  eugster15:debugging,
  title		= {Debugging the {{Internet}} of {{Things}}: {{The Case}} of
		  {{Wireless Sensor Networks}}},
  shorttitle	= {Debugging the {{Internet}} of {{Things}}},
  author	= {Eugster, Patrick and Sundaram, Vinaitheerthan and Zhang,
		  Xiangyu},
  year		= {2015},
  month		= jan,
  journal	= {IEEE Software},
  volume	= {32},
  number	= {1},
  pages		= {38--49},
  issn		= {1937-4194},
  doi		= {10.1109/MS.2014.132},
  urldate	= {2024-02-29},
  abstract	= {The Internet of Things (IoT) has the strong potential to
		  support a human society interacting more symbiotically with
		  its physical environment. Indeed, the emergence of tiny
		  devices that sense environmental cues and trigger actuators
		  after consulting logic and human preferences promises a
		  more environmentally aware and less wasteful society.
		  However, the IoT inherently challenges software development
		  processes, particularly techniques for ensuring software
		  reliability. Researchers have developed debugging tools for
		  wireless sensor networks (WSNs), which can be viewed as the
		  enablers of perception in the IoT. These tools gather
		  run-time information on individual sensor node executions
		  and node interactions and then compress that information.},
  keywords	= {Computers,debugging,Debugging,Internet of things,Internet
		  of Things,Peer-to-peer computing,replay,Runtime,software
		  engineering,tracing,Wireless communication,wireless sensor
		  networks,Wireless sensor networks}
}

@InProceedings{	  evans66:on-line,
  title		= {On-Line Debugging Techniques: A Survey},
  shorttitle	= {On-Line Debugging Techniques},
  booktitle	= {Proceedings of the {{November}} 7-10, 1966, Fall Joint
		  Computer Conference},
  author	= {Evans, Thomas G. and Darley, D. Lucille},
  year		= {1966},
  month		= nov,
  series	= {{{AFIPS}} '66 ({{Fall}})},
  pages		= {37--50},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1464291.1464295},
  urldate	= {2025-05-07},
  abstract	= {One consequence of recent interest in the development of
		  large-scale time-sharing systems to provide on-line
		  computer access to a large number of users has been the
		  widespread realization that the usefulness of such a system
		  is critically dependent on the quality of the software
		  provided to facilitate the interaction between user and
		  machine. In particular, one area of critical importance for
		  effective utilization of such a system is that of
		  facilities for program debugging. In view of the important
		  role they play, surprisingly little attention has been paid
		  to the development of facilities to aid in the process of
		  on-line program debugging. Furthermore, much of the work in
		  this field has been described only in unpublished reports
		  or passed on through the oral tradition, rather than in the
		  published literature. The purpose of this paper is to
		  survey the existing work in this area and discuss some
		  possible extensions to it, with the dual goal of
		  acquainting a wider public with currently-existing
		  techniques and of stimulating further developments.},
  isbn		= {978-1-4503-7893-2}
}

@InProceedings{	  fang20:iotreplay,
  title		= {{{IoTReplay}}: {{Troubleshooting COTS IoT Devices}} with
		  {{Record}} and {{Replay}}},
  shorttitle	= {{{IoTReplay}}},
  booktitle	= {2020 {{IEEE}}/{{ACM Symposium}} on {{Edge Computing}}
		  ({{SEC}})},
  author	= {Fang, Kaiming and Yan, Guanhua},
  year		= {2020},
  month		= nov,
  pages		= {193--205},
  doi		= {10.1109/SEC50012.2020.00033},
  urldate	= {2025-01-13},
  abstract	= {Internet-of-Things (IoT) devices have been expanding at a
		  blistering pace in recent years. Many of these devices have
		  not been thoroughly tested for their security and
		  dependability prior to shipment. These COTS
		  (Commercial-Off-The-Shelf) IoT devices pose severe security
		  threats to not only their users but also critical
		  infrastructures, as evidenced by the infamous Mirai botnet
		  attack. This work explores how to use the record and replay
		  technique to troubleshoot COTS devices. To this end, we
		  have developed an edge-assisted system called IoTReplay,
		  which identifies contextual events in an IoT system that
		  may affect the operations of the target IoT device. These
		  contextual events are recorded when the IoT device is
		  operating in the real world and then replayed in a test
		  environment. We evaluate the performance of IoTReplay for
		  troubleshooting four different types of COTS IoT devices.
		  Our experiments demonstrate that IoTReplay is able to
		  replay execution sequences of these devices with high
		  fidelity while causing negligible interference with the
		  operations of these IoT devices in the real world.},
  keywords	= {Critical infrastructure,Degradation,Edge
		  computing,Interference,IoT,Object recognition,Performance
		  evaluation,record and replay,Security,troubleshooting}
}

@InProceedings{	  fard17:javascript,
  title		= {{{JavaScript}}: {{The}} (Un)Covered Parts},
  booktitle	= {2017 {{IEEE}} International Conference on Software
		  Testing, Verification and Validation},
  author	= {Fard, Amin Milani and Mesbah, Ali},
  year		= {2017},
  series	= {{{ICST}}},
  pages		= {230--240},
  publisher	= {IEEE},
  address	= {New York, NY, USA},
  doi		= {10.1109/ICST.2017.28}
}

@InProceedings{	  fazzini20:managing,
  title		= {Managing {{App Testing Device Clouds}}: {{Issues}} and
		  {{Opportunities}}},
  shorttitle	= {Managing {{App Testing Device Clouds}}},
  booktitle	= {2020 35th {{IEEE}}/{{ACM International Conference}} on
		  {{Automated Software Engineering}} ({{ASE}})},
  author	= {Fazzini, Mattia and Orso, Alessandro},
  year		= {2020},
  month		= sep,
  pages		= {1257--1259},
  issn		= {2643-1572},
  urldate	= {2025-05-04},
  abstract	= {Because creating and maintaining an in-house test lab is
		  expensive and time-consuming, companies and app developers
		  often use device clouds to test their apps. Because
		  quality-assurance activities depend on such device clouds,
		  it is important to understand possible issues related to
		  their use. To this end, in this paper we present a
		  preliminary study that investigates issues and highlights
		  research opportunities in the context of managing and
		  maintaining device clouds. In the study, we analyzed over
		  12 million test executions on 110 devices. We found that
		  the management software of the cloud infrastructure we
		  considered affected some test executions, and almost all
		  the cloud devices had at least one security-related
		  issue.},
  keywords	= {Monitoring,Object recognition,Performance
		  evaluation,Software,Software engineering,Taxonomy,Testing}
}

@Article{	  feldman88:igor,
  title		= {{{IGOR}}: A System for Program Debugging via Reversible
		  Execution},
  shorttitle	= {{{IGOR}}},
  author	= {Feldman, Stuart I. and Brown, Channing B.},
  year		= {1988},
  month		= nov,
  journal	= {ACM SIGPLAN Notices},
  volume	= {24},
  number	= {1},
  pages		= {112--123},
  issn		= {0362-1340},
  doi		= {10.1145/69215.69226},
  urldate	= {2023-12-14},
  abstract	= {Typical debugging tools are insufficiently powerful to
		  find the most difficult types of program misbehaviors. We
		  have implemented a prototype of a new debugging system,
		  IGOR, which provides a great deal more useful information
		  and offers new abilities that are quite promising. The
		  system runs fast enough to be quite useful while providing
		  many features that are usually available only in an
		  interpreted environment. We describe here some improved
		  facilities (reverse execution, selective searching of
		  execution history, substitution of data and executable
		  parts of the programs) that are needed for serious
		  debugging and are not found in traditional single-thread
		  debugging tools. With a little help from the operating
		  system, we provide these capabilities at reasonable cost
		  without modifying the executable code and running fairly
		  close to full speed. The prototype runs under the DUNE
		  distributed operating system. The current system only
		  supports debugging of single-thread programs. The paper
		  describes planned extensions to make use of extra
		  processors to speed the system and for applying the
		  technique to multi-thread and time dependent executions.}
}

@Book{		  felleisen09:semantics,
  title		= {Semantics Engineering with {{PLT}} Redex},
  author	= {Felleisen, Matthias and Findler, Robert Bruce and Flatt,
		  Matthew},
  year		= {2009},
  publisher	= {Mit Press}
}

@Book{		  felleisen86:control,
  title		= {Control Operators, the {{SECD-machine}}, and the
		  [1]-Calculus},
  author	= {Felleisen, Matthias and Friedman, Daniel P},
  year		= {1986},
  publisher	= {Indiana University, Computer Science Department}
}

@Article{	  feltey18:collapsible,
  title		= {Collapsible Contracts: Fixing a Pathology of Gradual
		  Typing},
  shorttitle	= {Collapsible Contracts},
  author	= {Feltey, Daniel and Greenman, Ben and Scholliers,
		  Christophe and Findler, Robert Bruce and {St-Amour},
		  Vincent},
  year		= {2018},
  month		= oct,
  journal	= {Artifact Virtual Machine Image for Collapsible Contracts:
		  Fixing a Pathology of Gradual Typing},
  volume	= {2},
  number	= {OOPSLA},
  pages		= {133:1--133:27},
  doi		= {10.1145/3276503},
  urldate	= {2024-12-16},
  abstract	= {The promise of gradual typing is that programmers should
		  get the best of both worlds: the static guarantees of
		  static types, and the dynamic flexibility of untyped
		  programming. This is an enticing benefit, but one that, in
		  practice, may carry significant costs. Significant enough,
		  in fact, to threaten the very practicality of gradual
		  typing; slowdowns as high as 120x are reported as arising
		  from gradual typing. If one examines these results closely,
		  though, it becomes clear that the costs of gradual typing
		  are not evenly distributed. Indeed, while mixing typed and
		  untyped code almost invariably carries non-trivial costs,
		  many truly deal-breaking slowdowns exhibit pathological
		  performance. Unfortunately, the very presence of these
		  pathological cases---and therefore the possibility of
		  hitting them during development---makes gradual typing a
		  risky proposition in any setting that even remotely cares
		  about performance. This work attacks one source of large
		  overheads in these pathological cases: an accumulation of
		  contract wrappers that perform redundant checks. The work
		  introduces a novel strategy for contract
		  checking---collapsible contracts---which eliminates this
		  redundancy for function and vector contracts and
		  drastically reduces the overhead of contract wrappers. We
		  implemented this checking strategy as part of the Racket
		  contract system, which is used in the Typed Racket gradual
		  typing system. Our experiments show that our strategy
		  successfully brings a class of pathological cases in line
		  with normal cases, while not introducing an undue overhead
		  to any of the other cases. Our results also show that the
		  performance of gradual typing in Racket remains prohibitive
		  for many programs, but that collapsible contracts are one
		  essential ingredient in reducing the cost of gradual
		  typing.}
}

@Misc{		  fermyon-technologies--inc-23:webassembly,
  title		= {{{WebAssembly}} Language Support Matrix},
  author	= {{Fermyon Technologies, Inc.}},
  year		= {2023},
  urldate	= {2023-01-10},
  lastaccessed	= {January 10, 2023}
}

@Article{	  ferrante87:program,
  title		= {The Program Dependence Graph and Its Use in Optimization},
  author	= {Ferrante, Jeanne and Ottenstein, Karl J. and Warren, Joe
		  D.},
  year		= {1987},
  month		= jul,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {9},
  number	= {3},
  pages		= {319--349},
  issn		= {0164-0925},
  doi		= {10.1145/24039.24041},
  urldate	= {2024-01-22},
  abstract	= {In this paper we present an intermediate program
		  representation, called the program dependence graph (PDG),
		  that makes explicit both the data and control dependences
		  for each operation in a program. Data dependences have been
		  used to represent only the relevant data flow relationships
		  of a program. Control dependences are introduced to
		  analogously represent only the essential control flow
		  relationships of a program. Control dependences are derived
		  from the usual control flow graph. Many traditional
		  optimizations operate more efficiently on the PDG. Since
		  dependences in the PDG connect computationally related
		  parts of the program, a single walk of these dependences is
		  sufficient to perform many optimizations. The PDG allows
		  transformations such as vectorization, that previously
		  required special treatment of control dependence, to be
		  performed in a manner that is uniform for both control and
		  data dependences. Program transformations that require
		  interaction of the two dependence types can also be easily
		  handled with our representation. As an example, an
		  incremental approach to modifying data dependences
		  resulting from branch deletion or loop unrolling is
		  introduced. The PDG supports incremental optimization,
		  permitting transformations to be triggered by one another
		  and applied only to affected dependences.}
}

@Article{	  ferrante87:programa,
  title		= {The Program Dependence Graph and Its Use in Optimization},
  author	= {Ferrante, Jeanne and Ottenstein, Karl J. and Warren, Joe
		  D.},
  year		= {1987},
  month		= jul,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {9},
  number	= {3},
  pages		= {319--349},
  issn		= {0164-0925},
  doi		= {10.1145/24039.24041},
  urldate	= {2024-03-18},
  abstract	= {In this paper we present an intermediate program
		  representation, called the program dependence graph (PDG),
		  that makes explicit both the data and control dependences
		  for each operation in a program. Data dependences have been
		  used to represent only the relevant data flow relationships
		  of a program. Control dependences are introduced to
		  analogously represent only the essential control flow
		  relationships of a program. Control dependences are derived
		  from the usual control flow graph. Many traditional
		  optimizations operate more efficiently on the PDG. Since
		  dependences in the PDG connect computationally related
		  parts of the program, a single walk of these dependences is
		  sufficient to perform many optimizations. The PDG allows
		  transformations such as vectorization, that previously
		  required special treatment of control dependence, to be
		  performed in a manner that is uniform for both control and
		  data dependences. Program transformations that require
		  interaction of the two dependence types can also be easily
		  handled with our representation. As an example, an
		  incremental approach to modifying data dependences
		  resulting from branch deletion or loop unrolling is
		  introduced. The PDG supports incremental optimization,
		  permitting transformations to be triggered by one another
		  and applied only to affected dependences.}
}

@InProceedings{	  ferrari01:debugging,
  title		= {A Debugging Calculus for Mobile Ambients},
  booktitle	= {Proceedings of the 2001 {{ACM}} Symposium on {{Applied}}
		  Computing},
  author	= {Ferrari, GianLuigi and Tuosto, Emilio},
  year		= {2001},
  month		= mar,
  publisher	= {ACM},
  address	= {Las Vegas Nevada USA},
  doi		= {10.1145/372202.380701},
  urldate	= {2025-03-05},
  abstract	= {Advancements in network-aware computing has prompted the
		  studyof novel programming languages with advanced
		  programmingabstractions to support various forms of
		  mobility and to coordinateand monitor the use of resources.
		  This work addresses the issue ofdesigning debuggers for
		  network-aware programming languages. In ourapproach a
		  debugger is viewed as being an extension of theunderlying
		  programming language with suitable debuggingabstractions.
		  We apply this idea to Cardelli and Gordon's AmbientCalculus
		  [3]. The resulting debugger is designed to monitor andtrace
		  executions of mobile ambients by keeping track of
		  causalinformations about events of computations.},
  isbn		= {978-1-58113-287-8},
  langid	= {english}
}

@Misc{		  ferreira24:open,
  title		= {Open {{Bot Brain}}},
  author	= {Ferreira Ruiz, Francisco and Collins, Ben and {al},
		  {\relax et}.},
  year		= {2024},
  abstract	= {Open Bot Brain is an educational project to develop open
		  hardware and software to control Mindstorm Lego motors and
		  sensors. It is developed on GitHub as open hardware and
		  open source software.}
}

@TechReport{	  fielding14:hypertext,
  type		= {Request for {{Comments}}},
  title		= {Hypertext {{Transfer Protocol}} ({{HTTP}}/1.1): {{Message
		  Syntax}} and {{Routing}}},
  shorttitle	= {Hypertext {{Transfer Protocol}} ({{HTTP}}/1.1)},
  author	= {Fielding, Roy T. and Reschke, Julian},
  year		= {2014},
  month		= jun,
  number	= {RFC 7230},
  institution	= {Internet Engineering Task Force},
  doi		= {10.17487/RFC7230},
  urldate	= {2022-04-22},
  abstract	= {The Hypertext Transfer Protocol (HTTP) is a stateless
		  application-level protocol for distributed, collaborative,
		  hypertext information systems. This document provides an
		  overview of HTTP architecture and its associated
		  terminology, defines the "http" and "https" Uniform
		  Resource Identifier (URI) schemes, defines the HTTP/1.1
		  message syntax and parsing requirements, and describes
		  related security concerns for implementations.}
}

@Book{		  flanagan20:javascript,
  title		= {{{JavaScript}}: {{The}} Definitive Guide},
  author	= {Flanagan, David},
  year		= {2020},
  month		= may,
  edition	= {7th.},
  publisher	= {O'Reilly Media, Inc.},
  address	= {Sebastopol, CA, USA},
  isbn		= {978-1-4919-5202-3}
}

@InCollection{	  frattini16:reproducibility,
  title		= {Reproducibility of {{Software Bugs}}},
  booktitle	= {Principles of {{Performance}} and {{Reliability Modeling}}
		  and {{Evaluation}}: {{Essays}} in {{Honor}} of {{Kishor
		  Trivedi}} on His 70th {{Birthday}}},
  author	= {Frattini, Flavio and Pietrantuono, Roberto and Russo,
		  Stefano},
  editor	= {Fiondella, Lance and Puliafito, Antonio},
  year		= {2016},
  pages		= {551--565},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-30599-8_21},
  urldate	= {2024-09-01},
  abstract	= {Understanding software bugs and their effects is important
		  in several engineering activities, including testing,
		  debugging, and design of fault containment or tolerance
		  methods. Dealing with hard-to-reproduce failures requires a
		  deep comprehension of the mechanisms leading from bug
		  activation to software failure. This chapter surveys
		  taxonomies and recent studies about bugs from the
		  perspective of their reproducibility, providing insights
		  into the process of bug manifestation and the factors
		  influencing it. These insights are based on the analysis of
		  thousands of bug reports of a widely used open-source
		  software, namely MySQL Server. Bug reports are
		  automatically classified according to reproducibility
		  characteristics, providing figures about the proportion of
		  hard to reproduce bug their features, and evolution over
		  releases.},
  isbn		= {978-3-319-30599-8},
  langid	= {english},
  keywords	= {Bug Reports,Concurrency Bugs,MySQL Server,Naive Bayes
		  (NB),Workload Requests}
}

@Article{	  freeman91:refinement,
  title		= {Refinement Types for {{ML}}},
  author	= {Freeman, Tim and Pfenning, Frank},
  year		= {1991},
  month		= may,
  journal	= {ACM SIGPLAN Notices},
  volume	= {26},
  number	= {6},
  pages		= {268--277},
  issn		= {0362-1340},
  doi		= {10.1145/113446.113468},
  urldate	= {2023-09-27}
}

@InProceedings{	  friedman84:programming,
  title		= {Programming with {{Continuations}}},
  booktitle	= {Program {{Transformation}} and {{Programming
		  Environments}}},
  author	= {Friedman, Daniel P. and Haynes, Christopher T. and
		  Kohlbecker, Eugene},
  editor	= {Pepper, Peter},
  year		= {1984},
  series	= {{{NATO ASI Series}}},
  pages		= {263--274},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-46490-4_23},
  abstract	= {Progress in programming language design has often been
		  achieved by making an abstraction a ``first class object'',
		  one that can be passed to and returned from procedures and
		  entered in data structures. For example, the importance of
		  functional parameters has long been recognized, though it
		  is only more recently that actor semantics [2] and object
		  oriented programming have demonstrated the power of first
		  class functional objects. This paper illustrates, with a
		  novel example, the power of first class control objects,
		  called continuations.},
  isbn		= {978-3-642-46490-4},
  langid	= {english},
  keywords	= {Class Object,Common Lisp,Lambda Calculus,Lambda
		  Expression,Single Argument}
}

@InCollection{	  front,
  title		= {Front {{Matter}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {i-xxix},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.fmatter},
  urldate	= {2024-12-04},
  abstract	= {The prelims comprise: Half-Title Page Dedication Title
		  Page Copyright Page Table of Contents Preface Glossary},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InCollection{	  fundamentals,
  title		= {Fundamentals of {{Testing}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {1--41},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch1},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Why is testing
		  necessary? (FL 1.1) What is testing? (FL 1.2) Paradoxes and
		  main principles (FL 1.3) Fundamental test process (FL 1.4)
		  Psychology of testing (FL 1.5) Testers and code of ethics
		  (FL 1.6) Synopsis of this chapter Sample exam questions},
  chapter	= {1},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Association for Computing Machinery (ACM),International
		  Software Testing Qualifications Board (ISTQB),National
		  Aeronautics and Space Administration (NASA's),Random-access
		  memory (RAM),Service level agreement (SLA),Software
		  systems}
}

@Article{	  gait86:probe,
  title		= {A Probe Effect in Concurrent Programs},
  author	= {Gait, Jason},
  year		= {1986},
  journal	= {Software: Practice and Experience},
  volume	= {16},
  number	= {3},
  pages		= {225--233},
  issn		= {1097-024X},
  doi		= {10.1002/spe.4380160304},
  urldate	= {2024-08-31},
  abstract	= {This paper reports on an experimental study of the probe
		  effect, defined as an alteration in the frequency of
		  run-time computational errors observed when delays are
		  introduced into concurrent programs. If the concurrent
		  program being studied has no synchronization errors, then
		  there is no probe effect. In the presence of
		  synchronization errors, the frequency of observable output
		  errors for a sample experimental program starts at a high
		  value for small delays, oscillates rapidly as the delay is
		  increased, and apparently settles at zero errors for larger
		  values of delay. Thus, for sufficiently large delays, the
		  probe effect can almost completely mask synchronization
		  errors in concurrent programs. For sufficiently large
		  concurrent process sets, even small values of embedded
		  delay may mask synchronization errors, provided side
		  effects in shared memory are not included in the
		  observation.},
  copyright	= {Copyright {\copyright} 1986 John Wiley \& Sons, Ltd},
  langid	= {english},
  keywords	= {Concurrent programming,Debugging concurrent
		  programs,Embedded delays,Probe effect,Shared-memory side
		  effect,Synchronization errors}
}

@Book{		  gamma94:design,
  title		= {Design Patterns: {{Elements}} of Reusable Object-Oriented
		  Software},
  author	= {Gamma, Erich and Vlissides, John and Helm, Richard and
		  Johnson, Ralph E.},
  year		= {1994}
}

@InProceedings{	  garcia-ferreira14:survey,
  title		= {A {{Survey}} on {{Static Analysis}} and {{Model
		  Checking}}},
  booktitle	= {International {{Joint Conference
		  SOCO}}'14-{{CISIS}}'14-{{ICEUTE}}'14},
  author	= {{Garc{\'i}a-Ferreira}, Iv{\'a}n and Laorden, Carlos and
		  Santos, Igor and Bringas, Pablo Garc{\'i}a},
  editor	= {{de la Puerta}, Jos{\'e} Gaviria and Ferreira, Iv{\'a}n
		  Garc{\'i}a and Bringas, Pablo Garcia and Klett, Fanny and
		  Abraham, Ajith and {de Carvalho}, Andr{\'e} C.P.L.F. and
		  Herrero, {\'A}lvaro and Baruque, Bruno and Quinti{\'a}n,
		  H{\'e}ctor and Corchado, Emilio},
  year		= {2014},
  pages		= {443--452},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-07995-0_44},
  abstract	= {The error detection in software is a problem that causes
		  the loss of large amount of money in updates and patches.
		  Many programmers spend their time correcting code instead
		  of programming new features for their applications. This
		  makes early detection of software errors become essential.
		  Both in the fields of static analysis and model checking,
		  great advances are being made to find errors in the
		  software before the products are released. Although model
		  checking techniques are more dedicated to find malware, it
		  can be adapted for errors in the software. In this article
		  we will discuss the techniques used today for the search of
		  patterns and vulnerabilities within the software to know
		  what are the possible solutions to this issue. We examine
		  the problem from the point of view of their algorithms and
		  their effectiveness in finding bugs. Although there are
		  similar surveys, none of them addresses the comparison of
		  best static analysis algorithms against the best
		  mathematical logic languages for model checking, two fields
		  that are becoming very important in the search for errors
		  in software.},
  isbn		= {978-3-319-07995-0},
  langid	= {english}
}

@Misc{		  gdb,
  title		= {{{GDB}}: {{The GNU Project Debugger}}},
  author	= {{Free Software Foundation}},
  urldate	= {2025-03-01},
  collaborator	= {Stallman, Richard and Gilmore, John},
  howpublished	= {https://sourceware.org/gdb/}
}

@Article{	  geller24:indexed,
  title		= {Indexed {{Types}} for a {{Statically Safe WebAssembly}}},
  author	= {Geller, Adam T. and Frank, Justin and Bowman, William J.},
  year		= {2024},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {8},
  number	= {POPL},
  pages		= {80:2395--80:2424},
  doi		= {10.1145/3632922},
  urldate	= {2024-01-12},
  abstract	= {We present Wasm-prechk, a superset of WebAssembly (Wasm)
		  that uses indexed types to express and check simple
		  constraints over program values. This additional static
		  reasoning enables safely removing dynamic safety checks
		  from Wasm, such as memory bounds checks. We implement
		  Wasm-prechk as an extension of the Wasmtime compiler and
		  runtime, evaluate the run-time and compile-time performance
		  of Wasm-prechk vs WebAssembly configurations with explicit
		  dynamic checks, and find an average run-time performance
		  gain of 1.71x faster in the widely used PolyBenchC
		  benchmark suite, for a small overhead in binary size
		  (7.18\% larger) and type-checking time (1.4\% slower). We
		  also prove type and memory safety of Wasm-prechk, prove
		  Wasm safely embeds into Wasm-prechk ensuring backwards
		  compatibility, prove Wasm-prechk type-erases to Wasm, and
		  discuss design and implementation trade-offs.},
  keywords	= {Indexed Types,Optimization and Compiler Design,Program
		  Logics,Type Systems,WebAssembly}
}

@Misc{		  george21:micropython,
  title		= {{{MicroPython}}},
  author	= {George, Damien},
  year		= {2021-12-16, 2021}
}

@Article{	  ghica22:high-level,
  title		= {High-Level Effect Handlers in {{C}}++},
  author	= {Ghica, Dan and Lindley, Sam and Bravo, Marcos Maro{\~n}as
		  and Pir{\'o}g, Maciej},
  year		= {2022},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {OOPSLA2},
  pages		= {183:1639--183:1667},
  doi		= {10.1145/3563445},
  urldate	= {2023-12-08},
  abstract	= {Effect handlers allow the programmer to implement
		  computational effects, such as custom error handling,
		  various forms of lightweight concurrency, and dynamic
		  binding, inside the programming language. We introduce
		  cpp-effects, a C++ library for effect handlers with a typed
		  high-level, object-oriented interface. We demonstrate that
		  effect handlers can be successfully applied in imperative
		  systems programming languages with manual memory
		  management. Through a collection of examples, we explore
		  how to program effectively with effect handlers in C++,
		  discuss the intricacies and challenges of the
		  implementation, and show that despite its limitations,
		  cpp-effects performance is competitive and in some cases
		  even outperforms state-of-the-art approaches such as C++20
		  coroutines and the libmprompt library for multiprompt
		  delimited control.},
  keywords	= {algebraic effects,context switching,Effect
		  handlers,lightweight concurrency}
}

@InProceedings{	  giachino14:causal-consistent-reversible-debugging,
  title		= {Causal-{{Consistent Reversible Debugging}}},
  booktitle	= {Fundamental {{Approaches}} to {{Software Engineering}}},
  author	= {Giachino, Elena and Lanese, Ivan and Mezzina, Claudio
		  Antares},
  editor	= {Gnesi, Stefania and Rensink, Arend},
  year		= {2014},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {370--384},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-54804-8_26},
  abstract	= {Reversible debugging provides developers with a way to
		  execute their applications both forward and backward,
		  seeking the cause of an unexpected or undesired event. In a
		  concurrent setting, reversing actions in the exact reverse
		  order in which they have been executed may lead to undo
		  many actions that were not related to the bug under
		  analysis. On the other hand, undoing actions in some order
		  that violates causal dependencies may lead to states that
		  could not be reached in a forward execution. We propose an
		  approach based on causal-consistent reversibility: each
		  action can be reversed if all its consequences have already
		  been reversed. The main feature of the approach is that it
		  allows the programmer to easily individuate and undo
		  exactly the actions that caused a given misbehavior till
		  the corresponding bug is reached. This paper major
		  contribution is the individuation of the appropriate
		  primitives for causal-consistent reversible debugging and
		  their prototype implementation in the CaReDeb tool. We also
		  show how to apply CaReDeb to individuate common real-world
		  concurrent bugs.},
  isbn		= {978-3-642-54804-8},
  langid	= {english},
  keywords	= {Atomicity Violation,Causal Dependency,Causality
		  Information,FIFO Queue,Port Result}
}

@Book{		  giouroukis19:resense,
  title		= {Resense: {{Transparent Record}} and {{Replay}} of {{Sensor
		  Data}} in the {{Internet}} of {{Things}}},
  shorttitle	= {Resense},
  author	= {Giouroukis, Dimitris and H{\"u}lsmann, Julius and {von
		  Bleichert}, Janis and Geldenhuys, Morgan and Stullich, Tim
		  and Gutierrez, Felipe and Traub, Jonas and Beedkar,
		  Kaustubh and Markl, Volker},
  year		= {2019},
  month		= mar,
  abstract	= {As the scientific interest in the Internet of Things (IoT)
		  continues to grow, emulating IoT infrastructure involving a
		  large number of heterogeneous sensors plays a crucial role.
		  Existing research on emulating sensors is often tailored to
		  specific hardware and/or software, which makes it difficult
		  to reproduce and extend. In this paper we show how to
		  emulate different kinds of sensors in a unified way that
		  makes the downstream application agnostic as to whether the
		  sensor data is acquired from real sensors or is read from
		  memory using emulated sensors. We propose the Resense
		  framework that allows for replaying sensor data using
		  emulated sensors and provides an easy-to-use software for
		  setting up and executing IoT experiments involving a large
		  number of heterogeneous sensors. We demonstrate various
		  aspects of Resense in the context of a sports analytics
		  application using real-world sensor data and a set of
		  Raspberry Pis.}
}

@InProceedings{	  giuffrida10:taxonomy,
  title		= {A {{Taxonomy}} of {{Live Updates}}},
  booktitle	= {Proceedings of the 16th {{Annual Conference}} of the
		  {{Advanced School}} for {{Computing}} and {{Imaging}}},
  author	= {Giuffrida, C. and Tanenbaum, A.S.},
  year		= {2010}
}

@Article{	  gluck16:linear-time-self-interpreter,
  title		= {A {{Linear-Time Self-Interpreter}} of a {{Reversible
		  Imperative Language}}},
  author	= {Gl{\"u}ck, Robert and Yokoyama, Tetsuo},
  year		= {2016},
  month		= sep,
  journal	= {Information and Media Technologies},
  pages		= {160--180},
  doi		= {10.11185/imt.11.160},
  abstract	= {A linear-time reversible self-interpreter in an r-Turing
		  complete reversible imperative language is presented. The
		  proposed imperative language has reversible structured
		  control ow operators and symbolic tree-structured data
		  (S-expressions). The latter data structures are dynamically
		  allocated and enable reversible simulation of programs of
		  arbitrary size and space consumption. As self-interpreters
		  are used to show a number of fundamental properties in
		  classic computability and complexity theory, the present
		  study of an efficient reversible self-interpreter is
		  intended as a basis for future work on reversible
		  computability and complexity theory as well as programming
		  language theory for reversible computing. Although the
		  proposed reversible interpreter consumes superlinear space,
		  the restriction of the number of variables in the source
		  language leads to linear-time reversible simulation.}
}

@Article{	  gluck23:reversible,
  title		= {Reversible Computing from a Programming Language
		  Perspective},
  author	= {Gl{\"u}ck, Robert and Yokoyama, Tetsuo},
  year		= {2023},
  month		= apr,
  journal	= {Theoretical Computer Science},
  volume	= {953},
  pages		= {113429},
  issn		= {0304-3975},
  doi		= {10.1016/j.tcs.2022.06.010},
  urldate	= {2023-09-28},
  abstract	= {Software plays a central role in all aspects of reversible
		  computing systems, and a variety of reversible programming
		  languages have been developed. This presentation highlights
		  the principles and main ideas of reversible computing
		  viewed from a programming language perspective with a focus
		  on clean reversible languages. They are the building
		  material for software that can reap the benefits of
		  reversible hardware and interesting in their own right.
		  Reversible computing is situated within programming
		  languages in general, and the relevant concepts are
		  elaborated, including computability, injectivization and
		  reversibilization. Features representative for many
		  reversible languages are presented, such as reversible
		  updates, reversible iterations, and access to a program's
		  inverse semantics. Metaprogramming methods of particular
		  importance to reversible programming, are introduced,
		  including program inversion and inverse interpretation. Our
		  presentation is independent of a particular language,
		  although primarily the reversible language, Janus, will be
		  used in examples.},
  keywords	= {Compute-uncompute,Function injectivization,Inverse
		  interpretation,Metacomputation,Program inversion,Program
		  reversibilization,Reversible computing,Reversible
		  programming}
}

@Article{	  gluhak11:survey,
  title		= {A Survey on Facilities for Experimental Internet of Things
		  Research},
  author	= {Gluhak, A. and Krco, S. and Nati, M. and Pfisterer, D. and
		  Mitton, N. and Razafindralambo, T.},
  year		= {2011},
  journal	= {IEEE Communications Magazine},
  volume	= {49},
  number	= {11},
  pages		= {58--67},
  doi		= {10.1109/MCOM.2011.6069710},
  abstract	= {The initial vision of the Internet of Things was of a
		  world in which all physical objects are tagged and uniquely
		  identified by RFID transponders. However, the concept has
		  grown into multiple dimensions, encompassing sensor
		  networks able to provide real-world intelligence and
		  goal-oriented collaboration of distributed smart objects
		  via local networks or global interconnections such as the
		  Internet. Despite significant technological advances,
		  difficulties associated with the evaluation of IoT
		  solutions under realistic conditions in real-world
		  experimental deployments still hamper their maturation and
		  significant rollout. In this article we identify
		  requirements for the next generation of IoT experimental
		  facilities. While providing a taxonomy, we also survey
		  currently available research testbeds, identify existing
		  gaps, and suggest new directions based on experience from
		  recent efforts in this field. {\copyright} 2011 IEEE.}
}

@Article{	  godefroid05:dart,
  title		= {{{DART}}: Directed Automated Random Testing},
  shorttitle	= {{{DART}}},
  author	= {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
  year		= {2005},
  month		= jun,
  journal	= {SIGPLAN Not.},
  volume	= {40},
  number	= {6},
  pages		= {213--223},
  issn		= {0362-1340},
  doi		= {10.1145/1064978.1065036},
  urldate	= {2025-03-11},
  abstract	= {We present a new tool, named DART, for automatically
		  testing software that combines three main techniques: (1)
		  automated extraction of the interface of a program with its
		  external environment using static source-code parsing; (2)
		  automatic generation of a test driver for this interface
		  that performs random testing to simulate the most general
		  environment the program can operate in; and (3) dynamic
		  analysis of how the program behaves under random testing
		  and automatic generation of new test inputs to direct
		  systematically the execution along alternative program
		  paths. Together, these three techniques constitute Directed
		  Automated Random Testing, or DART for short. The main
		  strength of DART is thus that testing can be performed
		  completely automatically on any program that compiles --
		  there is no need to write any test driver or harness code.
		  During testing, DART detects standard errors such as
		  program crashes, assertion violations, and non-termination.
		  Preliminary experiments to unit test several examples of C
		  programs are very encouraging.}
}

@InProceedings{	  godefroid97:model,
  title		= {Model Checking for Programming Languages Using
		  {{VeriSoft}}},
  booktitle	= {Proceedings of the 24th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Godefroid, Patrice},
  year		= {1997},
  month		= jan,
  series	= {{{POPL}} '97},
  pages		= {174--186},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/263699.263717},
  urldate	= {2025-03-11},
  abstract	= {Verification by state-space exploration, also often
		  referred to as "model checking", is an effective method for
		  analyzing the correctness of concurrent reactive systems
		  (e.g., communication protocols). Unfortunately, existing
		  model-checking techniques are restricted to the
		  verification of properties of models, i.e., abstractions,
		  of concurrent systems.In this paper, we discuss how model
		  checking can be extended to deal directly with "actual"
		  descriptions of concurrent systems, e.g., implementations
		  of communication protocols written in programming languages
		  such as C or C++. We then introduce a new search technique
		  that is suitable for exploring the state spaces of such
		  systems. This algorithm has been implemented in VeriSoft, a
		  tool for systematically exploring the state spaces of
		  systems composed of several concurrent processes executing
		  arbitrary C code. As an example of application, we describe
		  how VeriSoft successfully discovered an error in a
		  2500-line C program controlling robots operating in an
		  unpredictable environment.},
  isbn		= {978-0-89791-853-4}
}

@Misc{		  googletest23:googletest,
  title		= {{{GoogleTest}} User's Guide},
  author	= {{GoogleTest}},
  year		= {2023},
  urldate	= {2023-02-15},
  lastaccessed	= {February 15, 2023}
}

@Book{		  gosling96:java-language-specification,
  title		= {The {{Java Language Specification}}},
  author	= {Gosling, James and Joy, Bill and Steele, Guy L.},
  year		= {1996},
  edition	= {1},
  publisher	= {Addison-Wesley Longman Publishing Co., Inc.},
  address	= {Boston, MA, USA},
  isbn		= {0-201-63451-1}
}

@Article{	  graf20:lower,
  title		= {Lower Your Guards: A Compositional Pattern-Match Coverage
		  Checker},
  shorttitle	= {Lower Your Guards},
  author	= {Graf, Sebastian and Peyton Jones, Simon and Scott, Ryan
		  G.},
  year		= {2020},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {ICFP},
  pages		= {107:1--107:30},
  doi		= {10.1145/3408989},
  urldate	= {2023-09-26},
  abstract	= {A compiler should warn if a function defined by pattern
		  matching does not cover its inputs---that is, if there are
		  missing or redundant patterns. Generating such warnings
		  accurately is difficult for modern languages due to the
		  myriad of language features that interact with pattern
		  matching. This is especially true in Haskell, a language
		  with a complicated pattern language that is made even more
		  complex by extensions offered by the Glasgow Haskell
		  Compiler (GHC). Although GHC has spent a significant amount
		  of effort towards improving its pattern-match coverage
		  warnings, there are still several cases where it reports
		  inaccurate warnings. We introduce a coverage checking
		  algorithm called Lower Your Guards, which boils down the
		  complexities of pattern matching into guard trees. While
		  the source language may have many exotic forms of patterns,
		  guard trees only have three different constructs, which
		  vastly simplifies the coverage checking process. Our
		  algorithm is modular, allowing for new forms of
		  source-language patterns to be handled with little changes
		  to the overall structure of the algorithm. We have
		  implemented the algorithm in GHC and demonstrate places
		  where it performs better than GHC's current coverage
		  checker, both in accuracy and performance.},
  keywords	= {guards,Haskell,pattern matching,strictness}
}

@InProceedings{	  graver89:type,
  title		= {A Type System for {{Smalltalk}}},
  booktitle	= {Proceedings of the 17th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Graver, Justin O. and Johnson, Ralph E.},
  year		= {1989},
  month		= dec,
  series	= {{{POPL}} '90},
  pages		= {136--150},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/96709.96722},
  urldate	= {2023-10-20},
  abstract	= {This paper describes a type system for Smalltalk that is
		  type-safe, that allows most Smalltalk programs to be
		  type-checked, and that can be used as the basis of an
		  optimizing compiler.},
  isbn		= {978-0-89791-343-0}
}

@Article{	  green60:ipl-v,
  title		= {{{IPL-V}}: {{The Newell-Shaw-Simon Programming
		  Language}}},
  shorttitle	= {{{IPL-V}}},
  author	= {Green, Bert F.},
  year		= {1960},
  journal	= {Behavioral Science},
  volume	= {5},
  number	= {1},
  pages		= {94--100},
  publisher	= {University of Michigan, Mental Health Research Institute},
  address	= {Baltimore, Md., United States},
  issn		= {0005-7940},
  urldate	= {2025-05-09},
  langid	= {english},
  keywords	= {Psychology,Social Sciences (General)}
}

@Article{	  grigore17:java,
  title		= {Java Generics Are Turing Complete},
  author	= {Grigore, Radu},
  year		= {2017},
  month		= jan,
  journal	= {ACM SIGPLAN Notices},
  volume	= {52},
  number	= {1},
  pages		= {73--85},
  issn		= {0362-1340},
  doi		= {10.1145/3093333.3009871},
  urldate	= {2024-01-12},
  abstract	= {This paper describes a reduction from the halting problem
		  of Turing machines to subtype checking in Java. It follows
		  that subtype checking in Java is undecidable, which answers
		  a question posed by Kennedy and Pierce in 2007. It also
		  follows that Java's type checker can recognize any
		  recursive language, which improves a result of Gill and
		  Levy from 2016. The latter point is illustrated by a parser
		  generator for fluent interfaces.},
  keywords	= {decidability,fluent interface,Java,parser
		  generator,subtype checking,Turing machine}
}

@Book{		  gruber23:debugging,
  title		= {Debugging {{Flaky Tests}} Using {{Spectrum-based Fault
		  Localization}}},
  author	= {Gruber, Martin and Fraser, Gordon},
  year		= {2023},
  month		= may,
  pages		= {139},
  doi		= {10.1109/AST58925.2023.00017}
}

@Misc{		  gu23:understanding,
  title		= {Understanding and {{Supporting Debugging Workflows}} in
		  {{Multiverse Analysis}}},
  author	= {Gu, Ken and Jun, Eunice and Althoff, Tim},
  year		= {2023},
  month		= jun,
  number	= {arXiv:2210.03804},
  eprint	= {2210.03804},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2210.03804},
  urldate	= {2024-05-13},
  abstract	= {Multiverse analysis, a paradigm for statistical analysis
		  that considers all combinations of reasonable analysis
		  choices in parallel, promises to improve transparency and
		  reproducibility. Although recent tools help analysts
		  specify multiverse analyses, they remain difficult to use
		  in practice. In this work, we identify debugging as a key
		  barrier due to the latency from running analyses to
		  detecting bugs and the scale of metadata processing needed
		  to diagnose a bug. To address these challenges, we
		  prototype a command-line interface tool, Multiverse
		  Debugger, which helps diagnose bugs in the multiverse and
		  propagate fixes. In a qualitative lab study (n=13), we use
		  Multiverse Debugger as a probe to develop a model of
		  debugging workflows and identify specific challenges,
		  including difficulty in understanding the multiverse's
		  composition. We conclude with design implications for
		  future multiverse analysis authoring systems.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Human-Computer Interaction,Computer
		  Science - Software Engineering}
}

@Article{	  guerraoui99:what,
  title		= {What Object-Oriented Distributed Programming Does Not Have
		  to Be, and What It May Be},
  author	= {Guerraoui, R.},
  year		= {1999},
  journal	= {Informatik}
}

@InProceedings{	  gupta21:survey,
  title		= {A {{Survey}} of {{Application Layer Protocols}} for
		  {{Internet}} of {{Things}}},
  booktitle	= {2021 {{International Conference}} on {{Communication}}
		  Information and {{Computing Technology}} ({{ICCICT}})},
  author	= {Gupta, Poonam and M, Indhra Om Prabha.},
  year		= {2021},
  month		= jun,
  pages		= {1--6},
  doi		= {10.1109/ICCICT50803.2021.9510140},
  urldate	= {2025-05-20},
  abstract	= {The application layer protocol plays a significant part in
		  IoT framework as it enables the communication between
		  things, devices or objects with the application interfaces.
		  These protocols are expected to guarantee security, speed,
		  low latency, less power consumption, reliability and
		  efficient transfer of information between the devices.
		  There are several application layer protocols available
		  like Constrained Application Protocol (CoAP), Message Queue
		  Telemetry Transport (MQTT), Websocket, Extensible Messaging
		  and Presence Protocol (XMPP), Advanced Message Queuing
		  Protocol (AMQP), Representational State Transfer (RESTFUL
		  Services) and Data Distribution Services (DDS) that are
		  employed in practice. The suitable protocol is selected
		  based on the nature and requirements of the IoT system.
		  However there are no standard guidelines in deciding a
		  particular protocol for the IoT application. There is
		  always uncertainty in deciding the application protocol
		  suitable for the IoT requirements. Thereby, it is
		  inevitable to know the strengths and weakness of the widely
		  accepted protocols to determine the best-fit scenarios.
		  Amongst these CoAP and MQTT are the most diffused protocols
		  in the IoT landscape. This paper surveys five established
		  protocols -- CoAP, MQTT, Websocket, XMPP and AMQP. It
		  discusses the origin of these protocols, the general
		  characteristics, advantages and limitations. Furthermore,
		  the paper does an in-depth comparative analysis of the
		  protocols against the suitability of application areas.
		  Additionally, the paper also explains the standard
		  implementation architecture of the protocols. Thus the
		  detailed evaluation will result in helping to choose the
		  best suited protocol for any given IoT system.},
  keywords	= {AMQP,CoAP,Computer architecture,Internet of
		  Things,MQTT,Protocols,Quality of service,Representational
		  state
		  transfer,RESTFUL,Security,Uncertainty,Websocket,XMPP}
}

@Article{	  gupta96:formal,
  title		= {A Formal Framework for On-Line Software Version Change},
  author	= {Gupta, D. and Jalote, P. and Barua, G.},
  year		= {1996},
  month		= feb,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {22},
  number	= {2},
  pages		= {120--131},
  issn		= {1939-3520},
  doi		= {10.1109/32.485222},
  urldate	= {2024-01-15},
  abstract	= {The usual way of installing a new version of a software
		  system is to shut down the running program and then install
		  the new version. This necessitates a sometimes unacceptable
		  delay during which service is denied to the users of the
		  software. An online software replacement system replaces
		  parts of the software while it is in execution, thus
		  eliminating the shutdown. While a number of implementations
		  of online version change systems have been described in the
		  literature, little investigation has been done on its
		  theoretical aspects. We describe a formal framework for
		  studying online software version change. We give a general
		  definition of validity of an online change, show that it is
		  in general undecidable and then develop sufficient
		  conditions for ensuring validity for a procedural
		  language.}
}

@Article{	  gurdeep19:multiverse,
  title		= {Multiverse {{Debugging}}: {{Non-Deterministic Debugging}}
		  for {{Non-Deterministic Programs}} ({{Artifact}})},
  shorttitle	= {Multiverse {{Debugging}}},
  author	= {Gurdeep Singh, Robbert and Torres Lopez, Carmen and Marr,
		  Stefan and Gonzalez Boix, Elisa and Scholliers,
		  Christophe},
  year		= {2019},
  journal	= {Dagstuhl Artifacts Series},
  volume	= {5},
  number	= {2},
  pages		= {4:1-4:3},
  publisher	= {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  issn		= {2509-8195},
  doi		= {10.4230/DARTS.5.2.4},
  urldate	= {2024-11-12},
  abstract	= {Many of today's software systems are parallel or
		  concurrent. With the rise of Node.js and more generally
		  event-loop architectures, many systems need to handle
		  concurrency. However, their non-deterministic behavior
		  makes it hard to debug. Today's interactive debuggers
		  unfortunately do not support developers in debugging
		  non-deterministic issues. They only allow exploring a
		  single execution path. Therefore, some bugs may never be
		  reproduced in the debugging session, because the conditions
		  to trigger are not reached. As a solution, we propose
		  multiverse debugging, a new approach for debugging
		  non-deterministic programs that allow developers to observe
		  all possible execution paths of a parallel program and
		  debug it interactively. We introduce the concepts of
		  multiverse breakpoints and stepping, which can halt a
		  program in different execution paths, i.e. universes. We
		  apply multiverse debugging to AmbientTalk, an actor-based
		  language, resulting in Voyager, a proof of concept
		  multiverse debugger that takes as input Featherweight
		  AmbientTalk programs written in PLT-Redex, and allows
		  programmers to interactively browse all possible execution
		  states by means of multiverse breakpoints and stepping
		  commands. We provide a proof of non-interference, i.e we
		  prove that observing the behavior of a program by the
		  debugger does not affect the behavior of that program and
		  vice versa. Multiverse debugging establishes the foundation
		  for debugging non-deterministic programs interactively,
		  which we believe can aid the development of parallel and
		  concurrent systems.},
  copyright	= {https://creativecommons.org/licenses/by/3.0/de/legalcode},
  langid	= {english}
}

@InProceedings{	  gurdeep19:warduino,
  title		= {{{WARDuino}}: A Dynamic {{WebAssembly}} Virtual Machine
		  for Programming Microcontrollers},
  shorttitle	= {{{WARDuino}}},
  booktitle	= {Proceedings of the 16th {{ACM SIGPLAN International
		  Conference}} on {{Managed Programming Languages}} and
		  {{Runtimes}}},
  author	= {Gurdeep Singh, Robbert and Scholliers, Christophe},
  year		= {2019},
  month		= oct,
  series	= {{{MPLR}} 2019},
  pages		= {27--36},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3357390.3361029},
  urldate	= {2023-09-26},
  abstract	= {It is extremely hard and time-consuming to make correct
		  and efficient programs for microcontrollers. Usually
		  microcontrollers are programmed in a low level programming
		  language such as C which makes them hard to debug and
		  maintain. To raise the abstraction level, many high level
		  programming languages have provided support for programming
		  microcontrollers. Examples include Python, Lua, C\# and
		  JavaScript. Using these languages has the downside that
		  they are orders of magnitude slower than the low-level
		  languages. Moreover, they often provide no remote debugging
		  support. In this paper we investigate the feasibility of
		  using WebAssembly to program Arduino compatible
		  microcontrollers. Our experiments lead to extending the
		  standard WebAssembly VM with: 1) safe live code updates for
		  functions and data 2) remote debugging support at the VM
		  level 3) programmer configurable (Arduino) modules in order
		  to keep the virtual machine's footprint as small as
		  possible. The resulting WARDuino VM enables the programmer
		  to have better performance than an interpreted approach
		  while simultaneously increasing the ease of development. To
		  evaluate our approach, we implemented a simple breakout
		  game and conducted micro benchmarks which show that the VM
		  runs approximately 5 times faster than Espruino, a popular
		  JavaScript interpreter for the ESP32 microcontroller.},
  isbn		= {978-1-4503-6977-0},
  keywords	= {Arduino,Live Code Updates,Virtual Machine,WebAssembly}
}

@PhDThesis{	  gurdeep22:taming,
  title		= {Taming Nondeterminism : Programming Language Abstractions
		  and Tools for Dealing with Nondeterministic Programs},
  shorttitle	= {Taming Nondeterminism},
  author	= {Gurdeep Singh, Robbert},
  year		= {2022},
  urldate	= {2024-08-29},
  abstract	= {Computer programs need to deal with nondeterministic
		  environments. This nondeterminism may arise from many
		  sources, like user input and concurrency for example. If
		  program input were to be deterministic, there would be no
		  need for complex programs. A word processor with
		  deterministic input can simply present the user with their
		  envisioned written document without them having to type it.
		  Nondeterminism caused by concurrency stems from the unknown
		  speed of each thread, the possibility of lost messages and
		  so on. Although it leads to nondeterministic execution, we
		  sometimes need it to fulfill real-world demands such as
		  execution performance and high availability. If a program
		  is nondeterministic, the next state may be one of multiple
		  possibilities. When writing the program, the developer must
		  imagine all possible executions to prevent bugs. Even if
		  there are only two possibilities per program step, there
		  are 2{\textasciicircum}n possible executions of n steps.
		  This exponential state explosion is what makes working with
		  nondeterminism so difficult. If a failure occurs in one of
		  the myriad of execution traces, it is difficult to find its
		  root cause. Typical debuggers only allow users the debug
		  just one of the possible traces, while the failure may only
		  manifest in very rare execution traces. Both humans and
		  computers cannot deal with state explosion well.
		  Programming languages have nondeterminism introducing
		  constructs to facilitate working in nondeterministic
		  environments. There are constructs for acquiring input,
		  starting concurrent threads and so on. The chosen
		  constructs greatly impact the nondeterminism the programmer
		  has to deal with. In this dissertation we investigate the
		  tree main ways programming systems can work with
		  nondeterminism: embrace it, capture it, and avoid it.
		  First, to embrace nondeterminism we must have the tools to
		  deal with the state explosion it generates. In this
		  dissertation, we present a tool called GraphRedex, which
		  allows exploring the state space graph of nondeterministic
		  programs. Our tool contributes a novel exploration
		  technique for dealing with state explosion: interactive
		  exploration. We allow developers to choose what path in the
		  state space graph they want to follow. This helps
		  developers see the wood for the trees when visualizing all
		  possible execution paths of a program. We conducted a user
		  study to confirm GraphRedex is user friendly and helps
		  uncover bugs. Additionally, we used it to find errors in
		  published research. A second option is to capture the
		  nondeterminism. When something goes wrong in a program's
		  execution, it is often difficult to determine the exact
		  conditions that triggered a bug. By keeping track of the
		  nondeterministic choices the program makes during its
		  execution, we can replay them, even backwards. If the
		  program failed, stepping backwards can help find the bug
		  that caused the failure. We have implemented such a
		  backwards stepping functionality for a platform that is
		  notoriously difficult to debug or even write programs for:
		  microcontrollers. To do this, we created a WebAssembly
		  virtual machine (VM) for these devices. Our VM, WARDuino
		  allows programmers to use higher level languages to program
		  microcontrollers. A language interoperability layer ensures
		  that device peripherals are safely accessible. While higher
		  level languages alone already prevent bugs, WARDuino
		  additionally allows debugging applications remotely via a
		  VSCode plugin. We show that our novel event-based
		  out-of-place debugging technique reduces debugging latency
		  and permits backwards stepping. Additionally, we determine
		  that WARDuino is fast enough to implement IoT applications
		  by carrying out micro benchmarks. Third, nondeterminism can
		  be avoided by carefully selecting the provided language
		  constructs. As an example of this approach, this
		  dissertation presents Gaiwan. This is a general-purpose GPU
		  (GPGPU) programming language intended for processing time
		  series data. The language is based on a novel
		  size-polymorphic type system we designed and implemented
		  Additionally, Gaiwan only features race condition free
		  constructs. By using our language, non-expert GPGPU users
		  avoid two sources of nondeterminism: the nondeterministic
		  size of the input, and the nondeterminism arising from data
		  races on these extremely parallel devices. Gaiwan's type
		  system allows developers to use affine functions in one
		  variable to declare the effect parts of their program have
		  on data buffers. From this, our type system derives a set
		  of constraints to which the input should adhere for the
		  program to work. Inputs that do not satisfy these
		  constraints will be rejected. Gaiwan prevents data races by
		  only providing deterministic data race free language
		  constructs. We provide the standard correctness proofs for
		  our type system. Although our proof-of-concept evaluator is
		  not yet fully optimized, we also implement a bitonic
		  sorting algorithm in it and demonstrate that it only has a
		  25\% overhead compared to a handwritten OpenCL
		  implementation from Intel.},
  copyright	= {Creative Commons Attribution 4.0 International Public
		  License (CC-BY 4.0)},
  langid	= {english},
  school	= {Ghent University}
}

@InProceedings{	  haas17:bringing,
  title		= {Bringing the Web up to Speed with {{WebAssembly}}},
  booktitle	= {Proceedings of the 38th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Haas, Andreas and Rossberg, Andreas and Schuff, Derek L.
		  and Titzer, Ben L. and Holman, Michael and Gohman, Dan and
		  Wagner, Luke and Zakai, Alon and Bastien, {\relax JF}},
  year		= {2017},
  month		= jun,
  series	= {{{PLDI}} 2017},
  pages		= {185--200},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3062341.3062363},
  urldate	= {2023-10-03},
  abstract	= {The maturation of the Web platform has given rise to
		  sophisticated and demanding Web applications such as
		  interactive 3D visualization, audio and video software, and
		  games. With that, efficiency and security of code on the
		  Web has become more important than ever. Yet JavaScript as
		  the only built-in language of the Web is not well-equipped
		  to meet these requirements, especially as a compilation
		  target. Engineers from the four major browser vendors have
		  risen to the challenge and collaboratively designed a
		  portable low-level bytecode called WebAssembly. It offers
		  compact representation, efficient validation and
		  compilation, and safe low to no-overhead execution. Rather
		  than committing to a specific programming model,
		  WebAssembly is an abstraction over modern hardware, making
		  it language-, hardware-, and platform-independent, with use
		  cases beyond just the Web. WebAssembly has been designed
		  with a formal semantics from the start. We describe the
		  motivation, design and formal semantics of WebAssembly and
		  provide some preliminary experience with implementations.},
  isbn		= {978-1-4503-4988-8},
  keywords	= {assembly languages,just-in-time compilers,programming
		  languages,type systems,virtual machines}
}

@Article{	  hahm21:reliable,
  title		= {Reliable {{Real-Time Operating System}} for {{IoT
		  Devices}}},
  author	= {Hahm, Seong-Il and Kim, Jeongchan and Jeong, Ahreum and
		  Yi, Hyunjin and Chang, Sunghan and Kishore, Shobha Nanda
		  and Chauhan, Amandeep and Cherian, Siju Punnoose},
  year		= {2021},
  month		= mar,
  journal	= {IEEE Internet of Things Journal},
  volume	= {8},
  number	= {5},
  pages		= {3705--3716},
  issn		= {2327-4662},
  doi		= {10.1109/JIOT.2020.3025612},
  urldate	= {2023-10-12},
  abstract	= {Internet of Things (IoT) technologies have so deeply
		  penetrated our daily lives that IoT devices have been
		  everywhere. Not only do IoT devices provide basic means to
		  convenient living but they also offer intelligent services
		  tailored to diverse user needs. For instance, beyond
		  remotely turning ON and OFF small gadgets, such as lamps
		  and switches, users can now control appliances via
		  smartphones and also interact with them verbally. In the
		  backdrop of multifarious, complex IoT applications, their
		  reliability becomes of paramount importance. This article
		  focuses on achieving user-level reliability in an IoT
		  operating system (OS) that executes both real-time (RT) and
		  non-real-time (NRT) tasks concurrently. For example, smart
		  appliances typically run RT tasks such as a motor
		  controller, as well as NRT tasks such as Wi-Fi-based
		  network functions, concurrently. In general, RT tasks are
		  critical and should be protected from error-prone tasks.
		  Otherwise, a motor controller failure may cause appliances
		  to malfunction. To this end, we propose a novel, reliable
		  IoT OS, called TizenRT that achieves user-level reliability
		  through two key features, namely, fault isolation and fast
		  recovery, while maintaining RT constraints. Our evaluation
		  shows that TizenRT can isolate faulty tasks in memory
		  space, while guaranteeing normal RT tasks to complete their
		  missions within a required time, e.g., 50
		  {\textbackslash}mu {\textbackslash}texts . Moreover,
		  corrupted tasks can be recovered within a few milliseconds,
		  e.g., 10 ms, without the need for a system reboot. This
		  makes TizenRT a preferred choice for mission-critical IoT
		  applications.}
}

@InProceedings{	  hambarde14:survey,
  title		= {The {{Survey}} of {{Real Time Operating System}}:
		  {{RTOS}}},
  shorttitle	= {The {{Survey}} of {{Real Time Operating System}}},
  booktitle	= {2014 {{International Conference}} on {{Electronic
		  Systems}}, {{Signal Processing}} and {{Computing
		  Technologies}}},
  author	= {Hambarde, Prasanna and Varma, Rachit and Jha, Shivani},
  year		= {2014},
  month		= jan,
  pages		= {34--39},
  doi		= {10.1109/ICESC.2014.15},
  urldate	= {2023-10-12},
  abstract	= {The paper discusses the literature survey of RTOS (Real
		  Time Operating Systems) and its contributions to the
		  embedded world. RTOS is defined as a system in which the
		  correctness of the system does not depend only on the
		  logical results of computation but also on the time at
		  which the results are produced. It has to perform critical
		  tasks on priority basis keeping the context switching time
		  minimum. It is often associated with few misconceptions \&
		  we have tried to throw some light on it. Since last 20
		  years, RTOS is undergoing continuous evolution and has
		  resulted into development of many commercial RTOS products.
		  We have selected few commercial RTOS of different
		  categories of real-time applications and have discussed its
		  real-time features. A comparison of the commercial RTOSs'
		  is presented. We conclude by discussing the results of the
		  survey and comparing the RTOS based on performance
		  parameters.}
}

@Article{	  hanford60:share,
  title		= {The Share Operating System for the {{IBM}} 709},
  author	= {Hanford, K. V},
  year		= {1960},
  month		= jan,
  journal	= {Annual Review in Automatic Programming},
  volume	= {1},
  pages		= {169--177},
  issn		= {0066-4138},
  doi		= {10.1016/0066-4138(60)90039-2},
  urldate	= {2025-05-08},
  abstract	= {The Share Operating System for the IBM 709 represents an
		  important advance in the art of machine usage. A single
		  symbolic language is used for all communication between the
		  programmer and the machine throughout the programming,
		  debugging and production phases. The system also provides
		  automatic programming systems for debugging and
		  input-output. A supervisory control program will perform
		  many of the functions hitherto handled by professional
		  machine operators.}
}

@InProceedings{	  harman18:from,
  title		= {From {{Start-ups}} to {{Scale-ups}}: {{Opportunities}} and
		  {{Open Problems}} for {{Static}} and {{Dynamic Program
		  Analysis}}},
  shorttitle	= {From {{Start-ups}} to {{Scale-ups}}},
  booktitle	= {2018 {{IEEE}} 18th {{International Working Conference}} on
		  {{Source Code Analysis}} and {{Manipulation}} ({{SCAM}})},
  author	= {Harman, Mark and O'Hearn, Peter},
  year		= {2018},
  month		= sep,
  pages		= {1--23},
  issn		= {2470-6892},
  doi		= {10.1109/SCAM.2018.00009},
  urldate	= {2025-05-04},
  abstract	= {This paper describes some of the challenges and
		  opportunities when deploying static and dynamic analysis at
		  scale, drawing on the authors' experience with the Infer
		  and Sapienz Technologies at Facebook, each of which started
		  life as a research-led start-up that was subsequently
		  deployed at scale, impacting billions of people worldwide.
		  The paper identifies open problems that have yet to receive
		  significant attention from the scientific community, yet
		  which have potential for profound real world impact,
		  formulating these as research questions that, we believe,
		  are ripe for exploration and that would make excellent
		  topics for research projects. Note: This paper accompanies
		  the authors' joint keynote at the 18th IEEE International
		  Working Conference on Source Code Analysis and
		  Manipulation, September 23rd-24th, 2018 - Madrid, Spain.},
  keywords	= {compositional reasoning,Facebook,flaky
		  test,Industries,Infer,Prototypes,Sapienz,SBSE,Separation
		  Logic,Software,Static
		  analysis,testing,Testing,Tools,verification}
}

@InProceedings{	  haulund17:implementing,
  title		= {Implementing {{Reversible Object-Oriented Language
		  Features}} on {{Reversible Machines}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Haulund, Tue and Mogensen, Torben {\AE}gidius and
		  Gl{\"u}ck, Robert},
  editor	= {Phillips, Iain and Rahaman, Hafizur},
  year		= {2017},
  pages		= {66--73},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-59936-6_5},
  abstract	= {We extend the reversible language Janus with support for
		  class-based object-oriented programming, class inheritance
		  and subtype-polymorphism. We describe how to implement
		  these features on reversible hardware - with emphasis on
		  the implementation of reversible dynamic dispatch using
		  virtual method tables. Our translation is effective (i.e.
		  garbage-free) and we demonstrate its practicality by
		  implementation of a fully-featured compiler targeting the
		  reversible assembly language PISA.},
  isbn		= {978-3-319-59936-6},
  langid	= {english},
  keywords	= {Class Field,Class Instance,Data Access Control,Method
		  Invocation,Virtual Method}
}

@InProceedings{	  hay-schmidt21:towards,
  title		= {Towards a {{Unified Language Architecture}} for
		  {{Reversible Object-Oriented Programming}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {{Hay-Schmidt}, Lasse and Gl{\"u}ck, Robert and Cservenka,
		  Martin Holm and Haulund, Tue},
  editor	= {Yamashita, Shigeru and Yokoyama, Tetsuo},
  year		= {2021},
  pages		= {96--106},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-79837-6_6},
  abstract	= {A unified language architecture for an advanced reversible
		  object-oriented language is described. The design and
		  implementation choices made for a tree-walking interpreter
		  and source-language inverter are discussed, as well as the
		  integration with an existing monadic parser, type checker
		  and PISA compiler backend. A demonstration of the web
		  interface and the interactions required to interpret,
		  compile and invert reversible object-oriented programs is
		  given. Our aim is that this platform will make reversible
		  programming approachable to a wider community.},
  isbn		= {978-3-030-79837-6},
  langid	= {english}
}

@InProceedings{	  he23:eunomia,
  title		= {Eunomia: {{Enabling User-Specified Fine-Grained Search}}
		  in {{Symbolically Executing WebAssembly Binaries}}},
  shorttitle	= {Eunomia},
  booktitle	= {Proceedings of the 32nd {{ACM SIGSOFT International
		  Symposium}} on {{Software Testing}} and {{Analysis}}},
  author	= {He, Ningyu and Zhao, Zhehao and Wang, Jikai and Hu, Yubin
		  and Guo, Shengjian and Wang, Haoyu and Liang, Guangtai and
		  Li, Ding and Chen, Xiangqun and Guo, Yao},
  year		= {2023},
  month		= jul,
  series	= {{{ISSTA}} 2023},
  pages		= {385--397},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3597926.3598064},
  urldate	= {2023-10-20},
  abstract	= {Although existing techniques have proposed automated
		  approaches to alleviate the path explosion problem of
		  symbolic execution, users still need to optimize symbolic
		  execution by applying various searching strategies
		  carefully. As existing approaches mainly support only
		  coarse-grained global searching strategies, they cannot
		  efficiently traverse through complex code structures. In
		  this paper, we propose Eunomia, a symbolic execution
		  technique that supports fine-grained search with local
		  domain knowledge. Eunomia uses Aes, a DSL that lets users
		  specify local searching strategies for different parts of
		  the program. Eunomia also isolates the context of variables
		  for different local searching strategies, avoiding
		  conflicts. We implement Eunomia for WebAssembly, which can
		  analyze applications written in various languages. Eunomia
		  is the first symbolic execution engine that supports the
		  full features of WebAssembly. We evaluate Eunomia with a
		  microbenchmark suite and six real-world applications. Our
		  evaluation shows that Eunomia improves bug detection by up
		  to three orders of magnitude. We also conduct a user study
		  that shows the benefits of using Aes. Moreover, Eunomia
		  verifies six known bugs and detects two new zero-day bugs
		  in Collections-C.},
  isbn		= {9798400702211},
  keywords	= {Domain Specific Language,Path Explosion,Symbolic
		  Execution,WebAssembly}
}

@Article{	  hentschel19:symbolic-execution-debugger,
  title		= {The {{Symbolic Execution Debugger}} ({{SED}}): A Platform
		  for Interactive Symbolic Execution, Debugging, Verification
		  and More},
  shorttitle	= {The {{Symbolic Execution Debugger}} ({{SED}})},
  author	= {Hentschel, Martin and Bubel, Richard and H{\"a}hnle,
		  Reiner},
  year		= {2019},
  month		= oct,
  journal	= {International Journal on Software Tools for Technology
		  Transfer},
  volume	= {21},
  number	= {5},
  pages		= {485--513},
  issn		= {1433-2787},
  doi		= {10.1007/s10009-018-0490-9},
  urldate	= {2024-03-18},
  abstract	= {The Symbolic Execution Debugger (SED), is an extension of
		  the debug platform for interactive debuggers based on
		  symbolic execution. The SED comes with a static symbolic
		  execution engine for sequential programs, but any
		  third-party symbolic execution engine can be integrated
		  into the SED. An interactive debugger based on symbolic
		  execution allows one like a traditional debugger to locate
		  defects in the source code. The difference is that all
		  feasible execution paths are explored at once, and thus
		  there is no need to know input values resulting in an
		  execution that exhibits the failure. In addition, such a
		  debugger can be used in code reviews and to guide and
		  present results of an analysis based on symbolic execution
		  such as, in our case, correctness proofs. Experimental
		  evaluations proved that the SED increases the effectiveness
		  of code reviews and proof understanding tasks.},
  langid	= {english},
  keywords	= {Debugging,Deductive program verification,Program
		  understanding,Slicing,Symbolic execution}
}

@InProceedings{	  herklotz23:mechanised,
  title		= {Mechanised {{Semantics}} for {{Gated Static Single
		  Assignment}}},
  booktitle	= {Proceedings of the 12th {{ACM SIGPLAN International
		  Conference}} on {{Certified Programs}} and {{Proofs}}},
  author	= {Herklotz, Yann and Demange, Delphine and Blazy, Sandrine},
  year		= {2023},
  month		= jan,
  series	= {{{CPP}} 2023},
  pages		= {182--196},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3573105.3575681},
  urldate	= {2023-09-27},
  abstract	= {The Gated Static Single Assignment (GSA) form was proposed
		  by Ottenstein et al. in 1990, as an intermediate
		  representation for implementing advanced static analyses
		  and optimisation passes in compilers. Compared to SSA, GSA
		  records additional data dependencies and provides more
		  context, making optimisations more effective and allowing
		  one to reason about programs as data-flow graphs. Many
		  practical implementations have been proposed that follow,
		  more or less faithfully, Ottenstein et al.'s seminal paper.
		  But many discrepancies remain between these, depending on
		  the kind of dependencies they are supposed to track and to
		  leverage in analyses and code optimisations. In this paper,
		  we present a formal semantics for GSA, mechanised in Coq.
		  In particular, we clarify the nature and the purpose of
		  gates in GSA, and define control-flow insensitive semantics
		  for them. We provide a specification that can be used as a
		  reference description for GSA. We also specify a
		  translation from SSA to GSA and prove that this
		  specification is semantics-preserving. We demonstrate that
		  the approach is practical by implementing the specification
		  as a validated translation within the CompCertSSA verified
		  compiler.},
  isbn		= {9798400700262},
  keywords	= {Gated SSA,SSA,Verified Compilation}
}

@Article{	  herlihy90:linearizability,
  title		= {Linearizability: A Correctness Condition for Concurrent
		  Objects},
  shorttitle	= {Linearizability},
  author	= {Herlihy, Maurice P. and Wing, Jeannette M.},
  year		= {1990},
  month		= jul,
  journal	= {ACM Trans. Program. Lang. Syst.},
  volume	= {12},
  number	= {3},
  pages		= {463--492},
  issn		= {0164-0925},
  doi		= {10.1145/78969.78972},
  urldate	= {2025-03-04},
  abstract	= {A concurrent object is a data object shared by concurrent
		  processes. Linearizability is a correctness condition for
		  concurrent objects that exploits the semantics of abstract
		  data types. It permits a high degree of concurrency, yet it
		  permits programmers to specify and reason about concurrent
		  objects using known techniques from the sequential domain.
		  Linearizability provides the illusion that each operation
		  applied by concurrent processes takes effect
		  instantaneously at some point between its invocation and
		  its response, implying that the meaning of a concurrent
		  object's operations can be given by pre- and
		  post-conditions. This paper defines linearizability,
		  compares it to other correctness conditions, presents and
		  demonstrates a method for proving the correctness of
		  implementations, and shows how to reason about concurrent
		  objects, given they are linearizable.}
}

@Article{	  heunen15:reversible,
  title		= {Reversible {{Monadic Computing}}},
  author	= {Heunen, Chris and Karvonen, Martti},
  year		= {2015},
  month		= dec,
  journal	= {Electronic Notes in Theoretical Computer Science},
  series	= {The 31st {{Conference}} on the {{Mathematical
		  Foundations}} of {{Programming Semantics}} ({{MFPS
		  XXXI}}).},
  volume	= {319},
  pages		= {217--237},
  issn		= {1571-0661},
  doi		= {10.1016/j.entcs.2015.12.014},
  urldate	= {2023-09-29},
  abstract	= {We extend categorical semantics of monadic programming to
		  reversible computing, by considering monoidal closed dagger
		  categories: the dagger gives reversibility, whereas closure
		  gives higher-order expressivity. We demonstrate that
		  Frobenius monads model the appropriate notion of coherence
		  between the dagger and closure by reinforcing Cayley's
		  theorem; by proving that effectful computations (Kleisli
		  morphisms) are reversible precisely when the monad is
		  Frobenius; by characterizing the largest reversible
		  subcategory of Eilenberg--Moore algebras; and by
		  identifying the latter algebras as measurements in our
		  leading example of quantum computing. Strong Frobenius
		  monads are characterized internally by Frobenius monoids.},
  keywords	= {dagger category,Frobenius monad,quantum
		  measurement,reversible computing}
}

@Article{	  hgskola01:monitoring,
  title		= {Monitoring, {{Testing}} and {{Debugging}} of {{Distributed
		  Real-Time Systems}}},
  author	= {Hgskola, Chalmers and Thane, Henrik and Ab, Artes/ssf},
  year		= {2001},
  month		= mar,
  abstract	= {Testing is an important part of any software development
		  project, and can typically surpass more than half of the
		  development cost. For safety-critical computer based
		  systems, testing is even more important due to stringent
		  reliability and safety requirements. However, most
		  safety-critical computer based systems are real-time
		  systems, and the majority of current testing and debugging
		  techniques have been developed for sequential (non
		  real-time) programs. These techniques are not directly
		  applicable to real-time systems, since they disregard
		  issues of timing and concurrency. This means that existing
		  techniques for reproducible testing and debugging cannot be
		  used. Reproducibility is essential for regression testing
		  and cyclic debugging, where the same test cases are run
		  repeatedly with the intention of verifying modified program
		  code or to track down errors. The current trend of consumer
		  and industrial applications goes from single
		  micro-controllers to sets of distributed micro-controllers,
		  which are even more challenging than handling real-time
		  per-see, since multiple loci of observation and control
		  additionally must be considered. In this thesis we try to
		  remedy these problems by presenting an integrated approach
		  to monitoring, testing, and debugging of distributed
		  real-time systems.}
}

@Misc{		  hickey20:webassemblywasi,
  title		= {{{WebAssembly}}/{{WASI}}: Snapshot-01},
  author	= {Hickey, Pat and Konka, Jakub and Gohman, Dan and Clegg,
		  Sam and Brown, Andrew and Crichton, Alex and Clark, Lin and
		  Ihrig, Colin and Huene, Peter and Yuji, {\relax YAMAMOTO}
		  and Vasilik, Denis and Triplett, Josh and Rubanov, Sergey
		  and Akbary, Syrus and Frysinger, Mike and Turner, Aaron and
		  Zakai, Alon and Mackenzie, Andrew and Brittain, Benjamin
		  and Beyer, Casper and McKay, David and Wang, Leon and
		  Mielniczuk, Marcin and Berger, Mendy and {PTrottier} and
		  Sikora, Piotr and Schneidereit, Till and {martin}, katelyn
		  and {nasso}},
  year		= {2020},
  month		= dec,
  doi		= {10.5281/zenodo.4323447},
  howpublished	= {Zenodo}
}

@Article{	  hillerstrom22:foundations,
  title		= {Foundations for Programming and Implementing Effect
		  Handlers},
  author	= {Hillerstr{\"o}m, Daniel},
  year		= {2022},
  month		= apr,
  publisher	= {The University of Edinburgh},
  doi		= {10.7488/era/2122},
  urldate	= {2023-12-07},
  abstract	= {First-class control operators provide programmers with an
		  expressive and efficient means for manipulating control
		  through reification of the current control state as a
		  first-class object, enabling programmers to implement their
		  own computational effects and control idioms as shareable
		  libraries. Effect handlers provide a particularly
		  structured approach to programming with first-class control
		  by naming control reifying operations and separating from
		  their handling. This thesis is composed of three strands of
		  work in which I develop operational foundations for
		  programming and implementing effect handlers as well as
		  exploring the expressive power of effect handlers. The
		  first strand develops a fine-grain call-by-value core
		  calculus of a statically typed programming language with a
		  structural notion of effect types, as opposed to the
		  nominal notion of effect types that dominates the
		  literature. With the structural approach, effects need not
		  be declared before use. The usual safety properties of
		  statically typed programming are retained by making crucial
		  use of row polymorphism to build and track effect
		  signatures. The calculus features three forms of handlers:
		  deep, shallow, and parameterised. They each offer a
		  different approach to manipulate the control state of
		  programs. Traditional deep handlers are defined by folds
		  over computation trees, and are the original con-struct
		  proposed by Plotkin and Pretnar. Shallow handlers are
		  defined by case splits (rather than folds) over computation
		  trees. Parameterised handlers are deep handlers extended
		  with a state value that is threaded through the folds over
		  computation trees. To demonstrate the usefulness of effects
		  and handlers as a practical programming abstraction I
		  implement the essence of a small UNIX-style operating
		  system complete with multi-user environment, time-sharing,
		  and file I/O. The second strand studies continuation
		  passing style (CPS) and abstract machine semantics, which
		  are foundational techniques that admit a unified basis for
		  implementing deep, shallow, and parameterised effect
		  handlers in the same environment. The CPS translation is
		  obtained through a series of refinements of a basic
		  first-order CPS translation for a fine-grain call-by-value
		  language into an untyped language. Each refinement moves
		  toward a more intensional representation of continuations
		  eventually arriving at the notion of generalised
		  continuation, which admit simultaneous support for deep,
		  shallow, and parameterised handlers. The initial refinement
		  adds support for deep handlers by representing stacks of
		  continuations and handlers as a curried sequence of
		  arguments. The image of the resulting translation is not
		  properly tail-recursive, meaning some function application
		  terms do not appear in tail position. To rectify this the
		  CPS translation is refined once more to obtain an uncurried
		  representation of stacks of continuations and handlers.
		  Finally, the translation is made higher-order in order to
		  contract administrative redexes at translation time. The
		  generalised continuation representation is used to
		  construct an abstract machine that provide simultaneous
		  support for deep, shallow, and parameterised effect
		  handlers. kinds of effect handlers. The third strand
		  explores the expressiveness of effect handlers. First, I
		  show that deep, shallow, and parameterised notions of
		  handlers are interdefinable by way of typed
		  macro-expressiveness, which provides a syntactic notion of
		  expressiveness that affirms the existence of encodings
		  between handlers, but it provides no information about the
		  computational content of the encodings. Second, using the
		  semantic notion of expressiveness I show that for a class
		  of programs a programming language with first-class control
		  (e.g. effect handlers) admits asymptotically faster
		  implementations than possible in a language without
		  first-class control.},
  langid	= {english},
  annotation	= {Accepted: 2022-04-12T12:40:37Z}
}

@Article{	  hirsch22:systematic,
  title		= {A Systematic Literature Review on Benchmarks for
		  Evaluating Debugging Approaches},
  author	= {Hirsch, Thomas and Hofer, Birgit},
  year		= {2022},
  month		= oct,
  journal	= {Journal of Systems and Software},
  volume	= {192},
  pages		= {111423},
  issn		= {0164-1212},
  doi		= {10.1016/j.jss.2022.111423},
  urldate	= {2025-05-08},
  abstract	= {Bug benchmarks are used in development and evaluation of
		  debugging approaches, e.g. fault localization and automated
		  repair. Quantitative performance comparison of different
		  debugging approaches is only possible when they have been
		  evaluated on the same dataset or benchmark. However,
		  benchmarks are often specialized towards usage for certain
		  debugging approaches in their contained data, metrics, and
		  artifacts. Such benchmarks cannot be easily used on
		  debugging approaches outside their scope as such approach
		  may rely on specific data such as bug reports or code
		  metrics that are not included in the dataset. Furthermore,
		  benchmarks vary in their size w.r.t. the number of subject
		  programs and the size of the individual subject programs.
		  For these reasons, we have performed a systematic
		  literature review where we have identified 73 benchmarks
		  that can be used to evaluate debugging approaches. We
		  compare the different benchmarks w.r.t. their size and the
		  provided information such as bug reports, contained test
		  cases, and other code metrics. This comparison is intended
		  to help researchers to quickly identify all suitable
		  benchmarks for evaluating their specific debugging
		  approaches. Furthermore, we discuss reoccurring issues and
		  challenges in selection, acquisition, and usage of such bug
		  benchmarks, i.e., data availability, data quality,
		  duplicated content, data formats, reproducibility, and
		  extensibility. Editor's note: Open Science material was
		  validated by the Journal of Systems and Software Open
		  Science Board.},
  keywords	= {Automatic repair,Benchmark,Debugging,Fault localization}
}

@Article{	  ho22:aeneas,
  title		= {Aeneas: {{Rust}} Verification by Functional Translation},
  shorttitle	= {Aeneas},
  author	= {Ho, Son and Protzenko, Jonathan},
  year		= {2022},
  month		= aug,
  journal	= {Aeneas: Rust Verification by Functional Translation},
  volume	= {6},
  number	= {ICFP},
  pages		= {116:711--116:741},
  doi		= {10.1145/3547647},
  urldate	= {2024-12-18},
  abstract	= {We present Aeneas, a new verification toolchain for Rust
		  programs based on a lightweight functional translation. We
		  leverage Rust's rich region-based type system to eliminate
		  memory reasoning for a large class of Rust programs, as
		  long as they do not rely on interior mutability or unsafe
		  code. Doing so, we relieve the proof engineer of the burden
		  of memory-based reasoning, allowing them to instead focus
		  on functional properties of their code. The first
		  contribution of Aeneas is a new approach to borrows and
		  controlled aliasing. We propose a pure, functional
		  semantics for LLBC, a Low-Level Borrow Calculus that
		  captures a large subset of Rust programs. Our semantics is
		  value-based, meaning there is no notion of memory,
		  addresses or pointer arithmetic. Our semantics is also
		  ownership-centric, meaning that we enforce soundness of
		  borrows via a semantic criterion based on loans rather than
		  through a syntactic type-based lifetime discipline. We
		  claim that our semantics captures the essence of the borrow
		  mechanism rather than its current implementation in the
		  Rust compiler. The second contribution of Aeneas is a
		  translation from LLBC to a pure lambda-calculus. This
		  allows the user to reason about the original Rust program
		  through the theorem prover of their choice, and fulfills
		  our promise of enabling lightweight verification of Rust
		  programs. To deal with the well-known technical difficulty
		  of terminating a borrow, we rely on a novel approach, in
		  which we approximate the borrow graph in the presence of
		  function calls. This in turn allows us to perform the
		  translation using a new technical device called backward
		  functions. We implement our toolchain in a mixture of Rust
		  and OCaml; our chief case study is a low-level, resizing
		  hash table, for which we prove functional correctness, the
		  first such result in Rust. Our evaluation shows significant
		  gains of verification productivity for the programmer. This
		  paper therefore establishes a new point in the design space
		  of Rust verification toolchains, one that aims to verify
		  Rust programs simply, and at scale. Rust goes to great
		  lengths to enforce static control of aliasing; the proof
		  engineer should not waste any time on memory reasoning when
		  so much already comes ``for free''!}
}

@Article{	  ho24:sound,
  title		= {Sound {{Borrow-Checking}} for {{Rust}} via {{Symbolic
		  Semantics}}},
  author	= {Ho, Son and Fromherz, Aymeric and Protzenko, Jonathan},
  year		= {2024},
  month		= aug,
  journal	= {Artifact for: Sound Borrow-Checking for Rust via Symbolic
		  Semantics},
  volume	= {8},
  number	= {ICFP},
  pages		= {251:426--251:454},
  doi		= {10.1145/3674640},
  urldate	= {2024-12-17},
  abstract	= {The Rust programming language continues to rise in
		  popularity, and as such, warrants the close attention of
		  the programming languages community. In this work, we
		  present a new foundational contribution towards the
		  theoretical understanding of Rust's semantics. We prove
		  that LLBC, a high-level, borrow-centric model previously
		  proposed for Rust's semantics and execution, is sound with
		  regards to a low-level pointer-based language {\`a} la
		  CompCert. Specifically, we prove the following: that LLBC
		  is a correct view over a traditional model of execution;
		  that LLBC's symbolic semantics are a correct abstraction of
		  LLBC programs; and that LLBC's symbolic semantics act as a
		  borrow-checker for LLBC, i.e. that symbolically-checked
		  LLBC programs do not get stuck when executed on a
		  heap-and-addresses model of execution. To prove these
		  results, we introduce a new proof style that considerably
		  simplifies our proofs of simulation, which relies on a
		  notion of hybrid states. Equipped with this reasoning
		  framework, we show that a new addition to LLBC's symbolic
		  semantics, namely a join operation, preserves the
		  abstraction and borrow-checking properties. This in turn
		  allows us to add support for loops to the Aeneas framework;
		  we show, using a series of examples and case studies, that
		  this unlocks new expressive power for Aeneas.}
}

@Misc{		  hoey18:reversing,
  title		= {Reversing {{Parallel Programs}} with {{Blocks}} and
		  {{Procedures}}},
  author	= {Hoey, James and Ulidowski, Irek and Yuen, Shoji},
  year		= {2018},
  month		= aug,
  number	= {arXiv:1808.08651},
  eprint	= {1808.08651},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.1808.08651},
  urldate	= {2024-11-10},
  abstract	= {We show how to reverse a while language extended with
		  blocks, local variables, procedures and the interleaving
		  parallel composition. Annotation is defined along with a
		  set of operational semantics capable of storing necessary
		  reversal information, and identifiers are introduced to
		  capture the interleaving order of an execution. Inversion
		  is defined with a set of operational semantics that use
		  saved information to undo an execution. We prove that
		  annotation does not alter the behaviour of the original
		  program, and that inversion correctly restores the initial
		  program state.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Programming Languages}
}

@InProceedings{	  hoey19:reversible,
  title		= {Reversible Imperative Parallel Programs and Debugging},
  booktitle	= {Reversible Computation},
  author	= {Hoey, James and Ulidowski, Irek},
  editor	= {Thomsen, Michael Kirkedal and Soeken, Mathias},
  year		= {2019},
  pages		= {108--127},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  abstract	= {We present a state-saving approach to reversible execution
		  of imperative programs containing parallel composition.
		  Given an original program, we produce an annotated version
		  of the program that both performs forwards execution and
		  all necessary state-saving of required reversal
		  information. We further produce an inverted version of our
		  program, capable of using this saved information to reverse
		  the effects of each step of the forwards execution. We show
		  that this process implements correct and garbage-free
		  inversion. We give examples of how our implementation of
		  reversible execution can be used for debugging, and
		  demonstrate how a simulation tool we have developed for our
		  approach can be used to examine the program state. Finally,
		  we evaluate the performance and overheads associated with
		  state-saving and inversion.},
  isbn		= {978-3-030-21500-2}
}

@Article{	  hogl06:open,
  title		= {Open On-Chip Debugger--Openocd--},
  author	= {H{\"o}gl, Hubert and Rath, Dominic},
  year		= {2006},
  journal	= {Fakultat fur Informatik, Tech. Rep},
  publisher	= {Citeseer}
}

@InProceedings{	  holter24:abstract,
  title		= {Abstract {{Debuggers}}: {{Exploring Program Behaviors}}
		  Using {{Static Analysis Results}}},
  shorttitle	= {Abstract {{Debuggers}}},
  booktitle	= {Proceedings of the 2024 {{ACM SIGPLAN International
		  Symposium}} on {{New Ideas}}, {{New Paradigms}}, and
		  {{Reflections}} on {{Programming}} and {{Software}}},
  author	= {Holter, Karoliine and Hennoste, Juhan Oskar and Lam,
		  Patrick and Saan, Simmo and Vojdani, Vesal},
  year		= {2024},
  month		= oct,
  series	= {Onward! '24},
  pages		= {130--146},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3689492.3690053},
  urldate	= {2025-03-01},
  abstract	= {Traditional, or concrete, debuggers allow developers to
		  step through programs and explore the corresponding
		  concrete program states---developers can query current
		  values of program variables. This exploration enables
		  developers to formulate and refine hypotheses about program
		  behaviors. We propose the novel notion of abstract
		  debuggers, which allow developers to explore abstract
		  program states, as computed by sound static analyzers.
		  Giving developers the ability to interactively explore
		  abstract states empowers them to work with hypotheses that
		  are true for all program executions: they can examine and
		  rule out false positives, or better understand a static
		  analysis's declaration that some code is indeed safe.
		  Abstract debuggers' interfaces, reminiscent of conventional
		  debuggers, aim to make navigating and interpreting static
		  analysis results more straightforward. We have formalized
		  the concept, applied it by implementing a tool that
		  leverages the static analyzer Goblint, and illustrate its
		  usefulness through case studies.},
  isbn		= {9798400712159}
}

@Book{		  homes24:fundamentals,
  title		= {Fundamentals of {{Software Testing}}},
  author	= {Hom{\`e}s, Bernard},
  year		= {2024},
  month		= jun,
  edition	= {2},
  publisher	= {John Wiley \& Sons},
  abstract	= {Software testing has greatly evolved since the first
		  edition of this book in 2011. Testers are now required to
		  work in "agile" teams and focus on automating test cases.
		  It has thus been necessary to update this work, in order to
		  provide fundamental knowledge that testers should have to
		  be effective and efficient in today's world. This book
		  describes the fundamental aspects of testing in the
		  different lifecycles, and how to implement and benefit from
		  reviews and static analysis. Multiple other techniques are
		  approached, such as equivalence partitioning, boundary
		  value analysis, use case testing, decision tables and state
		  transitions. This second edition also covers test
		  management, test progress monitoring and incident
		  management, in order to ensure that the testing information
		  is correctly provided to the stakeholders. This book
		  provides detailed course-study material for the 2023
		  version of the ISTQB Foundation level syllabus, including
		  sample questions to help prepare for exams.},
  googlebooks	= {uBAOEQAAQBAJ},
  isbn		= {978-1-394-29896-9},
  langid	= {english},
  keywords	= {Computers / Computer Engineering,Computers / Information
		  Technology,Computers / Software Development & Engineering /
		  Quality Assurance & Testing,Technology & Engineering /
		  Electronics / General}
}

@Article{	  horwitz88:interprocedural,
  title		= {Interprocedural Slicing Using Dependence Graphs},
  author	= {Horwitz, S. and Reps, T. and Binkley, D.},
  year		= {1988},
  month		= jun,
  journal	= {ACM SIGPLAN Notices},
  volume	= {23},
  number	= {7},
  pages		= {35--46},
  issn		= {0362-1340},
  doi		= {10.1145/960116.53994},
  urldate	= {2024-03-13},
  abstract	= {A slice of a program with respect to a program point p and
		  variable x consists of all statements of the program that
		  might affect the value of x at point p. This paper concerns
		  the problem of interprocedural slicing --- generating a
		  slice of an entire program, where the slice crosses the
		  boundaries of procedure calls. To solve this problem, we
		  introduce a new kind of graph to represent programs, called
		  a system dependence graph, which extends previous
		  dependence representations to incorporate collections of
		  procedures (with procedure calls) rather than just
		  monolithic programs. Our main result is an algorithm for
		  interprocedural slicing that uses the new representation.
		  The chief difficulty in interprocedural slicing is
		  correctly accounting for the calling context of a called
		  procedure. To handle this problem, system dependence graphs
		  include some data-dependence edges that represent
		  transitive dependencies due to the effects of procedure
		  calls, in addition to the conventional direct-dependence
		  edges. These edges are constructed with the aid of an
		  auxiliary structure that represents calling and
		  parameter-linkage relationships. This structure takes the
		  form of an attribute grammar. The step of computing the
		  required transitive-dependence edges is reduced to the
		  construction of the subordinate characteristic graphs for
		  the grammar's nonterminals.}
}

@InProceedings{	  huang14:appacts,
  title		= {{{AppACTS}}: {{Mobile App Automated Compatibility Testing
		  Service}}},
  shorttitle	= {{{AppACTS}}},
  booktitle	= {2014 2nd {{IEEE International Conference}} on {{Mobile
		  Cloud Computing}}, {{Services}}, and {{Engineering}}},
  author	= {Huang, Jun-fei},
  year		= {2014},
  month		= apr,
  pages		= {85--90},
  doi		= {10.1109/MobileCloud.2014.13},
  urldate	= {2025-05-04},
  abstract	= {Android fragmentation remains a compatibility issue for
		  third-party Android application (app) developers. Most of
		  development teams may not have enough mobile devices for
		  compatibility testing because of limited budget. They may
		  not have enough time to finish the testing on tens kind of
		  devices one by one even devices are sufficient, since the
		  applications have to be launched on time under market
		  pressure. In this paper, we present Mobile App Automated
		  Compatibility Testing Service (AppACTS), which is aimed at
		  helping developers to improve mobile application
		  compatibility testing efficiency, save cost and ensure
		  mobile application quality and reliability. Developers
		  could upload their apps through a web interface, designate
		  interesting mobile device models, and review testing report
		  after finishing testing. The whole compatibility testing
		  process of AppACTS includes the installation, startup,
		  random key and screen actions, and removal of mobile apps.
		  The architecture of AppACTS is scalable and the mobile
		  devices of AppACTS are real devices and geographically
		  distributed.},
  keywords	= {Android,AppACTS,Cloud computing,compatibility testing
		  service,Conferences,Mobile communication}
}

@Misc{		  huang21:webassembly-micro-runtime,
  title		= {{{WebAssembly Micro Runtime}}},
  author	= {Huang, Wenyong and {Wang Xin}},
  year		= {2021},
  month		= aug,
  urldate	= {2021-08-04},
  abstract	= {WebAssembly Micro Runtime (WAMR). Contribute to
		  bytecodealliance/wasm-micro-runtime development by creating
		  an account on GitHub.},
  langid	= {english}
}

@Book{		  hunt99:pragmatic,
  title		= {The Pragmatic Programmer},
  author	= {Hunt, Andrew and Thomas, David},
  year		= {1999},
  publisher	= {Addison-Wesley},
  isbn		= {978-0-13-595705-9}
}

@Article{	  ieee-standard,
  title		= {{{IEEE Standard}} for {{Test Access Port}} and
		  {{Boundary-Scan Architecture}}},
  year		= {2013},
  month		= may,
  journal	= {IEEE Std 1149.1-2013 (Revision of IEEE Std 1149.1-2001)},
  pages		= {1--444},
  doi		= {10.1109/IEEESTD.2013.6515989},
  urldate	= {2024-11-13},
  abstract	= {Circuitry that may be built into an integrated circuit to
		  assist in the test, maintenance and support of assembled
		  printed circuit boards and the test of internal circuits is
		  defined. The circuitry includes a standard interface
		  through which instructions and test data are communicated.
		  A set of test features is defined, including a
		  boundary-scan register, such that the component is able to
		  respond to a minimum set of instructions designed to assist
		  with testing of assembled printed circuit boards. Also, a
		  language is defined that allows rigorous structural
		  description of the component-specific aspects of such
		  testability features, and a second language is defined that
		  allows rigorous procedural description of how the
		  testability features may be used.},
  keywords	= {boundary scan,Boundary value problems,boundary-scan
		  architecture,boundary-scan boundary scan,Boundary-Scan
		  Description Language,Boundary-Scan Description Language
		  (BSDL),boundary-scan register,circuit boards,circuitry,IEEE
		  1149.1,IEEE standards,integrated circuit,Integrated
		  circuits,printed circuit boards,Printed circuits,Procedural
		  Description Language (PDL),test,test access port
		  (TAP),Testing,very high speed integrated circuit
		  (VHSIC),Very high speed integrated circuits,VHSIC Hardware
		  Description Language (VHDL)}
}

@Article{	  ierusalimschy96:lua-an-extensible-extension-language,
  title		= {Lua---{{An Extensible Extension Language}}},
  author	= {Ierusalimschy, Roberto and {de Figueiredo}, Luiz Henrique
		  and Filho, Waldemar Celes},
  year		= {1996},
  journal	= {Software: Practice and Experience},
  volume	= {26},
  number	= {6},
  pages		= {635--652},
  issn		= {1097-024X},
  doi		= {10.1002/(SICI)1097-024X(199606)26:6<635::AID-SPE26>3.0.CO;2-P},
  urldate	= {2025-01-14},
  abstract	= {This paper describes Lua, a language for extending
		  applications. Lua combines procedural features with
		  powerful data description facilities, by using a simple,
		  yet powerful, mechanism of tables . This mechanism
		  implements the concepts of records, arrays and recursive
		  data types (pointers), and adds some object-oriented
		  facilities, such as methods with dynamic dispatching. Lua
		  presents a mechanism of fallbacks that allows programmers
		  to extend the semantics of the language in some
		  unconventional ways. As a noteworthy example, fallbacks
		  allow the user to add different kinds of inheritance to the
		  language. Currently, Lua is being extensively used in
		  production for several tasks, including user configuration,
		  general-purpose data-entry, description of user interfaces,
		  storage of structured graphical metafiles, and generic
		  attribute configuration for finite element meshes.},
  copyright	= {Copyright {\copyright} 1996 John Wiley \& Sons, Ltd.},
  langid	= {english},
  keywords	= {end-user programming,extension languages,programming
		  languages}
}

@Misc{		  ifs-institut-fur-software23:cute,
  title		= {{{CUTE}}. {{C}}++ Unit Testing Easier},
  author	= {{IFS Institut f{\"u}r Software}},
  year		= {2023},
  urldate	= {2023-02-15},
  lastaccessed	= {February 15, 2023}
}

@InCollection{	  index,
  title		= {Index},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {335--342},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.index},
  urldate	= {2024-12-04},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InProceedings{	  iqbal12:empirical,
  title		= {Empirical Investigation of Search Algorithms for
		  Environment Model-Based Testing of Real-Time Embedded
		  Software},
  booktitle	= {Proceedings of the 2012 {{International Symposium}} on
		  {{Software Testing}} and {{Analysis}}},
  author	= {Iqbal, Muhammad Zohaib and Arcuri, Andrea and Briand,
		  Lionel},
  year		= {2012},
  month		= jul,
  series	= {{{ISSTA}} 2012},
  pages		= {199--209},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2338965.2336777},
  urldate	= {2025-03-03},
  abstract	= {System testing of real-time embedded systems (RTES) is a
		  challenging task and only a fully automated testing
		  approach can scale up to the testing requirements of
		  industrial RTES. One such approach, which offers the
		  advantage for testing teams to be black-box, is to use
		  environment models to automatically generate test cases and
		  oracles and an environment simulator to enable earlier and
		  more practical testing. In this paper, we propose novel
		  heuristics for search-based, RTES system testing which are
		  based on these environment models. We evaluate the fault
		  detection effectiveness of two search-based algorithms,
		  i.e., Genetic Algorithms and (1+1) Evolutionary Algorithm,
		  when using these novel heuristics and their combinations.
		  Preliminary experiments on 13 carefully selected,
		  non-trivial artificial problems, show that, under certain
		  conditions, these novel heuristics are effective at
		  bringing the environment into a state exhibiting a system
		  fault. The heuristic combination that showed the best
		  overall performance on the artificial problems was applied
		  on an industrial case study where it showed consistent
		  results.},
  isbn		= {978-1-4503-1454-1}
}

@Article{	  iqbal15:environment,
  title		= {Environment Modeling and Simulation for Automated Testing
		  of Soft Real-Time Embedded Software},
  author	= {Iqbal, Muhammad Zohaib and Arcuri, Andrea and Briand,
		  Lionel},
  year		= {2015},
  month		= feb,
  journal	= {Software \& Systems Modeling},
  volume	= {14},
  number	= {1},
  pages		= {483--524},
  issn		= {1619-1374},
  doi		= {10.1007/s10270-013-0328-6},
  urldate	= {2025-03-03},
  abstract	= {Given the challenges of testing at the system level, only
		  a fully automated approach can really scale up to
		  industrial real-time embedded systems (RTES). Our goal is
		  to provide a practical approach to the model-based testing
		  of RTES by allowing system testers, who are often not
		  familiar with the system's design but are application
		  domain experts, to model the system environment in such a
		  way as to enable its black-box test automation. Environment
		  models can support the automation of three tasks: the code
		  generation of an environment simulator to enable testing on
		  the development platform or without involving actual
		  hardware, the selection of test cases, and the evaluation
		  of their expected results (oracles). From a practical
		  standpoint---and such considerations are crucial for
		  industrial adoption---environment modeling should be based
		  on modeling standards (1) that are at an adequate level of
		  abstraction, (2) that software engineers are familiar with,
		  and (3) that are well supported by commercial or open
		  source tools. In this paper, we propose a precise
		  environment modeling methodology fitting these requirements
		  and discuss how these models can be used to generate
		  environment simulators. The environment models are
		  expressed using UML/MARTE and OCL, which are international
		  standards for real-time systems and constraint modeling.
		  The presented techniques are evaluated on a set of three
		  artificial problems and on two industrial RTES.},
  langid	= {english},
  keywords	= {Automated testing,Environment modeling,Environment
		  simulation,Model-based testing,Real-time embedded
		  systems,Search based software engineering}
}

@InProceedings{	  irfan22:testing,
  title		= {Testing {{Dafny}} (Experience Paper)},
  booktitle	= {Proceedings of the 31st {{ACM SIGSOFT International
		  Symposium}} on {{Software Testing}} and {{Analysis}}},
  author	= {Irfan, Ahmed and Porncharoenwase, Sorawee and
		  Rakamari{\'c}, Zvonimir and Rungta, Neha and Torlak, Emina},
  year		= {2022},
  month		= jul,
  series	= {{{ISSTA}} 2022},
  pages		= {556--567},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3533767.3534382},
  urldate	= {2023-09-26},
  abstract	= {Verification toolchains are widely used to prove the
		  correctness of critical software systems. To build
		  confidence in their results, it is important to develop
		  testing frameworks that help detect bugs in these
		  toolchains. Inspired by the success of fuzzing in finding
		  bugs in compilers and SMT solvers, we have built the first
		  fuzzing and differential testing framework for Dafny, a
		  high-level programming language with a Floyd-Hoare-style
		  program verifier and compilers to C\#, Java, Go, and
		  Javascript. This paper presents our experience building and
		  using XDsmith, a testing framework that targets the entire
		  Dafny toolchain, from verification to compilation. XDsmith
		  randomly generates annotated programs in a subset of Dafny
		  that is free of loops and heap-mutating operations. The
		  generated programs include preconditions, postconditions,
		  and assertions, and they have a known verification outcome.
		  These programs are used to test the soundness and precision
		  of the Dafny verifier, and to perform differential testing
		  on the four Dafny compilers. Using XDsmith, we uncovered 31
		  bugs across the Dafny verifier and compilers, each of which
		  has been confirmed by the Dafny developers. Moreover, 8 of
		  these bugs have been fixed in the mainline release of
		  Dafny.},
  isbn		= {978-1-4503-9379-9},
  keywords	= {differential testing,fuzzing,program verification}
}

@Misc{		  iry09:brief,
  title		= {A Brief, Incomplete, and Mostly Wrong History of
		  Programming Languages},
  author	= {Iry, James},
  year		= {2009},
  publisher	= {May}
}

@Article{	  isoiecieee-international-standard,
  title		= {{{ISO}}/{{IEC}}/{{IEEE International Standard}} -
		  {{Systems}} and Software Engineering--{{Vocabulary}}},
  year		= {2017},
  month		= aug,
  journal	= {ISO/IEC/IEEE 24765:2017(E)},
  pages		= {1--541},
  doi		= {10.1109/IEEESTD.2017.8016712},
  urldate	= {2025-05-06},
  abstract	= {This document provides a common vocabulary applicable to
		  all systems and software engineering work. It was prepared
		  to collect and standardize terminology. This document is
		  intended to serve as a useful reference for those in the
		  information technology field, and to encourage the use of
		  systems and software engineering standards prepared by ISO
		  and liaison organizations IEEE Computer Society and Project
		  Management Institute. This document includes references to
		  the active source standards for definitions so that systems
		  and software engineering concepts and requirements can be
		  further explored.},
  keywords	= {24765,computer,dictionary,IEC Standards,IEEE
		  Standards,Informatino technology,information technology,ISO
		  Standards,software engineering,Software engineering,systems
		  engineering,Systems engineering and theoryt,Terminology}
}

@InProceedings{	  jacoby61:automation,
  title		= {Automation of Program Debugging},
  booktitle	= {Proceedings of the 1961 16th {{ACM}} National Meeting},
  author	= {Jacoby, K. and Layton, H.},
  year		= {1961},
  month		= jan,
  series	= {{{ACM}} '61},
  pages		= {123.201--123.204},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/800029.808556},
  urldate	= {2025-05-08},
  abstract	= {The automatic debugging system discussed here is not
		  limited to a specific computer or programming system; it is
		  adaptable to use with most general purpose computer
		  systems. Automatic debugging of programs offers two main
		  advantages. First, the programmer must consider more
		  closely the conditions under which he can state with
		  assurance that his program is in reality debugged.
		  Secondly, automatic debugging can substantially reduce the
		  lead time required between the coding of a complex problem
		  and the achievement of effective production runs.},
  isbn		= {978-1-4503-7388-3}
}

@InProceedings{	  james13:isomorphic,
  title		= {Isomorphic {{Interpreters}} from {{Logically Reversible
		  Abstract Machines}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {James, Roshan P. and Sabry, Amr},
  editor	= {Gl{\"u}ck, Robert and Yokoyama, Tetsuo},
  year		= {2013},
  pages		= {57--71},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-36315-3_5},
  abstract	= {In our previous work, we developed a reversible
		  programming language and established that every computation
		  in it is a (partial) isomorphism that is reversible and
		  that preserves information. The language is founded on type
		  isomorphisms that have a clear categorical semantics but
		  that are awkward as a notation for writing actual programs,
		  especially recursive ones. This paper remedies this aspect
		  by presenting a systematic technique for developing a large
		  and expressive class of reversible recursive programs, that
		  of logically reversible small-step abstract machines. In
		  other words, this paper shows that once we have a logically
		  reversible machine in a notation of our choice, expressing
		  the machine as an isomorphic interpreter can be done
		  systematically and does not present any significant
		  conceptual difficulties. Concretely, we develop several
		  simple interpreters over numbers and addition, move on to
		  tree traversals, and finish with a meta-circular
		  interpreter for our reversible language. This gives us a
		  means of developing large reversible programs with the ease
		  of reasoning at the level of a conventional small-step
		  semantics.},
  isbn		= {978-3-642-36315-3},
  langid	= {english}
}

@InProceedings{	  jangda19:not,
  title		= {Not {{So Fast}}: {{Analyzing}} the {{Performance}} of
		  \{\vphantom\}{{WebAssembly}}\vphantom\{\} vs. {{Native Code}}},
  shorttitle	= {Not {{So Fast}}},
  booktitle	= {2019 {{USENIX Annual Technical Conference}} ({{USENIX
		  ATC}} 19)},
  author	= {Jangda, Abhinav and Powers, Bobby and Berger, Emery D. and
		  Guha, Arjun},
  year		= {2019},
  pages		= {107--120},
  urldate	= {2023-10-30},
  isbn		= {978-1-939133-03-8},
  langid	= {english}
}

@InCollection{	  jard99:remote,
  title		= {Remote Testing Can Be as Powerful as Local Testing},
  booktitle	= {Formal {{Methods}} for {{Protocol Engineering}} and
		  {{Distributed Systems}}: {{FORTE XII}} / {{PSTV XIX}}'99
		  {{IFIP TC6 WG6}}.1 {{Joint International Conference}} on
		  {{Formal Description Techniques}} for {{Distributed
		  Systems}} and {{Communication Protocols}} ({{FORTE XII}})
		  and {{Protocol Specification}}, {{Testing}} and
		  {{Verification}} ({{PSTV XIX}}) {{October}} 5--8, 1999,
		  {{Beijing}}, {{China}}},
  author	= {Jard, Claude and J{\'e}ron, Thierry and Tanguy,
		  L{\'e}na{\"i}ck and Viho, C{\'e}sar},
  editor	= {Wu, Jianping and Chanson, Samuel T. and Gao, Qiang},
  year		= {1999},
  pages		= {25--40},
  publisher	= {Springer US},
  address	= {Boston, MA},
  doi		= {10.1007/978-0-387-35578-8_2},
  urldate	= {2025-05-04},
  abstract	= {Designing test cases for remote asynchronous testing is
		  error-prone. This is due to the difficulty to foresee all
		  the disorders on the observations collected by the tester
		  as well as the possible collisions between stimuli and
		  observations. Designing correct synchronous test cases is
		  easier, but transforming,them into correct asynchronous
		  ones is a difficult task. Moreover, it is difficult to
		  compare remote testing and local testing as in general sets
		  of conformant implementations are not comparable.},
  isbn		= {978-0-387-35578-8},
  langid	= {english},
  keywords	= {Asynchronism,Conformance Testing,Local and Remote
		  Testing,Stamp,Test Generation}
}

@Misc{		  jetbrains-s-r-o-23:webstorm,
  title		= {{{WebStorm}}. {{The}} Smartest {{JavaScript IDE}}},
  author	= {{JetBrains s.r.o.}},
  year		= {2023},
  urldate	= {2023-08-28},
  lastaccessed	= {August 28, 2023}
}

@Article{	  jhala09:software,
  title		= {Software Model Checking},
  author	= {Jhala, Ranjit and Majumdar, Rupak},
  year		= {2009},
  month		= oct,
  journal	= {ACM Comput. Surv.},
  volume	= {41},
  number	= {4},
  pages		= {21:1--21:54},
  issn		= {0360-0300},
  doi		= {10.1145/1592434.1592438},
  urldate	= {2025-03-11},
  abstract	= {We survey recent progress in software model checking.}
}

@InProceedings{	  jin15:concolic,
  title		= {Concolic {{Metamorphic Debugging}}},
  booktitle	= {2015 {{IEEE}} 39th {{Annual Computer Software}} and
		  {{Applications Conference}}},
  author	= {Jin, Hao and Jiang, Yanyan and Liu, Na and Xu, Chang and
		  Ma, Xiaoxing and Lu, Jian},
  year		= {2015},
  month		= jul,
  volume	= {2},
  pages		= {232--241},
  issn		= {0730-3157},
  doi		= {10.1109/COMPSAC.2015.79},
  urldate	= {2024-03-28},
  abstract	= {Debugging is challenging and labor-intensive. Debugging
		  programs with weak or no oracle is even more difficult due
		  to lack of passing and failing test runs as well as their
		  comparisons. To address these challenges, we exploit
		  metamorphic relations to construct new programs that are
		  enhanced with synthesized oracle, and combine concolic
		  testing and branch-switching debugging to localize
		  potentially faulty places in original programs. We name our
		  approach concolic metamorphic debugging (or Comedy for
		  short). We experimentally evaluated Comedy with real-world
		  Java programs. The experimental results reported that
		  Comedy successfully generated debugging report for 88.4\%
		  of 2,330 faulty programs. The average branch distance
		  between the reported locations and the real fault places is
		  only 1.68. Besides, 36\% of the debugging reports precisely
		  locate the fault.},
  keywords	= {Arrays,Concrete,Debugging,Fault
		  localization,Java,Metamorphic
		  relation,Software,Switches,Testing}
}

@InProceedings{	  johnson13:fast,
  title		= {Fast Condensation of the Program Dependence Graph},
  booktitle	= {Proceedings of the 34th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Johnson, Nick P. and Oh, Taewook and Zaks, Ayal and
		  August, David I.},
  year		= {2013},
  month		= jun,
  series	= {{{PLDI}} '13},
  pages		= {39--50},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2491956.2491960},
  urldate	= {2024-03-18},
  abstract	= {Aggressive compiler optimizations are formulated around
		  the Program Dependence Graph (PDG). Many techniques,
		  including loop fission and parallelization are concerned
		  primarily with dependence cycles in the PDG. The Directed
		  Acyclic Graph of Strongly Connected Components (DAGSCC)
		  represents these cycles directly. The naive method to
		  construct the DAGSCC first computes the full PDG. This
		  approach limits adoption of aggressive optimizations
		  because the number of analysis queries grows quadratically
		  with program size, making DAGSCC construction expensive.
		  Consequently, compilers optimize small scopes with weaker
		  but faster analyses. We observe that many PDG edges do not
		  affect the DAGSCC and that ignoring them cannot affect
		  clients of the DAGSCC. Exploiting this insight, we present
		  an algorithm to omit those analysis queries to compute the
		  DAGSCC efficiently. Across 366 hot loops from 20 SPEC2006
		  benchmarks, this method computes the DAGSCC in half of the
		  time using half as many queries.},
  isbn		= {978-1-4503-2014-6},
  keywords	= {demand-driven analysis,dependence analysis,program
		  dependence graph (pdg),strongly-connected components
		  (scc)}
}

@Article{	  johnson81:dispel,
  title		= {Dispel: {{A}} Run-Time Debugging Language},
  shorttitle	= {Dispel},
  author	= {Johnson, M.S.},
  year		= {1981},
  journal	= {Computer Languages},
  volume	= {6},
  number	= {2},
  pages		= {79--94},
  doi		= {10.1016/0096-0551(81)90068-0},
  abstract	= {Dispel is a language designed to aid communication between
		  an interactive user and a run-time, symbolic debugging
		  system. Important attributes of Dispel are that it provides
		  a small set of primitive debugging actions, most
		  traditional debugging aids (such as variable traces and
		  postmortem dumps) are written in terms of these primitives
		  as debugging routines, and Dispel serves both as an
		  interactive debugging command language and as a
		  special-purpose programming language. The syntax and
		  semantics of Dispel are explained and examples of Dispel
		  commands and routines are presented. {\copyright} 1981.},
  keywords	= {Command languages,Control structures,Debugging,Debugging
		  languages,Dispel,Programming languages,Run-time
		  debugging,Special-purpose languages,Symbolic debugging}
}

@Article{	  jung17:rustbelt,
  title		= {{{RustBelt}}: Securing the Foundations of the {{Rust}}
		  Programming Language},
  shorttitle	= {{{RustBelt}}},
  author	= {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers,
		  Robbert and Dreyer, Derek},
  year		= {2017},
  month		= dec,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {2},
  number	= {POPL},
  pages		= {66:1--66:34},
  doi		= {10.1145/3158154},
  urldate	= {2024-11-27},
  abstract	= {Rust is a new systems programming language that promises
		  to overcome the seemingly fundamental tradeoff between
		  high-level safety guarantees and low-level control over
		  resource management. Unfortunately, none of Rust's safety
		  claims have been formally proven, and there is good reason
		  to question whether they actually hold. Specifically, Rust
		  employs a strong, ownership-based type system, but then
		  extends the expressive power of this core type system
		  through libraries that internally use unsafe features. In
		  this paper, we give the first formal (and machine-checked)
		  safety proof for a language representing a realistic subset
		  of Rust. Our proof is extensible in the sense that, for
		  each new Rust library that uses unsafe features, we can say
		  what verification condition it must satisfy in order for it
		  to be deemed a safe extension to the language. We have
		  carried out this verification for some of the most
		  important libraries that are used throughout the Rust
		  ecosystem.}
}

@Article{	  jungmair24:hipy,
  title		= {{{HiPy}}: {{Extracting High-Level Semantics}} from
		  {{Python Code}} for {{Data Processing}}},
  shorttitle	= {{{HiPy}}},
  author	= {Jungmair, Michael and Engelke, Alexis and Giceva, Jana},
  year		= {2024},
  month		= oct,
  journal	= {Artifact for "HiPy: Extracting High-Level Semantics From
		  Python Code For Data Processing"},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {297:736--297:762},
  doi		= {10.1145/3689737},
  urldate	= {2024-12-18},
  abstract	= {Data science workloads frequently include Python code, but
		  Python's dynamic nature makes efficient execution hard.
		  Traditional approaches either treat Python as a black box,
		  missing out on optimization potential, or are limited to a
		  narrow domain. However, a deep and efficient integration of
		  user-defined Python code into data processing systems
		  requires extracting the semantics of the entire Python
		  code. In this paper, we propose a novel approach for
		  extracting the high-level semantics by transforming general
		  Python functions into program generators that generate a
		  statically-typed IR when executed. The extracted IR then
		  allows for high-level, domain-specific optimizations and
		  the generation of efficient C++ code. With our prototype
		  implementation, HiPy, we achieve single-threaded speedups
		  of 2-20x for many workloads. Furthermore, HiPy is also
		  capable of accelerating Python code in other domains like
		  numerical data, where it can sometimes even outperform
		  specialized compilers.}
}

@Misc{		  junit,
  title		= {{{JUnit}} 5},
  author	= {{The JUnit Team}},
  urldate	= {2024-02-09},
  howpublished	= {https://junit.org/junit5/}
}

@InProceedings{	  kahlon09:monotonic,
  title		= {Monotonic {{Partial Order Reduction}}: {{An Optimal
		  Symbolic Partial Order Reduction Technique}}},
  shorttitle	= {Monotonic {{Partial Order Reduction}}},
  booktitle	= {Computer {{Aided Verification}}},
  author	= {Kahlon, Vineet and Wang, Chao and Gupta, Aarti},
  editor	= {Bouajjani, Ahmed and Maler, Oded},
  year		= {2009},
  pages		= {398--413},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-02658-4_31},
  abstract	= {We present a new technique called Monotonic Partial Order
		  Reduction (MPOR) that effectively combines dynamic partial
		  order reduction with symbolic state space exploration for
		  model checking concurrent software. Our technique hinges on
		  a new characterization of partial orders defined by
		  computations of a concurrent program in terms of
		  quasi-monotonic sequences of thread-ids. This
		  characterization, which is of independent interest, can be
		  used both for explicit or symbolic model checking. For
		  symbolic model checking, MPOR works by adding constraints
		  to allow automatic pruning of redundant interleavings in a
		  SAT/SMT solver based search by restricting the
		  interleavings explored to the set of quasi-monotonic
		  sequences. Quasi-monotonicity guarantees both soundness
		  (all necessary interleavings are explored) and optimality
		  (no redundant interleaving is explored) and is, to the best
		  of our knowledge, the only known optimal symbolic POR
		  technique.},
  isbn		= {978-3-642-02658-4},
  langid	= {english},
  keywords	= {Bound Model Check,Concurrent Program,Model Check,Schedule
		  Constraint,Symbolic Model Check}
}

@Article{	  kakarla24:diffy,
  title		= {Diffy: {{Data-Driven Bug Finding}} for
		  {{Configurations}}},
  shorttitle	= {Diffy},
  author	= {Kakarla, Siva Kesava Reddy and Yan, Francis Y. and
		  Beckett, Ryan},
  year		= {2024},
  month		= jun,
  journal	= {Source code for article "Diffy: Data-Driven Bug Finding
		  for Configurations"},
  volume	= {8},
  number	= {PLDI},
  pages		= {155:199--155:222},
  doi		= {10.1145/3656385},
  urldate	= {2024-08-20},
  abstract	= {Configuration errors remain a major cause of system
		  failures and service outages. One promising approach to
		  identify configuration errors automatically is to learn
		  common usage patterns (and anti-patterns) using data-driven
		  methods. However, existing data-driven learning approaches
		  analyze only simple configurations (e.g., those with no
		  hierarchical structure), identify only simple types of
		  issues (e.g., type errors), or require extensive
		  domain-specific tuning. In this paper, we present Diffy,
		  the first push-button configuration analyzer that detects
		  likely bugs in structured configurations. From example
		  configurations, Diffy learns a common template, with
		  "holes" that capture their variation. It then applies
		  unsupervised learning to identify anomalous template
		  parameters as likely bugs. We evaluate Diffy on a large
		  cloud provider's wide-area network, an operational 5G
		  network testbed, and MySQL configurations, demonstrating
		  its versatility, performance, and accuracy. During Diffy's
		  development, it caught and prevented a bug in a
		  configuration timer value that had previously caused an
		  outage for the cloud provider.}
}

@InProceedings{	  kanstren18:architectures,
  title		= {Architectures and Experiences in Testing {{IoT}}
		  Communications},
  booktitle	= {Proceedings - 2018 {{IEEE}} 11th {{International
		  Conference}} on {{Software Testing}}, {{Verification}} and
		  {{Validation Workshops}}, {{ICSTW}} 2018},
  author	= {Kanstr{\'e}n, T. and M{\"a}kel{\"a}, J. and Karhula, P.},
  year		= {2018},
  pages		= {98--103},
  doi		= {10.1109/ICSTW.2018.00034},
  abstract	= {A typical architecture for Internet of Things (IoT)
		  systems consist of simple embedded systems (e.g., sensor
		  nodes), collecting data, connected to a more traditional
		  backend system providing end-user services. In our
		  experience, compared to more general software testing, the
		  most specific element in IoT testing is that of highly
		  distributed and dynamic communication of IoT nodes, such as
		  sensors. Further challenges for IoT reliability testing
		  come from the architectural elements of IoT gateways
		  connecting the devices to the networks, and the networks
		  themselves which can host all other type of traffic at the
		  same time. In this paper, we describe our experiences with
		  these different aspects of IoT communications testing, and
		  related test architectures. {\copyright} 2018 IEEE.},
  keywords	= {Architecture,Experiences,Internet of things,IoT,Testing}
}

@InProceedings{	  karmios23:symbolic,
  title		= {Symbolic {{Debugging}} with {{Gillian}}},
  booktitle	= {Proceedings of the 1st {{ACM International Workshop}} on
		  {{Future Debugging Techniques}}},
  author	= {Karmios, Nat and Ayoun, Sacha-{\'E}lie and Gardner,
		  Philippa},
  year		= {2023},
  month		= jul,
  series	= {{{DEBT}} 2023},
  pages		= {1--2},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3605155.3605861},
  urldate	= {2025-05-08},
  abstract	= {Software debugging for concrete execution enjoys a mature
		  suite of tools, but debugging symbolic execution is still
		  in its infancy. It carries unique challenges, as a single
		  state can lead to multiple branches representing different
		  sets of conditions, and symbolic states must be 'matched'
		  against logical conditions. Some of today's otherwise
		  mature symbolic-execution tools still rely on plain-text
		  log files for debugging, which provide no good overview of
		  the execution process and can quickly become overwhelming.
		  We introduce a debugger for Gillian's verification
		  mode---complete with a custom interface---and ponder the
		  potential for this interface and the protocol behind it to
		  be used outside of Gillian.},
  isbn		= {9798400702457}
}

@InProceedings{	  keahey20:lessons,
  title		= {Lessons {{Learned}} from the {{Chameleon Testbed}}},
  booktitle	= {2020 {{USENIX Annual Technical Conference}} ({{USENIX
		  ATC}} 20)},
  author	= {Keahey, Kate and Anderson, Jason and Zhen, Zhuo and
		  Riteau, Pierre and Ruth, Paul and Stanzione, Dan and Cevik,
		  Mert and Colleran, Jacob and Gunawi, Haryadi S. and
		  Hammock, Cody and Mambretti, Joe and Barnes, Alexander and
		  Halbah, Fran{\c c}ois and Rocha, Alex and Stubbs, Joe},
  year		= {2020},
  pages		= {219--233},
  urldate	= {2025-05-04},
  isbn		= {978-1-939133-14-4},
  langid	= {english}
}

@Article{	  kecskemeti17:modelling,
  title		= {Modelling and {{Simulation Challenges}} in {{Internet}} of
		  {{Things}}},
  author	= {Kecskemeti, Gabor and Casale, Giuliano and Jha, Devki
		  Nandan and Lyon, Justin and Ranjan, Rajiv},
  year		= {2017},
  month		= jan,
  journal	= {IEEE Cloud Computing},
  volume	= {4},
  number	= {1},
  pages		= {62--69},
  issn		= {2325-6095},
  doi		= {10.1109/MCC.2017.18},
  urldate	= {2025-01-13},
  abstract	= {With the rise of internet of things (IoT) technology, it
		  is anticipated that large-scale sensor-based systems will
		  permeate society, calling for novel methodologies to
		  design, test, and operate these systems. IoT relies on
		  networked interconnected physical devices often featuring
		  computational capabilities. The sheer number of these
		  interconnected devices plays a key role in the IoT
		  revolution. For example, Gartner research predicts that IoT
		  will connect up to 50 to 100 billion devices by 2020. It is
		  estimated that IoT will generate 1.7 trillion US dollars in
		  value by 2020 with an approximate growth rate of 20\% year
		  over year.},
  keywords	= {Actuators,cloud computing,Cloud computing,Computational
		  modeling,Data models,Internet of Things,Internet of Things
		  (IoT),IoT Data Analytics Platform
		  (IoTDAPs),Programming,secure communication,Sensors}
}

@Article{	  kelly81:reversibility,
  title		= {Reversibility and Stochastic Networks / {{F}}.{{P}}.
		  {{Kelly}}},
  author	= {Kelly, F.P.},
  year		= {1981},
  month		= jun,
  journal	= {SERBIULA (sistema Librum 2.0)},
  volume	= {76},
  doi		= {10.2307/2287860},
  abstract	= {Incluye bibliograf{\'i}a e {\'i}ndice}
}

@Book{		  kemeny68:basic,
  title		= {Basic: A Manual for {{BASIC}}, the Elementary Algebraic
		  Language Designed for Use with the {{Dartmouth Time Sharing
		  System}}},
  author	= {Kemeny, John G and Kurtz, Thomas E and Cochran, David S},
  year		= {1968},
  publisher	= {Dartmouth Publications}
}

@Article{	  kennedy74:peanos,
  title		= {Peano's Concept of Number},
  author	= {Kennedy, Hubert C},
  year		= {1974},
  journal	= {Historia Mathematica},
  volume	= {1},
  number	= {4},
  pages		= {387--408},
  issn		= {0315-0860},
  doi		= {10.1016/0315-0860(74)90031-7},
  abstract	= {Giuseppe Peano's development of the real number system
		  from his postulates for the natural numbers and some of his
		  views on definitions in mathematics are presented in order
		  to clarify his concept of number. They show that his use of
		  the axiomatic method was intended to make mathematical
		  theory clearer, more precise, and easier to learn. They
		  further reveal some of his reasons for not accepting the
		  contemporary ``philosophies'' of logicism and formalism,
		  thus showing that he never tried to found mathematics on
		  anything beyond our experience of the material world.
		  Resumen Lo sviluppo dei numeri reali dai numeri naturali di
		  Giuseppe Peano {\`e} qui tracciato, ed alcune sue vedute
		  sulle definizioni matematiche sono presentate allo scopo di
		  chiarire il suo concetto di numero. Esse dimostrano ch'egli
		  adoper{\`o} il metodo assiomatico a fin di rendere la
		  teoria della matematica pi{\`u} chiara, pi{\`u} precisa e
		  pi{\`u} facile ad imparare. Esse rivelano, inoltre, alcune
		  sue ragioni per non accettare le ``filosofie''
		  contemporanee del logicismo e del formalismo. Cos{\'i}
		  {\`e} dimostrato ch'egli non ha mai cercato di fondare la
		  sua teoria matematica su altro che la nostra esperienza del
		  mondo materiale.}
}

@Book{		  kernighan89:c-programming-language,
  title		= {The {{C Programming Language}}},
  author	= {Kernighan, Brian W. and Ritchie, Dennis M.},
  year		= {1989},
  publisher	= {Prentice Hall Press},
  address	= {USA},
  abstract	= {This ebook is the first authorized digital version of
		  Kernighan and Ritchies 1988 classic, The C Programming
		  Language (2nd Ed.). One of the best-selling programming
		  books published in the last fifty years, K\&amp;R has been
		  called everything from the bible to a landmark in computer
		  science and it has influenced generations of programmers.
		  Available now for all leading ebook platforms, this concise
		  and beautifully written text is a must-have reference for
		  every serious programmers digital library. As modestly
		  described by the authors in the Preface to the First
		  Edition, this is not an introductory programming manual; it
		  assumes some familiarity with basic programming concepts
		  like variables, assignment statements, loops, and
		  functions. Nonetheless, a novice programmer should be able
		  to read along and pick up the language, although access to
		  a more knowledgeable colleague will help.},
  isbn		= {0-13-110362-8}
}

@InProceedings{	  kery17:exploring,
  title		= {Exploring Exploratory Programming},
  booktitle	= {2017 {{IEEE Symposium}} on {{Visual Languages}} and
		  {{Human-Centric Computing}} ({{VL}}/{{HCC}})},
  author	= {Kery, Mary Beth and Myers, Brad A.},
  year		= {2017},
  month		= oct,
  pages		= {25--29},
  issn		= {1943-6106},
  doi		= {10.1109/VLHCC.2017.8103446},
  urldate	= {2024-11-12},
  abstract	= {In open-ended tasks where a program's behavior cannot be
		  specified in advance, exploratory programming is a key
		  practice in which programmers actively experiment with
		  different possibilities using code. Exploratory programming
		  is highly relevant today to a variety of professional and
		  end-user programmer domains, including prototyping,
		  learning through play, digital art, and data science.
		  However, prior research has largely lacked clarity on what
		  exploratory programming is, and what behaviors are
		  characteristic of this practice. Drawing on this data and
		  prior literature, we provide an organized description of
		  what exploratory programming has meant historically and a
		  framework of four dimensions for studying exploratory
		  programming tasks: (1) applications, (2) required code
		  quality, (3) ease or difficulty of exploration, and (4) the
		  exploratory process. This provides a basis for better
		  analyzing tool support for exploratory programming.},
  keywords	= {Creativity Support,Debugging,End-user
		  programming,Exploratory Programming,Games,Programming
		  profession,Tools,Visualization}
}

@InProceedings{	  kery17:variolite,
  title		= {Variolite: {{Supporting Exploratory Programming}} by
		  {{Data Scientists}}},
  shorttitle	= {Variolite},
  booktitle	= {Proceedings of the 2017 {{CHI Conference}} on {{Human
		  Factors}} in {{Computing Systems}}},
  author	= {Kery, Mary Beth and Horvath, Amber and Myers, Brad},
  year		= {2017},
  month		= may,
  series	= {{{CHI}} '17},
  pages		= {1265--1276},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3025453.3025626},
  urldate	= {2024-10-30},
  abstract	= {How do people ideate through code? Using semi-structured
		  interviews and a survey, we studied data scientists who
		  program, often with small scripts, to experiment with data.
		  These studies show that data scientists frequently code new
		  analysis ideas by building off of their code from a
		  previous idea. They often rely on informal versioning
		  interactions like copying code, keeping unused code, and
		  commenting out code to repurpose older analysis code while
		  attempting to keep those older analyses intact. Unlike
		  conventional version control, these informal practices
		  allow for fast versioning of any size code snippet, and
		  quick comparisons by interchanging which versions are run.
		  However, data scientists must maintain a strong mental map
		  of their code in order to distinguish versions, leading to
		  errors and confusion. We explore the needs for improving
		  version control tools for exploratory tasks, and
		  demonstrate a tool for lightweight local versioning, called
		  Variolite, which programmers found usable and desirable in
		  a preliminary usability study.},
  isbn		= {978-1-4503-4655-9}
}

@InProceedings{	  kery18:story,
  title		= {The {{Story}} in the {{Notebook}}: {{Exploratory Data
		  Science}} Using a {{Literate Programming Tool}}},
  shorttitle	= {The {{Story}} in the {{Notebook}}},
  booktitle	= {Proceedings of the 2018 {{CHI Conference}} on {{Human
		  Factors}} in {{Computing Systems}}},
  author	= {Kery, Mary Beth and Radensky, Marissa and Arya, Mahima and
		  John, Bonnie E. and Myers, Brad A.},
  year		= {2018},
  month		= apr,
  series	= {{{CHI}} '18},
  pages		= {1--11},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3173574.3173748},
  urldate	= {2024-11-11},
  abstract	= {Literate programming tools are used by millions of
		  programmers today, and are intended to facilitate
		  presenting data analyses in the form of a narrative. We
		  interviewed 21 data scientists to study coding behaviors in
		  a literate programming environment and how data scientists
		  kept track of variants they explored. For participants who
		  tried to keep a detailed history of their experimentation,
		  both informal and formal versioning attempts led to
		  problems, such as reduced notebook readability. During
		  iteration, participants actively curated their notebooks
		  into narratives, although primarily through cell structure
		  rather than markdown explanations. Next, we surveyed 45
		  data scientists and asked them to envision how they might
		  use their past history in an future version control system.
		  Based on these results, we give design guidance for future
		  literate programming tools, such as providing history
		  search based on how programmers recall their explorations,
		  through contextual details including images and
		  parameters.},
  isbn		= {978-1-4503-5620-6}
}

@Article{	  keshav07:how,
  title		= {How to Read a Paper},
  author	= {Keshav, S.},
  year		= {2007},
  month		= jul,
  journal	= {ACM SIGCOMM Computer Communication Review},
  volume	= {37},
  number	= {3},
  pages		= {83--84},
  issn		= {0146-4833},
  doi		= {10.1145/1273445.1273458},
  urldate	= {2023-09-27},
  abstract	= {Researchers spend a great deal of time reading research
		  papers. However, this skill is rarely taught, leading to
		  much wasted effort. This article outlines a practical and
		  efficient three-pass method for reading research papers. I
		  also describe how to use this method to do a literature
		  survey.},
  keywords	= {hints,paper,reading}
}

@Article{	  kessler12:obamas,
  title		= {Obama's Whopper about {{Rutherford B}}. {{Hayes}} and the
		  Telephone},
  author	= {Kessler, Glenn},
  year		= {2012},
  month		= mar,
  journal	= {Washington Post},
  urldate	= {2024-04-18},
  abstract	= {FACT CHECKER {\textbar} The president gets his history
		  about the 19th president and the telephone wrong. Very
		  wrong. FACT CHECKER {\textbar} President Obama gets his
		  history about the 19th president and the telephone wrong.
		  Very wrong. How many Pinnochios does he earn?FACT CHECKER
		  {\textbar} The president gets history about the 19th
		  president and the phone wrong.},
  langid	= {american}
}

@Article{	  ketkar24:lightweight-polyglot-code-transformation-language,
  title		= {A {{Lightweight Polyglot Code Transformation Language}}},
  author	= {Ketkar, Ameya and Ramos, Daniel and Clapp, Lazaro and
		  Barik, Raj and Ramanathan, Murali Krishna},
  year		= {2024},
  month		= jun,
  journal	= {Replication of A Lightweight Polyglot Code Transformation
		  Language},
  volume	= {8},
  number	= {PLDI},
  pages		= {199:1288--199:1312},
  doi		= {10.1145/3656429},
  urldate	= {2024-08-20},
  abstract	= {In today's software industry, large-scale, multi-language
		  codebases are the norm. This brings substantial challenges
		  in developing automated tools for code maintenance tasks
		  such as API migration or dead code cleanup. Tool builders
		  often find themselves caught between two less-than-ideal
		  tooling options: (1) language-specific code rewriting tools
		  or (2) generic, lightweight match-replace transformation
		  tools with limited expressiveness. The former leads to tool
		  fragmentation and a steep learning curve for each language,
		  while the latter forces developers to create ad-hoc,
		  throwaway scripts to handle realistic tasks. To fill this
		  gap, we introduce a new declarative domain-specific
		  language (DSL) for expressing interdependent multi-language
		  code transformations. Our key insight is that we can
		  increase the expressiveness and applicability of
		  lightweight match-replace tools by extending them to
		  support for composition, ordering, and flow. We implemented
		  an open-source tool for our language, called
		  PolyglotPiranha, and deployed it in an industrial setting.
		  We demonstrate its effectiveness through three case
		  studies, where it deleted 210K lines of dead code and
		  migrated 20K lines, across 1611 pull requests. We compare
		  our DSL against state-of-the-art alternatives, and show
		  that the tools we developed are faster, more concise, and
		  easier to maintain.}
}

@InProceedings{	  khan11:limitations,
  title		= {Limitations of Simulation Tools for Large-Scale Wireless
		  Sensor Networks},
  booktitle	= {2011 {{IEEE}} Workshops of International Conference on
		  Advanced Information Networking and Applications},
  author	= {Khan, Muhammad Zahid and Askwith, Bob and Bouhafs, Faycal
		  and Asim, Muhammad},
  year		= {2011},
  pages		= {820--825},
  publisher	= {IEEE},
  address	= {New York, NY, USA},
  doi		= {10.1109/WAINA.2011.59}
}

@InProceedings{	  khan11:limitationsa,
  title		= {Limitations of Simulation Tools for Large-Scale Wireless
		  Sensor Networks},
  booktitle	= {Proceedings - 25th {{IEEE International Conference}} on
		  {{Advanced Information Networking}} and {{Applications
		  Workshops}}, {{WAINA}} 2011},
  author	= {Khan, M.Z. and Askwith, B. and Bouhafs, F. and Asim, M.},
  year		= {2011},
  pages		= {820--825},
  doi		= {10.1109/WAINA.2011.59},
  abstract	= {Wireless Sensor Networks (WSNs) consist of a large number
		  of wireless sensor nodes networked together. It is a
		  complex set of applications, link technologies,
		  communication protocols, traffic flows and routing
		  algorithms. Simulation is a predominant technique used to
		  study and analyse the performance and potency of a senor
		  network design. Since there are a huge variety of
		  simulation tools available for WSNs, which vary in their
		  characteristics and capabilities, it is often very
		  difficult to decide which simulation tool to choose and
		  which one is more appropriate for large-scale WSNs. To
		  address this issue, in this paper, we review some of the
		  most widely-used and state-of-the-art simulation tools for
		  WSNs. This distinguishing feature of this paper is that we
		  identify the key limitations of the reviewed simulation
		  tools and inspect their suitability for large-scale WSNs.
		  We review and investigate simulation tools based on a new
		  set of preferred criterion, i.e. popularity, accessibility
		  (open-source), complexity, accuracy, scalability,
		  extensibility and availability of various models and
		  protocols. {\copyright} 2011 IEEE.},
  keywords	= {scalability,Simulators,WSNs}
}

@Article{	  kim18:iot-taas,
  title		= {{{IoT-TaaS}}: {{Towards}} a {{Prospective IoT Testing
		  Framework}}},
  shorttitle	= {{{IoT-TaaS}}},
  author	= {Kim, Hiun and Ahmad, Abbas and Hwang, Jaeyoung and Baqa,
		  Hamza and Le Gall, Franck and Reina Ortega, Miguel Angel
		  and Song, JaeSeung},
  year		= {2018},
  journal	= {IEEE Access},
  volume	= {6},
  pages		= {15480--15493},
  issn		= {2169-3536},
  doi		= {10.1109/ACCESS.2018.2802489},
  urldate	= {2024-02-12},
  abstract	= {The Internet of Things (IoT) aims to change many aspects
		  of people's daily lives by extending the scope of computing
		  to the physical world, and thus shift the environment of
		  computing more to a distributed and decentralized form. The
		  amount of IoT devices and their collaborative behavior
		  causes new challenges to the scalability of traditional
		  software testing, and the heterogeneity of IoT devices
		  increases costs and the complexity of coordination of
		  testing due to the number of variables. In this paper, we
		  introduce IoT Testing as a Service-IoT-TaaS, a novel
		  service-based approach for an automated IoT testing
		  framework aims to resolve constraints regarding
		  coordination, costs, and scalability issues of traditional
		  software testing in the context of standards-based
		  development of IoT devices, and explore its design and
		  implementation. IoT-TaaS is composed of remote distributed
		  interoperability testing, scalable automated conformance
		  testing, and semantics validation testing components
		  adequate for testing IoT devices. To provide a conceptual
		  overview, we analyze its technical and systemic advancement
		  and compare it to traditional testing with concrete
		  examples.},
  keywords	= {automated testing,conformance testing,Internet of
		  Things,Interoperability,interoperability
		  testing,Protocols,semantic
		  testing,Semantics,Software,Software testing,Standards,test
		  as a service}
}

@Article{	  king76:symbolic,
  title		= {Symbolic Execution and Program Testing},
  author	= {King, James C.},
  year		= {1976},
  month		= jul,
  journal	= {Communications of the ACM},
  volume	= {19},
  number	= {7},
  pages		= {385--394},
  issn		= {0001-0782},
  doi		= {10.1145/360248.360252},
  urldate	= {2023-10-24},
  abstract	= {This paper describes the symbolic execution of programs.
		  Instead of supplying the normal inputs to a program (e.g.
		  numbers) one supplies symbols representing arbitrary
		  values. The execution proceeds as in a normal execution
		  except that values may be symbolic formulas over the input
		  symbols. The difficult, yet interesting issues arise during
		  the symbolic execution of conditional branch type
		  statements. A particular system called EFFIGY which
		  provides symbolic execution for program testing and
		  debugging is also described. It interpretively executes
		  programs written in a simple PL/I style programming
		  language. It includes many standard debugging features, the
		  ability to manage and to prove things about symbolic
		  expressions, a simple program testing manager, and a
		  program verifier. A brief discussion of the relationship
		  between symbolic execution and program proving is also
		  included.},
  keywords	= {program debugging,program proving,program testing,program
		  verification,symbolic execution,symbolic interpretation}
}

@Article{	  kirk23:formal,
  title		= {A Formal Framework for Security Testing of Automotive
		  Over-the-Air Update Systems},
  author	= {Kirk, Rhys and Nguyen, Hoang Nga and Bryans, Jeremy and
		  Shaikh, Siraj Ahmed and Wartnaby, Charles},
  year		= {2023},
  month		= jan,
  journal	= {Journal of Logical and Algebraic Methods in Programming},
  volume	= {130},
  pages		= {100812},
  issn		= {2352-2208},
  doi		= {10.1016/j.jlamp.2022.100812},
  urldate	= {2023-10-25},
  abstract	= {Modern vehicles are comparable to desktop computers due to
		  the increase in connectivity. This fact also extends to
		  potential cyber-attacks. A solution for preventing and
		  mitigating cyber attacks is Over-The-Air (OTA) updates.
		  This solution has also been used for both desktops and
		  mobile phones. The current de facto OTA security system for
		  vehicles is Uptane, which is developed to solve the unique
		  issues vehicles face. The Uptane system needs to have a
		  secure method of updating; otherwise, attackers will
		  exploit it. To this end, we have developed a comprehensive
		  and model-based security testing approach by translating
		  Uptane and our attack model into formal models in
		  Communicating Sequential Processes (CSP). These are
		  combined and verified to generate an exhaustive list of
		  test cases to see to which attacks Uptane may be
		  susceptible. Security testing is then conducted based on
		  these generated test cases, on a test-bed running an
		  implementation of Uptane. The security testing result
		  enables us to validate the security design of Uptane and
		  some vulnerabilities to which it is subject.},
  keywords	= {Automotive cybersecurity,Automotive OTA,CSP,Security
		  testing,Uptane}
}

@Article{	  klimushenkova17:improving,
  title		= {Improving the Performance of Reverse Debugging},
  author	= {Klimushenkova, M. A. and Dovgalyuk, P. M.},
  year		= {2017},
  month		= jan,
  journal	= {Programming and Computer Software},
  volume	= {43},
  number	= {1},
  pages		= {60--66},
  issn		= {1608-3261},
  doi		= {10.1134/S0361768817010042},
  urldate	= {2025-04-21},
  abstract	= {Reverse debugging is the software development technique
		  that effectively helps fix bugs occurring at the
		  nondeterministic program behavior. It allows one to examine
		  the past states of the program without rerunning it. An
		  implementation of reverse debugging based on deterministic
		  replay in the QEMU 2.0 emulator is described. A number of
		  techniques improving the debugging performance due to
		  reducing the amount of saved data, optimized storage of
		  system snapshots, indexing, and compressing of the event
		  log are proposed. The emulator can work together with the
		  interactive GDB debugger, which makes it possible to use
		  the reverse-continue, reverse-nexti, reverse-stepi and
		  reverse-finish commands in the course of debugging. The
		  execution time of these commands depends on the frequency
		  of recording the system's state snapshots. An estimate of
		  the optimal frequency for the reverse-continue command is
		  obtained.},
  langid	= {english},
  keywords	= {Artificial Intelligence}
}

@Article{	  knuth81:breaking,
  title		= {Breaking Paragraphs into Lines},
  author	= {Knuth, Donald E. and Plass, Michael F.},
  year		= {1981},
  month		= nov,
  journal	= {Software: Practice and Experience},
  volume	= {11},
  number	= {11},
  pages		= {1119--1184},
  issn		= {0038-0644, 1097-024X},
  doi		= {10.1002/spe.4380111102},
  urldate	= {2024-01-09},
  abstract	= {Abstract This paper discusses a new approach to the
		  problem of dividing the text of a paragraph into lines of
		  approximately equal length. Instead of simply making
		  decisions one line at a time, the method considers the
		  paragraph as a whole, so that the final appearance of a
		  given line might be influenced by the text on succeeding
		  lines. A system based on three simple primitive concepts
		  called `boxes', `glue', and `penalties' provides the
		  ability to deal satisfactorily with a wide variety of
		  typesetting problems in a unified framework, using a single
		  algorithm that determines optimum breakpoints. The
		  algorithm avoids backtracking by a judicious use of the
		  techniques of dynamic programming. Extensive computational
		  experience confirms that the approach is both efficient and
		  effective in producing high-quality output. The paper
		  concludes with a brief history of line-breaking methods,
		  and an appendix presents a simplified algorithm that
		  requires comparatively few resources.},
  langid	= {english}
}

@Misc{		  koji23:mruby-arduino,
  title		= {Mruby-Arduino. Mruby-Arduino Is Wrapper Mrbgem for
		  {{Arduino API}}.},
  author	= {Koji, Yoshioka and others},
  year		= {2023},
  urldate	= {2023-05},
  lastaccessed	= {May 11, 2023}
}

@Article{	  kong19:automated,
  title		= {Automated {{Testing}} of {{Android Apps}}: {{A Systematic
		  Literature Review}}},
  shorttitle	= {Automated {{Testing}} of {{Android Apps}}},
  author	= {Kong, Pingfan and Li, Li and Gao, Jun and Liu, Kui and
		  Bissyand{\'e}, Tegawend{\'e} F. and Klein, Jacques},
  year		= {2019},
  month		= mar,
  journal	= {IEEE Transactions on Reliability},
  volume	= {68},
  number	= {1},
  pages		= {45--66},
  issn		= {1558-1721},
  doi		= {10.1109/TR.2018.2865733},
  urldate	= {2025-05-04},
  abstract	= {Automated testing of Android apps is essential for app
		  users, app developers, and market maintainer communities
		  alike. Given the widespread adoption of Android and the
		  specificities of its development model, the literature has
		  proposed various testing approaches for ensuring that not
		  only functional requirements but also nonfunctional
		  requirements are satisfied. In this paper, we aim at
		  providing a clear overview of the state-of-the-art works
		  around the topic of Android app testing, in an attempt to
		  highlight the main trends, pinpoint the main methodologies
		  applied, and enumerate the challenges faced by the Android
		  testing approaches as well as the directions where the
		  community effort is still needed. To this end, we conduct a
		  systematic literature review during which we eventually
		  identified 103 relevant research papers published in
		  leading conferences and journals until 2016. Our thorough
		  examination of the relevant literature has led to several
		  findings and highlighted the challenges that Android
		  testing researchers should strive to address in the future.
		  After that, we further propose a few concrete research
		  directions where testing approaches are needed to solve
		  recurrent issues in app updates, continuous increases of
		  app sizes, as well as the Android ecosystem
		  fragmentation.},
  keywords	= {Android,Androids,automated
		  testing,Bibliographies,Ecosystems,Humanoid
		  robots,Java,literature review,survey,Systematics,Testing}
}

@InProceedings{	  konighofer09:debugging,
  title		= {Debugging Formal Specifications Using Simple
		  Counterstrategies},
  booktitle	= {2009 {{Formal Methods}} in {{Computer-Aided Design}}},
  author	= {K{\"o}nighofer, Robert and Hofferek, Georg and Bloem,
		  Roderick},
  year		= {2009},
  month		= nov,
  pages		= {152--159},
  doi		= {10.1109/FMCAD.2009.5351127},
  urldate	= {2025-03-01},
  abstract	= {Deriving a formal specification from an informal design
		  intent is an error-prone process. The resulting
		  specification may be incomplete, unrealizable, or in
		  conflict with the design intent. We propose a debugging
		  method for incorrect specifications that does not need an
		  implementation. We show that we can explain conflicts with
		  the design intent by explaining unrealizability. Our
		  approach for explaining unrealizability is based on
		  counterstrategies. Since counterstrategies may be large, we
		  propose several ways to simplify them. First, we simplify
		  the specification itself by removing both requirements and
		  variables that do not contribute to the problem. Second, we
		  heuristically search for a countertrace, i.e., a single
		  input trace that suffices to demonstrate unrealizability.
		  Finally, we present the countertrace or the counterstrategy
		  to the user in extensive form as a graph and implicitly as
		  an interactive game. We present experimental results for
		  specifications given as GR(1) formulas.},
  keywords	= {Computer errors,Debugging,Design engineering,Formal
		  specifications,Information processing,Protocols,Safety}
}

@Article{	  kopetz87:clock,
  title		= {Clock {{Synchronization}} in {{Distributed Real-Time
		  Systems}}},
  author	= {Kopetz, Hermann and Ochsenreiter, Wilhelm},
  year		= {1987},
  month		= aug,
  journal	= {IEEE Transactions on Computers},
  volume	= {C-36},
  number	= {8},
  pages		= {933--940},
  issn		= {1557-9956},
  doi		= {10.1109/TC.1987.5009516},
  urldate	= {2025-03-04},
  abstract	= {The generation of a fault-tolerant global time base with
		  known accuracy of synchronization is one of the important
		  operating system functions in a distributed real-time
		  system. Depending on the types and number of tolerated
		  faults, this paper presents upper bounds on the achievable
		  synchronization accuracy for external and internal
		  synchronization in a distributed real-time system. The
		  concept of continuous versus instantaneous synchronization
		  is introduced in order to generate a uniform common time
		  base for local, global, and external time measurements. In
		  the last section, the functions of a VLSI clock
		  synchronization unit, which improves the synchronization
		  accuracy and reduces the CPU load, are described. With this
		  unit, the CPU overhead and the network traffic for clock
		  synchronization in state-of-the-art distributed real-time
		  systems can be reduced to less than 1 percent.},
  keywords	= {Accuracy,Clocks,Delay,Distributed real-time
		  systems,external synchronization,Fault
		  tolerance,fault-tolerant clock synchronization,internal
		  synchronization,Real time
		  systems,Synchronization,synchronization accuracy,Time
		  measurement,VLSI clock}
}

@Article{	  kramer90:evolving,
  title		= {The Evolving Philosophers Problem: Dynamic Change
		  Management},
  shorttitle	= {The Evolving Philosophers Problem},
  author	= {Kramer, J. and Magee, J.},
  year		= {1990},
  month		= nov,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {16},
  number	= {11},
  pages		= {1293--1306},
  issn		= {1939-3520},
  doi		= {10.1109/32.60317},
  urldate	= {2024-01-16},
  abstract	= {A model for dynamic change management which separates
		  structural concerns from component application concerns is
		  presented. This separation of concerns permits the
		  formulation of general structural rules for change at the
		  configuration level without the need to consider
		  application state, and the specification of application
		  component actions without prior knowledge of the actual
		  structural changes which may be introduced. In addition,
		  the changes can be applied in such a way so as to leave the
		  modified system in a consistent state, and cause no
		  disturbance to the unaffected part of the operational
		  system. The model is applied to an example problem,
		  'evolving philosophers'. The principles of this model have
		  been implemented and tested in the Conic environment for
		  distributed systems.{$<>$}}
}

@InProceedings{	  krasnogolowy12:flexible,
  title		= {Flexible Debugging of Behavior Models},
  booktitle	= {2012 {{IEEE International Conference}} on {{Industrial
		  Technology}}},
  author	= {Krasnogolowy, Alexander and Hildebrandt, Stephan and
		  W{\"a}tzoldt, Sebastian},
  year		= {2012},
  month		= mar,
  pages		= {331--336},
  doi		= {10.1109/ICIT.2012.6209959},
  urldate	= {2025-04-18},
  abstract	= {Model-Driven Engineering shifts the focus from code to
		  models as the primary development artifacts. Therefore,
		  also testing and debugging efforts have to focus on models.
		  Some debuggers for modeling languages already exist but
		  they lack the flexibility to fix errors and verify the
		  correction at runtime. In this paper, we consider how
		  debugging concepts of general-purpose programming languages
		  can be mapped to story diagrams, a behavior modeling
		  language, and what has to be considered in general when
		  implementing debuggers for a modeling language. Then, we
		  present a debugger for story diagrams. In addition to
		  common debugging features, it allows to change the executed
		  model at runtime and to revert the execution to an earlier
		  point, which provides a higher flexibility to the
		  developer. After finding an error in the model, the
		  developer does not need to restart the execution from the
		  beginning, but can go back to a point before the error, fix
		  the error, and continue executing the model.},
  keywords	= {Irrigation,Pattern matching,Unified modeling language}
}

@InProceedings{	  krebs23:probe,
  title		= {Probe {{Log}}: {{Visualizing}} the {{Control Flow}} of
		  {{Babylonian Programming}}},
  shorttitle	= {Probe {{Log}}},
  booktitle	= {Companion {{Proceedings}} of the 7th {{International
		  Conference}} on the {{Art}}, {{Science}}, and
		  {{Engineering}} of {{Programming}}},
  author	= {Krebs, Eva and Rein, Patrick and Bergsiek, Joana and
		  Urban, Lina and Hirschfeld, Robert},
  year		= {2023},
  month		= sep,
  series	= {Programming '23},
  pages		= {61--67},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3594671.3594679},
  urldate	= {2024-03-13},
  abstract	= {Code itself is abstract, which makes it often difficult to
		  understand -- sometimes even by the programmers that wrote
		  it. When working with or thinking about code, programmers
		  thus often resort to concrete values and execution traces
		  to make the abstract more tangible. Such approaches like
		  exploration scripts in a workspace or unit tests of a test
		  suite are already very helpful, but still lack a convenient
		  conceptual and technical integration into core development
		  tools, leaving such examples and the code they refer to too
		  far apart. Example-based programming like Babylonian
		  Programming aims at offering the benefits of concrete, live
		  examples directly in program editors, interleaved with the
		  code it supports, to shorten feedback loops and reduce the
		  need for context switches coming with changing tools.
		  However, Babylonian Programming and its tools currently
		  focus on a local perspective on code exploration, but do
		  not yet extend to messages sent outside a particular unit
		  of code and with that do not yet directly support feedback
		  on more dynamic properties of a running program / system.
		  We developed Probe Log, a Babylonian Programming tool that
		  extends the benefits of example-based programming to
		  scenarios that span across multiple procedures. It provides
		  a linear view on the dynamics of evolving examples beyond a
		  local perspective.},
  isbn		= {9798400707551},
  keywords	= {babylonian programming,example-based
		  programming,examples,exploratory programming,live
		  programming,smalltalk,squeak}
}

@Misc{		  krekel23:pytest,
  title		= {Pytest: Helps You Write Better Programs},
  author	= {Krekel, Holger and {team}, pytest-dev},
  year		= {2023},
  urldate	= {2023-01-10},
  lastaccessed	= {January 10, 2023}
}

@InProceedings{	  krinke04:visualization,
  title		= {Visualization of Program Dependence and Slices},
  booktitle	= {20th {{IEEE International Conference}} on {{Software
		  Maintenance}}, 2004. {{Proceedings}}.},
  author	= {Krinke, J.},
  year		= {2004},
  month		= sep,
  pages		= {168--177},
  issn		= {1063-6773},
  doi		= {10.1109/ICSM.2004.1357801},
  urldate	= {2024-03-14},
  abstract	= {The program dependence graph (PDG) itself and the computed
		  slices within the program dependence graph are results that
		  should be presented to the user in a comprehensible form,
		  if not used in subsequent analyses. A graphical
		  presentation would be preferred as it is usually more
		  intuitive than textual ones. This work describes how a
		  layout for the PDGs can be generated to enable an appealing
		  presentation. However, experience shows that the graphical
		  presentation is less helpful than expected and a textual
		  presentation is superior. Therefore, this work contains an
		  approach to textually present slices of PDGs in source
		  code. The innovation of this approach is the fine-grained
		  visualization of arbitrary node sets based on tokens and
		  not on complete lines like in other approaches.
		  Furthermore, a major obstacle in visualization and
		  comprehension of slices is the loss of locality. Thus, this
		  work presents a simple, yet effective, approach to limit
		  the range of a slice. This approach enables a visualization
		  of slices where the local effects stand out against the
		  more global effects. A second, more sophisticated approach
		  visualizes the influence range of chops for variables and
		  procedures. This enables a visualization of the impact of
		  procedures and variables on the complete system.},
  keywords	= {Application software,Area measurement,Data flow
		  computing,Iterative methods,Layout,Software
		  maintenance,Software measurement,Software
		  testing,Technological innovation,Visualization}
}

@InProceedings{	  kurshan98:static,
  title		= {Static Partial Order Reduction},
  booktitle	= {Tools and {{Algorithms}} for the {{Construction}} and
		  {{Analysis}} of {{Systems}}},
  author	= {Kurshan, R. and Levin, V. and Minea, M. and Peled, D. and
		  Yenig{\"u}n, H.},
  editor	= {Steffen, Bernhard},
  year		= {1998},
  pages		= {345--357},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/BFb0054182},
  abstract	= {The state space explosion problem is central to automatic
		  verification algorithms. One of the successful techniques
		  to abate this problem is called `partial order reduction'.
		  It is based on the observation that in many cases the
		  specification of concurrent programs does not depend on the
		  order in which concurrently executed events are
		  interleaved. In this paper we present a new version of
		  partial order reduction that allows all of the reduction to
		  be set up at the time of compiling the system description.
		  Normally, partial order reduction requires developing
		  specialized verification algorithms, which in the course of
		  a state space search, select a subset of the possible
		  transitions from each reached global state. In our
		  approach, the set of atomic transitions obtained from the
		  system description after our special compilation, already
		  generates a smaller number of choices from each state.
		  Thus, rather than conducting a modified search of the state
		  space generated by the original state transition relation,
		  our approach involves an ordinary search of the reachable
		  state space generated by a modified state transition
		  relation. Among the advantages of this technique over other
		  versions of the reduction is that it can be directly
		  implemented using existing verification tools, as it
		  requires no change of the verification engine: the entire
		  reduction mechanism is set up at compile time. One major
		  application is the use of this reduction technique together
		  with symbolic model checking and localization reduction,
		  obtaining a combined reduction. We discuss an
		  implementation and experimental results for SDL programs
		  translated into Cospan notation by applying our reduction
		  techniques. This is part of a hardware-software
		  co-verification project.},
  isbn		= {978-3-540-69753-4},
  langid	= {english},
  keywords	= {Linear Time Temporal Logic,Model Check,Model Check
		  Algorithm,Symbolic Model Check,Visible Transition}
}

@InProceedings{	  lam19:root,
  title		= {Root Causing Flaky Tests in a Large-Scale Industrial
		  Setting},
  booktitle	= {Proceedings of the 28th {{ACM SIGSOFT}} International
		  Symposium on Software Testing and Analysis},
  author	= {Lam, Wing and Godefroid, Patrice and Nath, Suman and
		  Santhiar, Anirudh and Thummalapenta, Suresh},
  year		= {2019},
  series	= {Issta 2019},
  pages		= {101--111},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3293882.3330570},
  abstract	= {In today's agile world, developers often rely on
		  continuous integration pipelines to help build and validate
		  their changes by executing tests in an efficient manner.
		  One of the significant factors that hinder developers'
		  productivity is flaky tests---tests that may pass and fail
		  with the same version of code. Since flaky test failures
		  are not deterministically reproducible, developers often
		  have to spend hours only to discover that the occasional
		  failures have nothing to do with their changes. However,
		  ignoring failures of flaky tests can be dangerous, since
		  those failures may represent real faults in the production
		  code. Furthermore, identifying the root cause of flakiness
		  is tedious and cumbersome, since they are often a
		  consequence of unexpected and non-deterministic behavior
		  due to various factors, such as concurrency and external
		  dependencies. As developers in a large-scale industrial
		  setting, we first describe our experience with flaky tests
		  by conducting a study on them. Our results show that
		  although the number of distinct flaky tests may be low, the
		  percentage of failing builds due to flaky tests can be
		  substantial. To reduce the burden of flaky tests on
		  developers, we describe our end-to-end framework that helps
		  identify flaky tests and understand their root causes. Our
		  framework instruments flaky tests and all relevant code to
		  log various runtime properties, and then uses a preliminary
		  tool, called RootFinder, to find differences in the logs of
		  passing and failing runs. Using our framework, we collect
		  and publicize a dataset of real-world, anonymized execution
		  logs of flaky tests. By sharing the findings from our
		  study, our framework and tool, and a dataset of logs, we
		  hope to encourage more research on this important
		  problem.},
  isbn		= {978-1-4503-6224-5},
  keywords	= {debugging,flaky tests,regression testing}
}

@InProceedings{	  lami24:small-step-semantics,
  title		= {A {{Small-Step Semantics}} for~{{Janus}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Lami, Pietro and Lanese, Ivan and Stefani, Jean-Bernard},
  editor	= {Mogensen, Torben {\AE}gidius and Mikulski, {\L}ukasz},
  year		= {2024},
  pages		= {105--123},
  publisher	= {Springer Nature Switzerland},
  address	= {Cham},
  doi		= {10.1007/978-3-031-62076-8_8},
  abstract	= {Janus is an imperative, sequential language for
		  reversibility. While heavily studied in the reversibility
		  literature, to the best of our knowledge, no small-step
		  semantics for it exists. Hence, we propose a small-step
		  semantics for Janus and we prove it equivalent to a
		  big-step semantics from the literature, for programs that
		  have no runtime errors and no divergence. Our main
		  motivation is to enable a future extension of Janus with
		  concurrency primitives, which is more easily defined on top
		  of a small-step semantics. As additional feature, a
		  small-step semantics allows one to more easily distinguish
		  between failing and non-terminating computations.},
  isbn		= {978-3-031-62076-8},
  langid	= {english}
}

@Article{	  lamport78:time,
  title		= {Time, Clocks, and the Ordering of Events in a Distributed
		  System},
  author	= {Lamport, Leslie},
  year		= {1978},
  month		= jul,
  journal	= {Commun. ACM},
  volume	= {21},
  number	= {7},
  pages		= {558--565},
  issn		= {0001-0782},
  doi		= {10.1145/359545.359563},
  urldate	= {2025-03-04},
  abstract	= {The concept of one event happening before another in a
		  distributed system is examined, and is shown to define a
		  partial ordering of the events. A distributed algorithm is
		  given for synchronizing a system of logical clocks which
		  can be used to totally order the events. The use of the
		  total ordering is illustrated with a method for solving
		  synchronization problems. The algorithm is then specialized
		  for synchronizing physical clocks, and a bound is derived
		  on how far out of synchrony the clocks can become.}
}

@Article{	  lamport79:how,
  title		= {How to {{Make}} a {{Multiprocessor Computer That Correctly
		  Executes Multiprocess Programs}}},
  author	= {{Lamport}},
  year		= {1979},
  month		= sep,
  journal	= {IEEE Transactions on Computers},
  volume	= {C-28},
  number	= {9},
  pages		= {690--691},
  issn		= {1557-9956},
  doi		= {10.1109/TC.1979.1675439},
  urldate	= {2025-03-04},
  abstract	= {Many large sequential computers execute operations in a
		  different order than is specified by the program. A correct
		  execution is achieved if the results produced are the same
		  as would be produced by executing the program steps in
		  order. For a multiprocessor computer, such a correct
		  execution by each processor does not guarantee the correct
		  execution of the entire program. Additional conditions are
		  given which do guarantee that a computer correctly executes
		  multiprocess programs.},
  keywords	= {Computer design,concurrent computing,hardware
		  correctness,multiprocessing,parallel processing}
}

@InProceedings{	  lanese13:concurrent,
  title		= {Concurrent {{Flexible Reversibility}}},
  booktitle	= {Programming {{Languages}} and {{Systems}}},
  author	= {Lanese, Ivan and Lienhardt, Michael and Mezzina, Claudio
		  Antares and Schmitt, Alan and Stefani, Jean-Bernard},
  editor	= {Felleisen, Matthias and Gardner, Philippa},
  year		= {2013},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {370--390},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-37036-6_21},
  abstract	= {Concurrent reversibility has been studied in different
		  areas, such as biological or dependable distributed
		  systems. However, only ``rigid'' reversibility has been
		  considered, allowing to go back to a past state and restart
		  the exact same computation, possibly leading to divergence.
		  In this paper, we present croll-{$\pi$}, a concurrent
		  calculus featuring flexible reversibility, allowing the
		  specification of alternatives to a computation to be used
		  upon rollback. Alternatives in croll-{$\pi$} are attached
		  to messages. We show the robustness of this mechanism by
		  encoding more complex idioms for specifying flexible
		  reversibility, and we illustrate the benefits of our
		  approach by encoding a calculus of communicating
		  transactions.},
  isbn		= {978-3-642-37036-6},
  langid	= {english},
  keywords	= {Causal Dependence,Parallel Composition,Past
		  State,Reduction Rule,Transactional Memory}
}

@Article{	  lanese14:causal-consistent-reversibility,
  title		= {Causal-{{Consistent Reversibility}}},
  author	= {Lanese, Ivan and Mezzina, Claudio and Tiezzi, Francesco},
  year		= {2014},
  month		= nov,
  abstract	= {Reversible computing allows one to execute programs both
		  in the standard , forward direction, and backward, going
		  back to past states. In a concurrent scenario, the correct
		  notion of reversibility is causal-consistent
		  re-versibility: any action can be undone, provided that all
		  its consequences (if any) are undone beforehand. In this
		  paper we present an overview of the main approaches,
		  results, and applications of causal-consistent
		  reversibility.}
}

@InProceedings{	  lanese18:cauder,
  title		= {{{CauDEr}}: {{A Causal-Consistent Reversible Debugger}}
		  for {{Erlang}}},
  shorttitle	= {{{CauDEr}}},
  booktitle	= {Functional and {{Logic Programming}}},
  author	= {Lanese, Ivan and Nishida, Naoki and Palacios, Adri{\'a}n
		  and Vidal, Germ{\'a}n},
  editor	= {Gallagher, John P. and Sulzmann, Martin},
  year		= {2018},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {247--263},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-90686-7_16},
  abstract	= {Programming languages based on the actor model, such as
		  Erlang, avoid some concurrency bugs by design. However,
		  other concurrency bugs, such as message order violations
		  and livelocks, can still show up in programs. These
		  hard-to-find bugs can be more easily detected by using
		  causal-consistent reversible debugging, a debugging
		  technique that allows one to traverse a computation both
		  forward and backward. Most notably, causal consistency
		  implies that, when going backward, an action can only be
		  undone provided that its consequences, if any, have been
		  undone beforehand. To the best of our knowledge, we present
		  the first causal-consistent reversible debugger for Erlang,
		  which may help programmers to detect and fix various kinds
		  of bugs, including message order violations and
		  livelocks.},
  isbn		= {978-3-319-90686-7},
  langid	= {english},
  keywords	= {Backward Derivative,Concurrency Bugs,Core Erlang,Reverse
		  Debugging,Rollback Request}
}

@InProceedings{	  lanese18:from,
  title		= {From {{Reversible Semantics}} to {{Reversible
		  Debugging}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Lanese, Ivan},
  editor	= {Kari, Jarkko and Ulidowski, Irek},
  year		= {2018},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {34--46},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-99498-7_2},
  abstract	= {This paper presents a line of research in reversible
		  computing for concurrent systems. This line of research
		  started in 2004 with the definition of the first reversible
		  extensions for concurrent process calculi such as CCS, and
		  is currently heading to the production of practical
		  reversible debuggers for concurrent languages such as
		  Erlang. Main questions that had to be answered during the
		  research include the following. Which is the correct notion
		  of reversibility for concurrent systems? Which history
		  information needs to be stored? How to control the basic
		  reversibility mechanism? How to exploit reversibility for
		  debugging? How to apply reversible debugging to real
		  languages?},
  isbn		= {978-3-319-99498-7},
  langid	= {english}
}

@Article{	  lanese21:reversible,
  title		= {Reversible {{Execution}} for {{Robustness}} in {{Embodied
		  AI}} and {{Industrial Robots}}},
  author	= {Lanese, Ivan and Schultz, Ulrik P. and Ulidowski, Irek},
  year		= {2021},
  month		= may,
  journal	= {IT Professional},
  volume	= {23},
  number	= {3},
  pages		= {12--17},
  issn		= {1941-045X},
  doi		= {10.1109/MITP.2021.3073757},
  urldate	= {2024-11-11},
  abstract	= {Reversible computation is a computing paradigm where
		  execution can progress backward as well as in the usual,
		  forward direction. It has found applications in many areas
		  of computer science, such as circuit design, programming
		  languages, simulation, modeling of chemical reactions,
		  debugging, and robotics. In this article, we give an
		  overview of reversible computation focusing on its use in
		  robotics. We present an example of programming industrial
		  robots for assembly operations where we combine classical
		  AI planning with reversibility and embodied AI to increase
		  the robustness and versatility of industrial robots.},
  keywords	= {Artificial intelligence,Backtracking,Computational
		  modeling,Integrated circuit modeling,Robotic
		  assembly,Robustness,Service robots}
}

@InCollection{	  larus09:foreword,
  title		= {Foreword},
  booktitle	= {Why {{Programs Fail}} ({{Second Edition}})},
  author	= {Larus, James},
  editor	= {Zeller, Andreas},
  year		= {2009},
  month		= jan,
  pages		= {xv-xvi},
  publisher	= {Morgan Kaufmann},
  address	= {Boston},
  doi		= {10.1016/B978-0-12-374515-6.00022-8},
  urldate	= {2025-05-08},
  isbn		= {978-0-12-374515-6}
}

@Article{	  laursen18:modelling,
  title		= {Modelling Reversible Execution of Robotic Assembly},
  author	= {Laursen, Johan Sund and Ellekilde, Lars-Peter and Schultz,
		  Ulrik Pagh},
  year		= {2018},
  month		= may,
  journal	= {Robotica},
  volume	= {36},
  number	= {5},
  pages		= {625--654},
  issn		= {0263-5747, 1469-8668},
  doi		= {10.1017/S0263574717000613},
  urldate	= {2024-11-11},
  abstract	= {SUMMARY Programming robotic assembly for industrial
		  small-batch production is challenging; hence, it is vital
		  to increase robustness and reduce development effort in
		  order to achieve flexible robotic automation. A human who
		  has made an assembly error will often simply undo the
		  process until the error is undone and then restart the
		  assembly. Conceptually, robots could do the same. This
		  paper introduces a programming model that enables robot
		  assembly programs to be executed in reverse. We investigate
		  the challenges in running robot programs backwards and
		  present a classification of reversibility characteristics.
		  We demonstrate how temporarily switching the direction of
		  program execution can be an efficient error recovery
		  mechanism. Moreover, we demonstrate additional benefits
		  arising from supporting reversibility in an assembly
		  language, such as increased code reuse and automatically
		  derived disassembly sequences. As a default approach to
		  reversibility, we use program inversion and statement-level
		  inversion of commands, but with a novel override option
		  providing alternative sequences for asymmetric reverse
		  actions. To efficiently program for this model, this paper
		  introduces a new domain-specific language, SCP-RASQ (Simple
		  C++ Reversible Assembly SeQuences). In initial experiments,
		  where 200 consecutive assemblies of two industrial cases
		  were performed, 18 of 22 errors were corrected
		  automatically using only the trial-and-error capabilities
		  that come from reverse execution.},
  copyright	= {https://www.cambridge.org/core/terms},
  langid	= {english}
}

@InProceedings{	  lauwaerts22:event-based-out-of-place-debugging,
  title		= {Event-{{Based Out-of-Place Debugging}}},
  booktitle	= {Proceedings of the 19th {{International Conference}} on
		  {{Managed Programming Languages}} and {{Runtimes}}},
  author	= {Lauwaerts, Tom and Castillo, Carlos Rojas and Singh,
		  Robbert Gurdeep and Marra, Matteo and Scholliers,
		  Christophe and Gonzalez Boix, Elisa},
  year		= {2022},
  month		= nov,
  series	= {{{MPLR}} '22},
  pages		= {85--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3546918.3546920},
  urldate	= {2023-09-26},
  abstract	= {Debugging IoT applications is challenging due to the
		  hardware constraints of IoT devices, making advanced
		  techniques like record-replay debugging impractical. As a
		  result, programmers often rely on manual resets or
		  inefficient and time-consuming debugging techniques such as
		  printf. Although simulators can help in that regard, their
		  applicability is limited because they fall short of
		  accurately simulating and reproducing the runtime
		  conditions where bugs appear. In this work, we explore a
		  novel debugging approach called event-based out-of-place
		  debugging in which developers can capture a remotely
		  running program and debug it locally on a (more powerful)
		  machine. Our approach thus provides rich debugging features
		  (e.g., step-back) that normally would not run on the
		  hardware restricted devices. Two different strategies are
		  offered to deal with resources which cannot be easily
		  transferred (e.g., sensors): pull-based (akin to remote
		  debugging), or push-based (where data updates are pushed to
		  developer's machine during the debug session). We present
		  EDWARD, an event-based out-of-place debugger prototype,
		  implemented by extending the WARDuino WebAssembly
		  microcontroller Virtual Machine, that has been integrated
		  into Visual Studio Code. To validate our approach, we show
		  how our debugger helps uncover IoT bugs representative of
		  real-world applications through several use-case
		  applications. Initial benchmarks show that event-based
		  out-of-place debugging can drastically reduce debugging
		  latency.},
  isbn		= {978-1-4503-9696-7},
  keywords	= {Debugger,Internet-of-Things,Out-of-place debugging,Virtual
		  Machine,WARDuino,WebAssembly}
}

@Misc{		  lauwaerts22:warduino-vscode,
  title		= {{{WARDuino-vscode}}},
  author	= {Lauwaerts, Tom and Castillo, Carlos Rojas and Singh,
		  Robbert Gurdeep and Scholliers, Christophe},
  year		= {2022-05-01, 2021}
}

@Article{	  lauwaerts24:latch,
  title		= {Latch: {{Enabling}} Large-Scale Automated Testing on
		  Constrained Systems},
  author	= {Lauwaerts, Tom and Marr, Stefan and Scholliers,
		  Christophe},
  year		= {2024},
  journal	= {Science of Computer Programming},
  volume	= {238},
  pages		= {103157},
  issn		= {0167-6423},
  doi		= {10.1016/j.scico.2024.103157},
  abstract	= {Testing is an essential part of the software development
		  cycle. Unfortunately, testing on constrained devices is
		  currently very challenging. First, the limited memory of
		  constrained devices severely restricts the size of test
		  suites. Second, the limited processing power causes test
		  suites to execute slowly, preventing a fast feedback loop.
		  Third, when the constrained device becomes unresponsive, it
		  is impossible to distinguish between the test failing or
		  taking very long, forcing the developer to work with
		  timeouts. Unfortunately, timeouts can cause tests to be
		  flaky, i.e., have unpredictable outcomes independent of
		  code changes. Given these problems, most IoT developers
		  rely on laborious manual testing. In this paper, we propose
		  the novel testing framework Latch (Large-scale Automated
		  Testing on Constrained Hardware) to overcome the three main
		  challenges of running large test suites on constrained
		  hardware, as well as automate manual testing scenarios
		  through a novel testing methodology based on debugger-like
		  operations---we call this new testing approach managed
		  testing. The core idea of Latch is to enable testing on
		  constrained devices without those devices maintaining the
		  whole test suite in memory. Therefore, programmers script
		  and run tests on a workstation which then step-wise
		  instructs the constrained device to execute each test,
		  thereby overcoming the memory constraints. Our testing
		  framework further allows developers to mark tests as
		  depending on other tests. This way, Latch can skip tests
		  that depend on previously failing tests resulting in a
		  faster feedback loop. Finally, Latch addresses the issue of
		  timeouts and flaky tests by including an analysis mode that
		  provides feedback on timeouts and the flakiness of tests.
		  To illustrate the expressiveness of Latch, we present
		  testing scenarios representing unit testing, integration
		  testing, and end-to-end testing. We evaluate the
		  performance of Latch by testing a virtual machine against
		  the WebAssembly specification, with a large test suite
		  consisting of 10,213 tests running on an ESP32
		  microcontroller. Our experience shows that the testing
		  framework is expressive, reliable and reasonably fast,
		  making it suitable to run large test suites on constrained
		  devices. Furthermore, the debugger-like operations enable
		  to closely mimic manual testing.},
  keywords	= {Automated testing,Embedded devices,Flaky tests}
}

@Article{	  lauwaerts24:warduino,
  title		= {{{WARDuino}}: {{An}} Embedded {{WebAssembly}} Virtual
		  Machine},
  shorttitle	= {{{WARDuino}}},
  author	= {Lauwaerts, Tom and Singh, Robbert Gurdeep and Scholliers,
		  Christophe},
  year		= {2024},
  month		= feb,
  journal	= {Journal of Computer Languages},
  pages		= {101268},
  issn		= {2590-1184},
  doi		= {10.1016/j.cola.2024.101268},
  urldate	= {2024-02-13},
  abstract	= {Creating IoT programs for resource-constrained
		  microcontrollers differs significantly from conventional
		  computer programming. Microcontrollers are traditionally
		  programmed using low-level programming languages with poor
		  debugging facilities. By contrast, general-purpose systems
		  can be programmed with high-level languages, which make
		  programming easier by providing many useful tools such as
		  advanced debuggers, strong type systems, and/or automatic
		  memory management. Most existing solutions for programming
		  microcontrollers with high-level languages are strongly
		  tied to a specific microcontroller architecture, which
		  makes porting code difficult or impossible. In addition,
		  compiling and flashing software onto a microcontroller is
		  time-consuming, slowing down development. To solve these
		  problems we present WARDuino, a WebAssembly virtual machine
		  that runs on microcontrollers and provides WebAssembly
		  primitives to control embedded hardware and IoT
		  functionality. WARDuino runs programs written in a plethora
		  of high-level languages that compile to WebAssembly. We
		  give a general approach for language integration libraries
		  to expose the peripherals and networking capabilities of
		  the device following the idioms of the host language. To
		  ease development, we extend WebAssembly with support for
		  remote debugging and over-the-air reprogramming. WARDuino
		  can remotely instruct a microcontroller to pause, to step,
		  or to dump its state, and to replace local variables,
		  functions or even the entire running program. We use the
		  remote debugger of the virtual machine to create a visual
		  debugging environment in VS Code for WARDuino, that can
		  debug WebAssembly and AssemblyScript. Aside from these
		  important tools, we provide a novel mechanism to handle
		  asynchronous interrupts in WebAssembly, a fundamental
		  building block for responsive embedded applications. Our
		  extensions are implemented in the WARDuino virtual machine
		  and presented as formal extensions to the WebAssembly
		  operational semantics. We use the formalization to proof
		  observational equivalence for the core debugger semantics.
		  We compared the computational performance and memory size
		  with native C code, Espruino, and WASM3 which compiles
		  WebAssembly ahead-of-time. The comparison shows that
		  WARDuino's performance is acceptable. Although WARDuino is
		  on average 425.93 times slower than native code and 37.96
		  times slower than WASM3, it outperforms the popular
		  Espruino runtime by a factor of 11.66. Additionally, we
		  show that WARDuino is fast enough to program traditional
		  IoT applications that handle network and device interrupts
		  with a classic smart lamp application written in
		  AssemblyScript.},
  keywords	= {Internet-of-Things,Language symbiosis,Virtual
		  machine,WARDuino,WebAssembly}
}

@InProceedings{	  layman13:debugging,
  title		= {Debugging {{Revisited}}: {{Toward Understanding}} the
		  {{Debugging Needs}} of {{Contemporary Software
		  Developers}}},
  shorttitle	= {Debugging {{Revisited}}},
  booktitle	= {2013 {{ACM}} / {{IEEE International Symposium}} on
		  {{Empirical Software Engineering}} and {{Measurement}}},
  author	= {Layman, Lucas and Diep, Madeline and Nagappan, Meiyappan
		  and Singer, Janice and Deline, Robert and Venolia, Gina},
  year		= {2013},
  month		= oct,
  pages		= {383--392},
  issn		= {1949-3789},
  doi		= {10.1109/ESEM.2013.43},
  urldate	= {2025-05-06},
  abstract	= {We know surprisingly little about how professional
		  developers define debugging and the challenges they face in
		  industrial environments. To begin exploring professional
		  debugging challenges and needs, we conducted and analyzed
		  interviews with 15 professional software engineers at
		  Microsoft. The goals of this study are: 1) to understand
		  how professional developers currently use information and
		  tools to debug, 2) to identify new challenges in debugging
		  in contemporary software development domains (web services,
		  multithreaded/multicore programming), and 3) to identify
		  the improvements in debugging support desired by these
		  professionals that are needed from research. The interviews
		  were coded to identify the most common information
		  resources, techniques, challenges, and needs for debugging
		  as articulated by the developers. The study reveals several
		  debugging challenges faced by professionals, including: 1)
		  the interaction of hypothesis instrumentation and software
		  environment as a source of debugging difficulty, 2) the
		  impact of log file information on accurate debugging of web
		  services, and 3) the mismatch between the sequential human
		  thought process and the non-sequential execution of
		  multithreaded environments as source of difficulty. The
		  interviewees also describe desired improvements to tools to
		  support debugging, many of which have been discussed in
		  research but not transitioned to practice.},
  keywords	= {Computer
		  bugs,debugging,Debugging,Encoding,interview,Interviews,professionals,program
		  comprehension,qualitative analysis,software
		  engineering,Testing,Web services}
}

@InProceedings{	  lea97:design,
  title		= {Design for Open Systems in {{Java}}},
  booktitle	= {Coordination {{Languages}} and {{Models}}},
  author	= {Lea, Doug},
  editor	= {Garlan, David and Le M{\'e}tayer, Daniel},
  year		= {1997},
  pages		= {32--45},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-63383-9_71},
  abstract	= {Open systems consist of unbounded collections of objects
		  that may interact in support of any of a number of
		  activities. The features and services provided by each
		  object require various measures of policy control of
		  infrastructure components in order to provide appropriate
		  quality of service for supported activities. This paper
		  surveys some common and emerging Java-based design patterns
		  for establishing and controlling service and application
		  components in open object-oriented architectures.},
  isbn		= {978-3-540-69527-1},
  langid	= {english}
}

@InProceedings{	  lechenet18:fast,
  title		= {Fast {{Computation}} of {{Arbitrary Control
		  Dependencies}}},
  booktitle	= {Fundamental {{Approaches}} to {{Software Engineering}}},
  author	= {L{\'e}chenet, Jean-Christophe and Kosmatov, Nikolai and Le
		  Gall, Pascale},
  editor	= {Russo, Alessandra and Sch{\"u}rr, Andy},
  year		= {2018},
  pages		= {207--224},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-89363-1_12},
  abstract	= {In 2011, Danicic et al. introduced an elegant
		  generalization of the notion of control dependence for any
		  directed graph. They also proposed an algorithm computing
		  the weak control-closure of a subset of graph vertices and
		  performed a paper-and-pencil proof of its correctness. We
		  have performed its proof in the Coq proof assistant. This
		  paper also presents a novel, more efficient algorithm to
		  compute weak control-closure taking benefit of intermediate
		  propagation results of previous iterations in order to
		  accelerate the following ones. This optimization makes the
		  design and proof of the algorithm more complex and requires
		  subtle loop invariants. The new algorithm has been
		  formalized and mechanically proven in the Why3 verification
		  tool. Experiments on arbitrary generated graphs with up~to
		  thousands of vertices demonstrate that the proposed
		  algorithm remains practical for real-life programs and
		  significantly outperforms Danicic's initial technique.},
  isbn		= {978-3-319-89363-1},
  langid	= {english}
}

@InProceedings{	  lee16:brief-review,
  title		= {A {{Brief Review}} on {{JTAG Security}}},
  booktitle	= {2016 10th {{International Conference}} on {{Innovative
		  Mobile}} and {{Internet Services}} in {{Ubiquitous
		  Computing}} ({{IMIS}})},
  author	= {Lee, Kyungroul and Lee, Yeunsu and Lee, Hyeji and Yim,
		  Kangbin},
  year		= {2016},
  month		= jul,
  pages		= {486--490},
  doi		= {10.1109/IMIS.2016.102},
  urldate	= {2024-11-13},
  abstract	= {In this paper, we outline security issues on IEEE 1149.1
		  JTAG. The JTAG interface is provided for its beneficial
		  features, such as debugging and downloading firmware, but
		  attackers are abusing it by reverse engineering and by
		  modifying firmware. Hence, they are able to steal
		  confidential information in the system or are able clone
		  the embedded system. In order to solve this problem, a
		  variety of security techniques are proposed to improve
		  safety. These are classified based on the circuitry, the
		  authority, the integrity, the confidentiality, the access
		  control, and the authentication.},
  keywords	= {access control,authentication,Computer
		  architecture,Debugging,JTAG,Microprocessors,Microprogramming,Pins,Program
		  processors,Security}
}

@InProceedings{	  lee17:taming,
  title		= {Taming Undefined Behavior in {{LLVM}}},
  booktitle	= {Proceedings of the 38th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Lee, Juneyoung and Kim, Yoonseung and Song, Youngju and
		  Hur, Chung-Kil and Das, Sanjoy and Majnemer, David and
		  Regehr, John and Lopes, Nuno P.},
  year		= {2017},
  month		= jun,
  series	= {{{PLDI}} 2017},
  pages		= {633--647},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3062341.3062343},
  urldate	= {2024-12-18},
  abstract	= {A central concern for an optimizing compiler is the design
		  of its intermediate representation (IR) for code. The IR
		  should make it easy to perform transformations, and should
		  also afford efficient and precise static analysis. In this
		  paper we study an aspect of IR design that has received
		  little attention: the role of undefined behavior. The IR
		  for every optimizing compiler we have looked at, including
		  GCC, LLVM, Intel's, and Microsoft's, supports one or more
		  forms of undefined behavior (UB), not only to reflect the
		  semantics of UB-heavy programming languages such as C and
		  C++, but also to model inherently unsafe low-level
		  operations such as memory stores and to avoid
		  over-constraining IR semantics to the point that desirable
		  transformations become illegal. The current semantics of
		  LLVM's IR fails to justify some cases of loop unswitching,
		  global value numbering, and other important "textbook"
		  optimizations, causing long-standing bugs. We present
		  solutions to the problems we have identified in LLVM's IR
		  and show that most optimizations currently in LLVM remain
		  sound, and that some desirable new transformations become
		  permissible. Our solutions do not degrade compile time or
		  performance of generated code.},
  isbn		= {978-1-4503-4988-8}
}

@Article{	  leeman86:formal,
  title		= {A Formal Approach to Undo Operations in Programming
		  Languages},
  author	= {Leeman, George B.},
  year		= {1986},
  month		= jan,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {8},
  number	= {1},
  pages		= {50--87},
  issn		= {0164-0925},
  doi		= {10.1145/5001.5005},
  urldate	= {2023-09-26},
  abstract	= {A framework is presented for adding a general Undo
		  facility to programming languages. A discussion of relevant
		  literature is provided to show that the idea of Undoing
		  pervades several areas in computer science, and even other
		  disciplines. A simple model of computation is introduced,
		  and it is augmented with a minimal amount of additional
		  structure needed for recovery and reversal. Two different
		  interpretations of Undo are motivated with examples. Then,
		  four primitives are defined in a language-independent
		  manner; they are sufficient to support a wide range of Undo
		  capability. Two of these primitives carry out state saving,
		  and the others mirror the two versions of the Undo
		  operation. Properties of and relationships between these
		  primitives are explored, and there are some preliminary
		  remarks on how one could implement a system based on this
		  formalism. The main conclusion is that the notions of
		  recovery and reversal of actions can become part of the
		  programming process.}
}

@Article{	  leeman86:formala,
  title		= {A Formal Approach to Undo Operations in Programming
		  Languages},
  author	= {Leeman, George B.},
  year		= {1986},
  month		= jan,
  journal	= {ACM Trans. Program. Lang. Syst.},
  volume	= {8},
  number	= {1},
  pages		= {50--87},
  issn		= {0164-0925},
  doi		= {10.1145/5001.5005},
  urldate	= {2024-11-11},
  abstract	= {A framework is presented for adding a general Undo
		  facility to programming languages. A discussion of relevant
		  literature is provided to show that the idea of Undoing
		  pervades several areas in computer science, and even other
		  disciplines. A simple model of computation is introduced,
		  and it is augmented with a minimal amount of additional
		  structure needed for recovery and reversal. Two different
		  interpretations of Undo are motivated with examples. Then,
		  four primitives are defined in a language-independent
		  manner; they are sufficient to support a wide range of Undo
		  capability. Two of these primitives carry out state saving,
		  and the others mirror the two versions of the Undo
		  operation. Properties of and relationships between these
		  primitives are explored, and there are some preliminary
		  remarks on how one could implement a system based on this
		  formalism. The main conclusion is that the notions of
		  recovery and reversal of actions can become part of the
		  programming process.}
}

@InProceedings{	  lehmann19:wasabi,
  title		= {Wasabi: {{A Framework}} for {{Dynamically Analyzing
		  WebAssembly}}},
  shorttitle	= {Wasabi},
  booktitle	= {Proceedings of the {{Twenty-Fourth International
		  Conference}} on {{Architectural Support}} for {{Programming
		  Languages}} and {{Operating Systems}}},
  author	= {Lehmann, Daniel and Pradel, Michael},
  year		= {2019},
  month		= apr,
  series	= {{{ASPLOS}} '19},
  pages		= {1045--1058},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3297858.3304068},
  urldate	= {2023-11-08},
  abstract	= {WebAssembly is the new low-level language for the web and
		  has now been implemented in all major browsers since over a
		  year. To ensure the security, performance, and correctness
		  of future web applications, there is a strong need for
		  dynamic analysis tools for WebAssembly. However, building
		  such tools from scratch requires knowledge of low-level
		  details of the language and its runtime environment. This
		  paper presents Wasabi, the first general-purpose framework
		  for dynamically analyzing WebAssembly. Wasabi provides an
		  easy-to-use, high-level API that supports heavyweight
		  dynamic analyses. It is based on binary instrumentation,
		  which inserts calls to analysis functions written in
		  JavaScript into a WebAssembly binary. Dynamically analyzing
		  WebAssembly comes with several unique challenges, such as
		  the problem of tracing type-polymorphic instructions with
		  analysis functions that have a fixed type, which we address
		  through on-demand monomorphization. Our evaluation on
		  compute-intensive benchmarks and real-world applications
		  shows that Wasabi (i) faithfully preserves the original
		  program behavior, (ii) imposes an overhead that is
		  reasonable for heavyweight dynamic analysis, and (iii)
		  makes it straightforward to implement various dynamic
		  analyses, including instruction counting, call graph
		  extraction, memory access tracing, and taint analysis.},
  isbn		= {978-1-4503-6240-5}
}

@InProceedings{	  lehmann20:everything,
  title		= {Everything Old Is New Again: Binary Security of
		  Webassembly},
  shorttitle	= {Everything Old Is New Again},
  booktitle	= {Proceedings of the 29th {{USENIX Conference}} on
		  {{Security Symposium}}},
  author	= {Lehmann, Daniel and Kinder, Johannes and Pradel, Michael},
  year		= {2020},
  month		= aug,
  series	= {{{SEC}}'20},
  pages		= {217--234},
  publisher	= {USENIX Association},
  address	= {USA},
  urldate	= {2025-01-15},
  abstract	= {WebAssembly is an increasingly popular compilation target
		  designed to run code in browsers and on other platforms
		  safely and securely, by strictly separating code and data,
		  enforcing types, and limiting indirect control flow. Still,
		  vulnerabilities in memory-unsafe source languages can
		  translate to vulnerabilities in WebAssembly binaries. In
		  this paper, we analyze to what extent vulnerabilities are
		  exploitable in WebAssembly binaries, and how this compares
		  to native code. We find that many classic vulnerabilities
		  which, due to common mitigations, are no longer exploitable
		  in native binaries, are completely exposed in WebAssembly.
		  Moreover, WebAssembly enables unique attacks, such as
		  overwriting supposedly constant data or manipulating the
		  heap using a stack overflow. We present a set of attack
		  primitives that enable an attacker (i) to write arbitrary
		  memory, (ii) to overwrite sensitive data, and (iii) to
		  trigger unexpected behavior by diverting control flow or
		  manipulating the host environment. We provide a set of
		  vulnerable proof-of-concept applications along with
		  complete end-to-end exploits, which cover three WebAssembly
		  platforms. An empirical risk assessment on real-world
		  binaries and SPEC CPU programs compiled to WebAssembly
		  shows that our attack primitives are likely to be feasible
		  in practice. Overall, our findings show a perhaps
		  surprising lack of binary security in WebAssembly. We
		  discuss potential protection mechanisms to mitigate the
		  resulting risks.},
  isbn		= {978-1-939133-17-5}
}

@InProceedings{	  levis02:mate,
  title		= {Mat{\'e}: A Tiny Virtual Machine for Sensor Networks},
  shorttitle	= {Mat{\'e}},
  booktitle	= {Proceedings of the 10th International Conference on
		  {{Architectural}} Support for Programming Languages and
		  Operating Systems},
  author	= {Levis, Philip and Culler, David},
  year		= {2002},
  month		= oct,
  series	= {{{ASPLOS X}}},
  pages		= {85--95},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/605397.605407},
  urldate	= {2023-10-03},
  abstract	= {Composed of tens of thousands of tiny devices with very
		  limited resources ("motes"), sensor networks are subject to
		  novel systems problems and constraints. The large number of
		  motes in a sensor network means that there will often be
		  some failing nodes; networks must be easy to repopulate.
		  Often there is no feasible method to recharge motes, so
		  energy is a precious resource. Once deployed, a network
		  must be reprogrammable although physically unreachable, and
		  this reprogramming can be a significant energy cost.We
		  present Mat{\'e}, a tiny communication-centric virtual
		  machine designed for sensor networks. Mat{\'e}'s high-level
		  interface allows complex programs to be very short (under
		  100 bytes), reducing the energy cost of transmitting new
		  programs. Code is broken up into small capsules of 24
		  instructions, which can self-replicate through the network.
		  Packet sending and reception capsules enable the deployment
		  of ad-hoc routing and data aggregation algorithms.
		  Mat{\'e}'s concise, high-level program representation
		  simplifies programming and allows large networks to be
		  frequently reprogrammed in an energy-efficient manner; in
		  addition, its safe execution environment suggests a use of
		  virtual machines to provide the user/kernel boundary on
		  motes that have no hardware protection mechanisms.},
  isbn		= {978-1-58113-574-9}
}

@Article{	  levy03:modelling,
  title		= {Modelling Environments in Call-by-Value Programming
		  Languages},
  author	= {Levy, PaulBlain and Power, John and Thielecke, Hayo},
  year		= {2003},
  month		= sep,
  journal	= {Information and Computation},
  volume	= {185},
  number	= {2},
  pages		= {182--210},
  issn		= {0890-5401},
  doi		= {10.1016/S0890-5401(03)00088-9},
  urldate	= {2023-12-07},
  abstract	= {In categorical semantics, there have traditionally been
		  two approaches to modelling environments, one by use of
		  finite products in cartesian closed categories, the other
		  by use of the base categories of indexed categories with
		  structure. Each requires modifications in order to account
		  for environments in call-by-value programming languages.
		  There have been two more general definitions along both of
		  these lines: the first generalising from cartesian to
		  symmetric premonoidal categories, the second generalising
		  from indexed categories with specified structure to
		  {$\kappa$}-categories. In this paper, we investigate
		  environments in call-by-value languages by analysing a
		  fine-grain variant of Moggi's computational
		  {$\lambda$}-calculus, giving two equivalent sound and
		  complete classes of models: one given by closed Freyd
		  categories, which are based on symmetric premonoidal
		  categories, the other given by closed {$\kappa$}-categories.}
}

@Misc{		  lewis03:debugging,
  title		= {Debugging {{Backwards}} in {{Time}}},
  author	= {Lewis, Bil},
  year		= {2003},
  month		= oct,
  number	= {arXiv:cs/0310016},
  eprint	= {cs/0310016},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.cs/0310016},
  urldate	= {2024-11-12},
  abstract	= {By recording every state change in the run of a program,
		  it is possible to present the programmer every bit of
		  information that might be desired. Essentially, it becomes
		  possible to debug the program by going ``backwards in
		  time,'' vastly simplifying the process of debugging. An
		  implementation of this idea, the ``Omniscient Debugger,''
		  is used to demonstrate its viability and has been used
		  successfully on a number of large programs. Integration
		  with an event analysis engine for searching and control is
		  presented. Several small-scale user studies provide
		  encouraging results. Finally performance issues and
		  implementation are discussed along with possible
		  optimizations. This paper makes three contributions of
		  interest: the concept and technique of ``going backwards in
		  time,'' the GUI which presents a global view of the program
		  state and has a formal notion of ``navigation through
		  time,'' and the integration with an event analyzer.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Software Engineering}
}

@InProceedings{	  li09:research,
  title		= {Research of ``{{Stub}}'' Remote Debugging Technique},
  booktitle	= {2009 4th {{International Conference}} on {{Computer
		  Science}} \& {{Education}}},
  author	= {Li, Hongwei and Xu, Yaping and Wu, Fangsheng and Yin,
		  Changhong},
  year		= {2009},
  month		= jul,
  pages		= {990--994},
  doi		= {10.1109/ICCSE.2009.5228140},
  urldate	= {2024-11-12},
  abstract	= {Any application software will inevitably contain bugs
		  during the development cycle. In order to correct these
		  software flaws, developers need access to powerful
		  debugging tools that allow them to be more efficient as
		  well as be able to dig into the detailed operation of their
		  application. Therefore, the debugger is a comparatively
		  important tool in software development, particularly in the
		  embedded software development. The paper analyses and
		  studies the embedded debugging technique of stub mode. It
		  adopts the remote serial communication protocol of GNU GDB,
		  and takes over all exception handlers by software to
		  implement debugging and tracking of object program. It
		  realizes to read and to write memory units and registers,
		  to set breakpoint, single step and to continue running.
		  Stub mode is applied to RTEMS embedded real-time operating
		  system and application program for debugging based on
		  ARM.},
  keywords	= {Application software,breakpoint,Computer bugs,Embedded
		  software,embedded system,Programming,Protocols,Read-write
		  memory,Real time systems,Registers,remote
		  debugging,Software debugging,Software tools,step,stub}
}

@Article{	  li12:formal,
  title		= {A Formal Semantics for Program Debugging},
  author	= {Li, Wei and Li, Ning},
  year		= {2012},
  month		= jan,
  journal	= {Science China Information Sciences},
  volume	= {55},
  number	= {1},
  pages		= {133--148},
  issn		= {1869-1919},
  doi		= {10.1007/s11432-011-4530-2},
  urldate	= {2025-03-01},
  abstract	= {This work aims to build a semantic framework for automated
		  debugging. A debugging process consists of tracing,
		  locating, and fixing processes consecutively. The first two
		  processes are accomplished by a tracing procedure and a
		  locating procedure, respectively. The tracing procedure
		  reproduces the execution of the failed test case with
		  well-designed data structures and saves necessary
		  information for locating bugs. The locating procedure will
		  use the information obtained from the tracing procedure to
		  locate ill-designed statements and to generate a system of
		  fix-equations, whose solution will be used to fix the bugs.
		  A structural operational semantics is given to define the
		  functions of the tracing and locating procedures. Both of
		  them are proved to terminate. The main task of fixing
		  process is to solve the fix-equations. It turns out that
		  for a given failed test case, there exist four types of
		  fix-equations and three different solutions: 1) The bug is
		  solvable, i.e., there exists a solution of the system of
		  fix-equations, and the program can be repaired. 2) There
		  exists a structural design error in the program, i.e., the
		  system of fix-equations generated at each round of the
		  locating procedure is solvable, but a new bug will arise
		  when the old bug is being fixed. 3) There exists a logical
		  design error, and the system of fix-equations is not
		  solvable.},
  langid	= {english},
  keywords	= {debugging,failed test case,fix-equations,operational
		  semantics}
}

@InProceedings{	  li23:empirical-study,
  title		= {An {{Empirical Study}} on {{Concurrency Bugs}} in
		  {{Interrupt-Driven Embedded Software}}},
  booktitle	= {Proceedings of the 32nd {{ACM SIGSOFT International
		  Symposium}} on {{Software Testing}} and {{Analysis}}},
  author	= {Li, Chao and Chen, Rui and Wang, Boxiang and Wang, Zhixuan
		  and Yu, Tingting and Jiang, Yunsong and Gu, Bin and Yang,
		  Mengfei},
  year		= {2023},
  month		= jul,
  series	= {{{ISSTA}} 2023},
  pages		= {1345--1356},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3597926.3598140},
  urldate	= {2023-09-27},
  abstract	= {Interrupt-driven embedded software is widely used in
		  aerospace, automotive electronics, medical equipment, IoT,
		  and other industrial fields. This type of software is
		  usually programmed with interrupts to interact with
		  hardware and respond to external stimuli on time. However,
		  uncertain interleaving execution of interrupts may cause
		  concurrency bugs, resulting in task failure or serious
		  safety issues. A deep understanding of real-world
		  concurrency bugs in embedded software will significantly
		  improve the ability of techniques in combating concurrency
		  bugs, such as bug detection, testing and fixing. This paper
		  performs the first comprehensive and large-scale empirical
		  study on concurrency bugs in industrial interrupt-driven
		  embedded software. A total number of 132 real-world
		  concurrency bugs in 102 industrial embedded software have
		  been rigorously analyzed. Not only have the root causes,
		  impacts and fix strategies of bugs been studied, but also
		  the manifestation, including triggering scopes, racing
		  variables, access interleaving patterns, and variables
		  correlations. This study reveals several significant
		  findings, which can guide future research in developing
		  techniques and tools to combat concurrency bugs for
		  interrupt-driven embedded software.},
  isbn		= {9798400702211},
  keywords	= {concurrency bugs,embedded software,empirical
		  study,interrupt-driven programs}
}

@Article{	  li24:boosting,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}}},
  author	= {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
  year		= {2024},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {8},
  number	= {PLDI},
  pages		= {223--245},
  issn		= {2475-1421},
  doi		= {10.1145/3656386},
  urldate	= {2024-08-20},
  abstract	= {We introduce a novel approach for testing optimizing
		  compilers with code from real-world applications. The main
		  idea is to construct well-formed programs by fusing
		  multiple code snippets from various real-world projects.
		  The key insight is backed by the fact that the large volume
		  of real-world code exercises rich syntactical and semantic
		  language features, which current engineering-intensive
		  approaches like random program generators are hard to fully
		  support. To construct well-formed programs from real-world
		  code, our approach works by (1) extracting real-world code
		  at the granularity of function, (2) injecting function
		  calls into seed programs, and (3) leveraging dynamic
		  execution information to maintain the semantics and build
		  complex data dependencies between injected functions and
		  the seed program. With this idea, our approach complements
		  the existing generators by boosting their expressiveness
		  via fusing real-world code in a semantics-preserving way.
		  We implement our idea in a tool, Creal, to test C
		  compilers. In a nine-month testing period, we have reported
		  132 bugs to GCC and LLVM, two of the most popular and
		  well-tested C compilers. At the time of writing, 121 of
		  them have been confirmed as unknown bugs, and 101 of them
		  have been fixed. Most of these bugs were miscompilations,
		  and many were recognized as long-latent and critical. Our
		  evaluation results evidently demonstrate the significant
		  advantage of using real-world code to stress-test
		  compilers. We believe this idea will benefit the general
		  compiler testing direction and will be directly applicable
		  to other compilers.},
  langid	= {english}
}

@Article{	  li24:boostinga,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}}},
  author	= {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
  year		= {2024},
  month		= jun,
  journal	= {Artifact for PLDI'2024 paper "Boosting Compiler Testing by
		  Injecting Real-world Code"},
  volume	= {8},
  number	= {PLDI},
  pages		= {156:223--156:245},
  doi		= {10.1145/3656386},
  urldate	= {2024-08-20},
  abstract	= {We introduce a novel approach for testing optimizing
		  compilers with code from real-world applications. The main
		  idea is to construct well-formed programs by fusing
		  multiple code snippets from various real-world projects.
		  The key insight is backed by the fact that the large volume
		  of real-world code exercises rich syntactical and semantic
		  language features, which current engineering-intensive
		  approaches like random program generators are hard to fully
		  support. To construct well-formed programs from real-world
		  code, our approach works by (1) extracting real-world code
		  at the granularity of function, (2) injecting function
		  calls into seed programs, and (3) leveraging dynamic
		  execution information to maintain the semantics and build
		  complex data dependencies between injected functions and
		  the seed program. With this idea, our approach complements
		  the existing generators by boosting their expressiveness
		  via fusing real-world code in a semantics-preserving way.
		  We implement our idea in a tool, Creal, to test C
		  compilers. In a nine-month testing period, we have reported
		  132 bugs to GCC and LLVM, two of the most popular and
		  well-tested C compilers. At the time of writing, 121 of
		  them have been confirmed as unknown bugs, and 101 of them
		  have been fixed. Most of these bugs were miscompilations,
		  and many were recognized as long-latent and critical. Our
		  evaluation results evidently demonstrate the significant
		  advantage of using real-world code to stress-test
		  compilers. We believe this idea will benefit the general
		  compiler testing direction and will be directly applicable
		  to other compilers.}
}

@Article{	  li24:boostingb,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}}},
  author	= {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
  year		= {2024},
  month		= jun,
  journal	= {Artifact for PLDI'2024 paper "Boosting Compiler Testing by
		  Injecting Real-world Code"},
  volume	= {8},
  number	= {PLDI},
  pages		= {156:223--156:245},
  doi		= {10.1145/3656386},
  urldate	= {2024-08-20},
  abstract	= {We introduce a novel approach for testing optimizing
		  compilers with code from real-world applications. The main
		  idea is to construct well-formed programs by fusing
		  multiple code snippets from various real-world projects.
		  The key insight is backed by the fact that the large volume
		  of real-world code exercises rich syntactical and semantic
		  language features, which current engineering-intensive
		  approaches like random program generators are hard to fully
		  support. To construct well-formed programs from real-world
		  code, our approach works by (1) extracting real-world code
		  at the granularity of function, (2) injecting function
		  calls into seed programs, and (3) leveraging dynamic
		  execution information to maintain the semantics and build
		  complex data dependencies between injected functions and
		  the seed program. With this idea, our approach complements
		  the existing generators by boosting their expressiveness
		  via fusing real-world code in a semantics-preserving way.
		  We implement our idea in a tool, Creal, to test C
		  compilers. In a nine-month testing period, we have reported
		  132 bugs to GCC and LLVM, two of the most popular and
		  well-tested C compilers. At the time of writing, 121 of
		  them have been confirmed as unknown bugs, and 101 of them
		  have been fixed. Most of these bugs were miscompilations,
		  and many were recognized as long-latent and critical. Our
		  evaluation results evidently demonstrate the significant
		  advantage of using real-world code to stress-test
		  compilers. We believe this idea will benefit the general
		  compiler testing direction and will be directly applicable
		  to other compilers.}
}

@InProceedings{	  licklider62:on-line,
  title		= {On-Line Man-Computer Communication},
  booktitle	= {Proceedings of the {{May}} 1-3, 1962, Spring Joint
		  Computer Conference},
  author	= {Licklider, J. C. R. and Clark, Welden E.},
  year		= {1962},
  month		= may,
  series	= {{{AIEE-IRE}} '62 ({{Spring}})},
  pages		= {113--128},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1460833.1460847},
  urldate	= {2025-05-07},
  abstract	= {On-line man-computer communication requires much
		  development before men and computers can work together
		  effectively in formulative thinking and intuitive problem
		  solving. This paper examines some of the directions in
		  which advances can be made and describes on-going programs
		  that seek to improve man-machine interaction in teaching
		  and learning, in planning and design, and in visualizing
		  the internal processes of computers. The paper concludes
		  with a brief discussion of basic problems involved in
		  improving man-computer communication.},
  isbn		= {978-1-4503-7875-8}
}

@Article{	  lieberman97:debugging,
  title		= {The Debugging Scandal and What to Do about It.},
  author	= {Lieberman, Henry},
  year		= {1997},
  journal	= {Communications of the ACM},
  volume	= {40},
  number	= {4},
  pages		= {26--30},
  publisher	= {Association for Computing Machinery, Inc.}
}

@Article{	  lieberman97:zstep,
  title		= {{{ZStep}} 95: {{A}} Reversible, Animated Source Code
		  Stepper},
  author	= {Lieberman, Henry},
  year		= {1997},
  journal	= {Software Visualization: Programming as a Multimedia
		  Experience},
  publisher	= {MIT Press}
}

@Article{	  liell-cock24:let,
  title		= {Let a {{Thousand Flowers Bloom}}: {{An Algebraic
		  Representation}} for {{Edge Graphs}}},
  shorttitle	= {Let a {{Thousand Flowers Bloom}}},
  author	= {{Liell-Cock}, Jack and Schrijvers, Tom},
  year		= {2024},
  month		= feb,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {8},
  number	= {3},
  eprint	= {2403.02273},
  primaryclass	= {cs},
  pages		= {9},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2024/8/9},
  urldate	= {2024-03-11},
  abstract	= {Context: Edge graphs are graphs whose edges are labelled
		  with identifiers, and nodes can have multiple edges between
		  them. They are used to model a wide range of systems,
		  including networks with distances or degrees of connection
		  and complex relational data. Inquiry: Unfortunately, the
		  homogeneity of this graph structure prevents an effective
		  representation in (functional) programs. Either their
		  interface is riddled with partial functions, or the
		  representations are computationally inefficient to process.
		  Approach: We present a novel data type for edge graphs,
		  based on total and recursive definitions, that prevents
		  usage errors from partial APIs and promotes structurally
		  recursive computations. We follow an algebraic approach and
		  provide a set of primitive constructors and combinators,
		  along with equational laws that identify semantically
		  equivalent constructions. Knowledge: This algebra
		  translates directly into an implementation using algebraic
		  data types, and its homomorphisms give rise to functions
		  for manipulating and transforming these edge graphs.
		  Grounding: We exploit the fact that many common graph
		  algorithms are such homomorphisms to implement them in our
		  framework. Importance: In giving a theoretical grounding
		  for the edge graph data type, we can formalise properties
		  such as soundness and completeness of the representation
		  while also minimising usage errors and maximising
		  re-usability.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Programming Languages}
}

@InProceedings{	  lindley17:do,
  title		= {Do Be Do Be Do},
  booktitle	= {Proceedings of the 44th {{ACM SIGPLAN Symposium}} on
		  {{Principles}} of {{Programming Languages}}},
  author	= {Lindley, Sam and McBride, Conor and McLaughlin, Craig},
  year		= {2017},
  month		= jan,
  series	= {{{POPL}} '17},
  pages		= {500--514},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3009837.3009897},
  urldate	= {2023-12-07},
  abstract	= {We explore the design and implementation of Frank, a
		  strict functional programming language with a bidirectional
		  effect type system designed from the ground up around a
		  novel variant of Plotkin and Pretnar's effect handler
		  abstraction. Effect handlers provide an abstraction for
		  modular effectful programming: a handler acts as an
		  interpreter for a collection of commands whose interfaces
		  are statically tracked by the type system. However, Frank
		  eliminates the need for an additional effect handling
		  construct by generalising the basic mechanism of functional
		  abstraction itself. A function is simply the special case
		  of a Frank operator that interprets no commands. Moreover,
		  Frank's operators can be multihandlers which simultaneously
		  interpret commands from several sources at once, without
		  disturbing the direct style of functional programming with
		  values. Effect typing in Frank employs a novel form of
		  effect polymorphism which avoid mentioning effect variables
		  in source code. This is achieved by propagating an ambient
		  ability inwards, rather than accumulating unions of
		  potential effects outwards. We introduce Frank by example,
		  and then give a formal account of the Frank type system and
		  its semantics. We introduce Core Frank by elaborating Frank
		  operators into functions, case expressions, and unary
		  handlers, and then give a sound small-step operational
		  semantics for Core Frank. Programming with effects and
		  handlers is in its infancy. We contribute an exploration of
		  future possibilities, particularly in combination with
		  other forms of rich type system.},
  isbn		= {978-1-4503-4660-3},
  keywords	= {algebraic effects,bidirectional
		  typing,call-by-push-value,continuations,effect
		  handlers,effect polymorphism,pattern matching}
}

@Article{	  liu21:boba,
  title		= {Boba: {{Authoring}} and {{Visualizing Multiverse
		  Analyses}}},
  shorttitle	= {Boba},
  author	= {Liu, Yang and Kale, Alex and Althoff, Tim and Heer,
		  Jeffrey},
  year		= {2021},
  month		= feb,
  journal	= {IEEE Transactions on Visualization and Computer Graphics},
  volume	= {27},
  number	= {2},
  pages		= {1753--1763},
  issn		= {1941-0506},
  doi		= {10.1109/TVCG.2020.3028985},
  urldate	= {2024-10-30},
  abstract	= {Multiverse analysis is an approach to data analysis in
		  which all ``reasonable'' analytic decisions are evaluated
		  in parallel and interpreted collectively, in order to
		  foster robustness and transparency. However, specifying a
		  multiverse is demanding because analysts must manage myriad
		  variants from a cross-product of analytic decisions, and
		  the results require nuanced interpretation. We contribute
		  Baba: an integrated domain-specific language (DSL) and
		  visual analysis system for authoring and reviewing
		  multiverse analyses. With the Boba DSL, analysts write the
		  shared portion of analysis code only once, alongside local
		  variations defining alternative decisions, from which the
		  compiler generates a multiplex of scripts representing all
		  possible analysis paths. The Boba Visualizer provides
		  linked views of model results and the multiverse decision
		  space to enable rapid, systematic assessment of
		  consequential decisions and robustness, including sampling
		  uncertainty and model fit. We demonstrate Boba's utility
		  through two data analysis case studies, and reflect on
		  challenges and design opportunities for multiverse analysis
		  software.},
  keywords	= {Analytic Decisions,Analytical models,Computational
		  modeling,Data models,DSL,Load modeling,Multiverse
		  Analysis,Reproducibility,Robustness,Statistical
		  Analysis,Tools}
}

@InProceedings{	  loregian08:experimental-analysis,
  title		= {An {{Experimental Analysis}} of {{Undo}} in {{Ubiquitous
		  Computing Environments}}},
  booktitle	= {Ubiquitous {{Intelligence}} and {{Computing}}},
  author	= {Loregian, Marco and Locatelli, Marco P.},
  editor	= {Sandnes, Frode Eika and Zhang, Yan and Rong, Chunming and
		  Yang, Laurence T. and Ma, Jianhua},
  year		= {2008},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {505--519},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-540-69293-5_40},
  abstract	= {All personal computer application are provided with an
		  undo functionality, which can implement any of the models
		  available in literature. Users are generally aware of what
		  the undo function is expected to do, depending on the
		  application in use. Ubiquitous computing systems are
		  beginning to be understood and deployed in real life
		  situations, but little attention has been paid to what
		  users expect themselves to be able to do and undo in such
		  systems. In this paper, we present the results of a survey
		  we made to evaluate the perception of undo mechanisms with
		  respect to a simple ubiquitous-computing environment. Our
		  study shows that users already have a complex vision of
		  undo encompassing advanced features such as context
		  awareness and compensation.},
  isbn		= {978-3-540-69293-5},
  langid	= {english},
  keywords	= {Business Process Management,Completion Time,Context
		  Awareness,Smart Home,Ubiquitous Computing}
}

@Article{	  loring17:semantics,
  title		= {Semantics of Asynchronous {{JavaScript}}},
  author	= {Loring, Matthew C. and Marron, Mark and Leijen, Daan},
  year		= {2017},
  month		= oct,
  journal	= {ACM SIGPLAN Notices},
  volume	= {52},
  number	= {11},
  pages		= {51--62},
  issn		= {0362-1340},
  doi		= {10.1145/3170472.3133846},
  urldate	= {2023-09-26},
  abstract	= {JavaScript code running in the Node.js runtime is a major
		  platform for developers building cloud, mobile, or IoT
		  applications. A fundamental concept in Node.js programming
		  is the use of asynchronous callbacks and event loops to
		  provide highly responsive applications. While conceptually
		  simple, this programming model contains numerous subtleties
		  and behaviors that are defined implicitly by the current
		  Node.js implementation. This paper presents the first
		  comprehensive formalization of the Node.js asynchronous
		  execution model and defines a high-level notion of
		  async-contexts to formalize fundamental relationships
		  between asynchronous executions in an application. These
		  formalizations provide a foundation for the construction of
		  static or dynamic program analysis tools, support the
		  exploration of alternative Node.js event loop
		  implementations, and provide a high-level conceptual
		  framework for reasoning about relationships between the
		  execution of asynchronous callbacks in a Node.js
		  application.},
  keywords	= {Asynchrony,JavaScript}
}

@InProceedings{	  lowther23:cheri-performance-enhancement,
  title		= {{{CHERI Performance Enhancement}} for a {{Bytecode
		  Interpreter}}},
  booktitle	= {Proceedings of the 15th {{ACM SIGPLAN International
		  Workshop}} on {{Virtual Machines}} and {{Intermediate
		  Languages}}},
  author	= {Lowther, Duncan and Jacob, Dejice and Singer, Jeremy},
  year		= {2023},
  month		= oct,
  series	= {{{VMIL}} 2023},
  pages		= {1--10},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3623507.3623552},
  urldate	= {2024-01-18},
  abstract	= {During our port of the MicroPython bytecode interpreter to
		  the CHERI-based Arm Morello platform, we encountered a
		  number of serious performance degradations. This paper
		  explores several of these performance issues in detail, in
		  each case we characterize the cause of the problem, the
		  fix, and the corresponding interpreter performance
		  improvement over a set of standard Python benchmarks. While
		  we recognize that Morello is a prototypical physical
		  instantiation of the CHERI concept, we show that it is
		  possible to eliminate certain kinds of software-induced
		  runtime overhead that occur due to the larger size of CHERI
		  capabilities (128 bits) relative to native pointers
		  (generally 64 bits). In our case, we reduce a geometric
		  mean benchmark slowdown from 5x (before optimization) to
		  1.7x (after optimization) relative to AArch64,
		  non-capability, execution. The worst-case slowdowns are
		  greatly improved, from 100x (before optimization) to 2x
		  (after optimization). The key insight is that implicit
		  pointer size presuppositions pervade systems code; whereas
		  previous CHERI porting projects highlighted compile-time
		  and execution-time errors exposed by pointer size
		  assumptions, we instead focus on the performance
		  implications of such assumptions.},
  isbn		= {9798400704017},
  keywords	= {Capabilities,Morello,Python,software implementation}
}

@InProceedings{	  lowther23:morello,
  title		= {Morello {{MicroPython}}: {{A Python Interpreter}} for
		  {{CHERI}}},
  shorttitle	= {Morello {{MicroPython}}},
  booktitle	= {Proceedings of the 20th {{ACM SIGPLAN International
		  Conference}} on {{Managed Programming Languages}} and
		  {{Runtimes}}},
  author	= {Lowther, Duncan and Jacob, Dejice and Singer, Jeremy},
  year		= {2023},
  month		= oct,
  series	= {{{MPLR}} 2023},
  pages		= {62--69},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3617651.3622991},
  urldate	= {2024-01-18},
  abstract	= {Arm Morello is a prototype system that supports CHERI
		  hardware capabilities for improving runtime security. As
		  Morello becomes more widely available, there is a growing
		  effort to port open source code projects to this novel
		  platform. Although high-level applications generally need
		  minimal code refactoring for CHERI compatibility, low-level
		  systems code bases require significant modification to
		  comply with the stringent memory safety constraints that
		  are dynamically enforced by Morello. In this paper, we
		  describe our work on porting the MicroPython interpreter to
		  Morello with the CheriBSD OS. Our key contribution is to
		  present a set of generic lessons for adapting managed
		  runtime execution environments to CHERI, including (1) a
		  characterization of necessary source code changes, (2) an
		  evaluation of runtime performance of the interpreter on
		  Morello, and (3) a demonstration of pragmatic memory safety
		  bug detection. Although MicroPython is a lightweight
		  interpreter, mostly written in C, we believe that the
		  changes we have implemented and the lessons we have learned
		  are more widely applicable. To the best of our knowledge,
		  this is the first published description of meaningful
		  experience for scripting language runtime engineering with
		  CHERI and Morello.},
  isbn		= {9798400703805},
  keywords	= {capabilities,CHERI,software implementation}
}

@InProceedings{	  lu08:learning,
  title		= {Learning from Mistakes: A Comprehensive Study on Real
		  World Concurrency Bug Characteristics},
  shorttitle	= {Learning from Mistakes},
  booktitle	= {Proceedings of the 13th International Conference on
		  {{Architectural}} Support for Programming Languages and
		  Operating Systems},
  author	= {Lu, Shan and Park, Soyeon and Seo, Eunsoo and Zhou,
		  Yuanyuan},
  year		= {2008},
  month		= mar,
  series	= {{{ASPLOS XIII}}},
  pages		= {329--339},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1346281.1346323},
  urldate	= {2025-05-05},
  abstract	= {The reality of multi-core hardware has made concurrent
		  programs pervasive. Unfortunately, writing correct
		  concurrent programs is difficult. Addressing this challenge
		  requires advances in multiple directions, including
		  concurrency bug detection, concurrent program testing,
		  concurrent programming model design, etc. Designing
		  effective techniques in all these directions will
		  significantly benefit from a deep understanding of real
		  world concurrency bug characteristics.This paper provides
		  the first (to the best of our knowledge) comprehensive real
		  world concurrency bug characteristic study. Specifically,
		  we have carefully examined concurrency bug patterns,
		  manifestation, and fix strategies of 105 randomly selected
		  real world concurrency bugs from 4 representative server
		  and client open-source applications (MySQL, Apache, Mozilla
		  and OpenOffice). Our study reveals several interesting
		  findings and provides useful guidance for concurrency bug
		  detection, testing, and concurrent programming language
		  design.Some of our findings are as follows: (1) Around one
		  third of the examined non-deadlock concurrency bugs are
		  caused by violation to programmers' order intentions, which
		  may not be easily expressed via synchronization primitives
		  like locks and transactional memories; (2) Around 34\% of
		  the examined non-deadlock concurrency bugs involve multiple
		  variables, which are not well addressed by existing bug
		  detection tools; (3) About 92\% of the examined concurrency
		  bugs canbe reliably triggered by enforcing certain orders
		  among no more than 4 memory accesses. This indicates that
		  testing concurrent programs can target at exploring
		  possible orders among every small groups of memory
		  accesses, instead of among all memory accesses; (4) About
		  73\% of the examinednon-deadlock concurrency bugs were not
		  fixed by simply adding or changing locks, and many of the
		  fixes were not correct at the first try, indicating the
		  difficulty of reasoning concurrent execution by programmers.},
  isbn		= {978-1-59593-958-6}
}

@InProceedings{	  lubbers21:interpreting,
  title		= {Interpreting Task Oriented Programs on Tiny Computers},
  booktitle	= {Proceedings of the 31st {{Symposium}} on
		  {{Implementation}} and {{Application}} of {{Functional
		  Languages}}},
  author	= {Lubbers, Mart and Koopman, Pieter and Plasmeijer, Rinus},
  year		= {2021},
  month		= jul,
  series	= {{{IFL}} '19},
  pages		= {1--12},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3412932.3412936},
  urldate	= {2023-10-03},
  abstract	= {Small Microcontroller Units (MCUs) drive the omnipresent
		  Internet of Things (IoT). These devices are small, cheap,
		  and energy efficient. However, they are not very powerful
		  and lack an Operating System. Hence it is difficult to
		  apply high level abstractions and write software that stays
		  close to the design. Task Oriented Programming (TOP) is a
		  paradigm for creating multi-user collaborative systems. A
		  program consists of tasks---descriptions of what needs to
		  be done. The tasks represent the actual work and a task
		  value is observable during execution. Furthermore, tasks
		  can be combined and transformed using combinators. mTask is
		  an embedded Domain Specific Language (eDSL) to program MCUs
		  following the TOP paradigm. Previous work has described the
		  mTask language, a static C code generator, and how to
		  integrate mTask with TOP servers. This paper shows that for
		  dynamic IOT applications, tasks must be sent at runtime to
		  the devices for interpretation. It describes in detail how
		  to compile specialized IOT TOP tasks to bytecode and how to
		  interpret them on devices with very little memory. These
		  additions allow the creation of complete, dynamic IOT
		  applications arising from a single source using a mix of
		  iTasks and mTask tasks. Details such as serialization and
		  communication are captured in simple abstractions.},
  isbn		= {978-1-4503-7562-7},
  keywords	= {clean,distributed applications,functional
		  programming,internet of things,task oriented programming}
}

@Article{	  lunzer08:subjunctive,
  title		= {Subjunctive Interfaces: {{Extending}} Applications to
		  Support Parallel Setup, Viewing and Control of Alternative
		  Scenarios},
  shorttitle	= {Subjunctive Interfaces},
  author	= {Lunzer, Aran and Hornb{\ae}k, Kasper},
  year		= {2008},
  month		= jan,
  journal	= {ACM Trans. Comput.-Hum. Interact.},
  volume	= {14},
  number	= {4},
  pages		= {17:1--17:44},
  issn		= {1073-0516},
  doi		= {10.1145/1314683.1314685},
  urldate	= {2024-10-30},
  abstract	= {Many applications require exploration of alternative
		  scenarios; most support it poorly. Subjunctive interfaces
		  provide mechanisms for the parallel setup, viewing and
		  control of scenarios, aiming to support users' thinking
		  about and interaction with their choices. We illustrate how
		  applications for information access, real-time simulation,
		  and document design may be extended with these mechanisms.
		  To investigate the usability of this form of extension, we
		  compare a simple census browser against a version with a
		  subjunctive interface. In the first of three studies,
		  subjects reported higher satisfaction with the subjunctive
		  interface, and relied less on interim marks on paper. No
		  reduction in task completion time was found, however,
		  mainly because some subjects encountered problems in
		  setting up and controlling scenarios. At the end of a
		  second, five-session study, users of a redesigned interface
		  completed tasks 27\% more quickly than with the simple
		  interface. In the third study we examined how subjects
		  reasoned about multiple-scenario setups in pursuing
		  complex, open-ended data explorations. Our main observation
		  was that subjects treated scenarios as information holders,
		  using them creatively in various ways to facilitate task
		  completion.}
}

@InProceedings{	  luo14:empirical,
  title		= {An Empirical Analysis of Flaky Tests},
  booktitle	= {Proceedings of the 22nd {{ACM SIGSOFT International
		  Symposium}} on {{Foundations}} of {{Software
		  Engineering}}},
  author	= {Luo, Qingzhou and Hariri, Farah and Eloussi, Lamyaa and
		  Marinov, Darko},
  year		= {2014},
  month		= nov,
  series	= {{{FSE}} 2014},
  pages		= {643--653},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2635868.2635920},
  urldate	= {2024-11-10},
  abstract	= {Regression testing is a crucial part of software
		  development. It checks that software changes do not break
		  existing functionality. An important assumption of
		  regression testing is that test outcomes are deterministic:
		  an unmodified test is expected to either always pass or
		  always fail for the same code under test. Unfortunately, in
		  practice, some tests often called flaky tests---have
		  non-deterministic outcomes. Such tests undermine the
		  regression testing as they make it difficult to rely on
		  test results. We present the first extensive study of flaky
		  tests. We study in detail a total of 201 commits that
		  likely fix flaky tests in 51 open-source projects. We
		  classify the most common root causes of flaky tests,
		  identify approaches that could manifest flaky behavior, and
		  describe common strategies that developers use to fix flaky
		  tests. We believe that our insights and implications can
		  help guide future research on the important topic of
		  (avoiding) flaky tests.},
  isbn		= {978-1-4503-3056-5}
}

@Article{	  lutz86:janus,
  title		= {Janus: A Time-Reversible Language},
  author	= {Lutz, Christopher and Derby, Howard},
  year		= {1986},
  journal	= {Letter to R. Landauer},
  volume	= {2}
}

@Misc{		  m5stack21:m5stickc,
  title		= {{{M5StickC}}},
  author	= {{M5STACK}},
  year		= {2021-12-16, 2021}
}

@InCollection{	  ma15:chapter,
  title		= {Chapter 8 - {{Secure Development Life Cycle}}},
  booktitle	= {Smart {{Grid Security}}},
  author	= {Ma, Zhendong and Kupzog, Friederich and Murdock, Paul},
  editor	= {Skopik, Florian and Smith, Paul},
  year		= {2015},
  month		= jan,
  pages		= {219--245},
  publisher	= {Syngress},
  address	= {Boston},
  doi		= {10.1016/B978-0-12-802122-4.00008-0},
  urldate	= {2024-08-29},
  abstract	= {A sound security architecture and the implementing
		  technologies that have been discussed in previous chapters
		  address only part of the challenge. To ensure security in
		  Smart Grid, from development via roll-out to operation,
		  proven development processes and management are needed to
		  minimize or eliminate security vulnerabilities that are
		  introduced in the development lifecycle. As a system of
		  systems, the Smart Grid consists of software components
		  that have varied security and assurance levels, and diverse
		  origins and development processes. Building security into
		  Smart Grid from the component to the system level requires
		  appropriate methods and techniques to rigorously address
		  many heterogeneous security issues in all phases of the
		  software and system development lifecycle. This chapter
		  examines security considerations in all phases of the Smart
		  Grid system development lifecycle, identifying industrial
		  best practices and research activities, and describes a
		  system development lifecycle process with existing and
		  emerging methods and techniques for Smart Grid security.},
  isbn		= {978-0-12-802122-4},
  keywords	= {best practice,coding,Secure development lifecycle,Smart
		  Grid,software,standard}
}

@Misc{		  machine-to-machine,
  title		= {Machine-to-{{Machine}} ({{M2M}}) Communications: {{A}}
		  Survey - {{ScienceDirect}}},
  urldate	= {2025-05-03},
  howpublished	= {https://www.sciencedirect.com/science/article/pii/S1084804516000990}
}

@Misc{		  machine-to-machinea,
  title		= {Machine-to-{{Machine}} ({{M2M}}) Communications: {{A}}
		  Survey - {{ScienceDirect}}},
  urldate	= {2025-05-03},
  howpublished	= {https://www.sciencedirect.com/science/article/pii/S1084804516000990}
}

@Article{	  macqueen20:history,
  title		= {The History of {{Standard ML}}},
  author	= {MacQueen, David and Harper, Robert and Reppy, John},
  year		= {2020},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {HOPL},
  pages		= {86:1--86:100},
  doi		= {10.1145/3386336},
  urldate	= {2023-09-26},
  abstract	= {The ML family of strict functional languages, which
		  includes F\#, OCaml, and Standard ML, evolved from the Meta
		  Language of the LCF theorem proving system developed by
		  Robin Milner and his research group at the University of
		  Edinburgh in the 1970s. This paper focuses on the history
		  of Standard ML, which plays a central role in this family
		  of languages, as it was the first to include the complete
		  set of features that we now associate with the name ``ML''
		  (i.e., polymorphic type inference, datatypes with pattern
		  matching, modules, exceptions, and mutable state). Standard
		  ML, and the ML family of languages, have had enormous
		  influence on the world of programming language design and
		  theory. ML is the foremost exemplar of a functional
		  programming language with strict evaluation (call-by-value)
		  and static typing. The use of parametric polymorphism in
		  its type system, together with the automatic inference of
		  such types, has influenced a wide variety of modern
		  languages (where polymorphism is often referred to as
		  generics). It has popularized the idea of datatypes with
		  associated case analysis by pattern matching. The module
		  system of Standard ML extends the notion of type-level
		  parameterization to large-scale programming with the notion
		  of parametric modules, or functors. Standard ML also set a
		  precedent by being a language whose design included a
		  formal definition with an associated metatheory of
		  mathematical proofs (such as soundness of the type system).
		  A formal definition was one of the explicit goals from the
		  beginning of the project. While some previous languages had
		  rigorous definitions, these definitions were not integral
		  to the design process, and the formal part was limited to
		  the language syntax and possibly dynamic semantics or
		  static semantics, but not both. The paper covers the early
		  history of ML, the subsequent efforts to define a standard
		  ML language, and the development of its major features and
		  its formal definition. We also review the impact that the
		  language had on programming-language research.},
  keywords	= {Language design,Operational semantics,Standard ML,Type
		  checking}
}

@Article{	  madsen17:model,
  title		= {A Model for Reasoning about {{JavaScript}} Promises},
  author	= {Madsen, Magnus and Lhot{\'a}k, Ond{\v r}ej and Tip, Frank},
  year		= {2017},
  month		= oct,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {1},
  number	= {OOPSLA},
  pages		= {86:1--86:24},
  doi		= {10.1145/3133910},
  urldate	= {2025-05-04},
  abstract	= {In JavaScript programs, asynchrony arises in situations
		  such as web-based user-interfaces, communicating with
		  servers through HTTP requests, and non-blocking I/O.
		  Event-based programming is the most popular approach for
		  managing asynchrony, but suffers from problems such as lost
		  events and event races, and results in code that is hard to
		  understand and debug. Recently, ECMAScript 6 has added
		  support for promises, an alternative mechanism for managing
		  asynchrony that enables programmers to chain asynchronous
		  computations while supporting proper error handling.
		  However, promises are complex and error-prone in their own
		  right, so programmers would benefit from techniques that
		  can reason about the correctness of promise-based code.
		  Since the ECMAScript 6 specification is informal and
		  intended for implementers of JavaScript engines, it does
		  not provide a suitable basis for formal reasoning. This
		  paper presents {$\lambda$}p, a core calculus that captures
		  the essence of ECMAScript 6 promises. Based on
		  {$\lambda$}p, we introduce the promise graph, a program
		  representation that can assist programmers with debugging
		  of promise-based code. We then report on a case study in
		  which we investigate how the promise graph can be helpful
		  for debugging errors related to promises in code fragments
		  posted to the StackOverflow website.}
}

@Article{	  maes87:concepts,
  title		= {Concepts and Experiments in Computational Reflection},
  author	= {Maes, Pattie},
  year		= {1987},
  month		= dec,
  journal	= {SIGPLAN Not.},
  volume	= {22},
  number	= {12},
  pages		= {147--155},
  issn		= {0362-1340},
  doi		= {10.1145/38807.38821},
  urldate	= {2025-04-11},
  abstract	= {This paper brings some perspective to various concepts in
		  computational reflection. A definition of computational
		  reflection is presented, the importance of computational
		  reflection is discussed and the architecture of languages
		  that support reflection is studied. Further, this paper
		  presents a survey of some experiments in reflection which
		  have been performed. Examples of existing procedural,
		  logic-based and rule-based languages with an architecture
		  for reflection are briefly presented. The main part of the
		  paper describes an original experiment to introduce a
		  reflective architecture in an object-oriented language. It
		  stresses the contributions of this language to the field of
		  object-oriented programming and illustrates the new
		  programming style made possible. The examples show that a
		  lot of programming problems that were previously handled on
		  an ad hoc basis, can in a reflective architecture be solved
		  more elegantly.}
}

@Article{	  maes88:computational,
  title		= {Computational Reflection},
  author	= {Maes, Pattie},
  year		= {1988},
  journal	= {The Knowledge Engineering Review},
  volume	= {3},
  number	= {1},
  pages		= {1--19},
  doi		= {10.1017/S0269888900004355}
}

@InProceedings{	  makhshari21:iot-bugs,
  title		= {{{IoT Bugs}} and {{Development Challenges}}},
  booktitle	= {2021 {{IEEE}}/{{ACM}} 43rd {{International Conference}} on
		  {{Software Engineering}} ({{ICSE}})},
  author	= {Makhshari, Amir and Mesbah, Ali},
  year		= {2021},
  month		= may,
  pages		= {460--472},
  issn		= {1558-1225},
  doi		= {10.1109/ICSE43902.2021.00051},
  urldate	= {2025-01-13},
  abstract	= {IoT systems are rapidly adopted in various domains, from
		  embedded systems to smart homes. Despite their growing
		  adoption and popularity, there has been no thorough study
		  to understand IoT development challenges from the
		  practitioners' point of view. We provide the first
		  systematic study of bugs and challenges that IoT developers
		  face in practice, through a large-scale empirical
		  investigation. We collected 5,565 bug reports from 91
		  representative IoT project repositories and categorized a
		  random sample of 323 based on the observed failures, root
		  causes, and the locations of the faulty components. In
		  addition, we conducted nine interviews with IoT experts to
		  uncover more details about IoT bugs and to gain insight
		  into IoT developers' challenges. Lastly, we surveyed 194
		  IoT developers to validate our findings and gain further
		  insights. We propose the first bug taxonomy for IoT systems
		  based on our results. We highlight frequent bug categories
		  and their root causes, correlations between them, and
		  common pitfalls and challenges that IoT developers face. We
		  recommend future directions for IoT areas that require
		  research and development attention.},
  keywords	= {Computer bugs,Correlation,Empirical Study,Faces,Internet
		  of Things,Mining Software Repositories,Software
		  Engineering,Systematics,Taxonomy,Tools}
}

@InProceedings{	  maksimovic14:raspberry,
  title		= {Raspberry {{Pi}} as {{Internet}} of {{Things}} Hardware:
		  {{Performances}} and {{Constraints}}},
  shorttitle	= {Raspberry {{Pi}} as {{Internet}} of {{Things}} Hardware},
  booktitle	= {Proceedings of the 1st {{International Conference}} on
		  {{Electrical}}, {{Electronic}} and {{Computing
		  Engineering}}},
  author	= {Maksimovic, Mirjana and Vujovic, Vladimir and
		  Davidovi{\'c}, Nikola and Milosevic, Vladimir and Perisic,
		  Branko},
  year		= {2014},
  month		= jun,
  abstract	= {The Internet of Things (IoT) ideology can be looked as a
		  highly dynamic and radically distributed networked system
		  composed of a very large number of identifiable smart
		  objects. These objects are able to communicate and to
		  interact among themselves, with end-users or other entities
		  in the network. Entering the era of Internet of Things, the
		  use of small, cheap and flexible computer hardware that
		  allow end-user programming become present. One of them,
		  considered in this paper, is the Raspberry Pi, fully
		  customizable and programmable small computer board.
		  Comparative analysis of its key elements and performances
		  with some of current existing IoT prototype platforms have
		  shown that despite few disadvantages, the Raspberry Pi
		  remains an inexpensive computer with its very successfully
		  usage in diverse range of research applications in IoT
		  vision.}
}

@Article{	  maloney10:scratch-programming-language,
  title		= {The {{Scratch Programming Language}} and {{Environment}}},
  author	= {Maloney, John and Resnick, Mitchel and Rusk, Natalie and
		  Silverman, Brian and Eastmond, Evelyn},
  year		= {2010},
  month		= nov,
  journal	= {ACM Transactions on Computing Education},
  volume	= {10},
  number	= {4},
  pages		= {1--15},
  issn		= {1946-6226},
  doi		= {10.1145/1868358.1868363},
  langid	= {english},
  keywords	= {programming environment,programming
		  language,Scratch,visual programming language}
}

@Article{	  manhaeve21:neural,
  title		= {Neural Probabilistic Logic Programming in
		  {{DeepProbLog}}},
  author	= {Manhaeve, Robin and Duman{\v c}i{\'c}, Sebastijan and
		  Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
  year		= {2021},
  month		= sep,
  journal	= {Artificial Intelligence},
  volume	= {298},
  pages		= {103504},
  issn		= {0004-3702},
  doi		= {10.1016/j.artint.2021.103504},
  urldate	= {2024-11-20},
  abstract	= {We introduce DeepProbLog, a neural probabilistic logic
		  programming language that incorporates deep learning by
		  means of neural predicates. We show how existing inference
		  and learning techniques of the underlying probabilistic
		  logic programming language ProbLog can be adapted for the
		  new language. We theoretically and experimentally
		  demonstrate that DeepProbLog supports (i) both symbolic and
		  subsymbolic representations and inference, (ii) program
		  induction, (iii) probabilistic (logic) programming, and
		  (iv) (deep) learning from examples. To the best of our
		  knowledge, this work is the first to propose a framework
		  where general-purpose neural networks and expressive
		  probabilistic-logical modeling and reasoning are integrated
		  in a way that exploits the full expressiveness and
		  strengths of both worlds and can be trained end-to-end
		  based on examples.},
  keywords	= {Learning and reasoning,Logic,Neural
		  networks,Neuro-symbolic integration,Probabilistic logic
		  programming,Probability}
}

@InProceedings{	  mani18:architecture,
  title		= {An Architecture for {{IoT}} Clock Synchronization},
  booktitle	= {Proceedings of the 8th {{International Conference}} on the
		  {{Internet}} of {{Things}}},
  author	= {Mani, Sathiya Kumaran and Durairajan, Ramakrishnan and
		  Barford, Paul and Sommers, Joel},
  year		= {2018},
  month		= oct,
  series	= {{{IOT}} '18},
  pages		= {1--8},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3277593.3277606},
  urldate	= {2025-03-04},
  abstract	= {In this paper, we describe an architecture for clock
		  synchronization in IoT devices that is designed to be
		  scalable, flexibly accommodate diverse hardware, and
		  maintain tight synchronization over a range of operating
		  conditions. We begin by examining clock drift on two
		  standard IoT prototyping platforms. We observe clock drift
		  on the order of seconds over relatively short time periods,
		  as well as poor clock rate stability, each of which make
		  standard synchronization protocols ineffective. To address
		  this problem, we develop a synchronization system, which
		  includes a lightweight client, a new packet exchange
		  protocol called SPoT and a scalable reference server. We
		  evaluate the efficacy of our system over a range of
		  configurations, operating conditions and target platforms.
		  We find that SPoT performs synchronization 22x and 17x more
		  accurately than MQTT and SNTP, respectively, at high noise
		  levels, and maintains a clock accuracy of within
		  {\textasciitilde}15ms at various noise levels. Finally, we
		  report on the scalability of our server implementation
		  through microbenchmark and wide area experiments, which
		  show that our system can scale to support large numbers of
		  clients efficiently.},
  isbn		= {978-1-4503-6564-2}
}

@Article{	  marceau07:design,
  title		= {The Design and Implementation of a Dataflow Language for
		  Scriptable Debugging},
  author	= {Marceau, G. and Cooper, G.H. and Spiro, J.P. and
		  Krishnamurthi, S. and Reiss, S.P.},
  year		= {2007},
  journal	= {Automated Software Engineering},
  volume	= {14},
  number	= {1},
  pages		= {59--86},
  doi		= {10.1007/s10515-006-0003-z},
  abstract	= {Debugging is a laborious, manual activity that often
		  involves the repetition of common operations. Ideally,
		  users should be able to describe these repetitious
		  operations as little programs. Debuggers should therefore
		  be programmable, or scriptable. The operating environment
		  of these scripts, however, imposes interesting design
		  challenges on the programming language in which these
		  scripts are written. This paper presents our design of a
		  language for scripting debuggers. The language offers
		  powerful primitives that can precisely and concisely
		  capture many important debugging and comprehension
		  metaphors. The paper also describes a pair of debuggers,
		  one for Java and the other for Scheme, built in accordance
		  with these principles. The paper includes concrete examples
		  of applying this debugger to programs. {\copyright}
		  Springer Science+Business Media, LLC 2007.},
  keywords	= {Dataflow dsl scheme,Debugging,Java,Script automation}
}

@InProceedings{	  marques22:concolic,
  title		= {Concolic {{Execution}} for {{WebAssembly}}},
  booktitle	= {36th {{European Conference}} on {{Object-Oriented
		  Programming}} ({{ECOOP}} 2022)},
  author	= {Marques, Filipe and Fragoso Santos, Jos{\'e} and Santos,
		  Nuno and Ad{\~a}o, Pedro},
  editor	= {Ali, Karim and Vitek, Jan},
  year		= {2022},
  series	= {Leibniz {{International Proceedings}} in {{Informatics}}
		  ({{LIPIcs}})},
  volume	= {222},
  pages		= {11:1--11:29},
  publisher	= {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address	= {Dagstuhl, Germany},
  issn		= {1868-8969},
  doi		= {10.4230/LIPIcs.ECOOP.2022.11},
  urldate	= {2023-10-13},
  isbn		= {978-3-95977-225-9},
  keywords	= {Concolic Testing,Test-Generation,Testing C
		  Programs,WebAssembly}
}

@Article{	  marra18:out-of-place,
  title		= {Out-{{Of-Place}} Debugging: A Debugging Architecture to
		  Reduce Debugging Interference},
  shorttitle	= {Out-{{Of-Place}} Debugging},
  author	= {Marra, Matteo and Polito, Guillermo and Gonzalez Boix,
		  Elisa},
  year		= {2018},
  month		= nov,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {3},
  number	= {2},
  pages		= {3:1-3:29},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2019/3/3},
  urldate	= {2023-11-22},
  abstract	= {Context. Recent studies show that developers spend most of
		  their programming time testing, verifying and debugging
		  software. As applicati...},
  langid	= {english}
}

@Article{	  marra20:debugging,
  title		= {A Debugging Approach for Live {{Big Data}} Applications},
  author	= {Marra, Matteo and Polito, Guillermo and Gonzalez Boix,
		  Elisa},
  year		= {2020},
  month		= aug,
  journal	= {Science of Computer Programming},
  volume	= {194},
  pages		= {102460},
  issn		= {0167-6423},
  doi		= {10.1016/j.scico.2020.102460},
  urldate	= {2024-11-20},
  abstract	= {Many frameworks exist for programmers to develop and
		  deploy Big Data applications such as Hadoop Map/Reduce and
		  Apache Spark. However, very little debugging support is
		  currently provided in those frameworks. When an error
		  occurs, developers are lost in trying to understand what
		  has happened from the information provided in log files.
		  Recently, new solutions allow developers to record \&
		  replay the application execution, but replaying is not
		  always affordable when hours of computation need to be
		  re-executed. In this paper, we present an online approach
		  that allows developers to debug Big Data applications in
		  isolation by moving the debugging session to an external
		  process when a halting point is reached. We introduce
		  IDRAMR, our prototype implementation in Pharo. IDRAMR
		  centralizes the debugging of parallel applications by
		  introducing novel debugging concepts, such as composite
		  debugging events, and the ability to dynamically update
		  both the code of the debugged application and the same
		  configuration of the running framework. We validate our
		  approach by debugging both application and configuration
		  failures for two driving scenarios. The scenarios are
		  implemented and executed using Port, our Map/Reduce
		  framework for Pharo, also introduced in this paper.},
  keywords	= {Big Data,Live programming,Map/reduce,Online debugging}
}

@InProceedings{	  marra21:practical,
  title		= {Practical {{Online Debugging}} of {{Spark-like
		  Applications}}},
  booktitle	= {2021 {{IEEE}} 21st {{International Conference}} on
		  {{Software Quality}}, {{Reliability}} and {{Security}}
		  ({{QRS}})},
  author	= {Marra, Matteo and Polito, Guillermo and Boix, Elisa
		  Gonzalez},
  year		= {2021},
  month		= dec,
  pages		= {620--631},
  issn		= {2693-9177},
  doi		= {10.1109/QRS54544.2021.00072},
  urldate	= {2025-01-13},
  abstract	= {Apache Spark is a framework widely used for writing Big
		  Data analytics applications that offers a scalable and
		  fault-tolerant model based on rescheduling failing tasks on
		  other nodes. While this is well-suited for hardware and
		  infrastructure errors, it is not for application errors as
		  they will reappear in the rescheduled tasks. As a result,
		  applications are killed, losing all the progress and
		  forcing developers to restart them from scratch. Despite
		  the popularity of such a failure-recovery model,
		  understanding and debugging Spark-like applications remain
		  challenging. When an error occurs, developers need to
		  analyze huge log files or undergo time-consuming replays to
		  find the bug. To address these concerns, we present an
		  online debugging approach tailored to Big Data analytics
		  applications. Our approach includes local debugging of
		  remote parallel exceptions through dynamic local
		  checkpoints, extended with domain-specific debugging
		  operations and live code updating functionality. To deal
		  with data-cleaning errors, we extend our model to easily
		  allow developers to automatically ignore exceptions that
		  happen at runtime. We validate our solution through
		  performance benchmarks that show how our debugging approach
		  is comparable or better than state-of-the-art debugging
		  solutions for Big Data. Furthermore, we conduct a user
		  study to compare our approach with another state-of-the-art
		  debugging approach, and results show a lower time to find
		  the solution to a bug using our approach, as well as a
		  generally good perception of the features of the
		  debugger.},
  keywords	= {Benchmark testing,Big Data,Codes,Computer
		  bugs,Debugging,Live Programming,Software
		  quality,Spark,Writing}
}

@Misc{		  massey21:wasm3,
  title		= {{{WASM3}}},
  author	= {Massey, Steven and Shymanskyy, Volodymyr},
  year		= {2021},
  month		= jan,
  urldate	= {2021-04-01},
  keywords	= {containers,continuation-passing
		  style,cosmopolitan,devops,edge-computing,embedded,interpreter,iot,sandbox,scripting,serverless,smart-contracts,virtual-machine,wasm,wasm3,webassembly}
}

@Misc{		  massey22:m3,
  title		= {M3},
  author	= {Massey, Steven and Shymanskyy, Volodymyr},
  year		= {2022-11-12, 2022},
  urldate	= {2023-05-08},
  keywords	= {continuation-passing style,interpreter,wasm,wasm3}
}

@Article{	  matsuda20:sparcl,
  title		= {Sparcl: A Language for Partially-Invertible Computation},
  shorttitle	= {Sparcl},
  author	= {Matsuda, Kazutaka and Wang, Meng},
  year		= {2020},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {ICFP},
  pages		= {118:1--118:31},
  doi		= {10.1145/3409000},
  urldate	= {2024-04-03},
  abstract	= {Invertibility is a fundamental concept in computer
		  science, with various manifestations in software
		  development (serializer/deserializer, parser/printer,
		  redo/undo, compressor/decompressor, and so on). Full
		  invertibility necessarily requires bijectivity, but the
		  direct approach of composing bijective functions to develop
		  invertible programs is too restrictive to be useful. In
		  this paper, we take a different approach by focusing on
		  partially-invertible functions---functions that become
		  invertible if some of their arguments are fixed. The
		  simplest example of such is addition, which becomes
		  invertible when fixing one of the operands. More involved
		  examples include entropy-based compression methods (e.g.,
		  Huffman coding), which carry the occurrence frequency of
		  input symbols (in certain formats such as Huffman tree),
		  and fixing this frequency information makes the compression
		  methods invertible. We develop a language Sparcl for
		  programming such functions in a natural way, where
		  partial-invertibility is the norm and bijectivity is a
		  special case, hence gaining significant expressiveness
		  without compromising correctness. The challenge in
		  designing such a language is to allow ordinary programming
		  (the ``partially'' part) to interact with the invertible
		  part freely, and yet guarantee invertibility by
		  construction. The language Sparcl is linear-typed, and has
		  a type constructor to distinguish data that are subject to
		  invertible computation and those that are not. We present
		  the syntax, type system, and semantics of the language, and
		  prove that Sparcl correctly guarantees invertibility for
		  its programs. We demonstrate the expressiveness of Sparcl
		  with examples including tree rebuilding from preorder and
		  inorder traversals and Huffman coding.},
  keywords	= {linear types,reversible computation}
}

@InProceedings{	  maulana15:inverse,
  title		= {Inverse Kinematic Implementation of Four-Wheels Mecanum
		  Drive Mobile Robot Using Stepper Motors},
  booktitle	= {2015 {{International Seminar}} on {{Intelligent
		  Technology}} and {{Its Applications}} ({{ISITIA}})},
  author	= {Maulana, Eka and Muslim, M. Aziz and Hendrayawan, Veri},
  year		= {2015},
  month		= may,
  pages		= {51--56},
  doi		= {10.1109/ISITIA.2015.7219952},
  urldate	= {2024-09-12},
  abstract	= {An implementation of inverse kinematic model is applied
		  for the mobile robot using four-wheels mecanum drive. The
		  implementation is designed for omni-directional movement
		  without changes the robot position on a facing direction.
		  Four stepper motors are used to drive the mecanum wheels
		  due to these types have a good precision. This speed
		  control feedback is not necessary. The radius of the mobile
		  robot dimension is defined by the same distance of a and b
		  length between wheel axis and body center of 170 mm. The
		  inverse kinematic is conducted to control the mobile robot
		  movement and to convert the robot velocity component of vx,
		  vy, and {$\omega$} toward angular velocity each wheels of
		  {$\omega$}1, {$\omega$}2, {$\omega$}3, {$\omega$}4 and
		  wheel turn direction. Kinematic calculation and control
		  mechanism are proceed by a master microcontroller and
		  multi-slave microcontrollers which connected using SPI
		  communication protocol. The theta angle {\texttheta} is
		  described by vx and vy vector velocity direction toward
		  center point of the mobile robot. The movement capabilities
		  are performed by linear direction according to the certain
		  angle of the robot movement {\texttheta} of 0{$^\circ$} to
		  each multiples of 45{$^\circ$} thus obtained wheel velocity
		  and angle movement average errors.},
  keywords	= {Conferences,Four-Wheel,Inverse Kinematics,Measurement
		  uncertainty,Mecanum Drive,Mobile communication,Mobile
		  Robot,Mobile robots,Navigation,Wheels}
}

@Article{	  mcbride89:electrical,
  title		= {Electrical Contact Bounce in Medium-Duty Contacts},
  author	= {McBride, J.W.},
  year		= {1989},
  month		= mar,
  journal	= {IEEE Transactions on Components, Hybrids, and
		  Manufacturing Technology},
  volume	= {12},
  number	= {1},
  pages		= {82--90},
  issn		= {1558-3082},
  doi		= {10.1109/33.19016},
  urldate	= {2025-01-13},
  abstract	= {Electrical contact bounce occurs with most types of
		  switching contacts; it is often a major cause of wear and
		  erosion, leading to reduced reliability in a given system.
		  The author investigates the basic phenomena of contact
		  bounce with the passage of current in the medium duty range
		  (1-30 A AC and DC). An automated test system is used to
		  evaluate contact bounce. In the evaluation, surface
		  degradation is accounted for during endurance testing,
		  allowing the development of empirical relations between
		  mechanical and electrical bounce. Consideration of the
		  experimental results presented gives an understanding of
		  how current affects contact bounce. The current is shown to
		  influence single separations by applying additional forces
		  to the mechanical impact process. The constant time
		  duration of a first bounce is reconfirmed, and surface
		  conditions accounted for to present a complete picture of
		  the dynamics.{$<>$}},
  keywords	= {Automatic
		  testing,Circuits,Contacts,Degradation,Meetings,Physics,Protection,Springs,Voltage,Welding}
}

@Article{	  mccauley08:debugging,
  title		= {Debugging: A Review of the Literature from an Educational
		  Perspective},
  author	= {McCauley, Ren{\'e}e and Fitzgerald, Sue and Lewandowski,
		  Gary and Murphy, Laurie and Simon, Beth and Thomas, Lynda
		  and Zander, Carol},
  year		= {2008},
  journal	= {Computer Science Education},
  volume	= {18},
  number	= {2},
  eprint	= {https://doi.org/10.1080/08993400802114581},
  pages		= {67--92},
  publisher	= {Routledge},
  doi		= {10.1080/08993400802114581}
}

@Article{	  mcclelland95:why,
  title		= {Why There Are Complementary Learning Systems in the
		  Hippocampus and Neocortex: {{Insights}} from the Successes
		  and Failures of Connectionist Models of Learning and
		  Memory.},
  author	= {McClelland, James L. and McNaughton, Bruce L. and
		  O'Reilly, Randall C.},
  year		= {1995},
  journal	= {Psychological Review},
  volume	= {102},
  number	= {3},
  pages		= {419--457},
  publisher	= {American Psychological Association},
  address	= {US},
  issn		= {1939-1471(Electronic),0033-295X(Print)},
  doi		= {10.1037/0033-295X.102.3.419},
  abstract	= {Damage to the hippocampal system disrupts recent memory
		  but leaves remote memory intact. The account presented here
		  suggests that memories are first stored via synaptic
		  changes in the hippocampal system, that these changes
		  support reinstatement of recent memories in the neocortex,
		  that neocortical synapses change a little on each
		  reinstatement, and that remote memory is based on
		  accumulated neocortical changes. Models that learn via
		  changes to connections help explain this organization.
		  These models discover the structure in ensembles of items
		  if learning of each item is gradual and interleaved with
		  learning about other items. This suggests that the
		  neocortex learns slowly to discover the structure in
		  ensembles of experiences. The hippocampal system permits
		  rapid learning of new items without disrupting this
		  structure, and reinstatement of new memories interleaves
		  them with others to integrate them into structured
		  neocortical memory systems. (PsycINFO Database Record (c)
		  2019 APA, all rights reserved)},
  keywords	= {*Cerebral
		  Cortex,*Connectionism,*Hippocampus,*Learning,*Neural
		  Networks,Neocortex}
}

@Misc{		  mcdonald23:mruby-esp32-system,
  title		= {Mruby-Esp32-System. {{System}} Library for Mruby-Esp32.},
  author	= {McDonald, Carson and others},
  year		= {2023},
  urldate	= {2023-05},
  lastaccessed	= {May 11, 2023}
}

@Article{	  mcdowell89:debugging,
  title		= {Debugging Concurrent Programs},
  author	= {McDowell, Charles E. and Helmbold, David P.},
  year		= {1989},
  month		= dec,
  journal	= {ACM Comput. Surv.},
  volume	= {21},
  number	= {4},
  pages		= {593--622},
  issn		= {0360-0300},
  doi		= {10.1145/76894.76897},
  urldate	= {2024-08-30},
  abstract	= {The main problems associated with debugging concurrent
		  programs are increased complexity, the "probe effect,"
		  nonrepeatability, and the lack of a synchronized global
		  clock. The probe effect refers to the fact that any attempt
		  to observe the behavior of a distributed system may change
		  the behavior of that system. For some parallel programs,
		  different executions with the same data will result in
		  different results even without any attempt to observe the
		  behavior. Even when the behavior can be observed, in many
		  systems the lack of a synchronized global clock makes the
		  results of the observation difficult to interpret. This
		  paper discusses these and other problems related to
		  debugging concurrent programs and presents a survey of
		  current techniques used in debugging concurrent programs.
		  Systems using three general techniques are described:
		  traditional or breakpoint style debuggers, event monitoring
		  systems, and static analysis systems. In addition,
		  techniques for limiting, organizing, and displaying a large
		  amount of data produced by the debugging systems are
		  discussed.}
}

@Article{	  medhat20:framework,
  title		= {A {{Framework}} for {{Continuous Regression}} and
		  {{Integration Testing}} in {{IoT Systems Based}} on {{Deep
		  Learning}} and {{Search-Based Techniques}}},
  author	= {Medhat, Noha and Moussa, Sherin M. and Badr, Nagwa Lotfy
		  and Tolba, Mohamed F.},
  year		= {2020},
  journal	= {IEEE Access},
  volume	= {8},
  pages		= {215716--215726},
  issn		= {2169-3536},
  doi		= {10.1109/ACCESS.2020.3039931},
  urldate	= {2025-05-04},
  abstract	= {Tremendous systems are rapidly evolving based on the
		  trendy Internet of Things (IoT) in various domains.
		  Different technologies are used for communication between
		  the massive connected devices through all layers of the IoT
		  system, causing many security and performance issues.
		  Regression and integration testing are considered
		  repeatedly, in which the vast costs and efforts associated
		  with the frequent execution of these inflated test suites
		  hinder the adequate testing of such systems. This
		  necessitates the focus on exploring innovative scalable
		  testing approaches for large test suites in IoT-based
		  systems. In this paper, a scalable framework for continuous
		  integration and regression testing in IoT-based systems
		  (IoT-CIRTF) is proposed, based on IoT-related criteria for
		  test case prioritization and selection. The framework
		  utilizes search-based techniques to provide an optimized
		  prioritized set of test cases to select from. The selection
		  is based on a trained prediction model for IoT standard
		  components using supervised deep learning algorithms to
		  continuously ensure the overall reliability of IoT-based
		  systems. The experiments are held on two GSM datasets. The
		  experimental results achieved prioritization accuracy up to
		  90\% and 92\% for regression testing and integration
		  testing respectively. This provides an enhanced and
		  efficient framework for continuous testing of IoT-based
		  systems, as per IoT-related criteria for the prioritization
		  and selection purposes.},
  keywords	= {Classification algorithms,Deep learning,Feature
		  extraction,integration testing,IoT,Protocols,regression
		  testing,search-based techniques,test case
		  prioritization,test case selection,Testing,Tools,Unified
		  modeling language}
}

@InProceedings{	  mensing19:from,
  title		= {From Definitional Interpreter to Symbolic Executor},
  booktitle	= {Proceedings of the 4th {{ACM SIGPLAN International
		  Workshop}} on {{Meta-Programming Techniques}} and
		  {{Reflection}}},
  author	= {Mensing, Adrian D. and {van Antwerpen}, Hendrik and Bach
		  Poulsen, Casper and Visser, Eelco},
  year		= {2019},
  month		= oct,
  series	= {{{META}} 2019},
  pages		= {11--20},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3358502.3361269},
  urldate	= {2023-11-22},
  abstract	= {Symbolic execution is a technique for automatic software
		  validation and verification. New symbolic executors
		  regularly appear for both existing and new languages and
		  such symbolic executors are generally manually
		  (re)implemented each time we want to support a new
		  language. We propose to automatically generate symbolic
		  executors from language definitions, and present a
		  technique for mechanically (but as yet, manually) deriving
		  a symbolic executor from a definitional interpreter. The
		  idea is that language designers define their language as a
		  monadic definitional interpreter, where the monad of the
		  interpreter defines the meaning of branch points.
		  Developing a symbolic executor for a language is a matter
		  of changing the monadic interpretation of branch points. In
		  this paper, we illustrate the technique on a language with
		  recursive functions and pattern matching, and use the
		  derived symbolic executor to automatically generate test
		  cases for definitional interpreters implemented in our
		  defined language.},
  isbn		= {978-1-4503-6985-5},
  keywords	= {Definitional Interpreter,Haskell,Monads,Symbolic
		  Execution}
}

@InCollection{	  mezzina20:software,
  title		= {Software and {{Reversible Systems}}: {{A~Survey}} of
		  {{Recent Activities}}},
  shorttitle	= {Software and {{Reversible Systems}}},
  booktitle	= {Reversible {{Computation}}: {{Extending Horizons}} of
		  {{Computing}}: {{Selected Results}} of the {{COST Action
		  IC1405}}},
  author	= {Mezzina, Claudio Antares and Schlatte, Rudolf and
		  Gl{\"u}ck, Robert and Haulund, Tue and Hoey, James and Holm
		  Cservenka, Martin and Lanese, Ivan and Mogensen, Torben
		  {\AE}. and Siljak, Harun and Schultz, Ulrik P. and
		  Ulidowski, Irek},
  editor	= {Ulidowski, Irek and Lanese, Ivan and Schultz, Ulrik Pagh
		  and Ferreira, Carla},
  year		= {2020},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {41--59},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-47361-7_2},
  urldate	= {2023-09-28},
  abstract	= {Software plays a central role in all aspects of reversible
		  computing. We survey the breadth of topics and recent
		  activities on reversible software and systems including
		  behavioural types, recovery, debugging, concurrency, and
		  object-oriented programming. These have the potential to
		  provide linguistic abstractions and tools that will lead to
		  safer and more reliable reversible computing
		  applications.},
  isbn		= {978-3-030-47361-7},
  langid	= {english}
}

@InCollection{	  mezzina20:softwarea,
  title		= {Software and {{Reversible Systems}}: {{A~Survey}} of
		  {{Recent Activities}}},
  shorttitle	= {Software and {{Reversible Systems}}},
  booktitle	= {Reversible {{Computation}}: {{Extending Horizons}} of
		  {{Computing}}: {{Selected Results}} of the {{COST Action
		  IC1405}}},
  author	= {Mezzina, Claudio Antares and Schlatte, Rudolf and
		  Gl{\"u}ck, Robert and Haulund, Tue and Hoey, James and Holm
		  Cservenka, Martin and Lanese, Ivan and Mogensen, Torben
		  {\AE}. and Siljak, Harun and Schultz, Ulrik P. and
		  Ulidowski, Irek},
  editor	= {Ulidowski, Irek and Lanese, Ivan and Schultz, Ulrik Pagh
		  and Ferreira, Carla},
  year		= {2020},
  pages		= {41--59},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-47361-7_2},
  urldate	= {2024-11-10},
  abstract	= {Software plays a central role in all aspects of reversible
		  computing. We survey the breadth of topics and recent
		  activities on reversible software and systems including
		  behavioural types, recovery, debugging, concurrency, and
		  object-oriented programming. These have the potential to
		  provide linguistic abstractions and tools that will lead to
		  safer and more reliable reversible computing
		  applications.},
  isbn		= {978-3-030-47361-7},
  langid	= {english}
}

@Article{	  michael23:mswasm,
  title		= {{{MSWasm}}: {{Soundly Enforcing Memory-Safe Execution}} of
		  {{Unsafe Code}}},
  shorttitle	= {{{MSWasm}}},
  author	= {Michael, Alexandra E. and Gollamudi, Anitha and Bosamiya,
		  Jay and Johnson, Evan and Denlinger, Aidan and Disselkoen,
		  Craig and Watt, Conrad and Parno, Bryan and Patrignani,
		  Marco and Vassena, Marco and Stefan, Deian},
  year		= {2023},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {POPL},
  pages		= {15:425--15:454},
  doi		= {10.1145/3571208},
  urldate	= {2024-01-18},
  abstract	= {Most programs compiled to WebAssembly (Wasm) today are
		  written in unsafe languages like C and C++. Unfortunately,
		  memory-unsafe C code remains unsafe when compiled to
		  Wasm---and attackers can exploit buffer overflows and
		  use-after-frees in Wasm almost as easily as they can on
		  native platforms. Memory- Safe WebAssembly (MSWasm)
		  proposes to extend Wasm with language-level memory-safety
		  abstractions to precisely address this problem. In this
		  paper, we build on the original MSWasm position paper to
		  realize this vision. We give a precise and formal semantics
		  of MSWasm, and prove that well-typed MSWasm programs are,
		  by construction, robustly memory safe. To this end, we
		  develop a novel, language-independent memory-safety
		  property based on colored memory locations and pointers.
		  This property also lets us reason about the security
		  guarantees of a formal C-to-MSWasm compiler---and prove
		  that it always produces memory-safe programs (and preserves
		  the semantics of safe programs). We use these formal
		  results to then guide several implementations: Two
		  compilers of MSWasm to native code, and a C-to-MSWasm
		  compiler (that extends Clang). Our MSWasm compilers support
		  different enforcement mechanisms, allowing developers to
		  make security-performance trade-offs according to their
		  needs. Our evaluation shows that on the PolyBenchC suite,
		  the overhead of enforcing memory safety in software ranges
		  from 22\% (enforcing spatial safety alone) to 198\%
		  (enforcing full memory safety), and 51.7\% when using
		  hardware memory capabilities for spatial safety and pointer
		  integrity. More importantly, MSWasm's design makes it easy
		  to swap between enforcement mechanisms; as fast (especially
		  hardware-based) enforcement techniques become available,
		  MSWasm will be able to take advantage of these advances
		  almost for free.},
  keywords	= {Memory-safety,Secure Compilation,Semantics,WebAssembly}
}

@Misc{		  microsoft21:visual,
  title		= {Visual Studio Code: {{Extension API}}},
  author	= {{Microsoft}},
  year		= {2021-05-17, 2022}
}

@Misc{		  microsoft23:typescript,
  title		= {The {{TypeScript}} Handbook},
  author	= {{Microsoft}},
  year		= {2023},
  urldate	= {2023-02-07},
  lastaccessed	= {February 7, 2023}
}

@Article{	  mihali-c22:hardware-in-the-loop-simulations,
  title		= {Hardware-in-the-{{Loop Simulations}}: {{A Historical
		  Overview}} of {{Engineering Challenges}}},
  shorttitle	= {Hardware-in-the-{{Loop Simulations}}},
  author	= {Mihali{\v c}, Franc and Trunti{\v c}, Mitja and Hren,
		  Alenka},
  year		= {2022},
  month		= jan,
  journal	= {Electronics},
  volume	= {11},
  number	= {15},
  pages		= {2462},
  publisher	= {Multidisciplinary Digital Publishing Institute},
  issn		= {2079-9292},
  doi		= {10.3390/electronics11152462},
  urldate	= {2025-05-04},
  abstract	= {The design of modern industrial products is further
		  improved through the hardware-in-the-loop (HIL) simulation.
		  Realistic simulation is enabled by the closed loop between
		  the hardware under test (HUT) and real-time simulation.
		  Such a system involves a field programmable gate array
		  (FPGA) and digital signal processor (DSP). An HIL model can
		  bypass serious damage to the real object, reduce debugging
		  cost, and, finally, reduce the comprehensive effort during
		  the testing. This paper provides a historical overview of
		  HIL simulations through different engineering challenges,
		  i.e., within automotive, power electronics systems, and
		  different industrial drives. Various platforms, such as
		  National Instruments, dSPACE, Typhoon HIL, or MATLAB
		  Simulink Real-Time toolboxes and Speedgoat hardware
		  systems, offer a powerful tool for efficient and successful
		  investigations in different fields. Therefore, HIL
		  simulation practice must begin already during the
		  university's education process to prepare the students for
		  professional engagements in the industry, which was also
		  verified experimentally at the end of the paper.},
  copyright	= {http://creativecommons.org/licenses/by/3.0/},
  langid	= {english},
  keywords	= {automotive,controller-in-the-loop (CIL),DC-DC
		  converters,electric drives,grid
		  applications,hardware-in-the-loop (HIL),inverter
		  systems,power hardware-in-the-loop (PHIL),railway systems}
}

@Misc{		  mikejo500025:remote,
  title		= {Remote Debugging - {{Visual Studio}} ({{Windows}})},
  author	= {Mikejo5000},
  year		= {2025},
  month		= jan,
  urldate	= {2025-03-01},
  abstract	= {Debug a Visual Studio application that has been deployed
		  on a different computer by using the Visual Studio remote
		  debugger.},
  howpublished	= {https://learn.microsoft.com/en-us/visualstudio/debugger/remote-debugging?view=vs-2022},
  langid	= {american}
}

@Article{	  milner78:theory,
  title		= {A Theory of Type Polymorphism in Programming},
  author	= {Milner, Robin},
  year		= {1978},
  month		= dec,
  journal	= {Journal of Computer and System Sciences},
  volume	= {17},
  number	= {3},
  pages		= {348--375},
  issn		= {0022-0000},
  doi		= {10.1016/0022-0000(78)90014-4},
  urldate	= {2023-09-26},
  abstract	= {The aim of this work is largely a practical one. A widely
		  employed style of programming, particularly in
		  structure-processing languages which impose no discipline
		  of types, entails defining procedures which work well on
		  objects of a wide variety. We present a formal type
		  discipline for such polymorphic procedures in the context
		  of a simple programming language, and a compile time
		  type-checking algorithm W which enforces the discipline. A
		  Semantic Soundness Theorem (based on a formal semantics for
		  the language) states that well-type programs cannot ``go
		  wrong'' and a Syntactic Soundness Theorem states that if W
		  accepts a program then it is well typed. We also discuss
		  extending these results to richer languages; a
		  type-checking algorithm based on W is in fact already
		  implemented and working, for the metalanguage ML in the
		  Edinburgh LCF system.}
}

@InProceedings{	  miraglia16:peeking,
  title		= {Peeking into the {{Past}}: {{Efficient Checkpoint-Assisted
		  Time-Traveling Debugging}}},
  shorttitle	= {Peeking into the {{Past}}},
  booktitle	= {2016 {{IEEE}} 27th {{International Symposium}} on
		  {{Software Reliability Engineering}} ({{ISSRE}})},
  author	= {Miraglia, Armando and Vogt, Dirk and Bos, Herbert and
		  Tanenbaum, Andy and Giuffrida, Cristiano},
  year		= {2016},
  month		= oct,
  pages		= {455--466},
  issn		= {2332-6549},
  doi		= {10.1109/ISSRE.2016.9},
  urldate	= {2025-01-13},
  abstract	= {Debugging long-lived latent software bugs that manifest
		  themselves only long after their introduction in the system
		  is hard. Even state-of-the-artrecord/replay debugging
		  techniques are of limited use to identify the rootcause of
		  long-lived latent bugs in general and event-driven bugs in
		  particular. We propose DeLorean, a new end-to-end solution
		  for time-travelling debugging based on fast memory
		  checkpointing. Our design trades off replay guarantees with
		  efficient support for history-aware debug queries (or
		  time-travelling introspection) and provides novel analysis
		  tools to diagnose event-driven latent software bugs.
		  DeLorean imposes low run-time performance and memory
		  overhead while preserving in memory as much history
		  information as possible by deduplicating and/or compressing
		  the collected data. We evaluate DeLorean byextensive
		  experimentation, exploring the performance-memory tradeoffs
		  in different configurations and comparing our results
		  against state-of-the-art solutions. We show that DeLorean
		  can efficiently support high-frequency checkpoints and
		  store millions of them in memory.},
  keywords	= {Checkpointing,Computer
		  bugs,Debugging,History,Kernel,Memory Checkpointing,Memory
		  Management,Performance,Servers}
}

@Article{	  mishra20:use,
  title		= {The {{Use}} of {{MQTT}} in {{M2M}} and {{IoT Systems}}:
		  {{A Survey}}},
  shorttitle	= {The {{Use}} of {{MQTT}} in {{M2M}} and {{IoT Systems}}},
  author	= {Mishra, Biswajeeban and Kertesz, Attila},
  year		= {2020},
  journal	= {IEEE Access},
  volume	= {8},
  pages		= {201071--201086},
  issn		= {2169-3536},
  doi		= {10.1109/ACCESS.2020.3035849},
  urldate	= {2023-10-03},
  abstract	= {Nowadays billions of smart devices or things are present
		  in Internet of Things (IoT) environments, such as homes,
		  hospitals, factories, and vehicles, all around the world.
		  As a result, the number of interconnected devices is
		  continuously and rapidly growing. These devices communicate
		  with each other and with other services using various
		  communication protocols for the transportation of sensor or
		  event data. These protocols enable applications to collect,
		  store, process, describe, and analyze data to solve a
		  variety of problems. IoT also aims to provide secure,
		  bi-directional communication between interconnected
		  devices, such as sensors, actuators, microcontrollers or
		  smart appliances, and corresponding cloud services. In this
		  paper we analyze the growth of M2M protocol research (MQTT,
		  AMQP, and CoAP) over the past 20 years, and show how the
		  growth in MQTT research stands out from the rest. We also
		  gather relevant application areas of MQTT, as the most
		  widespread M2M/IoT protocol, by performing a detailed
		  literature search in major digital research archives. Our
		  quantitative evaluation presents some of the important
		  MQTT-related studies published in the past five years,
		  which we compare to discuss the main features, advantages,
		  and limitations of the MQTT protocol. We also propose a
		  taxonomy to compare the properties and features of various
		  MQTT implementations, i.e. brokers and libraries currently
		  available in the public domain to help researchers and
		  end-users to efficiently choose a broker or client library
		  based on their requirements. Finally, we discuss the
		  relevant findings of our comparison and highlight open
		  issues that need further research and attention.}
}

@Misc{		  mocha,
  title		= {Mocha - the Fun, Simple, Flexible {{JavaScript}} Test
		  Framework},
  author	= {{OpenJS Foundation}},
  urldate	= {2024-02-09},
  howpublished	= {https://mochajs.org/}
}

@InCollection{	  mock,
  title		= {Mock {{Exam}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {301--314},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch7},
  urldate	= {2024-12-04},
  chapter	= {7},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Black-box design techniques,Integration
		  testing,International Software Testing Qualifications Board
		  (ISTQB),Software testing,Test cases (TC)}
}

@InProceedings{	  moggi89:computational,
  title		= {Computational Lambda-Calculus and Monads},
  booktitle	= {[1989] {{Proceedings}}. {{Fourth Annual Symposium}} on
		  {{Logic}} in {{Computer Science}}},
  author	= {Moggi, E.},
  year		= {1989},
  month		= jun,
  pages		= {14--23},
  doi		= {10.1109/LICS.1989.39155},
  urldate	= {2023-10-02},
  abstract	= {The lambda -calculus is considered a useful mathematical
		  tool in the study of programming languages. However, if one
		  uses beta eta -conversion to prove equivalence of programs,
		  then a gross simplification is introduced. The author gives
		  a calculus based on a categorical semantics for
		  computations, which provides a correct basis for proving
		  equivalence of programs, independent from any specific
		  computational model.{$<>$}}
}

@Article{	  moggi91:notions,
  title		= {Notions of Computation and Monads},
  author	= {Moggi, Eugenio},
  year		= {1991},
  month		= jul,
  journal	= {Information and Computation},
  series	= {Selections from 1989 {{IEEE Symposium}} on {{Logic}} in
		  {{Computer Science}}},
  volume	= {93},
  number	= {1},
  pages		= {55--92},
  issn		= {0890-5401},
  doi		= {10.1016/0890-5401(91)90052-4},
  urldate	= {2023-10-02},
  abstract	= {The {$\lambda$}-calculus is considered a useful
		  mathematical tool in the study of programming languages,
		  since programs can be identified with {$\lambda$}-terms.
		  However, if one goes further and uses
		  {$\beta\eta$}-conversion to prove equivalence of programs,
		  then a gross simplification is introduced (programs are
		  identified with total functions from values to values) that
		  may jeopardise the applicability of theoretical results. In
		  this paper we introduce calculi, based on a categorical
		  semantics for computations, that provide a correct basis
		  for proving equivalence of programs for a wide range of
		  notions of computation.}
}

@Article{	  mogul06:emergent,
  title		= {Emergent (Mis)Behavior vs. Complex Software Systems},
  author	= {Mogul, Jeffrey C.},
  year		= {2006},
  month		= apr,
  journal	= {SIGOPS Oper. Syst. Rev.},
  volume	= {40},
  number	= {4},
  pages		= {293--304},
  issn		= {0163-5980},
  doi		= {10.1145/1218063.1217964},
  urldate	= {2025-05-06},
  abstract	= {Complex systems often behave in unexpected ways that are
		  not easily predictable from the behavior of their
		  components; this is known as emergent behavior. As software
		  systems grow in complexity, interconnectedness, and
		  geographic distribution, we will increasingly face unwanted
		  emergent behavior.Unpredictable software systems are hard
		  to debug and hard to manage. We need better tools and
		  methods for anticipating, detecting, diagnosing, and
		  ameliorating emergent misbehavior. These tools and methods
		  will require research into the causes and nature of
		  emergent misbehavior in software systems.}
}

@Article{	  moore08:high-level,
  title		= {High-Level Small-Step Operational Semantics for
		  Transactions},
  author	= {Moore, Katherine F. and Grossman, Dan},
  year		= {2008},
  month		= jan,
  journal	= {SIGPLAN Not.},
  volume	= {43},
  number	= {1},
  pages		= {51--62},
  issn		= {0362-1340},
  doi		= {10.1145/1328897.1328448},
  urldate	= {2024-09-11},
  abstract	= {Software transactions have received significant attention
		  as a way to simplify shared-memory concurrent programming,
		  but insufficient focus has been given to the precise
		  meaning of software transactions or their interaction with
		  other language features. This work begins to rectify that
		  situation by presenting a family of formal languages that
		  model a wide variety of behaviors for software
		  transactions. These languages abstract away implementation
		  details of transactional memory, providing high-level
		  definitions suitable for programming languages. We use
		  small-step semantics in order to represent explicitly the
		  interleaved execution of threads that is necessary to
		  investigate pertinent issues.We demonstrate the value of
		  our core approach to modeling transactions by investigating
		  two issues in depth. First, we consider parallel nesting,
		  in which parallelism and transactions can nest arbitrarily.
		  Second, we present multiple models for weak isolation, in
		  which nontransactional code can violate the isolation of a
		  transaction. For both, type-and-effect systems let us
		  soundly and statically restrict what computation can occur
		  inside or outside a transaction. We prove some key
		  language-equivalence theorems to confirm that under
		  sufficient static restrictions, in particular that each
		  mutable memory location is used outside transactions or
		  inside transactions (but not both), no program can
		  determine whether the language implementation uses weak
		  isolation or strong isolation.}
}

@Article{	  moore65:moores,
  title		= {Moore's Law},
  author	= {Moore, Gordon},
  year		= {1965},
  journal	= {Electronics Magazine},
  volume	= {38},
  number	= {8},
  pages		= {114}
}

@Article{	  morrisett99:from,
  title		= {From System {{F}} to Typed Assembly Language},
  author	= {Morrisett, Greg and Walker, David and Crary, Karl and
		  Glew, Neal},
  year		= {1999},
  month		= may,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {21},
  number	= {3},
  pages		= {527--568},
  issn		= {0164-0925},
  doi		= {10.1145/319301.319345},
  urldate	= {2023-10-20},
  abstract	= {We motivate the design of typed assembly language (TAL)
		  and present a type-preserving ttranslation from Systemn F
		  to TAL. The typed assembly language we pressent is based on
		  a conventional RISC assembly language, but its static type
		  sytem provides support for enforcing high-level language
		  abstratctions, such as closures, tuples, and user-defined
		  abstract data types. The type system ensures that
		  well-typed programs cannot violatet these abstractionsl In
		  addition, the typing constructs admit many low-level
		  compiler optimiztaions. Our translation to TAL is specified
		  as a sequence of type-preserving transformations, including
		  CPS and closure conversion phases; type-correct source
		  programs are mapped to type-correct assembly language. A
		  key contribution is an approach to polymorphic closure
		  conversion that is considerably simpler than previous work.
		  The compiler and typed assembly lanugage provide a fully
		  automatic way to produce certified code, suitable for use
		  in systems where unstrusted and potentially malicious code
		  must be checked for safety before execution.},
  keywords	= {certified code,closure conversion,secure extensible
		  systems,type-directed compilation,typed assembly
		  language,typed intermediate languages}
}

@InProceedings{	  mueller94:on,
  title		= {On Debugging Real-Time Applications},
  booktitle	= {{{ACM SIGPLAN}} Workshop on Language, Compiler, and Tool
		  Support for Real-Time Systems},
  author	= {Mueller, Frank and Whalley, David B},
  year		= {1994},
  publisher	= {Citeseer}
}

@InProceedings{	  mukhin21:testing-mechanism,
  title		= {The {{Testing Mechanism}} for {{Software}} and {{Services
		  Based}} on {{Mike Cohn}}'s {{Testing Pyramid
		  Modification}}},
  booktitle	= {Proceedings of the 11th {{IEEE International Conference}}
		  on {{Intelligent Data Acquisition}} and {{Advanced
		  Computing Systems}}: {{Technology}} and {{Applications}},
		  {{IDAACS}} 2021},
  author	= {Mukhin, V. and Kornaga, Y. and Bazaka, Y. and Krylov, I.
		  and Barabash, A. and Yakovleva, A. and Mukhin, O.},
  year		= {2021},
  volume	= {1},
  pages		= {589--595},
  doi		= {10.1109/IDAACS53288.2021.9660999},
  abstract	= {We modify the Mike Cohn's testing pyramid in order to
		  adapt it for testing the distributed information processing
		  systems, which allowed to expand the testing capabilities
		  and apply the features of distributed systems.
		  Recommendations for further use of the mechanisms of the
		  modified Mike Cohn's pyramid have been developed. We define
		  the requirements to ensure the permanent operation of all
		  services of the distributed computer system, which is
		  hosting the distributed information processing system and
		  to ensure the permanent transfer of request packets at a
		  certain rate. A model for testing software for distributed
		  systems based on the autonomous deployment of software
		  components has been developed, which is based on the a
		  modified Mike Cohn's pyramid, which allows to increase
		  testing efficiency and reduce the number of bulk tests.
		  {\copyright} 2021 IEEE.},
  keywords	= {Distributed system,Probability of proper work,Testing
		  pyramid}
}

@Article{	  muller23:responsive,
  title		= {Responsive {{Parallelism}} with {{Synchronization}}},
  author	= {Muller, Stefan K. and Singer, Kyle and Keeney, Devyn Terra
		  and Neth, Andrew and Agrawal, Kunal and Lee, I-Ting
		  Angelina and Acar, Umut A.},
  year		= {2023},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {PLDI},
  pages		= {135:712--135:735},
  doi		= {10.1145/3591249},
  urldate	= {2023-10-20},
  abstract	= {Many concurrent programs assign priorities to threads to
		  improve responsiveness. When used in conjunction with
		  synchronization mechanisms such as mutexes and condition
		  variables, however, priorities can lead to priority
		  inversions, in which high-priority threads are delayed by
		  low-priority ones. Priority inversions in the use of
		  mutexes are easily handled using dynamic techniques such as
		  priority inheritance, but priority inversions in the use of
		  condition variables are not well-studied and dynamic
		  techniques are not suitable. In this work, we use a
		  combination of static and dynamic techniques to prevent
		  priority inversion in code that uses mutexes and condition
		  variables. A type system ensures that condition variables
		  are used safely, even while dynamic techniques change
		  thread priorities at runtime to eliminate priority
		  inversions in the use of mutexes. We prove the soundness of
		  our system, using a model of priority inversions based on
		  cost models for parallel programs. To show that the type
		  system is practical to implement, we encode it within the
		  type systems of Rust and C++, and show that the
		  restrictions are not overly burdensome by writing sizeable
		  case studies using these encodings, including porting the
		  Memcached object server to use our C++ implementation.},
  keywords	= {condition variables,cost semantics,priority
		  inversions,type systems}
}

@Misc{		  murdoch23:arduinounit,
  title		= {{{ArduinoUnit}}},
  author	= {Murdoch, Matthew},
  year		= {2023},
  urldate	= {2023-02-15},
  lastaccessed	= {February 15, 2023}
}

@Article{	  musslick21:rationalizing,
  title		= {Rationalizing Constraints on the Capacity for Cognitive
		  Control},
  author	= {Musslick, Sebastian and Cohen, Jonathan D.},
  year		= {2021},
  journal	= {Trends in Cognitive Sciences},
  volume	= {25},
  number	= {9},
  pages		= {757--775},
  issn		= {1364-6613},
  doi		= {10.1016/j.tics.2021.06.001},
  abstract	= {Humans are remarkably limited in: (i) how many
		  control-dependent tasks they can execute simultaneously,
		  and (ii) how intensely they can focus on a single task.
		  These limitations are universal assumptions of most
		  theories of cognition. Yet, a rationale for why humans are
		  subject to these constraints remains elusive. This feature
		  review draws on recent insights from psychology,
		  neuroscience, and machine learning, to suggest that
		  constraints on cognitive control may result from a rational
		  adaptation to fundamental, computational dilemmas in neural
		  architectures. The reviewed literature implies that
		  limitations in multitasking may result from a trade-off
		  between learning efficacy and processing efficiency and
		  that limitations in the intensity of commitment to a single
		  task may reflect a trade-off between cognitive stability
		  and flexibility.},
  keywords	= {information processing limitations,multitasking,task
		  switching,visual attention,working memory}
}

@InProceedings{	  naik17:choice,
  title		= {Choice of Effective Messaging Protocols for {{IoT}}
		  Systems: {{MQTT}}, {{CoAP}}, {{AMQP}} and {{HTTP}}},
  shorttitle	= {Choice of Effective Messaging Protocols for {{IoT}}
		  Systems},
  booktitle	= {2017 {{IEEE International Systems Engineering Symposium}}
		  ({{ISSE}})},
  author	= {Naik, Nitin},
  year		= {2017},
  month		= oct,
  pages		= {1--7},
  doi		= {10.1109/SysEng.2017.8088251},
  urldate	= {2025-05-20},
  abstract	= {The standard and real-time communication technology is an
		  unalloyed inevitability for the development of Internet of
		  Things (IoT) applications. However, the selection of a
		  standard and effective messaging protocol is a challenging
		  and daunting task for any organisation because it depends
		  on the nature of the IoT system and its messaging
		  requirements. Copious messaging protocols have been
		  developed and employed by various organisations based on
		  their requirements in the last two decades. Though, none of
		  them is able to support all messaging requirements of all
		  types of IoT systems. Messaging protocol is an ongoing
		  dilemma for the IoT industry; consequently, it is important
		  to understand the pros and cons of the widely accepted and
		  emerging messaging protocols for IoT systems to determine
		  their best-fit scenarios. Therefore, this paper presents an
		  evaluation of the four established messaging protocols
		  MQTT, CoAP, AMQP and HTTP for IoT systems. Firstly, it
		  presents the broad comparison among these messaging
		  protocols to introduce their characteristics comparatively.
		  Afterwards, it performs a further in-depth and relative
		  analysis based on some interrelated criteria to gain
		  insight into their strengths and limitations. Thus, based
		  on this detailed evaluation, the user can decide their
		  appropriate usage in various IoT systems according to their
		  requirements and suitability.},
  keywords	= {AMQP,CoAP,HTTP,Interoperability,IoT Systems,M2M
		  Communication,Machine-to-machine communications,Messaging
		  Protocol,MQTT,Quality of service,Quality of
		  Services,Reliability,Security,Standards,Transport
		  protocols}
}

@Article{	  nandi18:functional,
  title		= {Functional Programming for Compiling and Decompiling
		  Computer-Aided Design},
  author	= {Nandi, Chandrakana and Wilcox, James R. and Panchekha,
		  Pavel and Blau, Taylor and Grossman, Dan and Tatlock,
		  Zachary},
  year		= {2018},
  month		= jul,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {2},
  number	= {ICFP},
  pages		= {99:1--99:31},
  doi		= {10.1145/3236794},
  urldate	= {2023-12-01},
  abstract	= {Desktop-manufacturing techniques like 3D printing are
		  increasingly popular because they reduce the cost and
		  complexity of producing customized objects on demand.
		  Unfortunately, the vibrant communities of early adopters,
		  often referred to as "makers," are not well-served by
		  currently available software pipelines. Users today must
		  compose idiosyncratic sequences of tools which are
		  typically repurposed variants of proprietary software
		  originally designed for expert specialists. This paper
		  proposes fundamental programming-languages techniques to
		  bring improved rigor, reduced complexity, and new
		  functionality to the computer-aided design (CAD) software
		  pipeline for applications like 3D-printing.
		  Compositionality, denotational semantics, compiler
		  correctness, and program synthesis all play key roles in
		  our approach, starting from the perspective that solid
		  geometry is a programming language. Specifically, we define
		  a purely functional language for CAD called LambdaCAD and a
		  polygon surface-mesh intermediate representation. We then
		  define denotational semantics of both languages to 3D
		  solids and a compiler from CAD to mesh accompanied by a
		  proof of semantics preservation. We illustrate the utility
		  of this foundation by developing a novel synthesis
		  algorithm based on evaluation contexts to "reverse compile"
		  difficult-to-edit meshes downloaded from online maker
		  communities back to more-editable CAD programs. All our
		  prototypes have been implemented in OCaml to enable further
		  exploration of functional programming for desktop
		  manufacturing.},
  keywords	= {3D printing,denotational semantics,language design,program
		  synthesis}
}

@Misc{		  nanoframework-contributors21:net-nanoframework,
  title		= {.{{NET nanoFramework}} Documentation},
  author	= {{nanoFramework Contributors}},
  year		= {2021},
  publisher	= {Online},
  urldate	= {2021-08-05}
}

@Article{	  new23:gradual,
  title		= {Gradual {{Typing}} for {{Effect Handlers}}},
  author	= {New, Max S. and Giovannini, Eric and Licata, Daniel R.},
  year		= {2023},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {OOPSLA2},
  pages		= {284:1758--284:1786},
  doi		= {10.1145/3622860},
  urldate	= {2024-01-09},
  abstract	= {We present a gradually typed language, GrEff, with effects
		  and handlers that supports migration from unchecked to
		  checked effect typing. This serves as a simple model of the
		  integration of an effect typing discipline with an existing
		  effectful typed language that does not track fine-grained
		  effect information. Our language supports a simple module
		  system to model the programming model of gradual migration
		  from unchecked to checked effect typing in the style of
		  Typed Racket. The surface language GrEff is given semantics
		  by elaboration to a core language Core GrEff. We equip Core
		  GrEff with an inequational theory for reasoning about the
		  semantic error ordering and desired program equivalences
		  for programming with effects and handlers. We derive an
		  operational semantics for the language from the equations
		  provable in the theory. We then show that the theory is
		  sound by constructing an operational logical relations
		  model to prove the graduality theorem. This extends prior
		  work on embedding-projection pair models of gradual typing
		  to handle effect typing and subtyping.},
  keywords	= {effect handlers,gradual typing,graduality,logical
		  relation,operational semantics}
}

@InProceedings{	  nielsen23:formalising,
  title		= {Formalising {{Decentralised Exchanges}} in {{Coq}}},
  booktitle	= {Proceedings of the 12th {{ACM SIGPLAN International
		  Conference}} on {{Certified Programs}} and {{Proofs}}},
  author	= {Nielsen, Eske Hoy and Annenkov, Danil and Spitters, Bas},
  year		= {2023},
  month		= jan,
  pages		= {290--302},
  publisher	= {ACM},
  address	= {Boston MA USA},
  doi		= {10.1145/3573105.3575685},
  urldate	= {2023-09-27},
  isbn		= {9798400700262},
  langid	= {english}
}

@InProceedings{	  niephaus20:example-based,
  title		= {Example-Based Live Programming for Everyone: Building
		  Language-Agnostic Tools for Live Programming with {{LSP}}
		  and {{GraalVM}}},
  shorttitle	= {Example-Based Live Programming for Everyone},
  booktitle	= {Proceedings of the 2020 {{ACM SIGPLAN International
		  Symposium}} on {{New Ideas}}, {{New Paradigms}}, and
		  {{Reflections}} on {{Programming}} and {{Software}}},
  author	= {Niephaus, Fabio and Rein, Patrick and Edding, Jakob and
		  Hering, Jonas and K{\"o}nig, Bastian and Opahle, Kolya and
		  Scordialo, Nico and Hirschfeld, Robert},
  year		= {2020},
  month		= nov,
  series	= {Onward! 2020},
  pages		= {1--17},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3426428.3426919},
  urldate	= {2024-10-30},
  abstract	= {Our community has explored various approaches to improve
		  the programming experience. Although many of them, such as
		  Example-Based Live Programming (ELP), have shown to be
		  effective, they are still not widespread in conventional
		  programming environments. A reason for that is the effort
		  required to provide sophisticated tools that rely on
		  run-time information. To target multiple language
		  ecosystems, it is often necessary to implement the same
		  concepts, but for different languages and runtimes. Two
		  emerging technologies present an opportunity to reduce this
		  effort significantly: the Language Server Protocol (LSP)
		  and language implementation frameworks such as GraalVM's
		  Truffle. In this paper, we show how an ELP system can be
		  built in a language-agnostic way by leveraging these two
		  technologies. Based on our approach, we implemented the
		  Babylonian Programming system, an ELP system that has
		  previously only been implemented for exploratory
		  ecosystems. Our system, on the other hand, brings ELP for
		  all languages supported by the GraalVM to Visual Studio
		  Code (VS Code). Moreover, we outline what a
		  language-agnostic infrastructure needs to provide and how
		  the LSP could be extended to support ELP also independently
		  from programming environments. Further, we demonstrate how
		  our approach enables the use of ELP in the context of
		  polyglot programming. We illustrate the consequences of our
		  approach by discussing its advantages and limitations and
		  by comparing the features of our system to other ELP
		  systems. Moreover, we give an outlook of how tools that
		  rely on run-time information could be built in the future.
		  This in turn might motivate future tool builders and
		  researchers to consider implementing more tools in a
		  language-agnostic way from the start to make them available
		  to a broader audience.},
  isbn		= {978-1-4503-8178-9}
}

@InProceedings{	  nikolaidis21:iotier,
  title		= {{{IOTier}}: {{A}} Virtual Testbed to Evaluate Systems for
		  {{IoT}} Environments},
  shorttitle	= {{{IOTier}}},
  booktitle	= {Proceedings - 21st {{IEEE}}/{{ACM International
		  Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet
		  Computing}}, {{CCGrid}} 2021},
  author	= {Nikolaidis, F. and Marazakis, M. and Bilas, A.},
  year		= {2021},
  pages		= {676--683},
  doi		= {10.1109/CCGrid51090.2021.00081},
  abstract	= {Internet of Things (IoT) is an emerging field
		  characterized by constrained resources, Internet-based
		  communication, arbitrary topologies, geographical distance,
		  and variable operational conditions. Additionally, IoT
		  architectures typically exhibit at least three tiers: IoT
		  devices, Edge gateways, Cloud servers. On top of
		  challenging the design of networked systems, multiple tiers
		  create a web of complexity that makes systems evaluation a
		  challenging endeavor. This paper presents a framework for
		  transforming a cluster of lab machines into a Virtual
		  Testbed that provides views of how systems will perform in
		  a tiered IoT environment. Experiments with constrained
		  resources (CPU, memory, block device, network), multiple
		  tiers, and programmables events are presented and
		  discussed. Their effects are analyzed on the common path
		  operation of micro-benchmarks and distributed key/value
		  store. {\copyright} 2021 IEEE.},
  keywords	= {Emulator,IoT,Systems evaluation,Testbed}
}

@InProceedings{	  ocallahan17:engineering,
  title		= {Engineering {{Record}} and {{Replay}} for
		  {{Deployability}}},
  booktitle	= {2017 {{USENIX Annual Technical Conference}} ({{USENIX
		  ATC}} 17)},
  author	= {O'Callahan, Robert and Jones, Chris and Froyd, Nathan and
		  Huey, Kyle and Noll, Albert and Partush, Nimrod},
  year		= {2017},
  pages		= {377--389},
  urldate	= {2025-02-18},
  isbn		= {978-1-931971-38-6},
  langid	= {english}
}

@InProceedings{	  olsson90:dalek,
  title		= {Dalek: A {{GNU}}, Improved Programmable Debugger.},
  booktitle	= {{{USENIX}} Technical Conference},
  author	= {Olsson, Ronald A and Crawford, Richard H and Ho, W
		  Wilson},
  year		= {1990},
  volume	= {90},
  pages		= {221--231},
  publisher	= {The USENIX Association},
  address	= {Berkeley, CA, USA}
}

@Misc{		  optimization,
  title		= {Optimization of Swift Protocols {\textbar} {{Proceedings}}
		  of the {{ACM}} on {{Programming Languages}}},
  urldate	= {2024-12-17},
  howpublished	= {https://dl.acm.org/doi/10.1145/3360590}
}

@Article{	  ottenstein84:program,
  title		= {The Program Dependence Graph in a Software Development
		  Environment},
  author	= {Ottenstein, Karl J. and Ottenstein, Linda M.},
  year		= {1984},
  month		= apr,
  journal	= {ACM SIGPLAN Notices},
  volume	= {19},
  number	= {5},
  pages		= {177--184},
  issn		= {0362-1340},
  doi		= {10.1145/390011.808263},
  urldate	= {2024-01-22},
  abstract	= {The internal program representation chosen for a software
		  development environment plays a critical role in the nature
		  of that environment. A form should facilitate
		  implementation and contribute to the responsiveness of the
		  environment to the user. The program dependence graph (PDG)
		  may be a suitable internal form. It allows programs to be
		  sliced in linear time for debugging and for use by
		  language-directed editors. The slices obtained are more
		  accurate than those obtained with existing methods because
		  I/O is accounted for correctly and irrelevant statements on
		  multi-statement lines are not displayed. The PDG may be
		  interpreted in a data driven fashion or may have highly
		  optimized (including vectorized) code produced from it. It
		  is amenable to incremental data flow analysis, improving
		  response time to the user in an interactive environment and
		  facilitating debugging through data flow anomaly detection.
		  It may also offer a good basis for software complexity
		  metrics, adding to the completeness of an environment based
		  on it.}
}

@InProceedings{	  ottenstein84:programa,
  title		= {The Program Dependence Graph in a Software Development
		  Environment},
  booktitle	= {Proceedings of the First {{ACM SIGSOFT}}/{{SIGPLAN}}
		  Software Engineering Symposium on {{Practical}} Software
		  Development Environments},
  author	= {Ottenstein, Karl J. and Ottenstein, Linda M.},
  year		= {1984},
  month		= apr,
  series	= {{{SDE}} 1},
  pages		= {177--184},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/800020.808263},
  urldate	= {2024-03-18},
  abstract	= {The internal program representation chosen for a software
		  development environment plays a critical role in the nature
		  of that environment. A form should facilitate
		  implementation and contribute to the responsiveness of the
		  environment to the user. The program dependence graph (PDG)
		  may be a suitable internal form. It allows programs to be
		  sliced in linear time for debugging and for use by
		  language-directed editors. The slices obtained are more
		  accurate than those obtained with existing methods because
		  I/O is accounted for correctly and irrelevant statements on
		  multi-statement lines are not displayed. The PDG may be
		  interpreted in a data driven fashion or may have highly
		  optimized (including vectorized) code produced from it. It
		  is amenable to incremental data flow analysis, improving
		  response time to the user in an interactive environment and
		  facilitating debugging through data flow anomaly detection.
		  It may also offer a good basis for software complexity
		  metrics, adding to the completeness of an environment based
		  on it.},
  isbn		= {978-0-89791-131-3},
  keywords	= {Code optimization,Control flow,Data
		  flow,Debugging,Internal program
		  representation,Interpreter,Program slice,Software
		  complexity metrics}
}

@InProceedings{	  ozcan19:remote,
  title		= {Remote {{Debugging}} for {{Containerized Applications}} in
		  {{Edge Computing Environments}}},
  booktitle	= {2019 {{IEEE International Conference}} on {{Edge
		  Computing}} ({{EDGE}})},
  author	= {Ozcan, Muhammet Oguz and Odaci, Fatih and Ari, Ismail},
  year		= {2019},
  month		= jul,
  pages		= {30--32},
  doi		= {10.1109/EDGE.2019.00021},
  urldate	= {2025-02-24},
  abstract	= {Edge Computing (EC) became popular again with the rise of
		  IoT, Cloud Computing, and Industry 4.0. In this paper,
		  difficulties of application development in the EC
		  environment are discussed and a container-based solution
		  using remote debugging at the edge is proposed. This
		  container allows application developers to write code in
		  the production environment. Our implementation increases
		  the development speed and facilitates in-place debugging
		  for EC environments.},
  keywords	= {Cloud computing,Container,Containers,Debugging,Docker,Edge
		  computing,Edge Computing,Industry 4.0,Internet of
		  Things,Production,Remote Debugging,Security}
}

@Article{	  pacheco11:postmortem,
  title		= {Postmortem Debugging in Dynamic Environments},
  author	= {Pacheco, David},
  year		= {2011},
  month		= dec,
  journal	= {Commun. ACM},
  volume	= {54},
  number	= {12},
  pages		= {44--51},
  issn		= {0001-0782},
  doi		= {10.1145/2043174.2043189},
  urldate	= {2025-01-13},
  abstract	= {Many modern dynamic languages lack tools for understanding
		  complex failures.}
}

@Article{	  pan21:test,
  title		= {Test Case Selection and Prioritization Using Machine
		  Learning: A Systematic Literature Review},
  shorttitle	= {Test Case Selection and Prioritization Using Machine
		  Learning},
  author	= {Pan, Rongqi and Bagherzadeh, Mojtaba and Ghaleb, Taher A.
		  and Briand, Lionel},
  year		= {2021},
  month		= dec,
  journal	= {Empirical Software Engineering},
  volume	= {27},
  number	= {2},
  pages		= {29},
  issn		= {1573-7616},
  doi		= {10.1007/s10664-021-10066-6},
  urldate	= {2025-05-04},
  abstract	= {Regression testing is an essential activity to assure that
		  software code changes do not adversely affect existing
		  functionalities. With the wide adoption of Continuous
		  Integration (CI) in software projects, which increases the
		  frequency of running software builds, running all tests can
		  be time-consuming and resource-intensive. To alleviate that
		  problem, Test case Selection and Prioritization (TSP)
		  techniques have been proposed to improve regression testing
		  by selecting and prioritizing test cases in order to
		  provide early feedback to developers. In recent years,
		  researchers have relied on Machine Learning (ML) techniques
		  to achieve effective TSP (ML-based TSP). Such techniques
		  help combine information about test cases, from partial and
		  imperfect sources, into accurate prediction models. This
		  work conducts a systematic literature review focused on
		  ML-based TSP techniques, aiming to perform an in-depth
		  analysis of the state of the art, thus gaining insights
		  regarding future avenues of research. To that end, we
		  analyze 29 primary studies published from 2006 to 2020,
		  which have been identified through a systematic and
		  documented process. This paper addresses five research
		  questions addressing variations in ML-based TSP techniques
		  and feature sets for training and testing ML models,
		  alternative metrics used for evaluating the techniques, the
		  performance of techniques, and the reproducibility of the
		  published studies. We summarize the results related to our
		  research questions in a high-level summary that can be used
		  as a taxonomy for classifying future TSP studies.},
  langid	= {english},
  keywords	= {Continuous integration,Machine learning,Software
		  testing,Systematic literature review,Test case
		  prioritization,Test case selection}
}

@PhDThesis{	  papoulias13:remote,
  title		= {Remote {{Debugging}} and {{Reflection}} in {{Resource
		  Constrained Devices}}},
  author	= {Papoulias, Nikolaos},
  year		= {2013},
  month		= dec,
  urldate	= {2025-02-24},
  abstract	= {Building software for devices that cannot locally support
		  development tools can be challenging. These devices have
		  either limited computing power to run an IDE (e.g.,
		  smart-phones), lack appropriate input/output interfaces
		  (display, keyboard, mouse) for programming (e.g., mobile
		  robots) or are simply unreachable for local development
		  (e.g., cloud-servers). In these situations developers need
		  appropriate infrastructure to remotely develop and debug
		  applications. Yet remote debugging solutions can prove
		  awkward to use due to their distributed nature. Empirical
		  studies show us that on average 10.5 minutes per coding
		  hour (over five 40-hour work weeks per year) are spend for
		  re-deploying applications while fixing bugs or improving
		  functionality [ZeroTurnAround 2011]. Moreover current
		  solutions lack facilities that would otherwise be available
		  in a local setting because its difficult to reproduce them
		  remotely (e.g., object-centric debugging [Ressia 2012b]).
		  This fact can impact the amount of experimentation during a
		  remote debugging session - compared to a local setting. In
		  this dissertation in order to overcome these issues we
		  first identify four desirable properties that an ideal
		  solution for remote debugging should exhibit, namely:
		  interactiveness, instrumentation, distribution and
		  security. Interactiveness is the ability of a remote
		  debugging solution to incrementally update all parts of a
		  remote application without losing the running context
		  (i.e., without stopping the application). Instrumentation
		  is the ability of a debugging solution to alter the
		  semantics of a running process in order to assist
		  debugging. Distribution is the ability of a debugging
		  solution to adapt its framework while debugging a remote
		  target. Finally security refers to the availability of
		  prerequisites for authentication and access restriction.
		  Given these properties we propose Mercury, a remote
		  debugging model and architecture for reflective OO
		  languages. Mercury supports interactiveness through a
		  mirror-based remote meta-level that is causally connected
		  to its target, instrumentation through reflective
		  intercession by reifying the underlying execution
		  environment, distribution through an adaptable middleware
		  and security by decomposing and authenticating access to
		  reflective facilities. We validate our proposal through a
		  prototype implementation in the Pharo programming language
		  using a diverse experimental setting of multiple constraint
		  devices. We exemplify remote debugging techniques supported
		  by Mercury's properties, such as remote agile debugging and
		  remote object instrumentation and show how these can solve
		  in practice the problems we have identified.},
  langid	= {english},
  school	= {Universit{\'e} des Sciences et Technologie de Lille -
		  Lille I}
}

@Book{		  parker15:javascript,
  title		= {{{JavaScript}} with Promises},
  author	= {Parker, Daniel},
  year		= {2015},
  edition	= {1},
  publisher	= {O'Reilly Media, Inc.},
  abstract	= {Asynchronous JavaScript is everywhere, whether youre using
		  Ajax, AngularJS, Node.js, or WebRTC. This practical guide
		  shows intermediate to advanced JavaScript developers how
		  Promises can help you manage asynchronous code
		  effectivelyincluding the inevitable flood of callbacks as
		  your codebase grows. Youll learn the inner workings of
		  Promises and ways to avoid difficulties and missteps when
		  using them.The ability to asynchronously fetch data and
		  load scripts in the browser broadens the capabilities of
		  JavaScript applications. But if you dont understand how the
		  async part works, youll wind up with unpredictable code
		  thats difficult to maintain. This book is ideal whether
		  youre new to Promises or want to expand your knowledge of
		  this technology.Understand how async JavaScript works by
		  delving into callbacks, the event loop, and threadingLearn
		  how Promises organize callbacks into discrete steps that
		  are easier to read and maintainExamine scenarios youll
		  encounter and techniques you can use when writing
		  real-world applicationsUse features in the Bluebird library
		  and jQuery to work with PromisesLearn how the Promise API
		  handles asynchronous errorsExplore ECMAScript 6 language
		  features that simplify Promise-related code},
  isbn		= {1-4493-7321-6}
}

@Article{	  parreaux20:simple,
  title		= {The Simple Essence of Algebraic Subtyping: Principal Type
		  Inference with Subtyping Made Easy (Functional Pearl)},
  shorttitle	= {The Simple Essence of Algebraic Subtyping},
  author	= {Parreaux, Lionel},
  year		= {2020},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {ICFP},
  pages		= {124:1--124:28},
  doi		= {10.1145/3409006},
  urldate	= {2023-11-27},
  abstract	= {MLsub extends traditional Hindley-Milner type inference
		  with subtyping while preserving compact principal types, an
		  exciting new development. However, its specification in
		  terms of biunification is difficult to understand, relying
		  on the new concepts of bisubstitution and polar types, and
		  making use of advanced notions from abstract algebra. In
		  this paper, we show that these are in fact not essential to
		  understanding the mechanisms at play in MLsub. We propose
		  an alternative algorithm called Simple-sub, which can be
		  implemented efficiently in under 500 lines of code
		  (including parsing, simplification, and pretty-printing),
		  looks more familiar, and is easier to understand. We
		  present an experimental evaluation of Simple-sub against
		  MLsub on a million randomly-generated well-scoped
		  expressions, showing that the two systems agree. The
		  mutable automaton-based implementation of MLsub is quite
		  far from its algebraic specification, leaving a lot of
		  space for errors; in fact, our evaluation uncovered several
		  bugs in it. We sketch more straightforward soundness and
		  completeness arguments for Simple-sub, based on a syntactic
		  specification of the type system. This paper is meant to be
		  light in formalism, rich in insights, and easy to consume
		  for prospective designers of new type systems and
		  programming languages. In particular, no abstract algebra
		  is inflicted on readers.},
  keywords	= {principal types,subtyping,type inference}
}

@Article{	  parry21:survey,
  title		= {A {{Survey}} of {{Flaky Tests}}},
  author	= {Parry, Owain and Kapfhammer, Gregory M. and Hilton,
		  Michael and McMinn, Phil},
  year		= {2021},
  month		= oct,
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  volume	= {31},
  number	= {1},
  pages		= {17:1--17:74},
  issn		= {1049-331X},
  doi		= {10.1145/3476105},
  urldate	= {2025-05-04},
  abstract	= {Tests that fail inconsistently, without changes to the
		  code under test, are described as flaky. Flaky tests do not
		  give a clear indication of the presence of software bugs
		  and thus limit the reliability of the test suites that
		  contain them. A recent survey of software developers found
		  that 59\% claimed to deal with flaky tests on a monthly,
		  weekly, or daily basis. As well as being detrimental to
		  developers, flaky tests have also been shown to limit the
		  applicability of useful techniques in software testing
		  research. In general, one can think of flaky tests as being
		  a threat to the validity of any methodology that assumes
		  the outcome of a test only depends on the source code it
		  covers. In this article, we systematically survey the body
		  of literature relevant to flaky test research, amounting to
		  76 papers. We split our analysis into four parts:
		  addressing the causes of flaky tests, their costs and
		  consequences, detection strategies, and approaches for
		  their mitigation and repair. Our findings and their
		  implications have consequences for how the software-testing
		  community deals with test flakiness, pertinent to
		  practitioners and of interest to those wanting to
		  familiarize themselves with the research area.}
}

@InProceedings{	  pasquier22:practical,
  title		= {Practical Multiverse Debugging through User-Defined
		  Reductions: Application to {{UML}} Models},
  shorttitle	= {Practical Multiverse Debugging through User-Defined
		  Reductions},
  booktitle	= {Proceedings of the 25th {{International Conference}} on
		  {{Model Driven Engineering Languages}} and {{Systems}}},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Roux, Luka Le and
		  Lagadec, Lo{\"i}c},
  year		= {2022},
  month		= oct,
  series	= {{{MODELS}} '22},
  pages		= {87--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3550355.3552447},
  urldate	= {2023-09-25},
  abstract	= {Multiverse debugging is an extension of classical
		  debugging methods, particularly adapted to
		  non-deterministic systems. Recently, a language-independent
		  formalization was proposed. Moreover, multiverse debugging
		  is particularly beneficial for specification and design
		  languages, such as UML. However, this method suffers from
		  scalability issues during breakpoint lookup. This problem
		  arises due to the exhaustive exploration performed on the
		  potentially infinite state-space of the system. In this
		  paper, we tackle this problem by introducing Reduced
		  Multiverse Debugging, an extension proposing a way for the
		  user to define reduction policies used during breakpoint
		  lookup. We enrich the formalization of multiverse debugging
		  with a modular breakpoint lookup strategy, which allows the
		  integration of the reduction policy. We validate our
		  approach by implementing a practical UML Statechart
		  debugger in the AnimUML web framework. We show several ways
		  the reduction can be applied, using methods such as
		  predicate abstraction for breakpoint lookup on an infinite
		  state-space, removing irrelevant variables, or creating
		  classes of equivalent values. Moreover, we show the
		  possibility to integrate probabilistic reduction
		  strategies. Relying on hash collisions, these strategies
		  can be iteratively refined to increase precision.},
  isbn		= {978-1-4503-9466-6},
  keywords	= {abstraction,concurrency,model analysis,multiverse
		  debugging}
}

@InProceedings{	  pasquier22:practicala,
  title		= {Practical Multiverse Debugging through User-Defined
		  Reductions: Application to {{UML}} Models},
  shorttitle	= {Practical Multiverse Debugging through User-Defined
		  Reductions},
  booktitle	= {Proceedings of the 25th {{International Conference}} on
		  {{Model Driven Engineering Languages}} and {{Systems}}},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Roux, Luka Le and
		  Lagadec, Lo{\"i}c},
  year		= {2022},
  month		= oct,
  series	= {{{MODELS}} '22},
  pages		= {87--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3550355.3552447},
  urldate	= {2024-05-13},
  abstract	= {Multiverse debugging is an extension of classical
		  debugging methods, particularly adapted to
		  non-deterministic systems. Recently, a language-independent
		  formalization was proposed. Moreover, multiverse debugging
		  is particularly beneficial for specification and design
		  languages, such as UML. However, this method suffers from
		  scalability issues during breakpoint lookup. This problem
		  arises due to the exhaustive exploration performed on the
		  potentially infinite state-space of the system. In this
		  paper, we tackle this problem by introducing Reduced
		  Multiverse Debugging, an extension proposing a way for the
		  user to define reduction policies used during breakpoint
		  lookup. We enrich the formalization of multiverse debugging
		  with a modular breakpoint lookup strategy, which allows the
		  integration of the reduction policy. We validate our
		  approach by implementing a practical UML Statechart
		  debugger in the AnimUML web framework. We show several ways
		  the reduction can be applied, using methods such as
		  predicate abstraction for breakpoint lookup on an infinite
		  state-space, removing irrelevant variables, or creating
		  classes of equivalent values. Moreover, we show the
		  possibility to integrate probabilistic reduction
		  strategies. Relying on hash collisions, these strategies
		  can be iteratively refined to increase precision.},
  isbn		= {978-1-4503-9466-6},
  keywords	= {abstraction,concurrency,model analysis,multiverse
		  debugging}
}

@InProceedings{	  pasquier23:debugging,
  title		= {Debugging {{Paxos}} in the {{UML Multiverse}}},
  booktitle	= {2023 {{ACM}}/{{IEEE International Conference}} on {{Model
		  Driven Engineering Languages}} and {{Systems Companion}}
		  ({{MODELS-C}})},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Lagadec, Lo{\"i}c},
  year		= {2023},
  month		= oct,
  pages		= {811--820},
  doi		= {10.1109/MODELS-C59198.2023.00130},
  urldate	= {2024-08-29},
  abstract	= {In this paper, we present experience feedback on the use
		  of animation and debugging tools to build, improve, and
		  verify a UML model of the Paxos consensus algorithm. The
		  need for consensus appears in our IoT industrial context,
		  where we need to switch between several service providers
		  for message passing, depending on their availability and
		  quality of service. However, Paxos is notoriously difficult
		  to understand, and as we plan to expand on the original
		  idea to adapt it to our needs, we have to make sure that
		  the base model is correct as well as fully understood by
		  the developers. To this end, we developed an AnimUML model
		  of Paxos, making it interactive and thus easier to work
		  with. During its construction, we tried to understand how
		  to verify that our requirements are met. By replicating
		  existing scenarios step by step, we found that our model
		  was incomplete. To validate how further model modifications
		  changed this, we wanted to write breakpoints to reach these
		  specific situations, but we found that configuration-based
		  breakpoints were not sufficient in this regard. This led us
		  to leverage the possibilities offered by a temporal
		  multiverse debugger, allowing the creation of temporal
		  breakpoints breaking on scenarios described by different
		  languages of temporal logic. With these tools, we can not
		  only correct the model faster, but also prove that some
		  scenarios are possible or not, allowing for a first step in
		  the model formal verification while keeping it accessible
		  to non-experts of the domain.},
  keywords	= {Adaptation models,consensus,Consensus
		  algorithm,debugging,Debugging,Message passing,model
		  analysis,Quality of service,Switches,temporal logic,Unified
		  modeling language}
}

@InProceedings{	  pasquier23:temporal,
  title		= {Temporal {{Breakpoints}} for {{Multiverse Debugging}}},
  booktitle	= {Proceedings of the 16th {{ACM SIGPLAN International
		  Conference}} on {{Software Language Engineering}}},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Le Roux, Luka and
		  Lagadec, Lo{\"i}c},
  year		= {2023},
  month		= oct,
  series	= {{{SLE}} 2023},
  pages		= {125--137},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3623476.3623526},
  urldate	= {2023-10-24},
  abstract	= {Multiverse debugging extends classical and omniscient
		  debugging to allow the exhaustive exploration of
		  non-deterministic and concurrent systems during debug
		  sessions. The introduction of user-defined reductions
		  significantly improves the scalability of the approach.
		  However, the literature fails to recognize the importance
		  of using more expressive logics, besides local-state
		  predicates, to express breakpoints. In this article, we
		  address this problem by introducing temporal breakpoints
		  for multiverse debugging. Temporal breakpoints greatly
		  enhance the expressivity of conditional breakpoints,
		  allowing users to reason about the past and future of
		  computations in the multiverse. Moreover, we show that it
		  is relatively straightforward to extend a language-agnostic
		  multiverse debugger semantics with temporal breakpoints,
		  while preserving its generality. To show the elegance and
		  practicability of our approach, we have implemented a
		  multiverse debugger for the AnimUML modeling environment
		  that supports 3 different temporal breakpoint formalisms:
		  regular-expressions, statecharts, and statechart-based
		  B{\"u}chi automata.},
  isbn		= {9798400703966},
  keywords	= {breakpoint,concurrency,multiverse debugging,temporal
		  logic}
}

@Misc{		  pdf,
  title		= {[{{PDF}}] {{Exploring IOT Application Using Raspberry Pi}}
		  {\textbar} {{Semantic Scholar}}},
  urldate	= {2023-10-18},
  howpublished	= {https://www.semanticscholar.org/paper/Exploring-IOT-Application-Using-Raspberry-Pi-Zhao-Jegatheesan/ac8b8cf9dd6dcacd4963da40200abcc56ce8ba49}
}

@Article{	  peano91:sul,
  title		= {Sul Concetto Di Numero},
  author	= {Peano, Giuseppe},
  year		= {1891},
  journal	= {Rivista Matematica},
  volume	= {1},
  pages		= {256--267}
}

@InProceedings{	  pedroza11:formal-methodology-applied,
  title		= {A {{Formal Methodology Applied}} to {{Secure Over-the-Air
		  Automotive Applications}}},
  booktitle	= {2011 {{IEEE Vehicular Technology Conference}} ({{VTC
		  Fall}})},
  author	= {Pedroza, Gabriel and Idrees, Muhammad Sabir and Apvrille,
		  Ludovic and Roudier, Yves},
  year		= {2011},
  month		= sep,
  pages		= {1--5},
  issn		= {1090-3038},
  doi		= {10.1109/VETECF.2011.6093061},
  urldate	= {2023-10-25},
  abstract	= {The expected high complexity in future automotive
		  applications will require to frequently update electronic
		  devices supporting those applications. Even if in-car
		  devices are trusted, potential attacks on over the air
		  exchanges impose stringent requirements on both safety and
		  security. To address the formal verification of safety
		  properties, we have previously introduced the AVATAR UML
		  profile whose methodology covers requirement, analysis,
		  design, and formal verification stages [1]. We now propose
		  to extend AVATAR to support both safety and security during
		  all methodological stages, and in the same models. The
		  paper applies the extended AVATAR to an over the-air
		  protocol for trusted firmware updates of in-car control
		  units, with a special focus on design and formal
		  verification stages.}
}

@InProceedings{	  perera16:causally,
  title		= {Causally {{Consistent Dynamic Slicing}}},
  booktitle	= {27th {{International Conference}} on {{Concurrency
		  Theory}} ({{CONCUR}} 2016)},
  author	= {Perera, Roly and Garg, Deepak and Cheney, James},
  editor	= {Desharnais, Jos{\'e}e and Jagadeesan, Radha},
  year		= {2016},
  series	= {Leibniz {{International Proceedings}} in {{Informatics}}
		  ({{LIPIcs}})},
  volume	= {59},
  pages		= {18:1--18:15},
  publisher	= {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address	= {Dagstuhl, Germany},
  issn		= {1868-8969},
  doi		= {10.4230/LIPIcs.CONCUR.2016.18},
  urldate	= {2023-10-24},
  isbn		= {978-3-95977-017-0},
  keywords	= {pi-calculus; dynamic slicing; causal equivalence; Galois
		  connection}
}

@Article{	  perera22:linked,
  title		= {Linked Visualisations via {{Galois}} Dependencies},
  author	= {Perera, Roly and Nguyen, Minh and Petricek, Tomas and
		  Wang, Meng},
  year		= {2022},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {POPL},
  pages		= {7:1--7:29},
  doi		= {10.1145/3498668},
  urldate	= {2023-09-26},
  abstract	= {We present new language-based dynamic analysis techniques
		  for linking visualisations and other structured outputs to
		  data in a fine-grained way, allowing users to explore how
		  data attributes and visual or other output elements are
		  related by selecting (focusing on) substructures of
		  interest. Our approach builds on bidirectional program
		  slicing techiques based on Galois connections, which
		  provide desirable round-tripping properties. Unlike the
		  prior work, our approach allows selections to be negated,
		  equipping the bidirectional analysis with a De Morgan dual
		  which can be used to link different outputs generated from
		  the same input. This offers a principled language-based
		  foundation for a popular view coordination feature called
		  brushing and linking where selections in one chart
		  automatically select corresponding elements in another
		  related chart.},
  keywords	= {data provenance,Galois connections}
}

@Misc{		  peress24:test,
  title		= {Test {{Framework}} --- {{Zephyr Project Documentation}}},
  author	= {Peress, Yuval and Nashif, Anas and Brunnen, Manoel and
		  Andersen, Henrik Brix and Emeltchenko, Andrei and Massey,
		  Aaron E. and Bolivar, Marti and Olivares, Ivan Herrera},
  year		= {2024},
  urldate	= {2024-02-13}
}

@Article{	  perez07:ipython,
  title		= {{{IPython}}: {{A System}} for {{Interactive Scientific
		  Computing}}},
  shorttitle	= {{{IPython}}},
  author	= {Perez, Fernando and Granger, Brian E.},
  year		= {2007},
  month		= may,
  journal	= {Computing in Science \& Engineering},
  volume	= {9},
  number	= {3},
  pages		= {21--29},
  issn		= {1558-366X},
  doi		= {10.1109/MCSE.2007.53},
  urldate	= {2024-11-12},
  abstract	= {Python offers basic facilities for interactive work and a
		  comprehensive library on top of which more sophisticated
		  systems can be built. The IPython project provides on
		  enhanced interactive environment that includes, among other
		  features, support for data visualization and facilities for
		  distributed and parallel computation},
  keywords	= {computer languages,Data analysis,Data
		  visualization,Hardware,Libraries,Parallel
		  processing,Production,Python,scientific
		  computing,Scientific computing,scientific
		  programming,Spine,Supercomputers,Testing}
}

@InProceedings{	  perrin16:causal,
  title		= {Causal Consistency: Beyond Memory},
  shorttitle	= {Causal Consistency},
  booktitle	= {Proceedings of the 21st {{ACM SIGPLAN Symposium}} on
		  {{Principles}} and {{Practice}} of {{Parallel
		  Programming}}},
  author	= {Perrin, Matthieu and Mostefaoui, Achour and Jard, Claude},
  year		= {2016},
  month		= feb,
  series	= {{{PPoPP}} '16},
  pages		= {1--12},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2851141.2851170},
  urldate	= {2025-03-04},
  abstract	= {In distributed systems where strong consistency is costly
		  when not impossible, causal consistency provides a valuable
		  abstraction to represent program executions as partial
		  orders. In addition to the sequential program order of each
		  computing entity, causal order also contains the semantic
		  links between the events that affect the shared objects --
		  messages emission and reception in a communication channel,
		  reads and writes on a shared register. Usual approaches
		  based on semantic links are very difficult to adapt to
		  other data types such as queues or counters because they
		  require a specific analysis of causal dependencies for each
		  data type. This paper presents a new approach to define
		  causal consistency for any abstract data type based on
		  sequential specifications. It explores, formalizes and
		  studies the differences between three variations of causal
		  consistency and highlights them in the light of PRAM,
		  eventual consistency and sequential consistency: weak
		  causal consistency, that captures the notion of causality
		  preservation when focusing on convergence; causal
		  convergence that mixes weak causal consistency and
		  convergence; and causal consistency, that coincides with
		  causal memory when applied to shared memory.},
  isbn		= {978-1-4503-4092-2}
}

@Article{	  perscheid17:studying,
  title		= {Studying the Advancement in Debugging Practice of
		  Professional Software Developers},
  author	= {Perscheid, Michael and Siegmund, Benjamin and Taeumel,
		  Marcel and Hirschfeld, Robert},
  year		= {2017},
  month		= mar,
  journal	= {Software Quality Journal},
  volume	= {25},
  number	= {1},
  pages		= {83--110},
  issn		= {1573-1367},
  doi		= {10.1007/s11219-015-9294-2},
  urldate	= {2025-01-13},
  abstract	= {In 1997, Henry Lieberman stated that debugging is the
		  dirty little secret of computer science. Since then,
		  several promising debugging technologies have been
		  developed such as back-in-time debuggers and automatic
		  fault localization methods. However, the last study about
		  the state-of-the-art in debugging is still more than
		  15~years old and so it is not clear whether these new
		  approaches have been applied in practice or not.For that
		  reason, we investigate the current state of debuggingin a
		  comprehensive study. First, we review the available
		  literature and learn about current approaches and study
		  results. Second, we observe several professional developers
		  while debugging and interview them about their experiences.
		  Third, we create a questionnaire that serves as the basis
		  for a larger online debugging survey. Based on these
		  results, we present new insights into debugging practice
		  that help to suggest new directions for future research.},
  langid	= {english},
  keywords	= {Debugging,Field study,Literature review,Online survey}
}

@Book{		  perumalla13:introduction,
  title		= {Introduction to {{Reversible Computing}}},
  author	= {Perumalla, Kalyan S.},
  year		= {2013},
  month		= sep,
  edition	= {1st},
  publisher	= {Chapman \& Hall},
  urldate	= {2024-09-11},
  abstract	= {Few books comprehensively cover the software and
		  programming aspects of reversible computing. Filling this
		  gap, Introduction to Reversible Computing offers an
		  expanded view of the field that includes the traditional
		  energy-motivated hardware viewpoint as well as the emerging
		  application-motivated software approach. Collecting
		  scattered knowledge into one coherent account, the book
		  provides a compendium of both classical and recently
		  developed results on reversible computing. It explores
		  up-and},
  isbn		= {978-1-4398-7340-3},
  langid	= {english}
}

@InProceedings{	  philips14:towards,
  title		= {Towards {{Tierless Web Development}} without {{Tierless
		  Languages}}},
  booktitle	= {Proceedings of the 2014 {{ACM International Symposium}} on
		  {{New Ideas}}, {{New Paradigms}}, and {{Reflections}} on
		  {{Programming}} \& {{Software}}},
  author	= {Philips, Laure and De Roover, Coen and Van Cutsem, Tom and
		  De Meuter, Wolfgang},
  year		= {2014},
  month		= oct,
  series	= {Onward! 2014},
  pages		= {69--81},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2661136.2661146},
  urldate	= {2023-11-07},
  abstract	= {Tierless programming languages enable developing the
		  typical server, client and database tiers of a web
		  application as a single mono-linguistic program. This
		  development style is in stark contrast to the current
		  practice which requires combining multiple technologies and
		  programming languages. A myriad of tierless programming
		  languages has already been proposed, often featuring a
		  JavaScript-like syntax. Instead of introducing yet another,
		  we advocate that it should be possible to develop tierless
		  web applications in existing general-purpose languages.
		  This not only reduces the complexity that developers are
		  exposed to, but also precludes the need for new development
		  tools. We concretize this novel approach to tierless
		  programming by discussing requirements on its future
		  instantiations. We explore the design space of the program
		  analysis for determining and the program transformation for
		  realizing the tier split respectively. The former
		  corresponds to new adaptations of an old familiar, program
		  slicing, for tier splitting. The latter includes several
		  strategies for handling cross-tier function calls and data
		  accesses. Using a prototype instantiation for JavaScript,
		  we demonstrate the feasibility of our approach on an
		  example web application. We conclude with a discussion of
		  open questions and challenges for future research.},
  isbn		= {978-1-4503-3210-1},
  keywords	= {javascript,program slicing,tier splitting,tierless
		  programming}
}

@Article{	  phipps-costin23:continuing,
  title		= {Continuing {{WebAssembly}} with {{Effect Handlers}}},
  author	= {{Phipps-Costin}, Luna and Rossberg, Andreas and Guha,
		  Arjun and Leijen, Daan and Hillerstr{\"o}m, Daniel and
		  Sivaramakrishnan, {\relax KC} and Pretnar, Matija and
		  Lindley, Sam},
  year		= {2023},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {OOPSLA2},
  pages		= {238:460--238:485},
  doi		= {10.1145/3622814},
  urldate	= {2023-12-06},
  abstract	= {WebAssembly (Wasm) is a low-level portable code format
		  offering near native performance. It is intended as a
		  compilation target for a wide variety of source languages.
		  However, Wasm provides no direct support for non-local
		  control flow features such as async/await,
		  generators/iterators, lightweight threads, first-class
		  continuations, etc. This means that compilers for source
		  languages with such features must ceremoniously transform
		  whole source programs in order to target Wasm. We present
		  WasmFX an extension to Wasm which provides a universal
		  target for non-local control features via effect handlers,
		  enabling compilers to translate such features directly into
		  Wasm. Our extension is minimal and only adds three main
		  instructions for creating, suspending, and resuming
		  continuations. Moreover, our primitive instructions are
		  type-safe providing typed continuations which are
		  well-aligned with the design principles of Wasm whose
		  stacks are typed. We present a formal specification of
		  WasmFX and show that the extension is sound. We have
		  implemented WasmFX as an extension to the Wasm reference
		  interpreter and also built a prototype WasmFX extension for
		  Wasmtime, a production-grade Wasm engine, piggybacking on
		  Wasmtime's existing fibers API. The preliminary performance
		  results for our prototype are encouraging, and we outline
		  future plans to realise a native implementation.},
  keywords	= {effect handlers,stack switching,WebAssembly}
}

@Book{		  pierce02:types,
  title		= {Types and Programming Languages},
  author	= {Pierce, Benjamin C.},
  year		= {2002},
  edition	= {1},
  publisher	= {The MIT Press},
  abstract	= {A type system is a syntactic method for automatically
		  checking the absence of certain erroneous behaviors by
		  classifying program phrases according to the kinds of
		  values they compute. The study of type systems -- and of
		  programming languages from a type-theoretic perspective --
		  has important applications in software engineering,
		  language design, high-performance compilers, and
		  security.This text provides a comprehensive introduction
		  both to type systems in computer science and to the basic
		  theory of programming languages. The approach is pragmatic
		  and operational; each new concept is motivated by
		  programming examples and the more theoretical sections are
		  driven by the needs of implementations. Each chapter is
		  accompanied by numerous exercises and solutions, as well as
		  a running implementation, available via the Web.
		  Dependencies between chapters are explicitly identified,
		  allowing readers to choose a variety of paths through the
		  material.The core topics include the untyped
		  lambda-calculus, simple type systems, type reconstruction,
		  universal and existential polymorphism, subtyping, bounded
		  quantification, recursive types, kinds, and type operators.
		  Extended case studies develop a variety of approaches to
		  modeling the features of object-oriented languages.},
  isbn		= {0-262-16209-1}
}

@InProceedings{	  plasmeijer12:task-oriented,
  title		= {Task-Oriented Programming in a Pure Functional Language},
  booktitle	= {Proceedings of the 14th Symposium on {{Principles}} and
		  Practice of Declarative Programming},
  author	= {Plasmeijer, Rinus and Lijnse, Bas and Michels, Steffen and
		  Achten, Peter and Koopman, Pieter},
  year		= {2012},
  month		= sep,
  series	= {{{PPDP}} '12},
  pages		= {195--206},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2370776.2370801},
  urldate	= {2023-10-18},
  abstract	= {Task-Oriented Programming (TOP) is a novel programming
		  paradigm for the construction of distributed systems where
		  users work together on the internet. When multiple users
		  collaborate, they need to interact with each other
		  frequently. TOP supports the definition of tasks that react
		  to the progress made by others. With TOP, complex
		  multi-user interactions can be programmed in a declarative
		  style just by defining the tasks that have to be
		  accomplished, thus eliminating the need to worry about the
		  implementation detail that commonly frustrates the
		  development of applications for this domain. TOP builds on
		  four core concepts: tasks that represent computations or
		  work to do which have an observable value that may change
		  over time, data sharing enabling tasks to observe each
		  other while the work is in progress, generic type driven
		  generation of user interaction, and special combinators for
		  sequential and parallel task composition. The semantics of
		  these core concepts is defined in this paper. As an example
		  we present the iTask3 framework, which embeds TOP in the
		  functional programming language Clean.},
  isbn		= {978-1-4503-1522-7},
  keywords	= {clean,task-oriented programming}
}

@Misc{		  platformio23:unit,
  title		= {Unit Testing},
  author	= {{PlatformIO}},
  year		= {2023},
  urldate	= {2023-02-08},
  lastaccessed	= {February 8, 2023}
}

@Misc{		  platformio23:unity,
  title		= {Unity},
  author	= {{PlatformIO}},
  year		= {2023},
  urldate	= {2023-02-15},
  lastaccessed	= {February 15, 2023}
}

@InProceedings{	  plotkin09:handlers,
  title		= {Handlers of {{Algebraic Effects}}},
  booktitle	= {Programming {{Languages}} and {{Systems}}},
  author	= {Plotkin, Gordon and Pretnar, Matija},
  editor	= {Castagna, Giuseppe},
  year		= {2009},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {80--94},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-00590-9_7},
  abstract	= {We present an algebraic treatment of exception handlers
		  and, more generally, introduce handlers for other
		  computational effects representable by an algebraic theory.
		  These include nondeterminism, interactive input/output,
		  concurrency, state, time, and their combinations; in all
		  cases the computation monad is the free-model monad of the
		  theory. Each such handler corresponds to a model of the
		  theory for the effects at hand. The handling construct,
		  which applies a handler to a computation, is based on the
		  one introduced by Benton and Kennedy, and is interpreted
		  using the homomorphism induced by the universal property of
		  the free model. This general construct can be used to
		  describe previously unrelated concepts from both theory and
		  practice.},
  isbn		= {978-3-642-00590-9},
  langid	= {english},
  keywords	= {Algebraic Theory,Base Signature,Base Type,Function
		  Symbol,Relation Symbol}
}

@InProceedings{	  popereshnyak18:iot,
  title		= {{{IoT}} Application Testing Features Based on the
		  Modelling Network},
  booktitle	= {International {{Conference}} on {{Perspective
		  Technologies}} and {{Methods}} in {{MEMS Design}}},
  author	= {Popereshnyak, S. and Suprun, O. and Suprun, O. and
		  Wieckowski, T.},
  year		= {2018},
  pages		= {127--131},
  doi		= {10.1109/MEMSTECH.2018.8365717},
  abstract	= {In the article the features of testing devices and IoT
		  applications are investigated. To make the problem clearer,
		  the basic aspects of IoT applications architecture are
		  considered. A set of requirements to the testing is
		  presented, which must be considered when planning and
		  organizing the testing process for IoT applications. The
		  difficulties that arise during the testing phase of IoT
		  applications and systems are described, same as mane
		  differences from the classic application testing. As an
		  approbation of the proposed test specifications, a
		  full-scale experiment was conducted to test a fragment of
		  the communication network in order to select an application
		  protocol for a typical IoT, according to the results the
		  conclusions are made. {\copyright} 2018 IEEE.},
  keywords	= {Internet of Things,Medical applications,Model
		  Network,Testing}
}

@Article{	  pothier07:scalable,
  title		= {Scalable Omniscient Debugging},
  author	= {Pothier, Guillaume and Tanter, {\'E}ric and Piquer,
		  Jos{\'e}},
  year		= {2007},
  month		= oct,
  journal	= {SIGPLAN Not.},
  volume	= {42},
  number	= {10},
  pages		= {535--552},
  issn		= {0362-1340},
  doi		= {10.1145/1297105.1297067},
  urldate	= {2024-11-12},
  abstract	= {Omniscient debuggers make it possible to navigate
		  backwards in time within a program execution trace,
		  drastically improving the task of debugging complex
		  applications. Still, they are mostly ignored in practice
		  due to the challenges raised by the potentially huge size
		  of the execution traces. This paper shows that omniscient
		  debugging can be realistically realized through the use of
		  different techniques addressing efficiency, scalability and
		  usability. We present TOD, a portable Trace-Oriented
		  Debugger for Java, which combines an efficient
		  instrumentation for event generation, a specialized
		  distributed database for scalable storage and efficient
		  querying, support for partial traces in order to reduce the
		  trace volume to relevant events, and innovative interface
		  components for interactive trace navigation and analysis in
		  the development environment. Provided a reasonable
		  infrastructure, the performance of TOD allows a responsive
		  debugging experience in the face of large programs.}
}

@Article{	  pothier09:back,
  title		= {Back to the {{Future}}: {{Omniscient Debugging}}},
  shorttitle	= {Back to the {{Future}}},
  author	= {Pothier, Guillaume and Tanter, {\'E}ric},
  year		= {2009},
  month		= nov,
  journal	= {IEEE Software},
  volume	= {26},
  number	= {6},
  pages		= {78--85},
  issn		= {1937-4194},
  doi		= {10.1109/MS.2009.169},
  urldate	= {2023-12-13},
  abstract	= {This article presents TOD (trace oriented debugger), a
		  prototype scalable omniscient debugger for Java, which aims
		  at making omniscient debugging practical, at last.
		  Omniscient debuggers, also known as back-in-time or
		  reversible debuggers, record the whole history, or
		  execution trace, of a debugged program and let the user
		  freely explore it. This approach combines the advantages of
		  both log-based (past activity is never lost) and breakpoint
		  based debugging (interactive navigation, step-by-step
		  execution, and complete stack inspection). Omniscient
		  debuggers simulate step-by-step execution both forward and
		  backward, avoiding having to rerun the whole program many
		  times to pinpoint the bug's root cause. More importantly,
		  they make it possible to navigate through the history of a
		  program by following causal links, so questions that would
		  otherwise require a significant effort can be answered
		  instantly for instance, "When was variable x assigned a
		  null value?" or "What was the state of object o when it was
		  passed as an argument to method foo?".}
}

@InProceedings{	  potsch17:advanced,
  title		= {Advanced Remote Debugging of {{LoRa-enabled IoT}} Sensor
		  Nodes},
  booktitle	= {Proceedings of the {{Seventh International Conference}} on
		  the {{Internet}} of {{Things}}},
  author	= {P{\"o}tsch, Albert and Haslhofer, Florian and Springer,
		  Andreas},
  year		= {2017},
  month		= oct,
  series	= {{{IoT}} '17},
  pages		= {1--2},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3131542.3140259},
  urldate	= {2024-11-10},
  abstract	= {This work demonstrates a complete setup of a distributed
		  LoRaWAN-based data-acquisition system where individual LoRa
		  end-devices can be supervised by a remote debugging
		  environment. We present the whole chain of data processing
		  from an embedded Indoor Air Quality (IAQ) monitoring sensor
		  in the field up to the data-storage and visualization for
		  human end-users connected over the cloud. In particular, we
		  focus on the development-process of the low-power sensor
		  node itself, which plays a key role in every IoT scenario.
		  The sensor node's hardware is realized with a low-cost
		  resource-constrained microcontroller unit (MCU) which
		  executes the sensor-application as well as the embedded
		  LoRaWAN stack. We demonstrate the possibility of remote
		  incircuit-debugging of the embedded wireless node's
		  firmware during operation in the field. Together with the
		  possibility to analyze the power consumption and the
		  radio-frequency spectrum of the wireless node as well as
		  undesired RF interferer the ability to remotely update and
		  debug the MCU's firmware allows to optimize the sensor node
		  for the specific usage scenario and the place of its final
		  operation.},
  isbn		= {978-1-4503-5318-2}
}

@Article{	  pretnar15:introduction,
  title		= {An {{Introduction}} to {{Algebraic Effects}} and
		  {{Handlers}}. {{Invited}} Tutorial Paper},
  author	= {Pretnar, Matija},
  year		= {2015},
  month		= dec,
  journal	= {Electronic Notes in Theoretical Computer Science},
  series	= {The 31st {{Conference}} on the {{Mathematical
		  Foundations}} of {{Programming Semantics}} ({{MFPS
		  XXXI}}).},
  volume	= {319},
  pages		= {19--35},
  issn		= {1571-0661},
  doi		= {10.1016/j.entcs.2015.12.003},
  urldate	= {2023-09-29},
  abstract	= {This paper is a tutorial on algebraic effects and
		  handlers. In it, we explain what algebraic effects are,
		  give ample examples to explain how handlers work, define an
		  operational semantics and a type \& effect system, show how
		  one can reason about effects, and give pointers for further
		  reading.},
  keywords	= {algebraic effects,effect
		  system,handlers,logic,semantics,tutorial}
}

@Article{	  prokopec19:on,
  title		= {On {{Evaluating}} the {{Renaissance Benchmarking Suite}}:
		  {{Variety}}, {{Performance}}, and {{Complexity}}},
  shorttitle	= {On {{Evaluating}} the {{Renaissance Benchmarking Suite}}},
  author	= {Prokopec, Aleksandar and Ros{\`a}, Andrea and
		  Leopoldseder, David and Duboscq, Gilles and T{\r u}ma, P.
		  and Studener, Martin and Bulej, L. and Zheng, Y. and
		  Villaz{\'o}n, A. and Simon, Doug and W{\"u}rthinger, Thomas
		  and Binder, Walter},
  year		= {2019},
  month		= mar,
  journal	= {ArXiv},
  urldate	= {2024-09-10},
  abstract	= {The recently proposed Renaissance suite is composed of
		  modern, real-world, concurrent, and object-oriented
		  workloads that exercise various concurrency primitives of
		  the JVM. Renaissance was used to compare performance of two
		  stateof-the-art, production-quality JIT compilers (HotSpot
		  C2 and Graal), and to show that the performance differences
		  are more significant than on existing suites such as DaCapo
		  and SPECjvm2008. In this technical report, we give an
		  overview of the experimental setup that we used to assess
		  the variety and complexity of the Renaissance suite, as
		  well as its amenability to new compiler optimizations. We
		  then present the obtained measurements in detail.}
}

@InProceedings{	  psarris92:on,
  title		= {On Exact Data Dependence Analysis},
  booktitle	= {Proceedings of the 6th International Conference on
		  {{Supercomputing}}},
  author	= {Psarris, Kleanthis},
  year		= {1992},
  month		= aug,
  series	= {{{ICS}} '92},
  pages		= {303--312},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/143369.143424},
  urldate	= {2024-01-22},
  abstract	= {The GCD test and the Banerjee-Wolfe test are the two tests
		  traditionally used to determine statement data dependence,
		  subject to direction vectors, in automatic vectorization /
		  parallelization of loops. In an earlier study [14] a
		  sufficient condition for the accuracy of the Banerjee-Wolfe
		  test was stated and proved. In the original presentation
		  only the case of general data dependence was considered,
		  i.e., the case of data dependence without direction vector
		  information. In this paper we extend the previous work to
		  the case of data dependence subject to an arbitrary
		  direction vector. We also state and prove a sufficient
		  condition for the accuracy of a combination of the GCD and
		  the Banerjee-Wolfe test. Finally, we demonstrate how these
		  results can be used in actual practice to obtain exact data
		  dependence information.},
  isbn		= {978-0-89791-485-7}
}

@InProceedings{	  racordon20:solving,
  title		= {Solving {{Schedulability}} as a {{Search Space Problem}}
		  with {{Decision Diagrams}}},
  booktitle	= {Search-{{Based Software Engineering}}},
  author	= {Racordon, Dimitri and Coet, Aur{\'e}lien and Stachtiari,
		  Emmanouela and Buchs, Didier},
  editor	= {Aleti, Aldeida and Panichella, Annibale},
  year		= {2020},
  pages		= {73--87},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-59762-7_6},
  abstract	= {Real-time system design involves proving the
		  schedulability of a set of tasks with hard timing and other
		  constraints that should run on one or several cores. When
		  those requirements are known at design time, it is possible
		  to compute a fixed scheduling of tasks before deployment.
		  This approach avoids the overhead induced by an online
		  scheduler and allows the designer to verify the
		  schedulability of the taskset design under normal and
		  degraded conditions, such as core failures. In this
		  context, we propose to solve the schedulability problem as
		  a state space exploration problem. We represent the
		  schedulings as partial functions that map each task to a
		  core and a point in time. Partial functions can be
		  efficiently encoded using a new variant of decision
		  diagrams, called Map-Family Decision Diagrams (MFDDs). Our
		  setting allows first to create the MFDD of all possible
		  schedulings and then apply homomorphic operations directly
		  on it, in order to obtain the schedulings that respect the
		  constraints of the taskset.},
  isbn		= {978-3-030-59762-7},
  langid	= {english},
  keywords	= {Decision diagrams,Multi-core architectures,Real-time
		  systems,Resilient systems,Schedulability,Search problems}
}

@InProceedings{	  ramprasad19:emu-iot-a-virtual-internet,
  title		= {{{EMU-IoT-A Virtual Internet}} of {{Things Lab}}},
  booktitle	= {Proceedings - 2019 {{IEEE International Conference}} on
		  {{Autonomic Computing}}, {{ICAC}} 2019},
  author	= {Ramprasad, B. and Fokaefs, M. and Mukherjee, J. and
		  Litoiu, M.},
  year		= {2019},
  pages		= {73--83},
  doi		= {10.1109/ICAC.2019.00019},
  abstract	= {Internet-of-Things technologies are rapidly emerging as
		  the cornerstone of modern digital life. IoT is the main
		  driver for the increased 'intelligence' in most aspects of
		  everyday life: Smart transportation, smart buildings, smart
		  energy, smart health. Nevertheless, further progress and
		  research are in danger of being slowed down. One important
		  reason is the cost of infrastructure at scale. The
		  difficulties in setting up very large IoT networks do not
		  permit us to stress test the systems and argue about their
		  performance and their durability. To tackle this problem,
		  this work proposes EMU-IoT, a virtual lab for IoT
		  technologies. Using virtualization and container
		  technologies, we demonstrate an experimentation
		  infrastructure to enable researchers and other
		  practitioners to conduct large scale experiments and test
		  several quality aspects of IoT systems with minimal
		  requirements in devices and other equipment. In this paper,
		  we show how easy and simple it is to set up experiments
		  with EMU-IoT and we demonstrate the usefulness of EMU-IoT
		  by conducting experiments in our lab. {\copyright} 2019
		  IEEE.},
  keywords	= {cloud computing,containers,empirical software
		  engineering,IoT,networks,performance}
}

@Article{	  rao23:iris-wasm,
  title		= {Iris-{{Wasm}}: {{Robust}} and {{Modular Verification}} of
		  {{WebAssembly Programs}}},
  shorttitle	= {Iris-{{Wasm}}},
  author	= {Rao, Xiaojia and Georges, A{\"i}na Linn and Legoupil,
		  Maxime and Watt, Conrad and {Pichon-Pharabod}, Jean and
		  Gardner, Philippa and Birkedal, Lars},
  year		= {2023},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {PLDI},
  pages		= {151:1096--151:1120},
  doi		= {10.1145/3591265},
  urldate	= {2023-12-06},
  abstract	= {WebAssembly makes it possible to run C/C++ applications on
		  the web with near-native performance. A WebAssembly program
		  is expressed as a collection of higher-order ML-like
		  modules, which are composed together through a system of
		  explicit imports and exports using a host language,
		  enabling a form of higher- order modular programming. We
		  present Iris-Wasm, a mechanized higher-order separation
		  logic building on a specification of Wasm 1.0 mechanized in
		  Coq and the Iris framework. Using Iris-Wasm, we are able to
		  specify and verify individual modules separately, and then
		  compose them modularly in a simple host language featuring
		  the core operations of the WebAssembly JavaScript
		  Interface. Building on Iris-Wasm, we develop a logical
		  relation that enforces robust safety: unknown, adversarial
		  code can only affect other modules through the functions
		  that they explicitly export. Together, the program logic
		  and the logical relation allow us to formally verify
		  functional correctness of WebAssembly programs, even when
		  they invoke and are invoked by unknown code, thereby
		  demonstrating that WebAssembly enforces strong isolation
		  between modules.},
  keywords	= {formal verification,higher-order logic,separation
		  logic,WebAssembly}
}

@InProceedings{	  rather76:forth,
  title		= {The {{FORTH}} Approach to Operating Systems},
  booktitle	= {Proceedings of the 1976 Annual Conference},
  author	= {Rather, Elizabeth D. and Moore, Charles H.},
  year		= {1976},
  month		= oct,
  series	= {{{ACM}} '76},
  pages		= {233--240},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/800191.805586},
  urldate	= {2025-01-14},
  abstract	= {FORTH is a programming technique designed for interactive,
		  on-line multi-task minicomputer applications. It features
		  an extensible command set which leads naturally to the
		  development of an application oriented vocabulary and
		  operating system. FORTH combines extreme compactness with
		  high speed performance.},
  isbn		= {978-1-4503-7489-7}
}

@Article{	  rauch19:babylonian-style,
  title		= {Babylonian-Style {{Programming}}},
  author	= {Rauch, David and Rein, Patrick and Ramson, Stefan and
		  Lincke, Jens and Hirschfeld, Robert},
  year		= {2019},
  month		= feb,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {3},
  number	= {3},
  pages		= {9:1-9:39},
  publisher	= {AOSA, Inc.},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2019/3/9},
  urldate	= {2024-03-11},
  abstract	= {When working on a program, developers traditionally have
		  to simulate the behavior of the abstract code in their
		  heads until they can execute the application. Live
		  programming aims to support the development and
		  comprehension of programs by providing more immediate
		  feedback on program behavior, bu...},
  langid	= {english}
}

@Article{	  reingold81:tidier,
  title		= {Tidier {{Drawings}} of {{Trees}}},
  author	= {Reingold, E.M. and Tilford, J.S.},
  year		= {1981},
  month		= mar,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {SE-7},
  number	= {2},
  pages		= {223--228},
  issn		= {1939-3520},
  doi		= {10.1109/TSE.1981.234519},
  urldate	= {2024-09-10},
  abstract	= {Various algorithms have been proposed for producing tidy
		  drawings of trees--drawings that are aesthetically pleasing
		  and use minimum drawing space. We show that these
		  algorithms contain some difficulties that lead to
		  aesthetically unpleasing, wider than necessary drawings. We
		  then present a new algorithm with comparable time and
		  storage requirements that produces tidier drawings.
		  Generalizations to forests and m-ary trees are discussed,
		  as are some problems in discretization when alphanumeric
		  output devices are used.},
  keywords	= {Binary trees,Computer science,Data structures,Engineering
		  drawings,Printing,Software algorithms,Tree data
		  structures,tree structures,trees}
}

@Misc{		  remote,
  title		= {Remote {{Debugging}} - {{LLDB}}},
  urldate	= {2025-03-01},
  howpublished	= {https://lldb.llvm.org/use/remote.html}
}

@Misc{		  robot-framework-foundation23:robot,
  title		= {Robot Framework},
  author	= {{Robot Framework Foundation}},
  year		= {2023},
  urldate	= {2023-08},
  lastaccessed	= {August, 2023}
}

@InProceedings{	  rodrigues22:aspect-oriented-webassembly-transformation,
  title		= {Aspect-{{Oriented Webassembly Transformation}}},
  booktitle	= {2022 17th {{Iberian Conference}} on {{Information
		  Systems}} and {{Technologies}} ({{CISTI}})},
  author	= {Rodrigues, Jo{\~a}o and Barreiros, Jorge},
  year		= {2022},
  month		= jun,
  pages		= {1--6},
  issn		= {2166-0727},
  doi		= {10.23919/CISTI54924.2022.9820136},
  urldate	= {2023-11-08},
  abstract	= {There are scenarios where it can be useful or necessary to
		  directly transform and instrument compiled code, rather
		  than resorting to source code changes with subsequent
		  compilation. These transformations can be motivated by
		  several reasons, such as: immediate repair of problems
		  encountered in production, neutralization of potentially
		  malicious code, performance improvements, instrumentation
		  for profiling and inspection purposes, fault injection, or
		  unavailability of source code. While tools are available
		  for conducting this kind of transformations for many
		  different software ecosystems and languages, there is a
		  limited set of options for doing so for WebAssembly
		  applications. In this paper, we present a novel tool and
		  language, the WasmManipulator/WmrLang, for manipulating
		  WebAssembly code, which allows you to perform code
		  transformations, using an aspect-oriented approach for
		  specifying code locations, and code insertion, replacement,
		  or deletion to be executed at those locations. In addition,
		  because WebAssembly routines can be heavily interdependent
		  on the JavaScript code that uses them, the tool has certain
		  features that allow you to take advantage of and exploit
		  this dependency. This includes defining additional types in
		  WASM code, and interpreting/executing expressions at
		  runtime.}
}

@Article{	  rodriguez19:software,
  title		= {Software {{Verification}} and {{Validation Technologies}}
		  and {{Tools}}},
  author	= {Rodriguez, Moises and Piattini, Mario and Ebert,
		  Christof},
  year		= {2019},
  month		= mar,
  journal	= {IEEE Software},
  volume	= {36},
  number	= {2},
  pages		= {13--24},
  issn		= {1937-4194},
  doi		= {10.1109/MS.2018.2883354},
  urldate	= {2025-05-06},
  abstract	= {Software quality matters-more than ever. Software has
		  become the most crucial infrastructure in this century. All
		  businesses is software businesses because they based their
		  operations and services in the Internet of Things, business
		  intelligence (BI), artificial intelligence, cloud
		  computing, social networks, and so forth. Classic IT and
		  embedded systems are converging toward ubiquitous software.
		  Systems will be connected and thus increasingly missing
		  critical. The digital transformation across industries
		  depends on systems performing according to their
		  requirements and needs. This importance of software quality
		  has grown considerably over recent years.},
  keywords	= {ISO Standards,Quality assessment,Software quality,Software
		  testing,Static analysis}
}

@Article{	  rojas21:wood,
  title		= {{{WOOD}}: {{Extending}} a {{WebAssembly VM}} with
		  {{Out-of-Place Debugging}} for {{IoT}} Applications},
  shorttitle	= {{{WOOD}}},
  author	= {Rojas Castillo, Carlos and Marra, Matteo and Bauwens, Jim
		  and Gonzalez Boix, Elisa},
  year		= {2021},
  month		= oct,
  journal	= {WOOD: Extending a WebAssembly VM with Out-of-Place
		  Debugging for IoT applications},
  abstract	= {Internet of Things (IoT) enables collaboration between
		  humans and a diverse range of machines, including embedded
		  devices and sensors. Software development of IoT
		  applications is challenging given the distributed nature of
		  the applications and the limited resources of some devices.
		  This paper focuses on an extension to the WARDuino IoT
		  platform that enhances debugging support, an integral part
		  of the software development cycle.Popular offline debugging
		  techniques such as logs, dumps, or record \& replay are not
		  suitable for IoT devices as they impose too much overhead
		  on devices and often miss contextual information on the
		  root cause of bugs. Online debuggers seem more suitable for
		  IoT since they enable developers to remotely debug devices,
		  but suffer from the probe-effect, non-reproducibility
		  issues and high latency.In this paper, we explore an online
		  debugging approach that deals with the constraints of IoT
		  devices and enables low latency remote debugging. To this
		  end, we bring ideas of out-of-place debugging, in which the
		  state of a running application is moved to the developer's
		  machine, to IoT. We implement our out-of-place debugging
		  approach for IoT in WOOD, an extension to the WARDuino VM
		  that executes Web Assembly on embedded devices. The paper
		  focuses on WOOD's features including capturing, moving and
		  reconstructing debugging sessions, as well as support for
		  accessing remote resources and live code updating.},
  keywords	= {debugger,IoT,VM}
}

@Article{	  rojas22:out-of-things-debugging,
  title		= {Out-of-{{Things Debugging}}: {{A Live Debugging Approach}}
		  for {{Internet}} of {{Things}}},
  shorttitle	= {Out-of-{{Things Debugging}}},
  author	= {Rojas Castillo, Carlos and Marra, Matteo and Bauwens, Jim
		  and Gonzalez Boix, Elisa},
  year		= {2022},
  month		= oct,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {7},
  number	= {2},
  pages		= {5:1-5:33},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2023/7/5},
  urldate	= {2024-01-09},
  abstract	= {Context Internet of Things (IoT) has become an important
		  kind of distributed systems thanks to the wide-spread of
		  cheap embedded devices ...},
  langid	= {english}
}

@InProceedings{	  rondon08:liquid,
  title		= {Liquid Types},
  booktitle	= {Proceedings of the 29th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Rondon, Patrick M. and Kawaguci, Ming and Jhala, Ranjit},
  year		= {2008},
  month		= jun,
  series	= {{{PLDI}} '08},
  pages		= {159--169},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1375581.1375602},
  urldate	= {2023-09-26},
  abstract	= {We present Logically Qualified Data Types, abbreviated to
		  Liquid Types, a system that combines Hindley-Milner type
		  inference with Predicate Abstraction to automatically infer
		  dependent types precise enough to prove a variety of safety
		  properties. Liquid types allow programmers to reap many of
		  the benefits of dependent types, namely static verification
		  of critical properties and the elimination of expensive
		  run-time checks, without the heavy price of manual
		  annotation. We have implemented liquid type inference in
		  DSOLVE, which takes as input an OCAML program and a set of
		  logical qualifiers and infers dependent types for the
		  expressions in the OCAML program. To demonstrate the
		  utility of our approach, we describe experiments using
		  DSOLVE to statically verify the safety of array accesses on
		  a set of OCAML benchmarks that were previously annotated
		  with dependent types as part of the DML project. We show
		  that when used in conjunction with a fixed set of array
		  bounds checking qualifiers, DSOLVE reduces the amount of
		  manual annotation required for proving safety from 31\% of
		  program text to under 1\%.},
  isbn		= {978-1-59593-860-2},
  keywords	= {dependent types,hindley-milner,predicate abstraction,type
		  inference}
}

@Article{	  ronsse99:recplay,
  title		= {{{RecPlay}}: A Fully Integrated Practical Record/Replay
		  System},
  shorttitle	= {{{RecPlay}}},
  author	= {Ronsse, Michiel and De Bosschere, Koen},
  year		= {1999},
  month		= may,
  journal	= {ACM Transactions on Computer Systems},
  volume	= {17},
  number	= {2},
  pages		= {133--152},
  issn		= {0734-2071},
  doi		= {10.1145/312203.312214},
  urldate	= {2023-12-14},
  abstract	= {This article presents a practical solution for the cyclic
		  debugging of nondeterministic parallel programs. The
		  solution consists of a combination of record/replay with
		  automatic on-the-fly data race detection. This combination
		  enables us to limit the record phase to the more efficient
		  recording of the synchronization operations, while
		  deferring the time-consuming data race detection to the
		  replay phase. As the record phase is highly efficient,
		  there is no need to switch it off, hereby eliminating the
		  possibility of Heisenbugs because tracing can be left on
		  all the time. This article describes an implementation of
		  the tools needed to support RecPlay.},
  keywords	= {binary code modification,multithreaded programming,race
		  detection}
}

@Article{	  root24:compilation,
  title		= {Compilation of {{Shape Operators}} on {{Sparse Arrays}}},
  author	= {Root, Alexander J and Yan, Bobby and Liu, Peiming and
		  Gyurgyik, Christophe and Bik, Aart J.C. and Kjolstad,
		  Fredrik},
  year		= {2024},
  month		= oct,
  journal	= {Artifact for OOPSLA 2024 Paper: Compilation of Shape
		  Operators on Sparse Arrays},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {312:1162--312:1188},
  doi		= {10.1145/3689752},
  urldate	= {2024-12-16},
  abstract	= {We show how to build a compiler for a sparse array
		  language that supports shape operators such as reshaping or
		  concatenating arrays, in addition to compute operators.
		  Existing sparse array programming systems implement generic
		  shape operators for only some sparse data structures,
		  reduce shape operators on other data structures to those,
		  and do not support fusion. Our system compiles sparse array
		  expressions to code that efficiently iterates over reshaped
		  views of irregular sparse data structures, without needing
		  to materialize temporary storage for intermediates. Our
		  evaluation shows that our approach generates sparse array
		  code competitive with popular sparse array libraries: our
		  generated shape operators achieve geometric mean speed-ups
		  of 1.66{\texttimes}--15.3{\texttimes} when compared to
		  hand-written kernels in scipy.sparse and
		  1.67{\texttimes}--651{\texttimes} when compared to generic
		  implementations in pydata/sparse. For operators that
		  require data structure conversions in these libraries, our
		  generated code achieves geometric mean speed-ups of
		  7.29{\texttimes}--13.0{\texttimes} when compared to
		  scipy.sparse and 21.3{\texttimes}--511{\texttimes} when
		  compared to pydata/sparse. Finally, our evaluation
		  demonstrates that fusing shape and compute operators
		  improves the performance of several expressions by
		  geometric mean speed-ups of 1.22{\texttimes}--2.23{\texttimes}.}
}

@Book{		  rosenberg96:how,
  title		= {How Debuggers Work: Algorithms, Data Structures, and
		  Architecture},
  shorttitle	= {How Debuggers Work},
  author	= {Rosenberg, Jonathan B.},
  year		= {1996},
  month		= oct,
  publisher	= {John Wiley \& Sons, Inc.},
  address	= {USA},
  isbn		= {978-0-471-14966-8}
}

@Article{	  roska90:limitations,
  title		= {Limitations and Complexity of Digital Hardware Simulators
		  Used for Large-Scale Analogue Circuit and System Dynamics},
  author	= {Roska, Tam{\'a}s},
  year		= {1990},
  journal	= {International Journal of Circuit Theory and Applications},
  volume	= {18},
  number	= {1},
  pages		= {11--21},
  issn		= {1097-007X},
  doi		= {10.1002/cta.4490180104},
  urldate	= {2024-08-31},
  abstract	= {Large-scale electronic circuits and systems are considered
		  with increasing complexity measured in terms of the number
		  of circuit or system elements. the dynamics will be
		  calculated by a digital prototype hardware simulator
		  exploiting parallelism, pipelining and look-up table
		  techniques to realize minimum solution time. Our
		  `canonical' conceptual prototype digital simulator (PDS) is
		  given and its parts are analysed in detail, including a
		  minimal memory realization of a multivariable non-linear
		  mapping (look-up table). It is shown that if the increase
		  of the complexity of the simulator does not exceed the
		  increase of the complexity of the circuit or system to be
		  simulated, then the simulation complexity (measured in
		  terms of the accumulated time of basic calculation steps)
		  will not decrease, but instead will increase. Hence there
		  is an inherent limitation in the digital simulation of
		  analogue operators. This result suggests at the same time
		  that the digital method of data and signal processing has
		  some inherent limitations, a striking example of overcoming
		  it being the neural circuit. the speeding up of the digital
		  hardware due to the scaling down of feature sizes in
		  integrated circuits and the reduction of the time step due
		  to the increase in system size are also taken into
		  account.},
  copyright	= {Copyright {\copyright} 1990 John Wiley \& Sons, Ltd.},
  langid	= {english}
}

@Article{	  rospocher14:ontology,
  title		= {An Ontology for the Business Process Modelling Notation},
  author	= {Rospocher, M. and Ghidini, Chiara and Serafini, Luciano},
  year		= {2014},
  month		= jan,
  journal	= {Frontiers in Artificial Intelligence and Applications},
  volume	= {267},
  pages		= {133--146},
  doi		= {10.3233/978-1-61499-438-1-133},
  abstract	= {In this paper we describe a formal ontological description
		  of the Business Process Modelling Notation (BPMN), one of
		  the most popular languages for business process modelling.
		  The proposed ontology (the BPMN Ontology) provides a
		  classification of all the elements of BPMN, together with
		  the formal description of the attributes and conditions
		  describing how the elements can be combined in a BPMN
		  business process description. Using the classes and
		  properties defined in the BPMN Ontology any BPMN diagram
		  can be represented as an A-box (i.e., a set of instances
		  and assertions on them) of the ontology: this allows the
		  exploitation of ontological reasoning services such as
		  consistency checking and query answering to investigate the
		  compliance of a process with the BPMN Specification as well
		  as other structural property of the process. The paper also
		  presents the modelling process followed for the creation of
		  the BPMN Ontology, and describes some application scenarios
		  exploiting the BPMN Ontology.}
}

@Misc{		  rossberg19:webassembly,
  title		= {{{WebAssembly}} ({{Release}} 1.0)},
  author	= {Rossberg, Andreas},
  year		= {2019},
  urldate	= {2020-01-01},
  howpublished	= {https://webassembly.github.io/spec/}
}

@Misc{		  rossberg23:webassembly,
  title		= {{{WebAssembly}} ({{Release}} 2.0)},
  author	= {Rossberg, Andreas},
  year		= {2023},
  urldate	= {2023-02-20},
  howpublished	= {https://webassembly.github.io/spec/}
}

@TechReport{	  rossum95:python,
  title		= {Python {{Reference Manual}}},
  author	= {Rossum, Guido},
  year		= {1995},
  address	= {Amsterdam, The Netherlands, The Netherlands},
  institution	= {{CWI (Centre for Mathematics and Computer Science)}}
}

@Article{	  sackman68:exploratory,
  title		= {Exploratory Experimental Studies Comparing Online and
		  Offline Programming Performance},
  author	= {Sackman, H. and Erikson, W. J. and Grant, E. E.},
  year		= {1968},
  month		= jan,
  journal	= {Commun. ACM},
  volume	= {11},
  number	= {1},
  pages		= {3--11},
  issn		= {0001-0782},
  doi		= {10.1145/362851.362858},
  urldate	= {2025-05-08}
}

@Article{	  saeedi13:synthesis,
  title		= {Synthesis and Optimization of Reversible Circuits---a
		  Survey},
  author	= {Saeedi, Mehdi and Markov, Igor L.},
  year		= {2013},
  month		= mar,
  journal	= {ACM Comput. Surv.},
  volume	= {45},
  number	= {2},
  pages		= {21:1--21:34},
  issn		= {0360-0300},
  doi		= {10.1145/2431211.2431220},
  urldate	= {2024-11-09},
  abstract	= {Reversible logic circuits have been historically motivated
		  by theoretical research in low-power electronics as well as
		  practical improvement of bit manipulation transforms in
		  cryptography and computer graphics. Recently, reversible
		  circuits have attracted interest as components of quantum
		  algorithms, as well as in photonic and nano-computing
		  technologies where some switching devices offer no signal
		  gain. Research in generating reversible logic distinguishes
		  between circuit synthesis, postsynthesis optimization, and
		  technology mapping. In this survey, we review algorithmic
		  paradigms---search based, cycle based, transformation
		  based, and BDD based---as well as specific algorithms for
		  reversible synthesis, both exact and heuristic. We conclude
		  the survey by outlining key open challenges in synthesis of
		  reversible and quantum logic, as well as most common
		  misconceptions.}
}

@InProceedings{	  salvaneschi16:debugging,
  title		= {Debugging for Reactive Programming},
  booktitle	= {Proceedings of the 38th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Salvaneschi, Guido and Mezini, Mira},
  year		= {2016},
  month		= may,
  series	= {{{ICSE}} '16},
  pages		= {796--807},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2884781.2884815},
  urldate	= {2025-03-03},
  abstract	= {Reactive programming is a recent programming technique
		  that provides dedicated language abstractions for reactive
		  software. Reactive programming relieves developers from
		  manually updating outputs when the inputs of a computation
		  change, it overcomes a number of well-know issues of the
		  Observer design pattern, and it makes programs more
		  comprehensible. Unfortunately, complementing the new
		  paradigm with proper tools is a vastly unexplored area.
		  Hence, as of now, developers can embrace reactive
		  programming only at the cost of a more challenging
		  development process.In this paper, we investigate a primary
		  issue in the field: debugging programs in the reactive
		  style. We analyze the problem of debugging reactive
		  programs, show that the reactive style requires a paradigm
		  shift in the concepts needed for debugging, and propose RP
		  Debugging, a methodology for effectively debugging reactive
		  programs. These ideas are implemented in Reactive
		  Inspector, a debugger for reactive programs integrated with
		  the Eclipse Scala IDE. Evaluation based on a controlled
		  experiment shows that RP Debugging outperforms traditional
		  debugging techniques.},
  isbn		= {978-1-4503-3900-1}
}

@Misc{		  savidis21:implementation,
  title		= {Implementation of {{Live Reverse Debugging}} in {{LLDB}}},
  author	= {Savidis, Anthony and Tsiatsianas, Vangelis},
  year		= {2021},
  month		= aug,
  number	= {arXiv:2105.12819},
  eprint	= {2105.12819},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2105.12819},
  urldate	= {2025-03-01},
  abstract	= {Debugging is an essential process with a large share of
		  the development effort, being a relentless quest for
		  offensive code through tracing, inspection and iterative
		  running sessions. Probably every developer has been in a
		  situation with a clear wish to rewind time just for a
		  while, only to retry some actions alternatively, instead of
		  restarting the entire session. Well, the genie to fulfill
		  such a wish is known as a reverse debugger. Their inherent
		  technical complexity makes them very hard to implement,
		  while the imposed execution overhead turns them to less
		  preferable for adoption. There are only a few available,
		  most being off-line tools, working on recorded, previously
		  run, sessions. We consider live reverse debuggers both
		  challenging and promising, since they can fit into existing
		  forward debuggers, and we developed the first live reverse
		  debugger on top of LLDB, discussing in detail our
		  implementation approach.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Programming Languages,Computer Science
		  - Software Engineering}
}

@Misc{		  scalable,
  title		= {Scalable Omniscient Debugging {\textbar} {{ACM SIGPLAN
		  Notices}}},
  urldate	= {2024-04-18},
  howpublished	= {https://dl.acm.org/doi/10.1145/1297105.1297067}
}

@InProceedings{	  schmuck90:continuous,
  title		= {Continuous Clock Amortization Need Not Affect the
		  Precision of a Clock Synchronization Algorithm},
  booktitle	= {Proceedings of the Ninth Annual {{ACM}} Symposium on
		  {{Principles}} of Distributed Computing},
  author	= {Schmuck, Frank and Cristian, Flaviu},
  year		= {1990},
  month		= aug,
  series	= {{{PODC}} '90},
  pages		= {133--143},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/93385.93411},
  urldate	= {2025-03-04},
  isbn		= {978-0-89791-404-8}
}

@Article{	  scholliers24:webpie,
  title		= {{{WebPie}}: {{A Tiny Slice}} of {{Dependent Typing}}},
  shorttitle	= {{{WebPie}}},
  author	= {Scholliers, Christophe},
  year		= {2024},
  month		= apr,
  journal	= {Electronic Proceedings in Theoretical Computer Science},
  volume	= {400},
  eprint	= {2404.05457},
  primaryclass	= {cs},
  pages		= {2--27},
  issn		= {2075-2180},
  doi		= {10.4204/EPTCS.400.2},
  urldate	= {2024-04-18},
  abstract	= {Dependently typed programming languages have become
		  increasingly relevant in recent years. They have been
		  adopted in industrial strength programming languages and
		  have been extremely successful as the basis for theorem
		  provers. There are however, very few entry level
		  introductions to the theory of language constructs for
		  dependently typed languages, and even less sources on
		  didactical implementations. In this paper, we present a
		  small dependently typed programming language called WebPie.
		  The main features of the language are inductive types,
		  recursion and case matching. While none of these features
		  are new, we believe this article can provide a step forward
		  towards the understanding and systematic construction of
		  dependently typed languages for researchers new to
		  dependent types.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Logic in Computer Science,Computer
		  Science - Programming Languages,Computer Science - Symbolic
		  Computation}
}

@InProceedings{	  schordan16:automatic,
  title		= {Automatic {{Generation}} of {{Reversible C}}++ {{Code}}
		  and {{Its Performance}} in a {{Scalable Kinetic Monte-Carlo
		  Application}}},
  booktitle	= {Proceedings of the 2016 {{ACM SIGSIM Conference}} on
		  {{Principles}} of {{Advanced Discrete Simulation}}},
  author	= {Schordan, Markus and Oppelstrup, Tomas and Jefferson,
		  David and Barnes, Peter D. and Quinlan, Dan},
  year		= {2016},
  month		= may,
  series	= {{{SIGSIM-PADS}} '16},
  pages		= {111--122},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2901378.2901394},
  urldate	= {2024-11-10},
  abstract	= {The fully automatic generation of code that establishes
		  the reversibility of arbitrary C/C++ code has been a target
		  of research and engineering for more than a decade as
		  reverse computation has become a central notion in large
		  scale parallel discrete event simulation (PDES). The
		  simulation models that are implemented for PDES are of
		  increasing complexity and size and require various language
		  features to support abstraction, encapsulation, and
		  composition when building a simulation model. In this paper
		  we focus on parallel simulation models that are written in
		  C++ and present an approach and an evaluation for a fully
		  automatically generated reversible code for a kinetic
		  Monte-Carlo application implemented in C++. Although a
		  significant runtime overhead is introduced with our
		  technique, the assurance that the reverse code is generated
		  automatically and correctly, is an enormous win that allows
		  simulation model developers to write forward event code
		  using the entire C++ language, and have that code
		  automatically transformed into reversible code to enable
		  parallel execution with the Rensselaer's Optimistic
		  Simulation System (ROSS).},
  isbn		= {978-1-4503-3742-7}
}

@Article{	  schroeder09:dram,
  title		= {{{DRAM}} Errors in the Wild: A Large-Scale Field Study},
  shorttitle	= {{{DRAM}} Errors in the Wild},
  author	= {Schroeder, Bianca and Pinheiro, Eduardo and Weber,
		  Wolf-Dietrich},
  year		= {2009},
  month		= jun,
  journal	= {SIGMETRICS Perform. Eval. Rev.},
  volume	= {37},
  number	= {1},
  pages		= {193--204},
  issn		= {0163-5999},
  doi		= {10.1145/2492101.1555372},
  urldate	= {2025-05-06},
  abstract	= {Errors in dynamic random access memory (DRAM) are a common
		  form of hardware failure in modern compute clusters.
		  Failures are costly both in terms of hardware replacement
		  costs and service disruption. While a large body of work
		  exists on DRAM in laboratory conditions, little has been
		  reported on real DRAM failures in large production
		  clusters. In this paper, we analyze measurements of memory
		  errors in a large fleet of commodity servers over a period
		  of 2.5 years. The collected data covers multiple vendors,
		  DRAM capacities and technologies, and comprises many
		  millions of DIMM days.The goal of this paper is to answer
		  questions such as the following: How common are memory
		  errors in practice? What are their statistical properties?
		  How are they affected by external factors, such as
		  temperature and utilization, and by chip-specific factors,
		  such as chip density, memory technology and DIMM age?We
		  find that DRAM error behavior in the field differs in many
		  key aspects from commonly held assumptions. For example, we
		  observe DRAM error rates that are orders of magnitude
		  higher than previously reported, with 25,000 to 70,000
		  errors per billion device hours per Mbit and more than 8\%
		  of DIMMs affected by errors per year. We provide strong
		  evidence that memory errors are dominated by hard errors,
		  rather than soft errors, which previous work suspects to be
		  the dominant error mode. We find that temperature, known to
		  strongly impact DIMM error rates in lab conditions, has a
		  surprisingly small effect on error behavior in the field,
		  when taking all other factors into account. Finally, unlike
		  commonly feared, we don't observe any indication that newer
		  generations of DIMMs have worse error behavior.}
}

@InProceedings{	  schultz16:elements,
  title		= {Elements of a {{Reversible Object-Oriented Language}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Schultz, Ulrik Pagh and Axelsen, Holger Bock},
  editor	= {Devitt, Simon and Lanese, Ivan},
  year		= {2016},
  pages		= {153--159},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-40578-0_10},
  abstract	= {This paper presents initial ideas for the design and
		  implementation of a reversible object-oriented language
		  based on extending Janus with object-oriented concepts such
		  as classes that encapsulate behavior and state,
		  inheritance, virtual dispatching, as well as constructors.
		  We show that virtual dispatching is a reversible decision
		  mechanism easily translatable to a standard reversible
		  programming model such as Janus, and we argue that
		  reversible management of state can be accomplished using
		  reversible constructors. The language is implemented in
		  terms of translation to standard Janus programs.},
  isbn		= {978-3-319-40578-0},
  langid	= {english},
  keywords	= {Memory Management,Modern Programming Language,Object
		  Reference,Runtime Type,Virtual Method}
}

@InCollection{	  schultz20:reversible,
  title		= {Reversible {{Control}} of {{Robots}}},
  booktitle	= {Reversible {{Computation}}: {{Extending Horizons}} of
		  {{Computing}}: {{Selected Results}} of the {{COST Action
		  IC1405}}},
  author	= {Schultz, Ulrik Pagh},
  editor	= {Ulidowski, Irek and Lanese, Ivan and Schultz, Ulrik Pagh
		  and Ferreira, Carla},
  year		= {2020},
  pages		= {177--186},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-47361-7_8},
  urldate	= {2024-11-10},
  abstract	= {Programming industrial robots is challenging due to the
		  difficulty of precisely specifying general yet robust
		  operations. As the complexity of these operations
		  increases, so does the likelihood of errors. Certain
		  classes of errors during industrial robot operations can
		  however be addressed using reverse execution, allowing the
		  robot to temporarily back out of an erroneous situation,
		  after which the operation can be automatically retried.
		  Moreover reverse execution permits automatically deriving
		  programs that physically reverse the operations of an
		  industrial robot. This can be useful in industrial
		  assembly, where a disassembly program can be automatically
		  derived from the assembly program.},
  isbn		= {978-3-030-47361-7},
  langid	= {english}
}

@InProceedings{	  seelemann95:limiting,
  title		= {Limiting the Probe Effect in Debugging Concurrent
		  Object-Oriented Programs},
  booktitle	= {Proceedings of the 1995 Conference of the {{Centre}} for
		  {{Advanced Studies}} on {{Collaborative}} Research},
  author	= {Seelemann, Ilene},
  year		= {1995},
  month		= nov,
  series	= {{{CASCON}} '95},
  pages		= {56},
  publisher	= {IBM Press},
  address	= {Toronto, Ontario, Canada},
  urldate	= {2024-11-18},
  abstract	= {Event-based tracers for visualizing distributed
		  applications use process-time diagrams for demonstrating
		  interaction among processes. Object-oriented programs can
		  also benefit from a similar presentation in which
		  object-time diagrams are drawn and the interaction between
		  objects represents method invocations. In this type of
		  diagram, it is necessary to identify the objects and
		  methods involved.This paper presents an approach for
		  resolving and storing class and method names at debug time
		  instead of run time. In a sequential environment, this
		  approach has the benefit of preserving class layouts. In a
		  distributed object-oriented environment, it has the further
		  benefit of minimizing the probe effect by separating
		  resolution of naming information from program execution.
		  Extensions were made to Poet , a partial-order event
		  tracer, to display programs written using ABC++, a class
		  library for adding concurrency to C++.}
}

@InProceedings{	  sen06:automated,
  title		= {Automated {{Systematic Testing}} of {{Open Distributed
		  Programs}}},
  booktitle	= {Fundamental {{Approaches}} to {{Software Engineering}}},
  author	= {Sen, Koushik and Agha, Gul},
  editor	= {Baresi, Luciano and Heckel, Reiko},
  year		= {2006},
  pages		= {339--356},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/11693017_25},
  abstract	= {We present an algorithm for automatic testing of
		  distributed programs, such as Unix processes with
		  inter-process communication, Web services, etc.
		  Specifically, we assume that a program consists of a number
		  of asynchronously executing concurrent processes or actors
		  which may take data inputs and communicate using
		  asynchronous messages. Because of the large numbers of
		  possible data inputs as well as the asynchrony in the
		  execution and communication, distributed programs exhibit
		  very large numbers of potential behaviors. Our goal is two
		  fold: to execute all reachable statements of a program, and
		  to detect deadlock states. Specifically, our algorithm uses
		  simultaneous concrete and symbolic execution, or concolic
		  execution, to explore all distinct behaviors that may
		  result from a program's execution given different data
		  inputs and schedules. The key idea is as follows. We use
		  the symbolic execution to generate data inputs that may
		  lead to alternate behaviors. At the same time, we use the
		  concrete execution to determine, at runtime, the partial
		  order of events in the program's execution. This enables us
		  to improve the efficiency of our algorithm by avoiding many
		  tests which would result in equivalent behaviors. We
		  describe our experience with a prototype tool that we have
		  developed as a part of our Java program testing tool
		  jCUTE.},
  isbn		= {978-3-540-33094-3},
  langid	= {english},
  keywords	= {Execution Path,Message Queue,Model Check,Multithreaded
		  Program,Symbolic Execution}
}

@InProceedings{	  shapiro11:conflict-free-replicated-data-types,
  title		= {Conflict-{{Free Replicated Data Types}}},
  booktitle	= {Stabilization, {{Safety}}, and {{Security}} of
		  {{Distributed Systems}}},
  author	= {Shapiro, Marc and Pregui{\c c}a, Nuno and Baquero, Carlos
		  and Zawirski, Marek},
  editor	= {D{\'e}fago, Xavier and Petit, Franck and Villain, Vincent},
  year		= {2011},
  pages		= {386--400},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-24550-3_29},
  abstract	= {Replicating data under Eventual Consistency (EC) allows
		  any replica to accept updates without remote
		  synchronisation. This ensures performance and scalability
		  in large-scale distributed systems (e.g., clouds). However,
		  published EC approaches are ad-hoc and error-prone. Under a
		  formal Strong Eventual Consistency (SEC) model, we study
		  sufficient conditions for convergence. A data type that
		  satisfies these conditions is called a Conflict-free
		  Replicated Data Type (CRDT). Replicas of any CRDT are
		  guaranteed to converge in a self-stabilising manner,
		  despite any number of failures. This paper formalises two
		  popular approaches (state- and operation-based) and their
		  relevant sufficient conditions. We study a number of useful
		  CRDTs, such as sets with clean semantics, supporting both
		  add and remove operations, and consider in depth the more
		  complex Graph data type. CRDT types can be composed to
		  develop large-scale distributed applications, and have
		  interesting theoretical properties.},
  isbn		= {978-3-642-24550-3},
  langid	= {english}
}

@Book{		  shapiro83:algorithmic,
  title		= {Algorithmic {{Program Debugging}}},
  author	= {Shapiro, Ehud Y.},
  year		= {1983},
  month		= apr,
  publisher	= {The MIT Press},
  doi		= {10.7551/mitpress/1192.001.0001},
  urldate	= {2025-05-08},
  abstract	= {Productively combines elements of programming languages,
		  environments, logic, and inductive inference to produce
		  effective debugging aids. Its use of the P},
  isbn		= {978-0-262-25696-4},
  langid	= {english}
}

@InProceedings{	  shi19:ifixflakies,
  title		= {{{iFixFlakies}}: A Framework for Automatically Fixing
		  Order-Dependent Flaky Tests},
  shorttitle	= {{{iFixFlakies}}},
  booktitle	= {Proceedings of the 2019 27th {{ACM Joint Meeting}} on
		  {{European Software Engineering Conference}} and
		  {{Symposium}} on the {{Foundations}} of {{Software
		  Engineering}}},
  author	= {Shi, August and Lam, Wing and Oei, Reed and Xie, Tao and
		  Marinov, Darko},
  year		= {2019},
  month		= aug,
  series	= {{{ESEC}}/{{FSE}} 2019},
  pages		= {545--555},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3338906.3338925},
  urldate	= {2025-05-04},
  abstract	= {Regression testing provides important pass or fail signals
		  that developers use to make decisions after code changes.
		  However, flaky tests, which pass or fail even when the code
		  has not changed, can mislead developers. A common kind of
		  flaky tests are order-dependent tests, which pass or fail
		  depending on the order in which the tests are run. Fixing
		  order-dependent tests is often tedious and time-consuming.
		  We propose iFixFlakies, a framework for automatically
		  fixing order-dependent tests. The key insight in
		  iFixFlakies is that test suites often already have tests,
		  which we call helpers, whose logic resets or sets the
		  states for order-dependent tests to pass. iFixFlakies
		  searches a test suite for helpers that make the
		  order-dependent tests pass and then recommends patches for
		  the order-dependent tests using code from these helpers.
		  Our evaluation on 110 truly orderdependent tests from a
		  public dataset shows that 58 of them have helpers, and
		  iFixFlakies can fix all 58. We opened pull requests for 56
		  order-dependent tests (2 of 58 were already fixed), and
		  developers have already accepted pull requests for 21 of
		  them, with all the remaining ones still pending.},
  isbn		= {978-1-4503-5572-8}
}

@InProceedings{	  shibanai17:actoverse,
  title		= {Actoverse: A Reversible Debugger for Actors},
  shorttitle	= {Actoverse},
  booktitle	= {Proceedings of the 7th {{ACM SIGPLAN International
		  Workshop}} on {{Programming Based}} on {{Actors}},
		  {{Agents}}, and {{Decentralized Control}}},
  author	= {Shibanai, Kazuhiro and Watanabe, Takuo},
  year		= {2017},
  month		= oct,
  series	= {{{AGERE}} 2017},
  pages		= {50--57},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3141834.3141840},
  urldate	= {2024-02-28},
  abstract	= {The Actor model is a concurrent computation model based on
		  asynchronous message passing and shared-nothing principle.
		  These characteristics and the absence of locks guarantee
		  that actor-based programs can avoid simple concurrency bugs
		  such as data races and deadlocks. However, they are not
		  completely free from application level concurrency bugs
		  that occur, for example, due to the indeterminate arrival
		  order of messages. To assist discovering such bugs in
		  actor-based systems, we designed and implemented Actoverse,
		  a debugger that adopts reverse debugging and provides an
		  interactive aid for controlling the arrival order of
		  messages upon re-execution. This paper briefly presents its
		  architecture and utilization in Akka-based applications.},
  isbn		= {978-1-4503-5516-2},
  keywords	= {Actor model,Debugging,Reverse Debugging,Visualization}
}

@Misc{		  shymanskyy23:wasm3wasm-debug,
  title		= {Wasm3/Wasm-Debug},
  author	= {Shymanskyy, Volodymyr},
  year		= {2023},
  month		= oct,
  urldate	= {2023-11-17},
  abstract	= {Direct, source-level WebAssembly debugger},
  copyright	= {MIT},
  howpublished	= {Wasm3 Labs},
  keywords	= {debugger,gdb,lldb,remote-debugger,webassembly}
}

@InProceedings{	  sidna20:analysis,
  title		= {Analysis and Evaluation of Communication {{Protocols}} for
		  {{IoT Applications}}},
  booktitle	= {Proceedings of the 13th {{International Conference}} on
		  {{Intelligent Systems}}: {{Theories}} and
		  {{Applications}}},
  author	= {Sidna, Jeddou and Amine, Baina and Abdallah, Najid and El
		  Alami, Hassan},
  year		= {2020},
  month		= nov,
  series	= {{{SITA}}'20},
  pages		= {1--6},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3419604.3419754},
  urldate	= {2025-05-19},
  abstract	= {The communication protocols are an essential part for the
		  data communication of Internet of Things (IoT)
		  applications. However, the selection of a communication
		  protocol is challenging because it depends on the nature of
		  the IoT system and its data transmission system. Copious
		  communications protocols have been developed and employed
		  by researchers based on their requirements in the last
		  decade. Though, none of them is able to support all
		  criteria requirements, like energy efficiency, security,
		  quality of service, etc. Of all types of IoT systems,
		  communication protocols are an ongoing dilemma for the IoT
		  industry; consequently, it is important to analyze the
		  comportments and mechanisms of this latter to determine
		  their best-fit scenarios. Therefore, this paper presents an
		  evaluation of established communication protocols HTTP,
		  MQTT, DDS, XMPP, AMQP and CoAP for IoT applications.
		  Firstly, it presents the broad comparison among these
		  communication protocols to introduce their characteristics
		  comparatively. Subsequently, it performs a detailed and
		  in-depth analysis of the related process of gaining an
		  understanding of their strengths and limitations.
		  Therefore, based on this detailed evaluation, the user can
		  determine their appropriate use for various IoT
		  applications depending on their needs, efficiency, and
		  suitability.},
  isbn		= {978-1-4503-7733-1}
}

@Book{		  siek06:gradual,
  title		= {Gradual Typing for Functional Languages},
  author	= {Siek, Jeremy and Taha, Walid},
  year		= {2006},
  month		= jan,
  journal	= {Scheme and Functional Programming},
  abstract	= {Static and dynamic type systems have well-known strengths
		  and weaknesses, and each is better suited for different
		  programming tasks. There have been many efforts to
		  integrate static and dynamic typing and thereby combine the
		  benefits of both typing disciplines in the same language.
		  The flexibility of static typing can be im- proved by
		  adding a type Dynamic and a typecase form. The safety and
		  performance of dynamic typing can be improved by adding
		  optional type annotations or by performing type inference
		  (as in soft typing). However, there has been little formal
		  work on type systems that allow a programmer-controlled
		  migration between dy- namic and static typing. Thatte
		  proposed Quasi-Static Typing, but it does not statically
		  catch all type errors in completely annotated programs.
		  Anderson and Drossopoulou defined a nominal type sys- tem
		  for an object-oriented language with optional type
		  annotations. However, developing a sound, gradual type
		  system for functional languages with structural types is an
		  open problem. In this paper we present a solution based on
		  the intuition that the structure of a type may be partially
		  known/unknown at compile- time and the job of the type
		  system is to catch incompatibilities between the known
		  parts of types. We define the static and dynamic semantics
		  of a -calculus with optional type annotations and we prove
		  that its type system is sound with respect to the
		  simply-typed -calculus for fully-annotated terms. We prove
		  that this calculus is type safe and that the cost of
		  dynamism is "pay-as-you-go".}
}

@InProceedings{	  simons90:overview,
  title		= {An Overview of Clock Synchronization},
  booktitle	= {Fault-{{Tolerant Distributed Computing}}},
  author	= {Simons, Barbara},
  editor	= {Simons, Barbara and Spector, Alfred},
  year		= {1990},
  pages		= {84--96},
  publisher	= {Springer},
  address	= {New York, NY},
  doi		= {10.1007/BFb0042327},
  isbn		= {978-0-387-34812-4},
  langid	= {english}
}

@InProceedings{	  skvar-c24:in-field-debugging,
  title		= {In-{{Field Debugging}} of {{Automotive Microcontrollers}}
		  for {{Highest System Availability}}},
  booktitle	= {Proceedings of the 2nd {{ACM International Workshop}} on
		  {{Future Debugging Techniques}}},
  author	= {Skvar{\v c} Bo{\v z}i{\v c}, Ga{\v s}per and Irigoyen
		  Ceberio, Ibai and Mayer, Albrecht},
  year		= {2024},
  month		= sep,
  series	= {{{DEBT}} 2024},
  pages		= {2--8},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3678720.3685314},
  urldate	= {2024-11-10},
  abstract	= {The software content in vehicles is increasing, including
		  their system complexity, which leads to a higher
		  probability of bugs appearing in a production vehicle.
		  Consequently, there is an increasing need to observe what
		  the production system is doing also once it is already in
		  the field. This paper introduces an emerging topic of
		  in-field diagnosis of microcontrollers in the automotive
		  domain. This includes the architecture and how to address
		  the safety and security challenges. We describe the
		  necessary components of an in-field diagnosis architecture,
		  including the required properties of an on-chip debug
		  monitor. We provide several ways an on-chip debug monitor
		  can be implemented by utilizing the available and, in some
		  cases, unused system resources. With the described
		  approach, we can utilize the same debug concepts and tools
		  for local, remote, and in-field diagnosis, enabling runtime
		  verification throughout a system's lifecycle.},
  isbn		= {9798400711107}
}

@InProceedings{	  smith58:design,
  title		= {Design of the {{RCA}} 501 System},
  booktitle	= {Papers and Discussions Presented at the {{December}} 3-5,
		  1958, Eastern Joint Computer Conference: {{Modern}}
		  Computers: Objectives, Designs, Applications},
  author	= {Smith, J. G. and Hurewitz, T. M.},
  year		= {1958},
  month		= dec,
  series	= {{{AIEE-ACM-IRE}} '58 ({{Eastern}})},
  pages		= {160--164},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1458043.1458077},
  urldate	= {2025-05-07},
  abstract	= {The Radio Corporation of America (RCA) 501 System (Fig. 1)
		  was designed specifically for a wide range of data
		  processing applications. This paper describes the system
		  and relates specific functional characteristics of the
		  requirements that are found in data processing
		  activities.},
  isbn		= {978-1-4503-7866-6}
}

@Misc{		  soderby24:debugging,
  title		= {Debugging with the Arduino {{IDE}} 2.0},
  author	= {S{\"o}derby, Karl and De Feo, Ubi},
  year		= {2024},
  month		= nov,
  urldate	= {2024-11-12},
  howpublished	= {https://docs.arduino.cc/software/ide-v2/tutorials/ide-v2-debugger},
  lastaccessed	= {November 12, 2024}
}

@InProceedings{	  song14:on,
  title		= {On the Existence of Probe Effect in Multi-Threaded
		  Embedded Programs},
  booktitle	= {Proceedings of the 14th {{International Conference}} on
		  {{Embedded Software}}},
  author	= {Song, Young Wn and Lee, Yann-Hang},
  year		= {2014},
  month		= oct,
  series	= {{{EMSOFT}} '14},
  pages		= {1--9},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2656045.2656062},
  urldate	= {2024-11-18},
  abstract	= {Software instrumentation has been a convenient and
		  portable approach for dynamic analysis, debugging, or
		  profiling of program execution. Unfortunately,
		  instrumentation may change the temporal behavior of
		  multi-threaded program execution and result in different
		  ordering of thread operations, which is called probe
		  effect. While the approaches to reduce instrumentation
		  overhead, to enable reproducible execution, and to enforce
		  deterministic threading have been studied, no research has
		  yet answered if an instrumented execution has the same
		  behavior as the program execution without any
		  instrumentation and how the execution gets changed if there
		  were any. In this paper, we propose a simulation-based
		  analysis to detect the changes of execution event ordering
		  that are induced by instrumentation operations. The
		  execution model of a program is constructed from the trace
		  of instrumented program execution and is used in a
		  simulation analysis where instrumentation overhead is
		  removed. As a consequence, we can infer the ordering of
		  events in the original program execution and verify the
		  existence of probe effect resulted from instrumentation.},
  isbn		= {978-1-4503-3052-7}
}

@Article{	  spinellis18:modern,
  title		= {Modern Debugging: The Art of Finding a Needle in a
		  Haystack},
  shorttitle	= {Modern Debugging},
  author	= {Spinellis, Diomidis},
  year		= {2018},
  month		= oct,
  journal	= {Commun. ACM},
  volume	= {61},
  number	= {11},
  pages		= {124--134},
  issn		= {0001-0782},
  doi		= {10.1145/3186278},
  urldate	= {2025-05-07},
  abstract	= {Systematic use of proven debugging approaches and tools
		  lets programmers address even apparently intractable
		  bugs.}
}

@Article{	  stallman88:debugging,
  title		= {Debugging with {{GDB}}},
  author	= {Stallman, Richard and Pesch, Roland and Shebs, Stan and
		  others},
  year		= {1988},
  journal	= {Free Software Foundation},
  volume	= {675}
}

@InProceedings{	  stansifer88:type,
  title		= {Type Inference with Subtypes},
  booktitle	= {Proceedings of the 15th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Stansifer, R.},
  year		= {1988},
  month		= jan,
  series	= {{{POPL}} '88},
  pages		= {88--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/73560.73568},
  urldate	= {2023-10-20},
  abstract	= {We give an algorithm for type inference in a language with
		  functions, records, and variant records. A similar language
		  was studied by Cardelli who gave a type checking algorithm.
		  This language is interesting because it captures aspects of
		  object-oriented programming using subtype polymorphism. We
		  give a type system for deriving types of expressions in the
		  language and prove the type inference algorithm is sound,
		  i.e., it returns a type derivable from the proof system. We
		  also prove that the type the algorithm finds is a
		  ``principal'' type, i.e., one which characterizes all
		  others. The approach taken here is due to Milner for
		  universal polymorphism. The result is a synthesis of
		  subtype polymorphism and universal polymorphism.},
  isbn		= {978-0-89791-252-5}
}

@InCollection{	  static,
  title		= {Static {{Techniques}} ({{FL}} 3.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {91--136},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch3},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Static techniques
		  and the test process (FL 3.1) Review process (FL 3.2)
		  Static analysis by tools (FL 3.3) Added value of static
		  activities Synopsis of this chapter Sample exam questions},
  chapter	= {3},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Architecture analysis,Data flow analysis,International
		  Software Testing Qualifications Board (ISTQB),Static
		  techniques,Unified modeling language (UML)}
}

@Article{	  steegen16:increasing,
  title		= {Increasing {{Transparency Through}} a {{Multiverse
		  Analysis}}},
  author	= {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew
		  and Vanpaemel, Wolf},
  year		= {2016},
  month		= sep,
  journal	= {Perspectives on Psychological Science},
  volume	= {11},
  number	= {5},
  pages		= {702--712},
  publisher	= {SAGE Publications Inc},
  issn		= {1745-6916},
  doi		= {10.1177/1745691616658637},
  urldate	= {2024-11-10},
  abstract	= {Empirical research inevitably includes constructing a data
		  set by processing raw data into a form ready for
		  statistical analysis. Data processing often involves
		  choices among several reasonable options for excluding,
		  transforming, and coding data. We suggest that instead of
		  performing only one analysis, researchers could perform a
		  multiverse analysis, which involves performing all analyses
		  across the whole set of alternatively processed data sets
		  corresponding to a large set of reasonable scenarios. Using
		  an example focusing on the effect of fertility on
		  religiosity and political attitudes, we show that analyzing
		  a single data set can be misleading and propose a
		  multiverse analysis as an alternative practice. A
		  multiverse analysis offers an idea of how much the
		  conclusions change because of arbitrary choices in data
		  construction and gives pointers as to which choices are
		  most consequential in the fragility of the result.},
  langid	= {english}
}

@InProceedings{	  steinert09:debugging,
  title		= {Debugging into {{Examples}}},
  booktitle	= {Testing of {{Software}} and {{Communication Systems}}},
  author	= {Steinert, Bastian and Perscheid, Michael and Beck, Martin
		  and Lincke, Jens and Hirschfeld, Robert},
  editor	= {N{\'u}{\~n}ez, Manuel and Baker, Paul and Merayo, Mercedes
		  G.},
  year		= {2009},
  pages		= {235--240},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-05031-2_18},
  abstract	= {Enhancing and maintaining a complex software system
		  requires detailed understanding of the underlying source
		  code. Gaining this understanding by reading source code is
		  difficult. Since software systems are inherently dynamic,
		  it is complex and time consuming to imagine, for example,
		  the effects of a method's source code at run-time. The
		  inspection of software systems during execution, as
		  encouraged by debugging tools, contributes to source code
		  comprehension. Leveraged by test cases as entry points, we
		  want to make it easy for developers to experience selected
		  execution paths in their code by debugging into examples.
		  We show how links between test cases and application code
		  can be established by means of dynamic analysis while
		  executing regular tests.},
  isbn		= {978-3-642-05031-2},
  langid	= {english},
  keywords	= {dynamic analysis,Program comprehension,test coverage}
}

@Article{	  steinert12:coexist,
  title		= {{{CoExist}}: Overcoming Aversion to Change},
  shorttitle	= {{{CoExist}}},
  author	= {Steinert, Bastian and Cassou, Damien and Hirschfeld,
		  Robert},
  year		= {2012},
  month		= oct,
  journal	= {SIGPLAN Not.},
  volume	= {48},
  number	= {2},
  pages		= {107--118},
  issn		= {0362-1340},
  doi		= {10.1145/2480360.2384591},
  urldate	= {2024-10-30},
  abstract	= {Programmers make many changes to the program to eventually
		  find a good solution for a given task. In this course of
		  change, every intermediate development state can of value,
		  when, for example, a promising ideas suddenly turn out
		  inappropriate or the interplay of objects turns out more
		  complex than initially expected before making changes.
		  Programmers would benefit from tool support that provides
		  immediate access to source code and run-time of previous
		  development states of interest. We present IDE extensions,
		  implemented for Squeak/Smalltalk, to preserve, retrieve,
		  and work with this information. With such tool support,
		  programmers can work without worries because they can rely
		  on tools that help them with whatever their explorations
		  will reveal. They no longer have to follow certain best
		  practices only to avoid undesired consequences of hanging
		  code.}
}

@InProceedings{	  stievenart20:compositional,
  title		= {Compositional {{Information Flow Analysis}} for
		  {{WebAssembly Programs}}},
  booktitle	= {2020 {{IEEE}} 20th {{International Working Conference}} on
		  {{Source Code Analysis}} and {{Manipulation}} ({{SCAM}})},
  author	= {Sti{\'e}venart, Quentin and Roover, Coen De},
  year		= {2020},
  month		= sep,
  pages		= {13--24},
  issn		= {2470-6892},
  doi		= {10.1109/SCAM51674.2020.00007},
  urldate	= {2023-11-22},
  abstract	= {WebAssembly is a new W3C standard, providing a portable
		  target for compilation for various languages. All major
		  browsers can run WebAssembly programs, and its use extends
		  beyond the web: there is interest in compiling
		  cross-platform desktop applications, server applications,
		  IoT and embedded applications to WebAssembly because of the
		  performance and security guarantees it aims to provide.
		  Indeed, WebAssembly has been carefully designed with
		  security in mind. In particular, WebAssembly applications
		  are sandboxed from their host environment. However, recent
		  works have brought to light several limitations that expose
		  WebAssembly to traditional attack vectors. Visitors of
		  websites using WebAssembly have been exposed to malicious
		  code as a result. In this paper, we propose an automated
		  static program analysis to address these security concerns.
		  Our analysis is focused on information flow and is
		  compositional. For every WebAssembly function, it first
		  computes a summary that describes in a sound manner where
		  the information from its parameters and the global program
		  state can flow to. These summaries can then be applied
		  during the subsequent analysis of function calls. Through a
		  classical fixed-point formulation, one obtains an
		  approximation of the information flow in the WebAssembly
		  program. This results in the first compositional static
		  analysis for WebAssembly. On a set of 34 benchmark programs
		  spanning 196kLOC of WebAssembly, we compute at least 64\%
		  of the function summaries precisely in less than a minute
		  in total.}
}

@InProceedings{	  stievenart22:static,
  title		= {Static Stack-Preserving Intra-Procedural Slicing of
		  Webassembly Binaries},
  booktitle	= {Proceedings of the 44th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Sti{\'e}venart, Quentin and Binkley, David W. and De
		  Roover, Coen},
  year		= {2022},
  month		= jul,
  series	= {{{ICSE}} '22},
  pages		= {2031--2042},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3510003.3510070},
  urldate	= {2023-12-01},
  abstract	= {The recently introduced WebAssembly standard aims to be a
		  portable compilation target, enabling the cross-platform
		  distribution of programs written in a variety of languages.
		  We propose an approach to slice WebAssembly programs in
		  order to enable applications in reverse engineering, code
		  comprehension, and security among others. Given a program
		  and a location in that program, program slicing produces a
		  minimal version of the program that preserves the behavior
		  at the given location. Specifically, our approach is a
		  static, intra-procedural, backward slicing approach that
		  takes into account WebAssembly-specific dependences to
		  identify the instructions of the slice. To do so it must
		  correctly overcome the considerable challenges of
		  performing dependence analysis at the binary level.
		  Furthermore, for the slice to be executable, the approach
		  needs to ensure that the stack behavior of its output
		  complies with WebAssembly's validation requirements. We
		  implemented and evaluated our approach on a suite of 8 386
		  real-world WebAssembly binaries, finding that the average
		  size of the 495 204 868 slices computed is 53\% of the
		  original code, an improvement over the 60\% attained by
		  related work slicing ARM binaries. To gain a more
		  qualitative understanding of the slices produced by our
		  approach, we compared them to 1 956 source-level slices of
		  benchmark C programs. This inspection helps to illustrate
		  the slicer's strengths and to uncover potential future
		  improvements.},
  isbn		= {978-1-4503-9221-1},
  keywords	= {binary analysis,static program slicing,webassembly}
}

@Article{	  stievenart23:dynamic,
  title		= {Dynamic {{Slicing}} of {{WebAssembly Binaries}}: 39th
		  {{IEEE International Conference}} on {{Software
		  Maintenance}} and {{Evolution}}},
  shorttitle	= {Dynamic {{Slicing}} of {{WebAssembly Binaries}}},
  author	= {Sti{\'e}venart, Quentin and Binkley, Dave and De Roover,
		  Coen},
  year		= {2023},
  journal	= {Proceedings of the 39th IEEE International Conference on
		  Software Maintenance and Evolution (ICSME 2023)},
  pages		= {84--96},
  publisher	= {IEEE},
  doi		= {10.1109/ICSME58846.2023.00020},
  abstract	= {The recently introduced WebAssembly standard aims to form
		  a portable compilation target, enabling the cross-platform
		  distribution of programs written in a variety of languages.
		  In this paper, we propose and investigate the first dynamic
		  slicing approaches for WebAssembly. Given a program and a
		  location in that program, a program slice is a reduced
		  version of the program that preserves the behavior at the
		  given location. Slicing has numerous applications in
		  software maintenance and evolution, including reverse
		  engineering, code comprehension, and quality assurance.Our
		  dynamic approaches are built on Observational-Based Slicing
		  (ORBS). We explore the design space for instantiating ORBS
		  for WebAssembly: for example, it can be applied to the
		  whole program or to only the function containing the
		  slicing criterion, and it can be applied before compilation
		  to WebAssembly or afterwards. We evaluate the slices
		  produced quantitatively and qualitatively, and compare them
		  to those obtained by a state-of-the-art static slicer for
		  WebAssembly. Our evaluation reveals that dynamic slicing at
		  the level of a function from a WebAssembly binary finds a
		  sweet spot in terms of slice time and slice size.},
  keywords	= {dynamic program slicing,program analysis,WebAssembly}
}

@Article{	  strijbol24:blink,
  title		= {Blink: {{An}} Educational Software Debugger for
		  {{Scratch}}},
  shorttitle	= {Blink},
  author	= {Strijbol, Niko and De Proft, Robbe and Goethals, Klaas and
		  Mesuere, Bart and Dawyndt, Peter and Scholliers,
		  Christophe},
  year		= {2024},
  month		= feb,
  journal	= {SoftwareX},
  volume	= {25},
  pages		= {101617},
  issn		= {2352-7110},
  doi		= {10.1016/j.softx.2023.101617},
  urldate	= {2024-02-13},
  abstract	= {The process of teaching children to code is often slowed
		  down by the delay in providing feedback on each student's
		  code. Especially in larger classrooms, teachers often lack
		  the time to give individual feedback to each student. That
		  is why it is important to equip children with tools that
		  can provide immediate feedback and thus enhance their
		  independent learning skills. This article presents Blink, a
		  debugging tool specifically designed for Scratch, the most
		  commonly taught programming language for children. Blink
		  comes with basic debugging features such as `step' and
		  `pause', allowing precise monitoring of the execution of
		  Scratch programs. It also provides users with more advanced
		  debugging options, such as back-in-time debugging and
		  programmable pause. A group of children attending an
		  extracurricular coding class have been testing the
		  usefulness of Blink. Feedback from these young users
		  indicates that Blink helps them pinpoint programming errors
		  more accurately, and they have expressed an overall
		  positive view of the tool.},
  keywords	= {Block-based programming,Debugging,Programming,Scratch}
}

@InProceedings{	  sulzmann06:framework,
  title		= {A {{Framework}} for {{Extended Algebraic Data Types}}},
  booktitle	= {Functional and {{Logic Programming}}},
  author	= {Sulzmann, Martin and Wazny, Jeremy and Stuckey, Peter J.},
  editor	= {Hagiya, Masami and Wadler, Philip},
  year		= {2006},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {47--64},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/11737414_5},
  abstract	= {There are a number of extended forms of algebraic data
		  types such as type classes with existential types and
		  generalized algebraic data types. Such extensions are
		  highly useful but their interaction has not been studied
		  formally so far. Here, we present a unifying framework for
		  these extensions. We show that the combination of type
		  classes and generalized algebraic data types allows us to
		  express a number of interesting properties which are
		  desired by programmers. We support type checking based on a
		  novel constraint solver. Our results show that our system
		  is practical and greatly extends the expressive power of
		  languages such as Haskell and ML.},
  isbn		= {978-3-540-33439-2},
  langid	= {english},
  keywords	= {Functional Dependency,Type Check,Type Class,Type
		  Inference,Typing Rule}
}

@Article{	  sundaram13:diagnostic,
  title		= {Diagnostic Tracing for Wireless Sensor Networks},
  author	= {Sundaram, Vinaitheerthan and Eugster, Patrick and Zhang,
		  Xiangyu and Addanki, Vamsidhar},
  year		= {2013},
  month		= jul,
  journal	= {ACM Transactions on Sensor Networks},
  volume	= {9},
  number	= {4},
  pages		= {38:1--38:41},
  issn		= {1550-4859},
  doi		= {10.1145/2489253.2489255},
  urldate	= {2024-02-29},
  abstract	= {Wireless sensor networks are typically deployed in harsh
		  environments, thus post-deployment failures are not
		  infrequent. An execution trace containing events in their
		  order of execution could play a crucial role in postmortem
		  diagnosis of these failures. Obtaining such a trace however
		  is challenging due to stringent resource constraints. We
		  propose an efficient approach to intraprocedural and
		  interprocedural control-flow tracing that generates traces
		  of all interleaving concurrent events and of the
		  control-flow paths taken inside those events. We
		  demonstrate the effectiveness of our approach with the help
		  of case studies and illustrate its low overhead through
		  measurements and simulations.},
  keywords	= {diagnosis,Embedded debugging,tracing,wireless sensor
		  networks}
}

@InProceedings{	  symeonides20:fogify,
  title		= {Fogify: {{A Fog Computing Emulation Framework}}},
  shorttitle	= {Fogify},
  booktitle	= {Proceedings - 2020 {{IEEE}}/{{ACM Symposium}} on {{Edge
		  Computing}}, {{SEC}} 2020},
  author	= {Symeonides, M. and Georgiou, Z. and Trihinas, D. and
		  Pallis, G. and Dikaiakos, M.D.},
  year		= {2020},
  pages		= {42--54},
  doi		= {10.1109/SEC50012.2020.00011},
  abstract	= {Fog Computing is emerging as the dominating paradigm
		  bridging the compute and connectivity gap between sensing
		  devices and latency-sensitive services. However,
		  experimenting and evaluating IoT services is a daunting
		  task involving the manual configuration and deployment of a
		  mixture of geodistributed physical and virtual
		  infrastructure with different resource and network
		  requirements. This results in sub-optimal, costly and
		  error-prone deployments due to numerous unexpected
		  overheads not initially envisioned in the design phase and
		  underwhelming testing conditions not resembling the end
		  environment. In this paper, we introduce Fogify, an
		  emulator easing the modeling, deployment and large-scale
		  experimentation of fog and edge testbeds. Fogify provides a
		  toolset to: (i) model complex fog topologies comprised of
		  heterogeneous resources, network capabilities and QoS
		  criteria; (ii) deploy the modelled configuration and
		  services using popular containerized descriptions to a
		  cloud or local environment; (iii) experiment, measure and
		  evaluate the deployment by injecting faults and adapting
		  the configuration at runtime to test different 'what-if'
		  scenarios that reveal the limitations of a service before
		  introduced to the public. In the evaluation,
		  proof-of-concept IoT services with real-world workloads are
		  introduced to show the wide applicability and benefits of
		  rapid prototyping via Fogify. {\copyright} 2020 IEEE.},
  keywords	= {Fog Computing,Internet of Things}
}

@InProceedings{	  tabar22:automatic,
  title		= {Automatic Loop Invariant Generation for Data Dependence
		  Analysis},
  booktitle	= {Proceedings of the {{IEEE}}/{{ACM}} 10th {{International
		  Conference}} on {{Formal Methods}} in {{Software
		  Engineering}}},
  author	= {Tabar, Asmae Heydari and Bubel, Richard and H{\"a}hnle,
		  Reiner},
  year		= {2022},
  month		= jul,
  series	= {{{FormaliSE}} '22},
  pages		= {34--45},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3524482.3527649},
  urldate	= {2024-01-22},
  abstract	= {Parallelization of programs relies on sound and precise
		  analysis of data dependences in the code, specifically,
		  when dealing with loops. State-of-art tools are based on
		  dynamic profiling and static analysis. They tend to over-
		  and, occasionally, to under-approximate dependences. The
		  former misses parallelization opportunities, the latter can
		  change the behavior of the parallelized program. In this
		  paper we present a sound and highly precise approach to
		  generate data dependences based on deductive verification.
		  The central technique is to infer a specific form of loop
		  invariant tailored to express dependences. To achieve full
		  automation, we adapt predicate abstraction in a suitable
		  manner. To retain as much precision as possible, we
		  generalized logic-based symbolic execution to compute
		  abstract dependence predicates. We implemented our approach
		  for Java on top of a deductive verification tool. The
		  evaluation shows that our approach can generate highly
		  precise data dependences for representative code taken from
		  HPC applications.},
  isbn		= {978-1-4503-9287-7},
  keywords	= {data dependence analysis,loop invariant
		  generation,predicate abstraction}
}

@InProceedings{	  tan09:real-time,
  title		= {Real-Time Operating System ({{RTOS}}) for Small (16-Bit)
		  Microcontroller},
  booktitle	= {2009 {{IEEE}} 13th {{International Symposium}} on
		  {{Consumer Electronics}}},
  author	= {Tan, Su-Lim and Anh, Tran Nguyen Bao},
  year		= {2009},
  month		= may,
  pages		= {1007--1011},
  issn		= {2159-1423},
  doi		= {10.1109/ISCE.2009.5156833},
  urldate	= {2023-10-12},
  abstract	= {Real-time operating system (RTOS) is gaining increasing
		  use not only in 32-bit systems but also in 16-bit systems.
		  RTOS is different from generic OS by several unique
		  characteristics and the use of RTOS in embedded system
		  development proves to be more advantageous. In this paper,
		  9 RTOSes targeting smaller processors have been evaluated
		  and four of the RTOSes have been selected for performance
		  benchmarking on the same M16/62P microcontroller platform
		  to avoid bias. Based on the comparison, the {$\mu$}TKernel
		  RTOS is chosen for porting to the H8S/2377 16-bit
		  microcontroller to demonstrate the ease of RTOS platform
		  migration. The same version of {$\mu$}TKernel RTOS running
		  on different platforms are then compared. Lastly, an
		  application is developed with the RTOS to demonstrate the
		  ease of multi-task application development on such
		  microcontroller platform.}
}

@Article{	  tan24:case,
  title		= {A {{Case}} for {{First-Class Environments}}},
  author	= {Tan, Jinhao and Oliveira, Bruno C. d. S.},
  year		= {2024},
  month		= oct,
  journal	= {A Case for First-Class Environments (Artifact)},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {360:2521--360:2550},
  doi		= {10.1145/3689800},
  urldate	= {2025-06-05},
  abstract	= {Formalizations of programming languages typically adopt
		  the substitution model from the lambda calculus. However,
		  substitution creates notorious complications for reasoning
		  and implementation. Furthermore, it is disconnected from
		  practical implementations, which normally adopt
		  environments and closures.In this paper we advocate for
		  formalizing programming languages using a novel style of
		  small-step environment-based semantics, which avoids
		  substitution and is closer to implementations. We present a
		  call-by-value statically typed calculus, called
		  {$\lambda$}E, using our small-step environment semantics.
		  With our alternative environment semantics programming
		  language constructs for first-class environments arise
		  naturally, without creating significant additional
		  complexity. Therefore, {$\lambda$}E also adopts first-class
		  environments, adding expressive power that is not available
		  in conventional lambda calculi. {$\lambda$}E is a
		  conservative extension of the call-by-value Simply Typed
		  Lambda Calculus (STLC), and employs de Bruijn indices for
		  its formalization, which fit naturally with the
		  environment-based semantics. Reasoning about {$\lambda$}E
		  is simple, and in many cases simpler than reasoning about
		  the traditional STLC. We show an abstract machine that
		  implements the semantics of {$\lambda$}E, and has an easy
		  correctness proof. We also extend {$\lambda$}E with
		  references. We show that {$\lambda$}E can model a simple
		  form of first-class modules, and suggest using first-class
		  environments as an alternative to objects for modelling
		  capabilities. All technical results are formalized in the
		  Coq proof assistant. In summary, our work shows that the
		  small-step environment semantics that we adopt has three
		  main and orthogonal benefits: 1) it simplifies the
		  notorious binding problem in formalizations and proof
		  assistants; 2) it is closer to implementations; and 3)
		  additional expressive power is obtained from first-class
		  environments almost for free.}
}

@InCollection{	  templates,
  title		= {Templates and {{Models}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {315--326},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch8},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Master test plan
		  Test plan Test design document Test case Test procedure
		  Test log Defect report Test report},
  chapter	= {8},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Customization,Documentation templates,Institute for
		  Electrical and Electronic Engineers (IEEE),Master test
		  plan,Test cases (TC)}
}

@InProceedings{	  terry02:side,
  title		= {Side Views: Persistent, on-Demand Previews for Open-Ended
		  Tasks},
  shorttitle	= {Side Views},
  booktitle	= {Proceedings of the 15th Annual {{ACM}} Symposium on
		  {{User}} Interface Software and Technology},
  author	= {Terry, Michael and Mynatt, Elizabeth D.},
  year		= {2002},
  month		= oct,
  series	= {{{UIST}} '02},
  pages		= {71--80},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/571985.571996},
  urldate	= {2024-10-30},
  abstract	= {We introduce Side Views, a user interface mechanism that
		  provides on-demand, persistent, and dynamic previews of
		  commands. Side Views are designed to explicitly support the
		  practices and needs of expert users engaged in openended
		  tasks. In this paper, we summarize results from field
		  studies of expert users that motivated this work, then
		  discuss the design of Side Views in detail. We show how
		  Side Views' design affords their use as tools for
		  clarifying, comparing, and contrasting commands; generating
		  alternative visualizations; experimenting without modifying
		  the original data (i.e., "what-if" tools); and as tools
		  that support the serendipitous discovery of viable
		  alternatives. We then convey lessons learned from
		  implementing Side Views in two sample applications, a rich
		  text editor and an image manipulation application. These
		  contributions include a discussion of how to implement Side
		  Views for commands with parameters, for commands that
		  require direct user input (such as mouse strokes for a
		  paint program), and for computationally-intensive
		  commands.},
  isbn		= {978-1-58113-488-9}
}

@InProceedings{	  terry04:variation,
  title		= {Variation in Element and Action: Supporting Simultaneous
		  Development of Alternative Solutions},
  shorttitle	= {Variation in Element and Action},
  booktitle	= {Proceedings of the {{SIGCHI Conference}} on {{Human
		  Factors}} in {{Computing Systems}}},
  author	= {Terry, Michael and Mynatt, Elizabeth D. and Nakakoji,
		  Kumiyo and Yamamoto, Yasuhiro},
  year		= {2004},
  month		= apr,
  series	= {{{CHI}} '04},
  pages		= {711--718},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/985692.985782},
  urldate	= {2024-10-30},
  abstract	= {The complexity of many problems necessitates creating and
		  exploring multiple, alternative solutions. However, current
		  user interfaces do not cleanly support creating
		  alternatives at a time when they are likely to be
		  discovered: as users interactively modify data. This paper
		  presents Parallel Paths, a novel model of interaction that
		  facilitates generating, manipulating, and comparing
		  alternative solutions. In contrast to existing approaches
		  such as automated history capture tools, Parallel Paths
		  emphasizes the active, simultaneous development of
		  multiple, alternative solutions. We demonstrate this model
		  of interaction in Parallel Pies, a user interface mechanism
		  developed for image manipulation tasks that allows users
		  to: easily create solution alternatives as they interact
		  with a command; embed the alternatives in the same
		  workspace; manipulate the alternatives independently or
		  simultaneously as if they were the same object; and perform
		  side-by-side comparisons of each. Results from an initial
		  evaluation are presented, along with implications for
		  future designs.},
  isbn		= {978-1-58113-702-6}
}

@InProceedings{	  terry94:session,
  title		= {Session Guarantees for Weakly Consistent Replicated Data},
  booktitle	= {Proceedings of 3rd {{International Conference}} on
		  {{Parallel}} and {{Distributed Information Systems}}},
  author	= {Terry, D.B. and Demers, A.J. and Petersen, K. and
		  Spreitzer, M.J. and Theimer, M.M. and Welch, B.B.},
  year		= {1994},
  month		= sep,
  pages		= {140--149},
  doi		= {10.1109/PDIS.1994.331722},
  urldate	= {2025-03-04},
  abstract	= {Four per-session guarantees are proposed to aid users and
		  applications of weakly consistent replicated data: "read
		  your writes", "monotonic reads", "writes follow reads", and
		  "monotonic writes". The intent is to present individual
		  applications with a view of the database that is consistent
		  with their own actions, even if they read and write from
		  various, potentially inconsistent servers. The guarantees
		  can be layered on existing systems that employ a
		  read-any/write-any replication scheme while retaining the
		  principal benefits of such a scheme, namely high
		  availability, simplicity, scalability, and support for
		  disconnected operation. These session guarantees were
		  developed in the context of the Bayou project at Xerox PARC
		  in which we are designing and building a replicated storage
		  system to support the needs of mobile computing users who
		  may be only intermittently connected.{$<>$}},
  keywords	= {Application software,Buildings,Computer
		  applications,Computer science,Databases,Laboratories,Mobile
		  communication,Mobile computing,Pipelines,Scalability}
}

@Article{	  tesone18:dynamic,
  title		= {Dynamic {{Software Update}} from {{Development}} to
		  {{Production}}.},
  author	= {Tesone, Pablo and Polito, Guillermo and Bouraqadi, Noury
		  and Ducasse, St{\'e}phane and Fabresse, Luc},
  year		= {2018},
  journal	= {The Journal of Object Technology},
  volume	= {17},
  number	= {1},
  pages		= {1:1},
  publisher	= {AITO - Association Internationale pour les Technologies
		  Objets},
  issn		= {1660-1769},
  doi		= {10.5381/jot.2018.17.1.a2},
  urldate	= {2025-01-14},
  langid	= {english}
}

@InCollection{	  test,
  title		= {Test {{Design Techniques}} ({{FL}} 4.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {137--207},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch4},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: The test
		  development process (FL 4.1) Categories of test design
		  techniques (FL 4.2) Black-box techniques (FL 4.3)
		  Structure-based techniques (FL 4.4) Experience-based
		  techniques (FL 4.5) Choosing test techniques (FL 4.6)
		  Synopsis of this chapter Sample exam questions},
  chapter	= {4},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Black-box techniques,Equivalence partitioning,Exploratory
		  testing,Orthogonal arrays testing,Reliability management
		  theories,State transition testing,Structure-based
		  techniques,Test design techniques,Unified modeling language
		  (UML),Vectors and matrix processing}
}

@InCollection{	  testa,
  title		= {Test {{Management}} ({{FL}} 5.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {209--276},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch5},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Test organization
		  (FL 5.1) Test planning and estimation (FL 5.2) Test
		  progress monitoring and control (FL 5.3) Reporting
		  Transverse processes and activities Risks management (FL
		  5.5) Defect management (FL 5.6) Synopsis of this chapter
		  Sample exam questions},
  chapter	= {5},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Configuration management,Estimation methods,Failure mode
		  and effect analysis (FMEA),Hazard analysis,International
		  Software Testing Qualifications Board (ISTQB),Risk-based
		  testing method,Scrum model,Test management,Uniform test
		  distribution}
}

@Misc{		  testb,
  title		= {Test {{Framework}} --- {{Zephyr Project Documentation}}},
  author	= {Peress, Yuval and Nashif, Anas and Brunnen, Manoel and
		  Andersen, Henrik Brix and Emeltchenko, Andrei and Massey,
		  Aaron E. and Bolivar, Marti and Olivares, Ivan Herrera and
		  Escolar, Alberto},
  urldate	= {2024-02-13},
  howpublished	= {https://docs.zephyrproject.org/latest/develop/test/ztest.html}
}

@InCollection{	  testing,
  title		= {Testing {{Throughout}} the {{Software Life Cycle}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {43--90},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch2},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Software
		  development models (FL 2.1) Test levels (FL 2.2) Types of
		  tests (FL 2.3) Test and maintenance (FL 2.4) Oracles
		  Specific cases Synopsis of this chapter Sample exam
		  questions},
  chapter	= {2},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Agile development models,Capability Maturity Model
		  Integration (CMMI),Code instrumentation,International
		  Software Testing Qualifications Board (ISTQB),Oracle,Rapid
		  application development (RAD) model,Regression
		  testing,Sequential models,Software life cycle,Test driven
		  development (TDD)}
}

@InProceedings{	  thane00:monitoring,
  title		= {Monitoring, {{Testing}} and {{Debugging}} of {{Distributed
		  Real-Time Systems}}},
  author	= {Thane, Henrik},
  year		= {2000},
  urldate	= {2025-01-15},
  abstract	= {Abstract Testing is an important part of any software
		  development project, and can typically surpass more than
		  half of the development cost. For safety-critical computer
		  based systems, testing is ...}
}

@InProceedings{	  thane00:using,
  title		= {Using Deterministic Replay for Debugging of Distributed
		  Real-Time Systems},
  booktitle	= {Proceedings 12th {{Euromicro Conference}} on {{Real-Time
		  Systems}}. {{Euromicro RTS}} 2000},
  author	= {Thane, H. and Hansson, H.},
  year		= {2000},
  month		= jun,
  pages		= {265--272},
  issn		= {1068-3070},
  doi		= {10.1109/EMRTS.2000.854015},
  urldate	= {2025-03-03},
  abstract	= {Cyclic debugging is one of the most important and most
		  commonly used activities in program development. During
		  cyclic debugging, a program is repeatedly re-executed to
		  track down errors when a failure has been observed. This
		  process necessitates reproducible program executions.
		  Applying classical debugging techniques, such as using
		  breakpoints or single stepping, in real-time systems
		  changes the temporal behaviour and makes reproduction of
		  the observed failure during debugging less likely, if not
		  impossible. Consequently, these techniques are not directly
		  applicable to the cyclic debugging of real-time systems. In
		  this paper, we present a novel software-based approach for
		  the cyclic debugging of distributed real-time systems. By
		  the online recording of significant system events, and then
		  deterministically replaying them off-line, we can inspect a
		  real-time system in great detail, while still preserving
		  its real-time behaviour.},
  keywords	= {Computer errors,Condition
		  monitoring,Debugging,Hardware,Real time
		  systems,Runtime,Sensor systems,Switches,System
		  testing,Timing}
}

@InProceedings{	  thane03:replay,
  title		= {Replay Debugging of Real-Time Systems Using Time
		  Machines},
  booktitle	= {Proceedings {{International Parallel}} and {{Distributed
		  Processing Symposium}}},
  author	= {Thane, H. and Sundmark, D. and Huselius, J. and
		  Pettersson, A.},
  year		= {2003},
  month		= apr,
  pages		= {8 pp.-},
  issn		= {1530-2075},
  doi		= {10.1109/IPDPS.2003.1213515},
  urldate	= {2025-03-03},
  abstract	= {In this paper we present a new approach to deterministic
		  replay using standard components. Our method facilitates
		  cyclic debugging of real-time systems with industry
		  standard real-time operating systems using industry
		  standard debuggers. The method is based on a number of new
		  techniques: A new marker for deterministic differentiation
		  between e.g., loop iterations for deterministic
		  reproduction of interrupts and task preemptions, an
		  algorithm for finding well-defined starting points of
		  replay sessions, as well as a technique for using
		  conditional breakpoints in standard debuggers to replay the
		  target system. We also propose and discuss different
		  methods for deterministic monitoring, and provide
		  benchmarking results from an industrial strength case study
		  demonstrating the feasibility of our method. Previously
		  published solutions to the problem of debugging real-time
		  systems have been based on the concept of deterministic
		  replay: where significant system events like task-switches
		  of multitasking software and external inputs are recorded
		  during run-time, and later replayed (re-executed) off-line.
		  Previous works have been based on either non-standard
		  hardware, specially designed compilers or modified
		  real-time operating systems. The reliance on non-standard
		  components has limited the success of the approach. Even
		  though this idea has been around for 20 years, no
		  industrial application for debugging of real-time systems
		  of the method has been presented.},
  keywords	= {Condition monitoring,Hardware,Multitasking,Operating
		  systems,Real time systems,Runtime,Software debugging,System
		  testing,Timing,Vehicles}
}

@Misc{		  the-assemblyscript-project23:assemblyscript,
  title		= {{{AssemblyScript}}},
  author	= {{The AssemblyScript Project}},
  year		= {2023},
  urldate	= {2023-01-10},
  lastaccessed	= {January 10, 2023}
}

@Misc{		  tian24:debugbench,
  title		= {{{DebugBench}}: {{Evaluating Debugging Capability}} of
		  {{Large Language Models}}},
  shorttitle	= {{{DebugBench}}},
  author	= {Tian, Runchu and Ye, Yining and Qin, Yujia and Cong, Xin
		  and Lin, Yankai and Pan, Yinxu and Wu, Yesai and Hui,
		  Haotian and Liu, Weichuan and Liu, Zhiyuan and Sun,
		  Maosong},
  year		= {2024},
  month		= jan,
  journal	= {arXiv.org},
  urldate	= {2025-06-11},
  abstract	= {Large Language Models (LLMs) have demonstrated exceptional
		  coding capability. However, as another critical component
		  of programming proficiency, the debugging capability of
		  LLMs remains relatively unexplored. Previous evaluations of
		  LLMs' debugging ability are significantly limited by the
		  risk of data leakage, the scale of the dataset, and the
		  variety of tested bugs. To overcome these deficiencies, we
		  introduce `DebugBench', an LLM debugging benchmark
		  consisting of 4,253 instances. It covers four major bug
		  categories and 18 minor types in C++, Java, and Python. To
		  construct DebugBench, we collect code snippets from the
		  LeetCode community, implant bugs into source data with
		  GPT-4, and assure rigorous quality checks. We evaluate two
		  commercial and four open-source models in a zero-shot
		  scenario. We find that (1) while closed-source models
		  exhibit inferior debugging performance compared to humans,
		  open-source models relatively lower pass rate scores; (2)
		  the complexity of debugging notably fluctuates depending on
		  the bug category; (3) incorporating runtime feedback has a
		  clear impact on debugging performance which is not always
		  helpful. As an extension, we also compare LLM debugging and
		  code generation, revealing a strong correlation between
		  them for closed-source models. These findings will benefit
		  the development of LLMs in debugging.},
  howpublished	= {https://arxiv.org/abs/2401.04621v3},
  langid	= {english}
}

@InProceedings{	  tiks24:reversible-debugger,
  title		= {A {{Reversible Debugger}} for {{MPI Applications}}},
  booktitle	= {Proceedings of the 2nd {{ACM International Workshop}} on
		  {{Future Debugging Techniques}}},
  author	= {Tiks, Mihkel and Martens, Ott-Kaarel and Vainikko, Eero
		  and Kuhn, Stefan},
  year		= {2024},
  month		= sep,
  series	= {{{DEBT}} 2024},
  pages		= {16--21},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3678720.3685316},
  urldate	= {2024-11-13},
  abstract	= {Cluster machines are gaining importance, for example in
		  high-performance computing and eScience. For this, programs
		  need to be parallelized and run with appropriate tools,
		  typically MPI (Message Passing Interface) in a scientific
		  context. Since writing programs for parallel computation is
		  significantly more difficult than programming for
		  sequential execution, debugging tools, which are considered
		  a necessary part of the toolset of software developers, are
		  of even higher importance there. Reversibility, providing
		  the ability to progress backwards in the program execution
		  in some form, has been added to some debuggers and is a
		  useful feature for debugging MPI applications as well. This
		  paper presents a debugger for MPI applications which offers
		  reversible debugging commands. This is done using a
		  checkpoint-restore mechanism. We demonstrate the viability
		  of this approach to enable reversible debugging for
		  parallel computation.},
  isbn		= {9798400711107}
}

@InProceedings{	  toffoli80:reversible,
  title		= {Reversible Computing},
  booktitle	= {Automata, {{Languages}} and {{Programming}}},
  author	= {Toffoli, Tommaso},
  editor	= {{de Bakker}, Jaco and {van Leeuwen}, Jan},
  year		= {1980},
  pages		= {632--644},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-10003-2_104},
  abstract	= {The theory of reversible computing is based on invertible
		  primitives and composition rules that preserve
		  invertibility. With these constraints, one can still
		  satisfactorily deal with both functional and structural
		  aspects of computing processes; at the same time, one
		  attains a closer correspondence between the behavior of
		  abstract computing systems and the microscopic physical
		  laws (which are presumed to be strictly reversible) that
		  underly any concrete implementation of such systems.},
  isbn		= {978-3-540-39346-7},
  langid	= {english}
}

@Misc{		  tollervey22:code,
  title		= {Code with Mu. a Simple {{Python}} Editor for Beginner
		  Programmers},
  author	= {Tollervey, Nicholas H.},
  year		= {2022},
  urldate	= {2023-05-22}
}

@Article{	  tolmach95:debugger,
  title		= {A {{Debugger}} for {{Standard ML}}},
  author	= {Tolmach, Andrew and Appel, Andrew W.},
  year		= {1995},
  month		= apr,
  journal	= {Journal of Functional Programming},
  volume	= {5},
  number	= {2},
  pages		= {155--200},
  publisher	= {Cambridge University Press},
  issn		= {1469-7653, 0956-7968},
  doi		= {10.1017/S0956796800001313},
  urldate	= {2023-09-28},
  abstract	= {We have built a portable, instrumentation-based, replay
		  debugger for the Standard ML of New Jersey compiler.
		  Traditional `source-level' debuggers for compiled languages
		  actually operate at machine level, which makes them
		  complex, difficult to port, and intolerant of compiler
		  optimization. For secure languages like ML, however,
		  debugging support can be provided without reference to the
		  underlying machine, by adding instrumentation to program
		  source code before compilation. Because instrumented code
		  is (almost) ordinary source, it can be processed by the
		  ordinary compiler. Our debugger is thus independent from
		  the underlying hardware and runtime system, and from the
		  optimization strategies used by the compiler. The debugger
		  also provides reverse execution, both as a user feature and
		  an internal mechanism. Reverse execution is implemented
		  using a checkpoint and replay system; checkpoints are
		  represented primarily by first-class continuations.},
  langid	= {english}
}

@InCollection{	  tools,
  title		= {Tools Support for {{Testing}} ({{FL}} 6.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {277--299},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch6},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Types of test tools
		  (FL 6.1) Assumptions and limitations of test tools (FL 6.2)
		  Selecting and introducing tools in an organization (FL 6.3)
		  Synopsis of this chapter Sample exam questions},
  chapter	= {6},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Application programming interfaces (API),Central
		  processing unit (CPU),Configuration management,Economic
		  analysis,International Software Testing Qualifications
		  Board (ISTQB),Network simulators,Regression tests,Static
		  analysis tools,Test management tools}
}

@InProceedings{	  torres17:principled,
  title		= {A Principled Approach towards Debugging Communicating
		  Event-Loops},
  booktitle	= {Proceedings of the 7th {{ACM SIGPLAN International
		  Workshop}} on {{Programming Based}} on {{Actors}},
		  {{Agents}}, and {{Decentralized Control}}},
  author	= {Torres Lopez, Carmen and Boix, Elisa Gonzalez and
		  Scholliers, Christophe and Marr, Stefan and
		  M{\"o}ssenb{\"o}ck, Hanspeter},
  year		= {2017},
  month		= oct,
  series	= {{{AGERE}} 2017},
  pages		= {41--49},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3141834.3141839},
  urldate	= {2025-03-05},
  abstract	= {Since the multicore revolution, software systems are more
		  and more inherently concurrent. Debugging such concurrent
		  software systems is still hard, but in the recent years new
		  tools and techniques are being proposed. For such novel
		  debugging techniques, the main question is how to make sure
		  that the proposed techniques are sufficiently expressive.
		  In this paper, we explore a formal foundation that allows
		  researchers to identify debugging techniques and assess how
		  complete their features are in the context of
		  message-passing concurrency. In particular, we describe a
		  principled approach for defining the operational semantics
		  of a debugger. Subsequently, we apply this technique to
		  derive the operational semantics for a communicating
		  event-loop debugger. We show that our technique scales for
		  defining the semantics of a wide set of novel breakpoints
		  recently proposed by systems such as REME-D and K{\'o}mpos.
		  To the best of our knowledge, this is the first formal
		  semantics for debugging asynchronous message passing-based
		  concurrency models.},
  isbn		= {978-1-4503-5516-2}
}

@InProceedings{	  torres19:multiverse,
  title		= {Multiverse {{Debugging}}: {{Non-Deterministic Debugging}}
		  for {{Non-Deterministic Programs}} ({{Brave New Idea
		  Paper}})},
  shorttitle	= {Multiverse {{Debugging}}},
  booktitle	= {{{DROPS-IDN}}/v2/Document/10.4230/{{LIPIcs}}.{{ECOOP}}.2019.27},
  author	= {Torres Lopez, Carmen and Gurdeep Singh, Robbert and Marr,
		  Stefan and Gonzalez Boix, Elisa and Scholliers,
		  Christophe},
  year		= {2019},
  publisher	= {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi		= {10.4230/LIPIcs.ECOOP.2019.27},
  urldate	= {2024-03-11},
  abstract	= {Many of today's software systems are parallel or
		  concurrent. With the rise of Node.js and more generally
		  event-loop architectures, many systems need to handle
		  concurrency. However, its non-deterministic behavior makes
		  it hard to reproduce bugs. Today's interactive debuggers
		  unfortunately do not support developers in debugging
		  non-deterministic issues. They only allow us to explore a
		  single execution path. Therefore, some bugs may never be
		  reproduced in the debugging session, because the right
		  conditions are not triggered. As a solution, we propose
		  multiverse debugging, a new approach for debugging
		  non-deterministic programs that allows developers to
		  observe all possible execution paths of a parallel program
		  and debug it interactively. We introduce the concepts of
		  multiverse breakpoints and stepping, which can halt a
		  program in different execution paths, i.e. universes. We
		  apply multiverse debugging to AmbientTalk, an actor-based
		  language, resulting in Voyager, a multiverse debugger
		  implemented on top of the AmbientTalk operational
		  semantics. We provide a proof of non-interference, i.e., we
		  prove that observing the behavior of a program by the
		  debugger does not affect the behavior of that program and
		  vice versa. Multiverse debugging establishes the foundation
		  for debugging non-deterministic programs interactively,
		  which we believe can aid the development of parallel and
		  concurrent systems.},
  copyright	= {https://creativecommons.org/licenses/by/3.0/legalcode},
  langid	= {english}
}

@Book{		  torres21:advanced,
  title		= {Advanced {{Debugging Techniques}} to {{Handle Concurrency
		  Bugs}} in {{Actor-based Applications}}},
  author	= {Torres L{\'o}pez, Carmen},
  year		= {2021},
  month		= jun,
  isbn		= {978-94-93079-89-2},
  langid	= {english}
}

@Misc{		  towards,
  title		= {Towards {{Efficient Mobile M2M Communications}}:
		  {{Survey}} and {{Open Challenges}}},
  urldate	= {2025-05-03},
  howpublished	= {https://www.mdpi.com/1424-8220/14/10/19582}
}

@InProceedings{	  tso13:glasgow-raspberry-pi-cloud,
  title		= {The {{Glasgow Raspberry Pi Cloud}}: {{A Scale Model}} for
		  {{Cloud Computing Infrastructures}}},
  shorttitle	= {The {{Glasgow Raspberry Pi Cloud}}},
  booktitle	= {2013 {{IEEE}} 33rd {{International Conference}} on
		  {{Distributed Computing Systems Workshops}}},
  author	= {Tso, Fung Po and White, David R. and Jouet, Simon and
		  Singer, Jeremy and Pezaros, Dimitrios P.},
  year		= {2013},
  month		= jul,
  pages		= {108--112},
  issn		= {2332-5666},
  doi		= {10.1109/ICDCSW.2013.25},
  urldate	= {2024-01-18},
  abstract	= {Data Centers (DC) used to support Cloud services often
		  consist of tens of thousands of networked machines under a
		  single roof. The significant capital outlay required to
		  replicate such infrastructures constitutes a major obstacle
		  to practical implementation and evaluation of research in
		  this domain. Currently, most research into Cloud computing
		  relies on either limited software simulation, or the use of
		  a testbed environments with a handful of machines. The
		  recent introduction of the Raspberry Pi, a low-cost,
		  low-power single-board computer, has made the construction
		  of a miniature Cloud DCs more affordable. In this paper, we
		  present the Glasgow Raspberry Pi Cloud (PiCloud), a scale
		  model of a DC composed of clusters of Raspberry Pi devices.
		  The PiCloud emulates every layer of a Cloud stack, ranging
		  from resource virtualisation to network behaviour,
		  providing a full-featured Cloud Computing research and
		  educational environment.}
}

@Article{	  turing37:on,
  title		= {On {{Computable Numbers}}, with an {{Application}} to the
		  {{Entscheidungsproblem}}},
  author	= {Turing, A. M.},
  year		= {1937},
  journal	= {Proceedings of the London Mathematical Society},
  volume	= {s2-42},
  number	= {1},
  pages		= {230--265},
  issn		= {1460-244X},
  doi		= {10.1112/plms/s2-42.1.230},
  urldate	= {2023-12-01},
  copyright	= {{\copyright} 1937 London Mathematical Society},
  langid	= {english}
}

@Misc{		  tutorial,
  title		= {Tutorial: {{Remote}} Debug {\textbar} {{IntelliJ IDEA}}},
  shorttitle	= {Tutorial},
  journal	= {IntelliJ~IDEA Help},
  urldate	= {2025-03-01},
  howpublished	= {https://www.jetbrains.com/help/idea/tutorial-remote-debug.html},
  langid	= {american}
}

@Article{	  tyler23:ucca,
  title		= {{{UCCA}}: {{A Verified Architecture}} for
		  {{Compartmentalization}} of {{Untrusted Code Sections}} in
		  {{Resource-Constrained Devices}}},
  shorttitle	= {{{UCCA}}},
  author	= {Tyler, Liam and Nunes, Ivan De Oliveira},
  year		= {2023},
  publisher	= {arXiv},
  doi		= {10.48550/ARXIV.2312.02348},
  urldate	= {2024-01-18},
  abstract	= {Micro-controller units (MCUs) implement the de facto
		  interface between the physical and digital worlds. As a
		  consequence, they appear in a variety of sensing/actuation
		  applications, from smart personal spaces to complex
		  industrial control systems and safety-critical medical
		  equipment. While many of these devices perform safety- and
		  time-critical tasks, they often lack support for security
		  features compatible with their importance to overall system
		  functions. This lack of architectural support leaves them
		  vulnerable to run-time attacks that can remotely alter
		  their intended behavior, with potentially catastrophic
		  consequences. In particular, we note that MCU software
		  often includes untrusted third-party libraries (some of
		  them closed-source) that are blindly used within MCU
		  programs, without proper isolation from the rest of the
		  system. In turn, a single vulnerability (or intentional
		  backdoor) in one such third-party software can often
		  compromise the entire MCU software state. In this paper, we
		  tackle this problem by proposing, demonstrating security,
		  and formally verifying the implementation of UCCA: an
		  Untrusted Code Compartment Architecture. UCCA provides
		  flexible hardware-enforced isolation of untrusted code
		  sections (e.g., third-party software modules) in
		  resource-constrained and time-critical MCUs. To demonstrate
		  UCCA's practicality, we implement an open-source version of
		  the design on a real resource-constrained MCU: the
		  well-known TI MSP430. Our evaluation shows that UCCA incurs
		  little overhead and is affordable even to lowest-end MCUs,
		  requiring significantly less overhead and assumptions than
		  prior related work.},
  copyright	= {arXiv.org perpetual, non-exclusive license},
  keywords	= {Cryptography and Security (cs.CR),FOS: Computer and
		  information sciences}
}

@InProceedings{	  ubayashi19:when,
  title		= {When and {{Why Do Software Developers Face
		  Uncertainty}}?},
  booktitle	= {2019 {{IEEE}} 19th {{International Conference}} on
		  {{Software Quality}}, {{Reliability}} and {{Security}}
		  ({{QRS}})},
  author	= {Ubayashi, Naoyasu and Kamei, Yasutaka and Sato, Ryosuke},
  year		= {2019},
  month		= jul,
  pages		= {288--299},
  doi		= {10.1109/QRS.2019.00045},
  urldate	= {2025-05-06},
  abstract	= {Recently, many developers begin to notice that uncertainty
		  is a crucial problem in software development.
		  Unfortunately, no one knows how often uncertainty appears
		  or what kinds of uncertainty exist in actual projects,
		  because there are no empirical studies on uncertainty. To
		  deal with this problem, we conduct a large-scale empirical
		  study analyzing commit messages and revision histories of
		  1,444 OSS projects randomly selected from the GitHub
		  repositories. The main findings are as follows: 1)
		  Uncertainty exists in the ratio of 1.44\% (average); 2)
		  Uncertain program behavior, uncertain variable/value/name,
		  and uncertain program defects are major kinds of
		  uncertainty; and 3) Sometimes developers tend to take an
		  action for not resolving but escaping or ignoring
		  uncertainty. Uncertainty exists everywhere in a certain
		  percentage and developers cannot ignore the existence of
		  uncertainty.},
  keywords	= {Dictionaries,Empirical Study,Face,History,OSS
		  Projects,Software,Solid modeling,Uncertainty,Unified
		  modeling language}
}

@Misc{		  use,
  title		= {The {{Use}} of {{MQTT}} in {{M2M}} and {{IoT Systems}}:
		  {{A Survey}} {\textbar} {{IEEE Journals}} \& {{Magazine}}
		  {\textbar} {{IEEE Xplore}}},
  urldate	= {2025-05-03},
  howpublished	= {https://ieeexplore.ieee.org/abstract/document/9247996}
}

@Misc{		  usea,
  title		= {The {{Use}} of {{MQTT}} in {{M2M}} and {{IoT Systems}}:
		  {{A Survey}} {\textbar} {{IEEE Journals}} \& {{Magazine}}
		  {\textbar} {{IEEE Xplore}}},
  urldate	= {2025-05-03},
  howpublished	= {https://ieeexplore.ieee.org/abstract/document/9247996}
}

@InCollection{	  valmari98:state,
  title		= {The State Explosion Problem},
  booktitle	= {Lectures on {{Petri Nets I}}: {{Basic Models}}:
		  {{Advances}} in {{Petri Nets}}},
  author	= {Valmari, Antti},
  editor	= {Reisig, Wolfgang and Rozenberg, Grzegorz},
  year		= {1998},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {429--528},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-65306-6_21},
  urldate	= {2023-12-13},
  abstract	= {State space methods are one of the most important
		  approaches to computer-aided analysis and verification of
		  the behaviour of concurrent systems. In their basic form,
		  they consist of enumerating and analysing the set of the
		  states the system can ever reach. Unfortunately, the number
		  of states of even a relatively small system is often far
		  greater than can be handled in a realistic computer. The
		  goal of this article is to analyse this state explosion
		  problem from several perspectives. Many advanced state
		  space methods alleviate the problem by using a subset or an
		  abstraction of the set of states. Unfortunately, their use
		  tends to restrict the set of analysis or verification
		  questions that can be answered, making it impossible to
		  discuss the methods without some taxonomy of the questions.
		  Therefore, the article contains a lengthy discussion on
		  alternative ways of stating analysis and verification
		  questions, and algorithms for answering them. After that,
		  many advanced state space methods are briefly described.
		  The state explosion problem is investigated also from the
		  computational complexity point of view.},
  isbn		= {978-3-540-49442-3},
  langid	= {english},
  keywords	= {Communicate Sequential Process,Coverability Graph,Linear
		  Temporal Logic,Liveness Property,Model Check}
}

@InProceedings{	  van-der-veen12:memory,
  title		= {Memory {{Errors}}: {{The Past}}, the {{Present}}, and the
		  {{Future}}},
  shorttitle	= {Memory {{Errors}}},
  booktitle	= {Research in {{Attacks}}, {{Intrusions}}, and
		  {{Defenses}}},
  author	= {{van der Veen}, Victor and {dutt-Sharma}, Nitish and
		  Cavallaro, Lorenzo and Bos, Herbert},
  editor	= {Balzarotti, Davide and Stolfo, Salvatore J. and Cova,
		  Marco},
  year		= {2012},
  pages		= {86--106},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-33338-5_5},
  abstract	= {Memory error exploitations have been around for over 25
		  years and still rank among the top 3 most dangerous
		  software errors. Why haven't we been able to stop them?
		  Given the host of security measures on modern machines, are
		  we less vulnerable than before, and can we expect to
		  eradicate memory error problems in the near future? In this
		  paper, we present a quarter century worth of memory errors:
		  attacks, defenses, and statistics. A historical overview
		  provides insights in past trends and developments, while an
		  investigation of real-world vulnerabilities and exploits
		  allows us to answer on the significance of memory errors in
		  the foreseeable future.},
  isbn		= {978-3-642-33338-5},
  langid	= {english}
}

@Misc{		  vandervoord15:unity,
  title		= {{{UNITY}}. {{Unit}} Testing for {{C}} (Especially Embedded
		  Software)},
  author	= {VanderVoord, Mark and Karlesky, Mike and Williams, Greg},
  year		= {2015},
  urlddate	= {2023-08}
}

@Article{	  vandewoude07:tranquility,
  title		= {Tranquility: {{A Low Disruptive Alternative}} to
		  {{Quiescence}} for {{Ensuring Safe Dynamic Updates}}},
  shorttitle	= {Tranquility},
  author	= {Vandewoude, Yves and Ebraert, Peter and Berbers, Yolande
		  and D'Hondt, Theo},
  year		= {2007},
  month		= dec,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {33},
  number	= {12},
  pages		= {856--868},
  issn		= {1939-3520},
  doi		= {10.1109/TSE.2007.70733},
  urldate	= {2024-01-16},
  abstract	= {This paper revisits a problem that was identified by
		  Kramer and Magee: placing a system in a consistent state
		  before and after runtime changes. We show that their notion
		  of quiescence as a necessary and sufficient condition for
		  safe runtime changes is too strict and results in a
		  significant disruption in the application being updated. In
		  this paper, we introduce a weaker condition: tranquillity.
		  We show that tranquillity is easier to obtain and less
		  disruptive for the running application but still a
		  sufficient condition to ensure application consistency. We
		  present an implementation of our approach on a component
		  middleware platform and experimentally verify the validity
		  and practical applicability of our approach using data
		  retrieved from a case study.}
}

@Book{		  vansickle01:programming,
  title		= {Programming {{Microcontrollers}} in {{C}}},
  author	= {VanSickle, Ted},
  year		= {2001},
  publisher	= {Newnes},
  abstract	= {Ted Van Sickle spent over fifteen years at Motorola as a
		  microcontroller specialist. He now consults and teaches
		  classes on software design and programming for
		  microcontroller systems. He holds a MSEE from the
		  University of Michigan. Introduces microcontrollers and
		  describes their programming environment, offering tips on
		  coding for microcontrollersDescribes techniques to get
		  maximum performance from your codeDiscusses the differences
		  between 8-bit and larger microcontrollers, giving
		  application examples and providing details on using
		  different compilers},
  googlebooks	= {i62vDVOJ3YgC},
  isbn		= {978-1-878707-57-4},
  langid	= {english},
  keywords	= {Computers / Hardware / Chips & Processors,Technology &
		  Engineering / Electronics / General,Technology &
		  Engineering / Electronics / Microelectronics}
}

@InProceedings{	  vekris16:refinement,
  title		= {Refinement Types for {{TypeScript}}},
  booktitle	= {Proceedings of the 37th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Vekris, Panagiotis and Cosman, Benjamin and Jhala,
		  Ranjit},
  year		= {2016},
  month		= jun,
  series	= {{{PLDI}} '16},
  pages		= {310--325},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2908080.2908110},
  urldate	= {2024-12-18},
  abstract	= {We present Refined TypeScript (RSC), a lightweight
		  refinement type system for TypeScript, that enables static
		  verification of higher-order, imperative programs. We
		  develop a formal system for RSC that delineates the
		  interaction between refinement types and mutability, and
		  enables flow-sensitive reasoning by translating input
		  programs to an equivalent intermediate SSA form. By
		  establishing type safety for the intermediate form, we
		  prove safety for the input programs. Next, we extend the
		  core to account for imperative and dynamic features of
		  TypeScript, including overloading, type reflection, ad hoc
		  type hierarchies and object initialization. Finally, we
		  evaluate RSC on a set of real-world benchmarks, including
		  parts of the Octane benchmarks, D3, Transducers, and the
		  TypeScript compiler. We show how RSC successfully
		  establishes a number of value dependent properties, such as
		  the safety of array accesses and downcasts, while incurring
		  a modest overhead in type annotations and code
		  restructuring.},
  isbn		= {978-1-4503-4261-2}
}

@Article{	  venkatesh91:semantic,
  title		= {The Semantic Approach to Program Slicing},
  author	= {Venkatesh, G. A.},
  year		= {1991},
  month		= may,
  journal	= {ACM SIGPLAN Notices},
  volume	= {26},
  number	= {6},
  pages		= {107--119},
  issn		= {0362-1340},
  doi		= {10.1145/113446.113455},
  urldate	= {2023-11-07}
}

@Article{	  vessey85:expertise,
  title		= {Expertise in Debugging Computer Programs: {{A}} Process
		  Analysis},
  shorttitle	= {Expertise in Debugging Computer Programs},
  author	= {Vessey, Iris},
  year		= {1985},
  month		= nov,
  journal	= {International Journal of Man-Machine Studies},
  volume	= {23},
  number	= {5},
  pages		= {459--494},
  issn		= {0020-7373},
  doi		= {10.1016/S0020-7373(85)80054-7},
  urldate	= {2025-05-06},
  abstract	= {This paper reports the results of an exploratory study
		  that investigated expert and novice debugging processes
		  with the aim of contributing to a general theory of
		  programming expertise. The method used was verbal protocol
		  analysis. Data was collected from 16 programmers employed
		  by the same organization. First, an expert-novice
		  classification of subjects was derived from information
		  based on subjects' problem solving processes: the criterion
		  of expertise was the subjects' ability to chunk effectively
		  the program they were required to debug. Then, significant
		  differences in subjects' approaches to debugging were used
		  to characterize programmers' debugging strategies.
		  Comparisons of these strategies with the expert-novice
		  classification showed programmer expertise based on
		  chunking ability to be strongly related to debugging
		  strategy. The following strategic propositions were
		  identified for further testing. 1. (a) Experts use
		  breadth-first approaches to debugging and, at the same
		  time, adopt a system view of the problem area; (b) Experts
		  are proficient at chunking programs and hence display
		  smooth-flowing approaches to debugging. 2. (a) Novices use
		  breadth-first approaches to debugging but are deficient in
		  their ability to think in system terms; (b) Novices use
		  depth-first approaches to debugging; (c) Novices are less
		  proficient at chunking programs and hence display erratic
		  approaches to debugging.}
}

@InProceedings{	  villegas19:study,
  title		= {A Study of Over-the-Air ({{OTA}}) Update Systems for
		  {{CPS}} and {{IoT}} Operating Systems},
  booktitle	= {Proceedings of the 13th {{European Conference}} on
		  {{Software Architecture}} - {{Volume}} 2},
  author	= {Villegas, M{\'o}nica M. and Orellana, Cristian and
		  Astudillo, Hern{\'a}n},
  year		= {2019},
  month		= sep,
  series	= {{{ECSA}} '19},
  pages		= {269--272},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3344948.3344972},
  urldate	= {2024-01-16},
  abstract	= {There is growing use of Internet-of-Things (IoT) and
		  Cyber-Physical Systems (CPS) in industry, homes, cars, and
		  other environments, and several operating systems have been
		  proposed to manage these environments. The growing use of
		  long-lived IoT and CPS has made them susceptible to
		  obsolescence and change, just like "normal" software,
		  demanding systematic support for periodic updates of their
		  embedded software. However, there is little empirical data
		  about the structure, architecture, specifications, and
		  dependencies of these subsystems. This article presents an
		  analysis of over-the-air (OTA) update support in 26
		  existing open-source IoT/CPS operating systems and embedded
		  software projects, performed primarily by examining their
		  documentation and supplementing with occasional source code
		  examination. We found that seven projects give details of
		  an OTA update mechanism; four projects do not report
		  details of OTA update mechanisms, but third-party
		  developers implemented specific solutions to support OTA
		  updates using these projects; and the remaining 15 projects
		  do not report a particular update capability at all in
		  their documentation. This study will allow extending,
		  organize, and compare OTA update capabilities of future
		  IoT/CPS operating systems.},
  isbn		= {978-1-4503-7142-1},
  keywords	= {cyber-physical systems,IoT,operating systems,OTA updates}
}

@Article{	  vishwakarma18:exploiting,
  title		= {Exploiting {{JTAG}} and {{Its Mitigation}} in {{IOT}}: {{A
		  Survey}}},
  shorttitle	= {Exploiting {{JTAG}} and {{Its Mitigation}} in {{IOT}}},
  author	= {Vishwakarma, Gopal and Lee, Wonjun},
  year		= {2018},
  month		= dec,
  journal	= {Future Internet},
  volume	= {10},
  number	= {12},
  pages		= {121},
  publisher	= {Multidisciplinary Digital Publishing Institute},
  issn		= {1999-5903},
  doi		= {10.3390/fi10120121},
  urldate	= {2024-11-13},
  abstract	= {Nowadays, companies are heavily investing in the
		  development of ``Internet of Things(IoT)'' products. These
		  companies usually and obviously hunt for lucrative business
		  models. Currently, each person owns at least 3--4 devices
		  (such as mobiles, personal computers, Google Assistant,
		  Alexa, etc.) that are connected to the Internet 24/7.
		  However, in the future, there might be hundreds of devices
		  that will be constantly online behind each person, keeping
		  track of body health, banking transactions, status of
		  personal devices, etc. to make one's life more efficient
		  and streamlined. Thus, it is very crucial that each device
		  should be highly secure since one's life will become
		  dependent on these devices. However, the current security
		  of IoT devices is mainly focused on resiliency of device.
		  In addition, less complex node devices are easily
		  accessible to the public resulting in higher vulnerability.
		  JTAG is an IEEE standard that has been defined to test
		  proper mounting of components on PCBs (printed circuit
		  boards) and has been extensively used by PCB manufacturers
		  to date. This JTAG interface can be used as a backdoor
		  entry to access and exploit devices, also defined as a
		  physical attack. This attack can be used to make products
		  malfunction, modify data, or, in the worst case, stop
		  working. This paper reviews previous successful JTAG
		  exploitations of well-known devices operating online and
		  also reviews some proposed possible solutions to see how
		  they can affect IoT products in a broader sense.},
  copyright	= {http://creativecommons.org/licenses/by/3.0/},
  langid	= {english},
  keywords	= {a survey,exploitation,Internet of
		  Things,IOT,JTAG,mitigation}
}

@InProceedings{	  vouillon04:semantic,
  title		= {Semantic Types: A Fresh Look at the Ideal Model for
		  Types},
  shorttitle	= {Semantic Types},
  booktitle	= {Proceedings of the 31st {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Vouillon, Jerome and Melli{\`e}s, Paul-Andr{\'e}},
  year		= {2004},
  month		= jan,
  series	= {{{POPL}} '04},
  pages		= {52--63},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/964001.964006},
  urldate	= {2023-09-26},
  abstract	= {We present a generalization of the ideal model for
		  recursive polymorphic types. Types are defined as sets of
		  terms instead of sets of elements of a semantic domain. Our
		  proof of the existence of types (computed by fixpoint of a
		  typing operator) does not rely on metric properties, but on
		  the fact that the identity is the limit of a sequence of
		  projection terms. This establishes a connection with the
		  work of Pitts on relational properties of domains. This
		  also suggests that ideals are better understood as closed
		  sets of terms defined by orthogonality with respect to a
		  set of contexts.},
  isbn		= {978-1-58113-729-3},
  keywords	= {ideal model,inductive/coinductive
		  principle,polymorphism,realizability,recursive
		  types,subtyping}
}

@InProceedings{	  waldo97:note,
  title		= {A Note on Distributed Computing},
  booktitle	= {Mobile {{Object Systems Towards}} the {{Programmable
		  Internet}}},
  author	= {Waldo, Jim and Wyant, Geoff and Wollrath, Ann and Kendall,
		  Sam},
  editor	= {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan and
		  Vitek, Jan and Tschudin, Christian},
  year		= {1997},
  volume	= {1222},
  pages		= {49--64},
  publisher	= {Springer Berlin Heidelberg},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-62852-5_6},
  urldate	= {2025-05-04},
  abstract	= {We argue that objects that interact in a distributed
		  system need to be dealt with in ways that are intrinsically
		  different from objects that interact in a single address
		  space. These differences are required because distributed
		  systems require that the programmer be aware of latency,
		  have a different model of memory access, and take into
		  account issues of concurrency and partial failure. We look
		  at a number of distributed systems that have attempted to
		  paper over the distinction between local and remote
		  objects, and show that such systems fail to support basic
		  requirements of robustness and reliability. These failures
		  have been masked in the past by the small size of the
		  distributed systems that have been built. In the
		  enterprise-wide distributed systems foreseen in the near
		  future, however, such a masking will be impossible. We
		  conclude by discussing what is required of both
		  systems-level and application-level programmers and
		  designers if one is to take distribution seriously.},
  isbn		= {978-3-540-62852-1 978-3-540-68705-4}
}

@Article{	  wambugu17:automatic,
  title		= {Automatic {{Debugging Approaches}}: {{A}} Literature
		  {{Review}}},
  shorttitle	= {Automatic {{Debugging Approaches}}},
  author	= {Wambugu, Geoffrey and Njeru, Kevin},
  year		= {2017},
  month		= apr,
  journal	= {International Journal of Applied Computer Science
		  (IJACS)},
  volume	= {1},
  abstract	= {Fixing failed computer programs involves completing two
		  fundamental debugging tasks: first, the programmer has to
		  reproduce the failure; second, s/he has to find the failure
		  cause. Software debugging is the process of locating and
		  correcting erroneous statements in a faulty program as a
		  result of testing. It is extremely time consuming and very
		  expensive. The term debugging collectively refers to fault
		  localization, understanding and correction. Automated tools
		  to locate and correct the erroneous statements in a program
		  can significantly reduce the cost of software development
		  and improve the overall quality of the software. This paper
		  discusses fault localization, program slicing and delta
		  debugging techniques. It identifies statistical fault
		  localization tools such as Tarantula, GZoltar and others
		  such as dbx and Microsoft Visual C++ debugger that provides
		  a snapshot of the program state at various break points
		  along an execution path. In conclusion we note that most
		  software development companies spend a huge amount of
		  resources in testing and debugging. A lot more research
		  need to be conducted to fully automate the debugging
		  process thereby reducing software production cost, time and
		  improve quality.}
}

@InProceedings{	  ward03:slicing,
  title		= {Slicing the {{SCAM}} Mug: A Case Study in Semantic
		  Slicing},
  shorttitle	= {Slicing the {{SCAM}} Mug},
  booktitle	= {Proceedings {{Third IEEE International Workshop}} on
		  {{Source Code Analysis}} and {{Manipulation}}},
  author	= {Ward, M.P.},
  year		= {2003},
  month		= sep,
  pages		= {88--97},
  doi		= {10.1109/SCAM.2003.1238035},
  urldate	= {2023-11-30},
  abstract	= {We describe an improved formalisation of slicing in WSL
		  transformation theory and apply the result to a
		  particularly challenging slicing problem: the SCAM mug
		  (Anon, 2001). We present both syntactic and semantic slices
		  of the mug program and give semantic slices for various
		  generalisations of the program. Although there is no
		  algorithm for constructing a minimal syntactic slice, we
		  show that it is possible, in the WSL language, to derive a
		  minimal semantic slice for any program and any slicing
		  criteria.}
}

@Misc{		  wasmer--inc-22:wasmer,
  title		= {Wasmer},
  author	= {{Wasmer, Inc.}},
  year		= {2022},
  month		= feb,
  urldate	= {2022-02-22}
}

@InProceedings{	  watson15:cheri,
  title		= {{{CHERI}}: {{A Hybrid Capability-System Architecture}} for
		  {{Scalable Software Compartmentalization}}},
  shorttitle	= {{{CHERI}}},
  booktitle	= {2015 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  author	= {Watson, Robert N.M. and Woodruff, Jonathan and Neumann,
		  Peter G. and Moore, Simon W. and Anderson, Jonathan and
		  Chisnall, David and Dave, Nirav and Davis, Brooks and
		  Gudka, Khilan and Laurie, Ben and Murdoch, Steven J. and
		  Norton, Robert and Roe, Michael and Son, Stacey and Vadera,
		  Munraj},
  year		= {2015},
  month		= may,
  pages		= {20--37},
  issn		= {2375-1207},
  doi		= {10.1109/SP.2015.9},
  urldate	= {2024-01-18},
  abstract	= {CHERI extends a conventional RISC Instruction-Set
		  Architecture, compiler, and operating system to support
		  fine-grained, capability-based memory protection to
		  mitigate memory-related vulnerabilities in C-language TCBs.
		  We describe how CHERI capabilities can also underpin a
		  hardware-software object-capability model for application
		  compartmentalization that can mitigate broader classes of
		  attack. Prototyped as an extension to the open-source
		  64-bit BERI RISC FPGA soft-core processor, Free BSD
		  operating system, and LLVM compiler, we demonstrate
		  multiple orders-of-magnitude improvement in scalability,
		  simplified programmability, and resulting tangible security
		  benefits as compared to compartmentalization based on pure
		  Memory-Management Unit (MMU) designs. We evaluate
		  incrementally deployable CHERI-based compartmentalization
		  using several real-world UNIX libraries and applications.}
}

@Article{	  watt19:weakening,
  title		= {Weakening {{WebAssembly}}},
  author	= {Watt, Conrad and Rossberg, Andreas and {Pichon-Pharabod},
		  Jean},
  year		= {2019},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {3},
  number	= {OOPSLA},
  pages		= {133:1--133:28},
  doi		= {10.1145/3360559},
  urldate	= {2023-12-06},
  abstract	= {WebAssembly (Wasm) is a safe, portable virtual instruction
		  set that can be hosted in a wide range of environments,
		  such as a Web browser. It is a low-level language whose
		  instructions are intended to compile directly to bare
		  hardware. While the initial version of Wasm focussed on
		  single-threaded computation, a recent proposal extends it
		  with low-level support for multiple threads and atomic
		  instructions for synchronised access to shared memory. To
		  support the correct compilation of concurrent programs, it
		  is necessary to give a suitable specification of its memory
		  model. Wasm's language definition is based on a fully
		  formalised specification that carefully avoids undefined
		  behaviour. We present a substantial extension to this
		  semantics, incorporating a relaxed memory model, along with
		  a few proposed extensions. Wasm's memory model is unique in
		  that its linear address space can be dynamically grown
		  during execution, while all accesses are bounds-checked.
		  This leads to the novel problem of specifying how
		  observations about the size of the memory can propagate
		  between threads. We argue that, considering desirable
		  compilation schemes, we cannot give a sequentially
		  consistent semantics to memory growth. We show that our
		  model provides sequential consistency for data-race-free
		  executions (SC-DRF). However, because Wasm is to run on the
		  Web, we must also consider interoperability of its model
		  with that of JavaScript. We show, by counter-example, that
		  JavaScript's memory model is not SC-DRF, in contrast to
		  what is claimed in its specification. We propose two
		  axiomatic conditions that should be added to the JavaScript
		  model to correct this difference. We also describe a
		  prototype SMT-based litmus tool which acts as an oracle for
		  our axiomatic model, visualising its behaviours, including
		  memory resizing.},
  keywords	= {assembly languages,just-in-time compilers,programming
		  languages,type systems,Virtual machines}
}

@InProceedings{	  watt21:two,
  title		= {Two {{Mechanisations}} of {{WebAssembly}} 1.0},
  booktitle	= {Formal {{Methods}}},
  author	= {Watt, Conrad and Rao, Xiaojia and {Pichon-Pharabod}, Jean
		  and Bodin, Martin and Gardner, Philippa},
  editor	= {Huisman, Marieke and P{\u a}s{\u a}reanu, Corina and Zhan,
		  Naijun},
  year		= {2021},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {61--79},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-90870-6_4},
  abstract	= {WebAssembly (Wasm) is a new bytecode language supported by
		  all major Web browsers, designed primarily to be an
		  efficient compilation target for low-level languages such
		  as C/C++ and Rust. It is unusual in that it is officially
		  specified through a formal semantics. An initial draft
		  specification was published in 2017~[14], with an
		  associated mechanised specification in Isabelle/HOL
		  published by Watt that found bugs in the original
		  specification, fixed before its publication~[37].},
  isbn		= {978-3-030-90870-6},
  langid	= {english},
  keywords	= {Mechanised specification,Type soundness,WasmCert}
}

@Misc{		  webassembly-community-group17:webassembly,
  title		= {{{WebAssembly}} Design},
  author	= {{WebAssembly Community Group}},
  year		= {2017-11-15, 2017},
  urldate	= {2021-05}
}

@Misc{		  webassembly-community-group18:webassembly,
  title		= {{{WebAssembly}} Security},
  author	= {{WebAssembly Community Group}},
  year		= {2018-05-04, 2018},
  urldate	= {2023-04}
}

@Misc{		  webassembly-community-group22:interface,
  title		= {Interface Types Proposal for {{WebAssembly}}},
  author	= {{WebAssembly Community Group}},
  year		= {2022-05-01, 2022},
  urldate	= {2023-05}
}

@Misc{		  webassembly-community-group22:webassembly,
  title		= {{{WebAssembly}} Proposals},
  author	= {{WebAssembly Community Group}},
  year		= {2022},
  publisher	= {Online},
  urldate	= {2022-02-22}
}

@Misc{		  webassembly22:wabt,
  title		= {{{WABT}}: {{The WebAssembly}} Binary Toolkit},
  author	= {{WebAssembly}},
  year		= {2022}
}

@Misc{		  webassemblycomponent-model,
  title		= {{{WebAssembly}}/Component-Model},
  year		= {2025},
  month		= may,
  urldate	= {2025-05-15},
  abstract	= {Repository for design and specification of the Component
		  Model},
  howpublished	= {WebAssembly}
}

@Article{	  webbers24:refinement,
  title		= {Refinement {{Type Refutations}}},
  author	= {Webbers, Robin and {von Gleissenthall}, Klaus and Jhala,
		  Ranjit},
  year		= {2024},
  month		= oct,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {305:962--305:987},
  doi		= {10.1145/3689745},
  urldate	= {2024-12-17},
  abstract	= {Refinement types combine SMT decidable constraints with a
		  compositional, syntax-directed type system to provide a
		  convenient way to statically and automatically check
		  properties of programs. However, when type checking fails,
		  programmers must use cryptic error messages that, at best,
		  point out the code location where a subtyping constraint
		  failed to determine the root cause of the failure. In this
		  paper, we introduce refinement type refutations, a new
		  approach to explaining why refinement type checking fails,
		  which mirrors the compositional way in which refinement
		  type checking is carried out. First, we show how to
		  systematically transform standard bidirectional type
		  checking rules to obtain refutations. Second, we extend the
		  approach to account for global constraint-based refinement
		  inference via the notion of a must-instantiation: a set of
		  concrete inhabitants of the types of subterms that suffice
		  to demonstrate why typing fails. Third, we implement our
		  method in HayStack---an extension to LiqidHaskell which
		  automatically finds type-refutations when refinement type
		  checking fails, and helps users understand refutations via
		  an interactive user-interface. Finally, we present an
		  empirical evaluation of HayStack using the regression
		  benchmark-set of LiqidHaskell, and the benchmark set of G2,
		  a previous method that searches for (non-compositional)
		  counterexample traces by symbolically executing Haskell
		  source. We show that HayStack can find refutations for
		  99.7\% of benchmarks, including those with complex typing
		  constructs (e.g., abstract and bounded refinements, and
		  reflection), and does so, an order of magnitude faster than
		  G2.}
}

@Article{	  weirich17:specification,
  title		= {A Specification for Dependent Types in {{Haskell}}},
  author	= {Weirich, Stephanie and Voizard, Antoine and {de Amorim},
		  Pedro Henrique Azevedo and Eisenberg, Richard A.},
  year		= {2017},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {1},
  number	= {ICFP},
  pages		= {31:1--31:29},
  doi		= {10.1145/3110275},
  urldate	= {2024-01-10},
  abstract	= {We propose a core semantics for Dependent Haskell, an
		  extension of Haskell with full-spectrum dependent types.
		  Our semantics consists of two related languages. The first
		  is a Curry-style dependently-typed language with
		  nontermination, irrelevant arguments, and equality
		  abstraction. The second, inspired by the Glasgow Haskell
		  Compiler's core language FC, is its explicitly-typed
		  analogue, suitable for implementation in GHC. All of our
		  results---chiefly, type safety, along with theorems that
		  relate these two languages---have been formalized using the
		  Coq proof assistant. Because our work is backwards
		  compatible with Haskell, our type safety proof holds in the
		  presence of nonterminating computation. However, unlike
		  other full-spectrum dependently-typed languages, such as
		  Coq, Agda or Idris, because of this nontermination,
		  Haskell's term language does not correspond to a consistent
		  logic.},
  keywords	= {Dependent Types,Haskell}
}

@InProceedings{	  weiser81:program,
  title		= {Program Slicing},
  booktitle	= {Proceedings of the 5th International Conference on
		  {{Software}} Engineering},
  author	= {Weiser, Mark},
  year		= {1981},
  month		= mar,
  series	= {{{ICSE}} '81},
  pages		= {439--449},
  publisher	= {IEEE Press},
  address	= {San Diego, California, USA},
  urldate	= {2023-11-29},
  abstract	= {Program slicing is a method used by experienced computer
		  programmers for abstracting from programs. Starting from a
		  subset of a program's behavior, slicing reduces that
		  program to a minimal form which still produces that
		  behavior. The reduced program, called a ``slice'', is an
		  independent program guaranteed to faithfully represent the
		  original program within the domain of the specified subset
		  of behavior. Finding a slice is in general unsolvable. A
		  dataflow algorithm is presented for approximating slices
		  when the behavior subset is specified as the values of a
		  set of variables at a statement. Experimental evidence is
		  presented that these slices are used by programmers during
		  debugging. Experience with two automatic slicing tools is
		  summarized. New measures of program complexity are
		  suggested based on the organization of a program's
		  slices.},
  isbn		= {978-0-89791-146-7},
  keywords	= {Data flow analysis,Debugging,Human factors,Program
		  maintenance,Program metrics,Software tools}
}

@Article{	  weiser99:computer,
  title		= {The Computer for the 21st Century},
  author	= {Weiser, Mark},
  year		= {1999},
  month		= jul,
  journal	= {ACM SIGMOBILE Mobile Computing and Communications Review},
  volume	= {3},
  number	= {3},
  pages		= {3--11},
  issn		= {1559-1662},
  doi		= {10.1145/329124.329126},
  urldate	= {2024-02-11},
  abstract	= {Specialized elements of hardware and software, connected
		  by wires, radio waves and infrared, will be so ubiquitous
		  that no one will notice their presence.}
}

@Article{	  weiss21:understanding,
  title		= {Understanding and {{Fixing Complex Faults}} in {{Embedded
		  Cyberphysical Systems}}},
  author	= {Weiss, Alexander and Gautham, Smitha and Jayakumar, Athira
		  Varma and Elks, Carl R. and Kuhn, D. Richard and Kacker,
		  Raghu N. and Preusser, Thomas B.},
  year		= {2021},
  month		= jan,
  journal	= {Computer},
  volume	= {54},
  number	= {1},
  pages		= {49--60},
  issn		= {1558-0814},
  doi		= {10.1109/MC.2020.3029975},
  urldate	= {2025-05-06},
  abstract	= {Embedded systems are becoming ubiquitous companions in all
		  our lives. This article reviews the terminology and modern
		  understanding of complex anomalies and state-of-the-art
		  debugging. It details sophisticated omniscient debugging
		  and runtime verification and describes a novel technique to
		  combine the benefits of those processes.},
  keywords	= {Cyber-physical systems,Debugging,Embedded
		  systems,Runtime,Terminology}
}

@Article{	  weiss75:time-reversibility,
  title		= {Time-Reversibility of Linear Stochastic Processes},
  author	= {Weiss, Gideon},
  year		= {1975},
  month		= dec,
  journal	= {Journal of Applied Probability},
  volume	= {12},
  number	= {4},
  pages		= {831--836},
  issn		= {0021-9002, 1475-6072},
  doi		= {10.2307/3212735},
  urldate	= {2024-11-11},
  abstract	= {Time-reversibility is defined for a process X(t) as the
		  property that \{X(t1), {\dots}, X(tn)\} and \{X(-- t1),
		  {\dots}, X(-- tn)\} have the same joint probability
		  distribution. It is shown that, for discrete mixed
		  autoregressive moving-average processes, this is a unique
		  property of Gaussian processes.},
  langid	= {english},
  keywords	= {CHARACTERISATIONS OF THE NORMAL DISTRIBUTION,SHOT
		  NOISE,STOCHASTIC PROCESSES,TIME SERIES,TIME-REVERSIBILITY}
}

@Misc{		  whitington24:debugging,
  title		= {Debugging {{Functional Programs}} by {{Interpretation}}},
  author	= {Whitington, John},
  year		= {2024},
  month		= nov,
  number	= {arXiv:2411.00637},
  eprint	= {2411.00637},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2411.00637},
  urldate	= {2025-05-08},
  abstract	= {Motivated by experience in programming and in the teaching
		  of programming, we make another assault on the longstanding
		  problem of debugging. Having explored why debuggers are not
		  used as widely as one might expect, especially in
		  functional programming environments, we define the
		  characteristics of a debugger which make it usable and thus
		  likely to be widely used. We present work on a new debugger
		  for the functional programming language OCaml which
		  operates by direct interpretation of the program source,
		  allowing the printing out of individual steps of the
		  program's evaluation, and discuss its technical
		  implementation and practical use. It has two parts: a
		  stand-alone debugger which can run OCaml programs by
		  interpretation and so allow their behaviour to be
		  inspected; and an OCaml syntax extension, which allows the
		  part of a program under scrutiny to be interpreted in the
		  same fashion as the stand-alone debugger whilst the rest of
		  the program runs natively. We show how this latter
		  mechanism can create a source-level debugging system that
		  has the characteristics of a usable debugger and so may
		  eventually be expected to be suitable for widespread
		  adoption.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Programming Languages}
}

@InProceedings{	  wieme24:distributed,
  title		= {Distributed {{Automated Testing Framework}} for
		  {{Bluetooth Mesh Applications}}},
  booktitle	= {{{NOMS}} 2024-2024 {{IEEE Network Operations}} and
		  {{Management Symposium}}},
  author	= {Wieme, Jorg and Baert, Mathias and Hoebeke, Jeroen},
  year		= {2024},
  month		= may,
  pages		= {1--5},
  issn		= {2374-9709},
  doi		= {10.1109/NOMS59830.2024.10575328},
  urldate	= {2025-05-15},
  abstract	= {We introduce a comprehensive testing framework built on
		  top of a Bluetooth Mesh Testbed, showcasing a blend of
		  user-friendly design, swift implementation, and
		  adaptability to diverse testing scenarios and technologies.
		  The framework's modular architecture ensures syntactic
		  validation, precise event scheduling, and efficient
		  execution. Its well-defined syntax facilitates easy
		  updates, catering to evolving requirements and maintaining
		  agility. Operating independently across multiple nodes and
		  accommodating various events, whether repetitive or
		  one-time, the framework proves to be a versatile and robust
		  solution for conducting tests. Tools like shared disks and
		  synchronized clocks, provided by the Testbed, further
		  enhance the framework's capability to schedule network flow
		  behavior and gain insights into network performance.
		  Overall, our testing framework presents a valuable tool for
		  researchers and practitioners seeking a seamless and
		  flexible approach to evaluate Bluetooth Mesh networks in a
		  realistic environment.},
  keywords	= {Automated testing,Bluetooth,Bluetooth Mesh,Distributed
		  testing,Mesh
		  networks,Reproducibility,Schedules,Synchronization,Syntactics,Testbed,Testing,Wireless
		  networks}
}

@Misc{		  wilkes79:birth,
  title		= {The {{Birth}} and {{Growth}} of the {{Digital Computer}}},
  author	= {Wilkes, Maurice},
  year		= {1979},
  publisher	= {Lecture delivered at the Digital Computer Museum,
		  available through the Computer History Museum},
  address	= {Boston, MA, USA},
  collaborator	= {Wilkes, Maurice}
}

@InProceedings{	  wilkin25:debugging,
  title		= {"{{Debugging}}: {{From Art}} to {{Science}}" {{A Case
		  Study}} on a {{Debugging Course}} and {{Its Impact}} on
		  {{Student Performance}} and {{Confidence}}},
  shorttitle	= {"{{Debugging}}},
  booktitle	= {Proceedings of the 56th {{ACM Technical Symposium}} on
		  {{Computer Science Education V}}. 1},
  author	= {Wilkin, G. Aaron},
  year		= {2025},
  month		= feb,
  series	= {{{SIGCSETS}} 2025},
  pages		= {1225--1231},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3641554.3701893},
  urldate	= {2025-05-07},
  abstract	= {This experience report examines a new course, "Debugging:
		  From Art to Science,'' and its impact on students'
		  debugging approach, skills, confidence, and overall
		  attitudes towards debugging. The course is designed to
		  transform perceptions and approaches to debugging from a
		  daunting task into a systematic and methodical approach,
		  implementing the scientific method. The course introduced
		  students to debugging techniques, tools, and best
		  practices, and utilized exercises from several different
		  programming languages, allowing students to apply debugging
		  techniques to a wide range of defects. This multi-language
		  approach ensured that students could generalize their
		  debugging skills. Quantitative data collected from two
		  smaller assignments with similar bugs, before and after the
		  course, showed a notable improvement in students' debugging
		  performance, with average error resolution times decreasing
		  by an average of 60\%. At the end of the course, 80\% of
		  the project teams working on a bug report in a non-trivial,
		  open-source project found and fixed the code defect using
		  the methods from the course. Qualitative data from surveys
		  and interviews revealed that students felt more confident
		  and positive about their debugging abilities, with 89\% of
		  participants expressing a heightened sense of competence
		  and reduced anxiety when facing debugging tasks. This
		  report highlights the course structure, key materials
		  covered, and the pedagogical approaches that contributed to
		  these outcomes. The findings suggest that a well-structured
		  debugging course can enhance students' practical skills and
		  alter their mindset, fostering a more confident, positive,
		  and proactive approach to debugging in their future careers.},
  isbn		= {9798400705311}
}

@Misc{		  williams14:espruino,
  title		= {Espruino},
  author	= {Williams, Gordon},
  year		= {2014},
  publisher	= {Online},
  commit	= {06661890de479ac1846772567f341f0707b339a7}
}

@Misc{		  wills22:bug,
  title		= {The {{Bug}} in the {{Computer Bug Story}}},
  author	= {Wills, Matthew},
  year		= {2022},
  month		= may,
  journal	= {JSTOR Daily},
  urldate	= {2025-05-05},
  abstract	= {Soon after a team of engineers discovered a moth in a
		  machine at Harvard, the word "bug" became a standard part
		  of the programmer's lexicon. Or did it?},
  howpublished	= {https://daily.jstor.org/the-bug-in-the-computer-bug-story/},
  langid	= {american}
}

@InProceedings{	  wolinski19:globally,
  title		= {Globally Optimal Page Breaking with Column Balancing: A
		  Case Study},
  shorttitle	= {Globally Optimal Page Breaking with Column Balancing},
  booktitle	= {Proceedings of the {{ACM Symposium}} on {{Document
		  Engineering}} 2019},
  author	= {Woli{\'n}ski, Marcin},
  year		= {2019},
  month		= sep,
  series	= {{{DocEng}} '19},
  pages		= {1--4},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3342558.3345405},
  urldate	= {2024-01-09},
  abstract	= {The paper presents a dynamic programming algorithm that
		  finds the globally optimal sequence of page breaks for a
		  book avoiding widows and orphans when the only source of
		  variation is the possibility to break selected paragraphs
		  into varying number of lines by skillful selection of line
		  breaks. The text is set in two-columns, on each last page
		  of a chapter the columns must be balanced. We show how the
		  balancing process can be included in the global
		  optimization. The algorithm is applied to a real-life
		  problem of typesetting a small-format two-column 800 pages
		  long dictionary. We analyze the typesetting process
		  including the proofing phase where local changes in the
		  text can globally influence page breaks. This problem
		  provides an ideal test-bed for global optimization since
		  the typographic model involved is relatively easy - the
		  material processed is merely a stream of paragraphs. On the
		  other hand, breaking the book under these conditions is a
		  very tedious and frustrating job for a human typesetter, as
		  it typically requires hours of trial and error.},
  isbn		= {978-1-4503-6887-2},
  keywords	= {automatic layout,global optimization,page
		  breaking,typesetting}
}

@Article{	  wong17:be,
  title		= {Be More Familiar with Our Enemies and Pave the Way
		  Forward: {{A}} Review of the Roles Bugs Played in Software
		  Failures},
  shorttitle	= {Be More Familiar with Our Enemies and Pave the Way
		  Forward},
  author	= {Wong, W. Eric and Li, Xuelin and Laplante, Philip A.},
  year		= {2017},
  month		= nov,
  journal	= {Journal of Systems and Software},
  volume	= {133},
  pages		= {68--94},
  issn		= {0164-1212},
  doi		= {10.1016/j.jss.2017.06.069},
  urldate	= {2025-05-06},
  abstract	= {There has been an increasing frequency of failures due to
		  defective software that cost millions of dollars. Recent
		  high profile incidents have drawn increased attention to
		  the risks of failed software systems to the public. Yet
		  aside from the Therac-25 case, very few incidents of
		  software failure causing humans harm have been proven and
		  widely reported. With increased government oversight and
		  the expanded use of social networking for real time
		  reporting of problems, we are only beginning to understand
		  the potential for major injury or death related to software
		  failures. However, debugging defective software can be
		  costly and time consuming. Moreover, undetected bugs could
		  induce great harm to the public when software systems are
		  applied in safety-critical areas, such as consumer
		  products, public infrastructure, transportation systems,
		  etc. Therefore, it is vital that we remove these bugs as
		  early as possible. To gain more understanding of the nature
		  of these bugs, we review the reported software failures
		  that have impacted the health, safety, and welfare of the
		  public. A focus on lessons learned and implications for
		  future software systems is also provided which acts as
		  guidelines for engineers to improve the quality of their
		  products and avoid similar failures from happening.},
  keywords	= {Accidents,Bugged software systems,Lessons
		  learned,Mishaps,Software failures}
}

@Article{	  woodruff14:cheri,
  title		= {The {{CHERI}} Capability Model: Revisiting {{RISC}} in an
		  Age of Risk},
  shorttitle	= {The {{CHERI}} Capability Model},
  author	= {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall,
		  David and Moore, Simon W. and Anderson, Jonathan and Davis,
		  Brooks and Laurie, Ben and Neumann, Peter G. and Norton,
		  Robert and Roe, Michael},
  year		= {2014},
  month		= jun,
  journal	= {ACM SIGARCH Computer Architecture News},
  volume	= {42},
  number	= {3},
  pages		= {457--468},
  issn		= {0163-5964},
  doi		= {10.1145/2678373.2665740},
  urldate	= {2024-01-18},
  abstract	= {Motivated by contemporary security challenges, we
		  reevaluate and refine capability-based addressing for the
		  RISC era. We present CHERI, a hybrid capability model that
		  extends the 64-bit MIPS ISA with byte-granularity memory
		  protection. We demonstrate that CHERI enables language
		  memory model enforcement and fault isolation in hardware
		  rather than software, and that the CHERI mechanisms are
		  easily adopted by existing programs for efficient
		  in-program memory safety. In contrast to past capability
		  models, CHERI complements, rather than replaces, the
		  ubiquitous page-based protection mechanism, providing a
		  migration path towards deconflating data-structure
		  protection and OS memory management. Furthermore, CHERI
		  adheres to a strict RISC philosophy: it maintains a
		  load-store architecture and requires only singlecycle
		  instructions, and supplies protection primitives to the
		  compiler, language runtime, and operating system. We
		  demonstrate a mature FPGA implementation that runs the
		  FreeBSD operating system with a full range of software and
		  an open-source application suite compiled with an extended
		  LLVM to use CHERI memory protection. A limit study compares
		  published memory safety mechanisms in terms of instruction
		  count and memory overheads. The study illustrates that
		  CHERI is performance-competitive even while providing
		  assurance and greater flexibility with simpler hardware}
}

@InProceedings{	  xie17:principles,
  title		= {Principles, Patterns, and Techniques for Designing and
		  Implementing Practical Fluent Interfaces in {{Java}}},
  booktitle	= {Proceedings {{Companion}} of the 2017 {{ACM SIGPLAN
		  International Conference}} on {{Systems}}, {{Programming}},
		  {{Languages}}, and {{Applications}}: {{Software}} for
		  {{Humanity}}},
  author	= {Xie, Haochen},
  year		= {2017},
  month		= oct,
  series	= {{{SPLASH Companion}} 2017},
  pages		= {45--47},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3135932.3135948},
  urldate	= {2025-05-04},
  abstract	= {In this research, the author sought a meta-theory that
		  establishes essential concepts and fundamental techniques
		  in helping programmers design and implement practical
		  fluent interfaces in the Java language. An anatomy of the
		  conceptual establishment of fluent interfaces is
		  established and presented. Six primitives, roles that a key
		  method could play are also identified. The author also
		  coined the term transition choreography and attributed it
		  as the core of the design theory for practical fluent
		  interfaces in Java. Results in this research may apply as
		  well in languages other than Java.},
  isbn		= {978-1-4503-5514-8}
}

@Article{	  xie19:automatic,
  title		= {Automatic {{Loop Summarization}} via {{Path Dependency
		  Analysis}}},
  author	= {Xie, Xiaofei and Chen, Bihuan and Zou, Liang and Liu, Yang
		  and Le, Wei and Li, Xiaohong},
  year		= {2019},
  month		= jun,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {45},
  number	= {6},
  pages		= {537--557},
  issn		= {1939-3520},
  doi		= {10.1109/TSE.2017.2788018},
  urldate	= {2024-03-18},
  abstract	= {Analyzing loops is very important for various software
		  engineering tasks such as bug detection, test case
		  generation and program optimization. However, loops are
		  very challenging structures for program analysis,
		  especially when (nested) loops contain multiple paths that
		  have complex interleaving relationships. In this paper, we
		  propose the path dependency automaton (PDA) to capture the
		  dependencies among the multiple paths in a loop. Based on
		  the PDA, we first propose a loop classification to
		  understand the complexity of loop summarization. Then, we
		  propose a loop analysis framework, named Proteus, which
		  takes a loop program and a set of variables of interest as
		  inputs and summarizes path-sensitive loop effects (i.e.,
		  disjunctive loop summary) on the variables of interest. An
		  algorithm is proposed to traverse the PDA to summarize the
		  effect for all possible executions in the loop. We have
		  evaluated Proteus using loops from five open-source
		  projects and two well-known benchmarks and applying the
		  disjunctive loop summary to three applications: loop bound
		  analysis, program verification and test case generation.
		  The evaluation results have demonstrated that Proteus can
		  compute a more precise bound than the existing loop bound
		  analysis techniques; Proteus can significantly outperform
		  the state-of-the-art tools for loop program verification;
		  and Proteus can help generate test cases for deep loops
		  within one second, while symbolic execution tools KLEE and
		  Pex either need much more time or fail.},
  keywords	= {Automata,Benchmark testing,Debugging,Disjunctive loop
		  summary,path dependency automaton,path interleaving,Public
		  domain software}
}

@Article{	  xu05:brief,
  title		= {A Brief Survey of Program Slicing},
  author	= {Xu, Baowen and Qian, Ju and Zhang, Xiaofang and Wu,
		  Zhongqiang and Chen, Lin},
  year		= {2005},
  month		= mar,
  journal	= {SIGSOFT Softw. Eng. Notes},
  volume	= {30},
  number	= {2},
  pages		= {1--36},
  issn		= {0163-5948},
  doi		= {10.1145/1050849.1050865},
  urldate	= {2025-03-04},
  abstract	= {Program slicing is a technique to extract program parts
		  with respect to some special computation. Since Weiser
		  first proposed the notion of slicing in 1979, hundreds of
		  papers have been presented in this area. Tens of variants
		  of slicing have been studied, as well as algorithms to
		  compute them. Different notions of slicing have different
		  properties and different applications. These notions vary
		  from Weiser's syntax-preserving static slicing to amorphous
		  slicing which is not syntax-preserving, and the algorithms
		  can be based on dataflow equations, information-flow
		  relations or dependence graphs.Slicing was first-developed
		  to facilitate debugging, but it is then found helpful in
		  many aspects of the software development life cycle,
		  including program debugging, software testing, software
		  measurement, program comprehension, software maintenance,
		  program parallelization and so on.Over the last two
		  decades, several surveys on program slicing have been
		  presented. However, most of them only reviewed parts of
		  researches on program slicing or have now been out of date.
		  People who are interested in program slicing need more
		  information about the up to date researches. Our survey
		  fills this gap. In this paper, we briefly review most of
		  existing slicing techniques including static slicing,
		  dynamic slicing and the latest slicing techniques. We also
		  discuss the contribution of each work and compare the major
		  difference between them. Researches on slicing are
		  classified by the research hot spots such that people can
		  be kept informed of the overall program slicing
		  researches.}
}

@InProceedings{	  yao05:framework,
  title		= {A Framework for Testing Distributed Software Components},
  booktitle	= {Canadian {{Conference}} on {{Electrical}} and {{Computer
		  Engineering}}},
  author	= {Yao, Y. and Wang, Y.},
  year		= {2005},
  volume	= {2005},
  pages		= {1566--1569},
  doi		= {10.1109/CCECE.2005.1557280},
  abstract	= {Component-based software engineering is an influential
		  trend in software engineering. Adopting component-based
		  techniques, a system can be constructed by synthesis of
		  various distributed components. This paper presents a
		  framework of remote testing of distributed software
		  components. Based on the CORBA architecture and Java
		  technology, this paper provides an environment to allow a
		  client-side software component to define tests for a
		  black-box component published on the server-side. This
		  technique simplifies test execution, test results check and
		  report, and supports test reuse and test automation. The
		  paper reveals a practical approach to test software
		  components by enhancing software component testability and
		  test re-usability. The incremental testing framework
		  introduced in this paper is helpful in saving time, energy,
		  and cost required for testing distributed components and
		  for enhancing software quality. A testing supporting tool
		  is implemented to facilitate distributed component testing
		  based on CORBA. {\copyright} 2005 IEEE.},
  keywords	= {Component-based software engineering,Distribute component
		  testing,Software testing,Test-reusability,Testability}
}

@InProceedings{	  yao05:frameworka,
  title		= {A Framework for Testing Distributed Software Components},
  booktitle	= {Canadian {{Conference}} on {{Electrical}} and {{Computer
		  Engineering}}},
  author	= {Yao, Y. and Wang, Y.},
  year		= {2005},
  volume	= {2005},
  pages		= {1566--1569},
  doi		= {10.1109/CCECE.2005.1557280},
  abstract	= {Component-based software engineering is an influential
		  trend in software engineering. Adopting component-based
		  techniques, a system can be constructed by synthesis of
		  various distributed components. This paper presents a
		  framework of remote testing of distributed software
		  components. Based on the CORBA architecture and Java
		  technology, this paper provides an environment to allow a
		  client-side software component to define tests for a
		  black-box component published on the server-side. This
		  technique simplifies test execution, test results check and
		  report, and supports test reuse and test automation. The
		  paper reveals a practical approach to test software
		  components by enhancing software component testability and
		  test re-usability. The incremental testing framework
		  introduced in this paper is helpful in saving time, energy,
		  and cost required for testing distributed components and
		  for enhancing software quality. A testing supporting tool
		  is implemented to facilitate distributed component testing
		  based on CORBA. {\copyright} 2005 IEEE.},
  keywords	= {Component-based software engineering,Distribute component
		  testing,Software testing,Test-reusability,Testability}
}

@Article{	  ye22:oblivious,
  title		= {Oblivious Algebraic Data Types},
  author	= {Ye, Qianchuan and Delaware, Benjamin},
  year		= {2022},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {POPL},
  pages		= {51:1--51:29},
  doi		= {10.1145/3498713},
  urldate	= {2023-10-17},
  abstract	= {Secure computation allows multiple parties to compute
		  joint functions over private data without leaking any
		  sensitive data, typically using powerful cryptographic
		  techniques. Writing secure applications using these
		  techniques directly can be challenging, resulting in the
		  development of several programming languages and compilers
		  that aim to make secure computation accessible.
		  Unfortunately, many of these languages either lack or have
		  limited support for rich recursive data structures, like
		  trees. In this paper, we propose a novel representation of
		  structured data types, which we call oblivious algebraic
		  data types, and a language for writing secure computations
		  using them. This language combines dependent types with
		  constructs for oblivious computation, and provides a
		  security-type system which ensures that adversaries can
		  learn nothing more than the result of a computation. Using
		  this language, authors can write a single function over
		  private data, and then easily build an equivalent secure
		  computation according to a desired public view of their
		  data.},
  keywords	= {Algebraic Data Types,Dependent Types,Multiparty
		  Computation,Oblivious Computation}
}

@Article{	  yi-gitler20:overview,
  title		= {Overview of {{Time Synchronization}} for {{IoT
		  Deployments}}: {{Clock Discipline Algorithms}} and
		  {{Protocols}}},
  shorttitle	= {Overview of {{Time Synchronization}} for {{IoT
		  Deployments}}},
  author	= {Yi{\u g}itler, H{\"u}seyin and Badihi, Behnam and
		  J{\"a}ntti, Riku},
  year		= {2020},
  month		= jan,
  journal	= {Sensors},
  volume	= {20},
  number	= {20},
  pages		= {5928},
  publisher	= {Multidisciplinary Digital Publishing Institute},
  issn		= {1424-8220},
  doi		= {10.3390/s20205928},
  urldate	= {2025-03-04},
  abstract	= {Internet of Things (IoT) is expected to change the
		  everyday life of its users by enabling data exchanges among
		  pervasive things through the Internet. Such a broad aim,
		  however, puts prohibitive constraints on applications
		  demanding time-synchronized operation for the chronological
		  ordering of information or synchronous execution of some
		  tasks, since in general the networks are formed by entities
		  of widely varying resources. On one hand, the existing
		  contemporary solutions for time synchronization, such as
		  Network Time Protocol, do not easily tailor to
		  resource-constrained devices, and on the other, the
		  available solutions for constrained systems do not extend
		  well to heterogeneous deployments. In this article, the
		  time synchronization problems for IoT deployments for
		  applications requiring a coherent notion of time are
		  studied. Detailed derivations of the clock model and
		  various clock relation models are provided. The clock
		  synchronization methods are also presented for different
		  models, and their expected performance are derived and
		  illustrated. A survey of time synchronization protocols is
		  provided to aid the IoT practitioners to select appropriate
		  components for a deployment. The clock discipline
		  algorithms are presented in a tutorial format, while the
		  time synchronization methods are summarized as a survey.
		  Therefore, this paper is a holistic overview of the
		  available time synchronization methods for IoT
		  deployments.},
  copyright	= {http://creativecommons.org/licenses/by/3.0/},
  langid	= {english},
  keywords	= {capillary networks,clock discipline algorithms,clock
		  synchronization,internet of things,time synchronization
		  protocols,wireless sensor networks}
}

@Article{	  yi24:compatible,
  title		= {Compatible {{Branch Coverage Driven Symbolic Execution}}
		  for {{Efficient Bug Finding}}},
  author	= {Yi, Qiuping and Yu, Yifan and Yang, Guowei},
  year		= {2024},
  month		= jun,
  journal	= {Reproduction Package For Article `Compatible Branch
		  Coverage Driven Symbolic Execution for Efficient Bug
		  Finding`},
  volume	= {8},
  number	= {PLDI},
  pages		= {213:1633--213:1655},
  doi		= {10.1145/3656443},
  urldate	= {2024-08-20},
  abstract	= {Symbolic execution is a powerful technique for bug finding
		  by generating test inputs to systematically explore all
		  feasible paths within a given threshold. However, its
		  practical usage is often limited by the path explosion
		  problem. In this paper, we propose compatible branch
		  coverage driven symbolic execution for efficient bug
		  finding. Our new technique owns a novel path-pruning
		  strategy obtained from program dependency analysis to
		  effectively avoid unnecessary explorations. Specifically,
		  based on a Compatible Branch Set, our technique directs
		  symbolic execution to explore feasible branches while
		  soundly pruning redundant paths that have no new
		  contributions to branch coverage. We have implemented our
		  approach atop KLEE and conducted experiments on a set of
		  programs from Siemens Suite, GNU Coreutils, and other
		  real-world programs. Experimental results show that,
		  compared with the state-of-the-art symbolic execution
		  techniques, our approach always uses significantly less
		  time to reproduce bugs while achieving the same or better
		  branch coverage. On average, our approach got over 45\%
		  path reduction and 3x speedup on the GNU Coreutils
		  programs.}
}

@InProceedings{	  yokoyama07:reversible,
  title		= {A Reversible Programming Language and Its Invertible
		  Self-Interpreter},
  booktitle	= {Proceedings of the 2007 {{ACM SIGPLAN}} Symposium on
		  {{Partial}} Evaluation and Semantics-Based Program
		  Manipulation},
  author	= {Yokoyama, Tetsuo and Gl{\"u}ck, Robert},
  year		= {2007},
  month		= jan,
  series	= {{{PEPM}} '07},
  pages		= {144--153},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1244381.1244404},
  urldate	= {2024-11-09},
  abstract	= {A reversible programming language supports deterministic
		  forward and backward computation. We formalize the
		  programming language Janus and prove its reversibility. We
		  provide a program inverter for the language and implement a
		  self-interpreter that achieves deterministic forward and
		  backward interpretation of Janus programs without using a
		  computation history. As the self-interpreter is implemented
		  in a reversible language, it is invertible using local
		  program inversion. Many physical phenomena are reversible
		  and we demonstrate the power of Janus by implementing a
		  reversible program for discrete simulation of the
		  Schr{\"o}dinger wave equation that can be inverted as well
		  as run forward and backward.},
  isbn		= {978-1-59593-620-2}
}

@InProceedings{	  yokoyama08:principles,
  title		= {Principles of a Reversible Programming Language},
  booktitle	= {Proceedings of the 5th Conference on {{Computing}}
		  Frontiers},
  author	= {Yokoyama, Tetsuo and Axelsen, Holger Bock and Gl{\"u}ck,
		  Robert},
  year		= {2008},
  month		= may,
  series	= {{{CF}} '08},
  pages		= {43--54},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1366230.1366239},
  urldate	= {2024-11-10},
  abstract	= {The principles of reversible programming languages are
		  explicated and illustrated with reference to the design of
		  a high-level imperative language, Janus. The fundamental
		  properties for such languages include backward as well as
		  forward determinism and reversible updates of data. The
		  unique design features of the language include explicit
		  post-condition assertions, direct access to an inverse
		  semantics and the possibility of clean
		  (\{{\textbackslash}ie\}, garbage-free) computation of
		  injective functions. We suggest the clean simulation of
		  reversible Turing machines as a criterion for computing
		  strength of reversible languages, and demonstrate this for
		  Janus. We show the practicality of the language by
		  implementation of a reversible fast Fourier transform. Our
		  results indicate that the reversible programming paradigm
		  has fundamental properties that are relevant to many
		  different areas of computer science.},
  isbn		= {978-1-60558-077-7}
}

@InProceedings{	  yokoyama12:towards,
  title		= {Towards a {{Reversible Functional Language}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Yokoyama, Tetsuo and Axelsen, Holger Bock and Gl{\"u}ck,
		  Robert},
  editor	= {De Vos, Alexis and Wille, Robert},
  year		= {2012},
  pages		= {14--29},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-29517-1_2},
  abstract	= {We identify concepts of reversibility for a functional
		  language by means of a set of semantic rules with specific
		  properties. These properties include injectivity along with
		  local backward determinism, an important operational
		  property for an efficient reversible language. We define a
		  concise reversible first-order functional language in which
		  access to the backward semantics is provided to the
		  programmer by inverse function calls. Reversibility
		  guarantees that in this language a backward run (inverse
		  interpretation) is as fast as the corresponding forward run
		  itself. By adopting a symmetric first-match policy for case
		  expressions, we can write overlapping patterns in case
		  branches, as is customary in ordinary functional languages,
		  and also in leaf expressions, unlike existing inverse
		  interpreter methods, which enables concise programs. In
		  patterns, the use of a duplication/equality operator also
		  simplifies inverse computation and program inversion. We
		  discuss the advantages of a reversible functional language
		  using example programs, including run-length encoding.
		  Program inversion is seen to be as lightweight as for
		  imperative reversible languages and realized by recursive
		  descent. Finally, we show that the proposed language is
		  r-Turing complete.},
  isbn		= {978-3-642-29517-1},
  langid	= {english},
  keywords	= {Functional Language,General Matcher,Inverse
		  Computation,Operational Semantic,Turing Machine}
}

@Misc{		  yukihiro23:mruby,
  title		= {Mruby. Mruby Is the Lightweight Implementation of the
		  {{Ruby}} Language Complying with Part of the {{ISO}}
		  Standard. Mruby Can Be Linked and Embedded within Your
		  Application.},
  author	= {Yukihiro, Matsumoto and others},
  year		= {2023},
  urldate	= {2023-05},
  lastaccessed	= {May 11, 2023}
}

@InProceedings{	  yvon21:small,
  title		= {A Small Scheme {{VM}}, Compiler, and {{REPL}} in 4k},
  booktitle	= {Proceedings of the 13th {{ACM SIGPLAN International
		  Workshop}} on {{Virtual Machines}} and {{Intermediate
		  Languages}}},
  author	= {Yvon, Samuel and Feeley, Marc},
  year		= {2021},
  month		= oct,
  series	= {{{VMIL}} 2021},
  pages		= {14--24},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3486606.3486783},
  urldate	= {2025-01-14},
  abstract	= {Compact language implementations are increasingly popular
		  for use in resource constrained environments. For embedded
		  applications such as robotics and home automation, it is
		  useful to support a Read-Eval-Print-Loop (REPL) so that a
		  basic level of interactive development is possible directly
		  on the device. Due to its minimalistic design, the Scheme
		  language is particularly well suited for such applications
		  and several implementations are available with different
		  tradeoffs. In this paper we explain the design and
		  implementation of Ribbit, a compact Scheme system that
		  supports a REPL, is extensible and has a 4 KB executable
		  code footprint.},
  isbn		= {978-1-4503-9109-2}
}

@Article{	  zelkowitz73:reversible,
  title		= {Reversible Execution},
  author	= {Zelkowitz, M. V.},
  year		= {1973},
  month		= sep,
  journal	= {Commun. ACM},
  volume	= {16},
  number	= {9},
  pages		= {566},
  issn		= {0001-0782},
  doi		= {10.1145/362342.362360},
  urldate	= {2024-11-10},
  abstract	= {The ability to backtrack, or retrace, the execution of a
		  computer program has gained wider acceptance recently as a
		  desired feature within a programming language. This is
		  particularly useful in two different applications: (1) In
		  debugging systems where the trace output is saved and can
		  be interrogated under programmer control [1, 3]; (2) In
		  artificial intelligence applications where one is trying to
		  prove a certain result. It is frequently necessary to
		  backup the proof and try some alternative path [2].}
}

@Book{		  zeller05:why,
  title		= {Why {{Programs Fail}}: {{A Guide}} to {{Systematic
		  Debugging}}},
  shorttitle	= {Why {{Programs Fail}}},
  author	= {Zeller, Andreas},
  year		= {2005},
  month		= sep,
  publisher	= {Morgan Kaufmann Publishers Inc.},
  address	= {San Francisco, CA, USA},
  isbn		= {978-1-55860-866-5}
}

@Book{		  zeller09:why,
  title		= {Why Programs Fail: A Guide to Systematic Debugging},
  author	= {Zeller, Andreas},
  year		= {2009},
  publisher	= {Morgan Kaufmann}
}

@Misc{		  zerynth-s-r-l-21:zerynth,
  title		= {Zerynth {{Technical}} Reference v3.0.3},
  author	= {{Zerynth s.r.l.}},
  year		= {2021},
  month		= jul,
  publisher	= {Zerynth s.r.l.},
  urldate	= {2021-08-03}
}

@Article{	  zhang23:interval,
  title		= {Interval {{Parsing Grammars}} for {{File Format
		  Parsing}}},
  author	= {Zhang, Jialun and Morrisett, Greg and Tan, Gang},
  year		= {2023},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {PLDI},
  pages		= {150:1073--150:1095},
  doi		= {10.1145/3591264},
  urldate	= {2023-10-20},
  abstract	= {File formats specify how data is encoded for persistent
		  storage. They cannot be formalized as context-free grammars
		  since their specifications include context-sensitive
		  patterns such as the random access pattern and the
		  type-length-value pattern. We propose a new grammar
		  mechanism called Interval Parsing Grammars IPGs) for file
		  format specifications. An IPG attaches to every
		  nonterminal/terminal an interval, which specifies the range
		  of input the nonterminal/terminal consumes. By connecting
		  intervals and attributes, the context-sensitive patterns in
		  file formats can be well handled. In this paper, we
		  formalize IPGs' syntax as well as its semantics, and its
		  semantics naturally leads to a parser generator that
		  generates a recursive-descent parser from an IPG. In
		  general, IPGs are declarative, modular, and enable
		  termination checking. We have used IPGs to specify a number
		  of file formats including ZIP, ELF, GIF, PE, and part of
		  PDF; we have also evaluated the performance of the
		  generated parsers.},
  keywords	= {Context-sensitive Grammars,File Formats}
}

@InProceedings{	  zhou22:synthesizing,
  title		= {Synthesizing Analytical {{SQL}} Queries from Computation
		  Demonstration},
  booktitle	= {Proceedings of the 43rd {{ACM SIGPLAN International
		  Conference}} on {{Programming Language Design}} and
		  {{Implementation}}},
  author	= {Zhou, Xiangyu and Bodik, Rastislav and Cheung, Alvin and
		  Wang, Chenglong},
  year		= {2022},
  month		= jun,
  series	= {{{PLDI}} 2022},
  pages		= {168--182},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3519939.3523712},
  urldate	= {2023-10-20},
  abstract	= {Analytical SQL is widely used in modern database
		  applications and data analysis. However, its partitioning
		  and grouping operators are challenging for novice users.
		  Unfortunately, programming by example, shown effective on
		  standard SQL, are less attractive because examples for
		  analytical queries are more laborious to solve by hand. To
		  make demonstrations easier to author, we designed a new
		  end-user specification, programming by computation
		  demonstration, that allows the user to demonstrate the task
		  using a (possibly incomplete) cell-level computation trace.
		  This specification is exploited in a new abstraction-based
		  synthesis algorithm to prove that a partially formed query
		  cannot be completed to satisfy the specification, allowing
		  us to prune the search tree. We implemented our approach in
		  a tool named Sickle and tested it on 80 real-world
		  analytical SQL tasks. Results show that even from small
		  demonstrations, Sickle can solve 76 tasks, in 12.8 seconds
		  on average, while the prior approaches can solve only 60
		  tasks and are on average 22.5 times slower. Furthermore,
		  our user study with 13 participants reveals that our
		  specification increases user efficiency and confidence on
		  challenging tasks.},
  isbn		= {978-1-4503-9265-5},
  keywords	= {program synthesis,programing languages}
}

@Article{	  zhu01:denotational,
  title		= {Denotational Semantics of Programming Languages and
		  Compiler Generation in {{PowerEpsilon}}},
  author	= {Zhu, Ming-Yuan},
  year		= {2001},
  month		= sep,
  journal	= {SIGPLAN Not.},
  volume	= {36},
  number	= {9},
  pages		= {39--53},
  issn		= {0362-1340},
  doi		= {10.1145/609769.609777},
  urldate	= {2025-03-01},
  abstract	= {Programming in constructive type theory corresponds to
		  theorem proving in mathematics: the specification plays the
		  role of the proposition to be proved and the program is
		  obtained from the proof. In this paper, we present an
		  approach of using constructive type theory to derive a
		  compiler of a given programming language from its
		  denotational semantic definition. The development is
		  supported by a proof development system called
		  PowerEpsilon.}
}

@Article{	  zhu01:formal,
  title		= {Formal Specifications of Debuggers},
  author	= {Zhu, Ming-Yuan},
  year		= {2001},
  month		= sep,
  journal	= {SIGPLAN Not.},
  volume	= {36},
  number	= {9},
  pages		= {54--63},
  issn		= {0362-1340},
  doi		= {10.1145/609769.609778},
  urldate	= {2025-03-01},
  abstract	= {Programming in constructive type theory corresponds to
		  theorem proving in mathematics: the specification plays the
		  role of the proposition to be proved and the program is
		  obtained from the proof. In this paper, we present an
		  approach of using constructive type theory to derive a
		  debugger of a given programming language from its
		  denotational semantic definition. The development is
		  supported by a proof development system called
		  PowerEpsilon.}
}

@TechReport{	  zhu91:higher-order,
  title		= {A Higher-Order Lambda Calculus: {{PowerEpsilon}}},
  author	= {Zhu, Ming-Yuan and Wang, {\relax CW}},
  year		= {1991},
  institution	= {Technical report, Beijing Institute of Systems
		  Engineering, Beijing}
}

@InProceedings{	  zhu92:program,
  title		= {Program Derivation in {{PowerEpsilon}}},
  booktitle	= {1992 {{Proceedings}}. {{The Sixteenth Annual International
		  Computer Software}} and {{Applications Conference}}},
  author	= {Zhu, M.-Y. and Wang, C.-W.},
  year		= {1992},
  month		= jan,
  pages		= {206,207,208,209,210,211--206,207,208,209,210,211},
  publisher	= {IEEE Computer Society},
  doi		= {10.1109/CMPSAC.1992.217567},
  urldate	= {2025-03-01},
  abstract	= {The authors present a proof development system called
		  PowerEpsilon, based on a constructive type theory which can
		  be used as a formal program development system for deriving
		  a program from a specification. PowerEpsilon is a
		  polymorphic language based on Martin-Lof's type theory and
		  the calculus of constructions. In PowerEpsilon, the concept
		  of limit of type universe hierarchies and a scheme for
		  inductive define types are introduced. The system can be
		  used as both a programming language with a very rich set of
		  data structures and a metalanguage for formalizing
		  constructive mathematics. The system has been implemented.
		  A programming exercise is given to show how the system
		  works.},
  langid	= {english}
}

@Article{	  zolfaghari21:root,
  title		= {Root Causing, Detecting, and Fixing Flaky Tests: {{State}}
		  of the Art and Future Roadmap},
  shorttitle	= {Root Causing, Detecting, and Fixing Flaky Tests},
  author	= {Zolfaghari, Behrouz and Parizi, Reza M. and Srivastava,
		  Gautam and Hailemariam, Yoseph},
  year		= {2021},
  journal	= {Software: Practice and Experience},
  volume	= {51},
  number	= {5},
  pages		= {851--867},
  issn		= {1097-024X},
  doi		= {10.1002/spe.2929},
  urldate	= {2025-05-04},
  abstract	= {A flaky test is a test that may lead to different results
		  in different runs on a single code under test without any
		  change in the test code. Test flakiness is a noxious
		  phenomenon that slows down software deployment, and
		  increases the expenditures in a broad spectrum of platforms
		  such as software-defined networks and Internet of Things
		  environments. Industrial institutes and labs have conducted
		  a whole lot of research projects aiming at tackling this
		  problem. Although this issue has been receiving more
		  attention from academia in recent years, the academic
		  research community is still behind the industry in this
		  area. A systematic review and trend analysis on the
		  existing approaches for detecting and root causing flaky
		  tests can pave the way for future research on this topic.
		  This can help academia keep pace with industrial
		  advancements and even lead the research in this field. This
		  article first presents a comprehensive review of recent
		  achievements of the industry as well as academia regarding
		  the detection and mitigation of flaky tests. In the next
		  step, recent trends in this line of research are analyzed
		  and a roadmap is established for future research.},
  langid	= {english},
  keywords	= {detection,flaky testing,software,tools}
}
