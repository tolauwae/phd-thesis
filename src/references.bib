
@InProceedings{	  abadi89,
  title		= {Dynamic Typing in a Statically-Typed Language},
  booktitle	= {Proceedings of the 16th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Abadi, M. and Cardelli, L. and Pierce, B. and Plotkin,
		  G.},
  year		= {1989},
  month		= jan,
  series	= {{{POPL}} '89},
  pages		= {213--227},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/75277.75296},
  urldate	= {2023-10-20},
  abstract	= {Statically-typed programming languages allow earlier error
		  checking, better enforcement of disciplined programming
		  styles, and generation of more efficient object code than
		  languages where all type-consistency checks are performed
		  at runtime. However, even in statically-type languages,
		  there is often the need to deal with data whose type cannot
		  be known at compile time. To handle such situations safely,
		  we propose to add a type Dynamic whose values are pairs of
		  a value v and a type tag T where v has the type denoted by
		  T. Instances of Dynamic are built with an explicit tagging
		  construct and inspected with a type-safe typecase
		  construct. This paper is an exploration of the syntax,
		  operational semantics, and denotational semantics of a
		  simple language with the type Dynamic. We give examples of
		  how dynamically-typed values might be used in programming.
		  Then we discuss an operational semantics for our language
		  and obtain a soundness theorem. We present two formulations
		  of the denotational semantics of this language and relate
		  them to the operational semantics. Finally, we consider the
		  implications of polymorphism and some implementation
		  issues.},
  isbn		= {978-0-89791-294-5}
}

@Article{	  agrawal91,
  title		= {An Execution-Backtracking Approach to Debugging},
  author	= {Agrawal, H. and De Millo, R.A. and Spafford, E.H.},
  year		= {1991},
  month		= may,
  journal	= {IEEE Software},
  volume	= {8},
  number	= {3},
  pages		= {21--26},
  issn		= {1937-4194},
  doi		= {10.1109/52.88940},
  urldate	= {2024-11-11},
  abstract	= {Spyder, a system for selective checkpointing of
		  computational sequences, is presented. It lets users
		  backtrack from checkpoints without the need to reexecute
		  the program to reach recent prior states. In contrast to
		  more comprehensive (and storage-intensive) checkpointing
		  schemes, backtracking in this approach is constrained to
		  limit storage requirements. The resulting debugger offers a
		  structured view of dynamic events, similar to lexical scope
		  rules' effect on static visibility. The debugger also
		  speeds backtracking to statements before loops and provides
		  what-if capabilities.{$<>$}},
  keywords	= {Debugging,Displays,Prototypes,Testing}
}

@Article{	  agrawal93,
  title		= {Debugging with Dynamic Slicing and Backtracking},
  author	= {Agrawal, Hiralal and Demillo, Richard A. and Spafford,
		  Eugene H.},
  year		= {1993},
  journal	= {Software: Practice and Experience},
  volume	= {23},
  number	= {6},
  pages		= {589--616},
  issn		= {1097-024X},
  doi		= {10.1002/spe.4380230603},
  urldate	= {2023-11-07},
  abstract	= {Programmers spend considerable time debugging code.
		  Symbolic debuggers provide some help but the task remains
		  complex and difficult. Other than breakpoints and tracing,
		  these tools provide little high-level help. Programmers
		  must perform many tasks manually that the tools could
		  perform automatically, such as finding which statements in
		  the program affect the value of an output variable for a
		  given test case, and what was the value of a given variable
		  when the control last reached a given program location. If
		  debugging tools provided explicit support for these tasks,
		  the debugging process could be automated to a significant
		  extent. In this paper we present a debugging model, based
		  on dynamic program slicing and execution backtracking
		  techniques, that easily lends itself to automation. This
		  model is based on experience with using these techniques to
		  debug software. We also present a prototype debugging tool,
		  SPYDER, that explicitly supports the proposed model, and
		  with which we are performing further debugging research.},
  langid	= {english},
  keywords	= {Dynamic program slicing,Execution backtracking,Program
		  debugging,Program slicing,Reverse program execution}
}

@InProceedings{	  aguzzi21,
  title		= {{{ScaFi-Web}}: {{A Web-Based Application}} for
		  {{Field-Based Coordination Programming}}},
  shorttitle	= {{{ScaFi-Web}}},
  booktitle	= {Coordination {{Models}} and {{Languages}}},
  author	= {Aguzzi, Gianluca and Casadei, Roberto and Maltoni,
		  Niccol{\`o} and Pianini, Danilo and Viroli, Mirko},
  editor	= {Damiani, Ferruccio and Dardha, Ornela},
  year		= {2021},
  pages		= {285--299},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-78142-2_18},
  abstract	= {Field-based coordination is a model for expressing the
		  coordination logic of large-scale adaptive systems,
		  composing functional blocks from a global perspective. As
		  for any coordination model, a proper toolchain must be
		  developed to support its adoption across all development
		  phases. Under this point of view, the ScaFi toolkit
		  provides a coordination language (field calculus) as a DSL
		  internal in the Scala language, a library of reusable
		  building blocks, and an infrastructure for simulation of
		  distributed deployments. In this work, we enrich such a
		  toolchain by introducing ScaFi-Web, a web-based application
		  allowing in-browser editing, execution, and visualisation
		  of ScaFi programs. ScaFi-Web facilitates access to the
		  ScaFi coordination technology by flattening the learning
		  curve and simplifying configuration and requirements, thus
		  promoting agile prototyping of field-based coordination
		  specifications. In turn, this opens the door to easier
		  demonstrations and experimentation, and also constitutes a
		  stepping stone towards monitoring and control of
		  simulated/deployed systems.},
  isbn		= {978-3-030-78142-2},
  langid	= {english}
}

@InProceedings{	  aguzzi23,
  title		= {{{MacroSwarm}}: {{A~Field-Based Compositional Framework}}
		  for~{{Swarm Programming}}},
  shorttitle	= {{{MacroSwarm}}},
  booktitle	= {Coordination {{Models}} and {{Languages}}},
  author	= {Aguzzi, Gianluca and Casadei, Roberto and Viroli, Mirko},
  editor	= {Jongmans, Sung-Shik and Lopes, Ant{\'o}nia},
  year		= {2023},
  pages		= {31--51},
  publisher	= {Springer Nature Switzerland},
  address	= {Cham},
  doi		= {10.1007/978-3-031-35361-1_2},
  abstract	= {Swarm behaviour engineering is an area of research that
		  seeks to investigate methods for coordinating computation
		  and action within groups of simple agents to achieve
		  complex global goals like collective movement, clustering,
		  and distributed sensing. Despite recent progress in the
		  study and engineering of swarms (of drones, robots,
		  vehicles), there is still need for general design and
		  implementation methods that can be used to define complex
		  swarm coordination in a principled way. To face this need,
		  this paper proposes a new field-based coordination
		  approach, called MacroSwarm, to design fully composable and
		  reusable blocks of swarm behaviour. Based on the
		  macroprogramming approach of aggregate computing, it roots
		  on the idea of modelling each block of swarm behaviour by a
		  purely functional transformation of sensing fields into
		  actuation description fields, typically including movement
		  vectors. We showcase the potential of MacroSwarm as a
		  framework for collective intelligence by simulation, in a
		  variety of scenarios including flocking, morphogenesis, and
		  collective decision-making.},
  isbn		= {978-3-031-35361-1},
  langid	= {english}
}

@InProceedings{	  ai20,
  title		= {A {{Novel Concolic Execution Approach}} on {{Embedded
		  Device}}},
  booktitle	= {Proceedings of the 2020 4th {{International Conference}}
		  on {{Cryptography}}, {{Security}} and {{Privacy}}},
  author	= {Ai, Chengwei and Dong, Weiyu and Gao, Zicong},
  year		= {2020},
  month		= feb,
  series	= {{{ICCSP}} 2020},
  pages		= {47--52},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3377644.3377654},
  urldate	= {2024-03-28},
  abstract	= {With the widely use of embeded device, its security issues
		  cause high attention. As one of the popular program testing
		  techniques, symbolic execution tests a program by treating
		  the program's input as symbols and interpreting the program
		  over these inputs. Due to the complex environment and
		  lackage of computing resources, there is no efficient
		  symbolic execution approach in analyzing firmware running
		  on device. In this paper, we present a novel concolic
		  execution approach for firmware programs. The approach
		  adopts Dynamic Test Generation scheme to perform concrete
		  execution on multiple architectures Unix-like physical
		  device and symbolic execution on the debugging host. In
		  order to gain the complex environment info, the concrete
		  execution performs by gdb debugging method collects program
		  trace and runtime information. And to overcome the lackage
		  of computing resources, the symbolic execution extracts
		  relevant constraints and solves the collected constraints
		  to generate new test cases on a high perfomance host. We
		  implement the approach in various architectures, including
		  x86-64, arm and ppc. The availability and effectiveness of
		  our approach can be verified by evaluating some binutil
		  programs in our approach's framework.},
  isbn		= {978-1-4503-7744-7},
  keywords	= {Concolic execution,Firmware analysis,Test case
		  generation}
}

@InProceedings{	  allen83,
  title		= {Conversion of Control Dependence to Data Dependence},
  booktitle	= {Proceedings of the 10th {{ACM SIGACT-SIGPLAN}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Allen, J. R. and Kennedy, Ken and Porterfield, Carrie and
		  Warren, Joe},
  year		= {1983},
  month		= jan,
  series	= {{{POPL}} '83},
  pages		= {177--189},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/567067.567085},
  urldate	= {2024-03-18},
  abstract	= {Program analysis methods, especially those which support
		  automatic vectorization, are based on the concept of
		  interstatement dependence where a dependence holds between
		  two statements when one of the statements computes values
		  needed by the other. Powerful program transformation
		  systems that convert sequential programs to a form more
		  suitable for vector or parallel machines have been
		  developed using this concept [AllK 82, KKLW 80].The
		  dependence analysis in these systems is based on data
		  dependence. In the presence of complex control flow, data
		  dependence is not sufficient to transform programs because
		  of the introduction of control dependences. A control
		  dependence exists between two statements when the execution
		  of one statement can prevent the execution of the other.
		  Control dependences do not fit conveniently into
		  dependence-based program translators.One solution is to
		  convert all control dependences to data dependences by
		  eliminating goto statements and introducing logical
		  variables to control the execution of statements in the
		  program. In this scheme, action statements are converted to
		  IF statements. The variables in the conditional expression
		  of an IF statement can be viewed as inputs to the statement
		  being controlled. The result is that control dependences
		  between statements become explicit data dependences
		  expressed through the definitions and uses of the
		  controlling logical variables.This paper presents a method
		  for systematically converting control dependences to data
		  dependences in this fashion. The algorithms presented here
		  have been implemented in PFC, an experimental vectorizer
		  written at Rice University.},
  isbn		= {978-0-89791-090-3}
}

@Article{	  almatary22,
  title		= {{{CompartOS}}: {{CHERI Compartmentalization}} for
		  {{Embedded Systems}}},
  shorttitle	= {{{CompartOS}}},
  author	= {Almatary, Hesham and Dodson, Michael and Clarke, Jessica
		  and Rugg, Peter and Gomes, Ivan and Podhradsky, Michal and
		  Neumann, Peter G. and Moore, Simon W. and Watson, Robert N.
		  M.},
  year		= {2022},
  publisher	= {arXiv},
  doi		= {10.48550/ARXIV.2206.02852},
  urldate	= {2024-01-18},
  abstract	= {Existing high-end embedded systems face frequent security
		  attacks. Software compartmentalization is one technique to
		  limit the attacks' effects to the compromised compartment
		  and not the entire system. Unfortunately, the existing
		  state-of-the-art embedded hardware-software solutions do
		  not work well to enforce software compartmentalization for
		  high-end embedded systems. MPUs are not fine-grained and
		  suffer from significant scalability limitations as they can
		  only protect a small and fixed number of memory regions. On
		  the other hand, MMUs suffer from non-determinism and
		  coarse-grained protection. This paper introduces CompartOS
		  as a lightweight linkage-based compartmentalization model
		  for high-end, complex, mainstream embedded systems.
		  CompartOS builds on CHERI, a capability-based hardware
		  architecture, to meet scalability, availability,
		  compatibility, and fine-grained security goals.
		  Microbenchmarks show that CompartOS' protection-domain
		  crossing is 95\% faster than MPU-based IPC. We applied the
		  CompartOS model, with low effort, to complex existing
		  systems, including TCP servers and a safety-critical
		  automotive demo. CompartOS not only catches 10 out of 13
		  FreeRTOS-TCP published vulnerabilities that MPU-based
		  protection (e.g., uVisor) cannot catch but can also recover
		  from them. Further, our TCP throughput evaluations show
		  that our CompartOS prototype is 52\% faster than relevant
		  MPU-based compartmentalization models (e.g., ACES), with a
		  15\% overhead compared to an unprotected system. This comes
		  at an FPGA's LUTs overhead of 10.4\% to support CHERI for
		  an unprotected baseline RISC-V processor, compared to 7.6\%
		  to support MPU, while CHERI only incurs 1.3\% of the
		  registers area overhead compared to 2\% for MPU.},
  copyright	= {Creative Commons Attribution 4.0 International},
  keywords	= {Cryptography and Security (cs.CR),FOS: Computer and
		  information sciences}
}

@Article{	  alrabaee22,
  title		= {A {{Survey}} of {{Binary Code Fingerprinting Approaches}}:
		  {{Taxonomy}}, {{Methodologies}}, and {{Features}}},
  shorttitle	= {A {{Survey}} of {{Binary Code Fingerprinting
		  Approaches}}},
  author	= {Alrabaee, Saed and Debbabi, Mourad and Wang, Lingyu},
  year		= {2022},
  month		= jan,
  journal	= {ACM Computing Surveys},
  volume	= {55},
  number	= {1},
  pages		= {19:1--19:41},
  issn		= {0360-0300},
  doi		= {10.1145/3486860},
  urldate	= {2024-03-18},
  abstract	= {Binary code fingerprinting is crucial in many security
		  applications. Examples include malware detection, software
		  infringement, vulnerability analysis, and digital
		  forensics. It is also useful for security researchers and
		  reverse engineers since it enables high fidelity reasoning
		  about the binary code such as revealing the functionality,
		  authorship, libraries used, and vulnerabilities. Numerous
		  studies have investigated binary code with the goal of
		  extracting fingerprints that can illuminate the semantics
		  of a target application. However, extracting fingerprints
		  is a challenging task since a substantial amount of
		  significant information will be lost during compilation,
		  notably, variable and function naming, the original data
		  and control flow structures, comments, semantic
		  information, and the code layout. This article provides the
		  first systematic review of existing binary code
		  fingerprinting approaches and the contexts in which they
		  are used. In addition, it discusses the applications that
		  rely on binary code fingerprints, the information that can
		  be captured during the fingerprinting process, and the
		  approaches used and their implementations. It also
		  addresses limitations and open questions related to the
		  fingerprinting process and proposes future directions.},
  keywords	= {Binary code analysis,reverse engineering,software
		  security}
}

@InProceedings{	  amar23,
  title		= {{{CHERIoT}}: {{Complete Memory Safety}} for {{Embedded
		  Devices}}},
  shorttitle	= {{{CHERIoT}}},
  booktitle	= {Proceedings of the 56th {{Annual IEEE}}/{{ACM
		  International Symposium}} on {{Microarchitecture}}},
  author	= {Amar, Saar and Chisnall, David and Chen, Tony and Filardo,
		  Nathaniel Wesley and Laurie, Ben and Liu, Kunyan and
		  Norton, Robert and Moore, Simon W. and Tao, Yucong and
		  Watson, Robert N. M. and Xia, Hongyan},
  year		= {2023},
  month		= dec,
  series	= {{{MICRO}} '23},
  pages		= {641--653},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3613424.3614266},
  urldate	= {2024-01-18},
  abstract	= {The ubiquity of embedded devices is apparent. The desire
		  for increased functionality and connectivity drives ever
		  larger software stacks, with components from multiple
		  vendors and entities. These stacks should be replete with
		  isolation and memory safety technologies, but existing
		  solutions impinge upon development, unit cost, power,
		  scalability, and/or real-time constraints, limiting their
		  adoption and production-grade deployments. As memory safety
		  vulnerabilities mount, the situation is clearly not tenable
		  and a new approach is needed. To slake this need, we
		  present a novel adaptation of the CHERI capability
		  architecture, co-designed with a green-field,
		  security-centric RTOS. It is scaled for embedded systems,
		  is capable of fine-grained software compartmentalization,
		  and provides affordances for full inter-compartment memory
		  safety. We highlight central design decisions and offloads
		  and summarize how our prototype RTOS uses these to enable
		  memory-safe, compartmentalized applications. Unlike many
		  state-of-the-art schemes, our solution deterministically
		  (not probabilistically) eliminates memory safety
		  vulnerabilities while maintaining source-level
		  compatibility. We characterize the power, performance, and
		  area microarchitectural impacts, run microbenchmarks of key
		  facilities, and exhibit the practicality of an end-to-end
		  IoT application. The implementation shows that full memory
		  safety for compartmentalized embedded systems is achievable
		  without violating resource constraints or real-time
		  guarantees, and that hardware assists need not be
		  expensive, intrusive, or power-hungry.},
  isbn		= {9798400703294}
}

@Article{	  axelsen16,
  title		= {On Reversible {{Turing}} Machines and Their Function
		  Universality},
  author	= {Axelsen, Holger Bock and Gl{\"u}ck, Robert},
  year		= {2016},
  month		= aug,
  journal	= {Acta Informatica},
  volume	= {53},
  number	= {5},
  pages		= {509--543},
  issn		= {1432-0525},
  doi		= {10.1007/s00236-015-0253-y},
  urldate	= {2024-11-09},
  abstract	= {We provide a treatment of the reversible Turing machines
		  (RTMs) under a strict function semantics. Unlike many
		  existing reversible computation models, we distinguish
		  strictly between computing the function
		  \$\${\textbackslash}lambda x.f(x)\$\$and computing the
		  function \$\${\textbackslash}lambda x. (x, f(x))\$\$, or
		  other injective embeddings of f. We reinterpret and adapt a
		  number of important foundational reversible computing
		  results under this semantics. Unifying the results in a
		  single model shows that, as expected (and previously
		  claimed), the RTMs are robust and can compute exactly all
		  injective computable functions. Because injectivity entails
		  that the RTMs are not strictly Turing-complete
		  w.r.t.~functions, we use an appropriate alternative
		  universality definition, and show how to derive universal
		  RTMs (URTMs) from existing irreversible universal machines.
		  We then proceed to construct a URTM from the ground up.
		  This resulting machine is the first URTM which does not
		  depend on a reversible simulation of an existing universal
		  machine. The new construction has the advantage that the
		  interpretive overhead of the URTM is limited to a (program
		  dependent) constant factor. Another novelty is that the
		  URTM can function as an inverse interpreter at no asymptotic cost.},
  langid	= {english},
  keywords	= {03D10,68Q05,68Q10}
}

@InProceedings{	  baccelli18,
  title		= {Reprogramming {{Low-end IoT Devices}} from the {{Cloud}}},
  booktitle	= {2018 3rd {{Cloudification}} of the {{Internet}} of
		  {{Things}} ({{CIoT}})},
  author	= {Baccelli, Emmanuel and Doerr, Joerg and Jallouli, Ons and
		  Kikuchi, Shinji and Morgenstern, Andreas and Padilla,
		  Francisco Acosta and Schleiser, Kaspar and Thomas, Ian},
  year		= {2018},
  month		= jul,
  pages		= {1--6},
  doi		= {10.1109/CIOT.2018.8627129},
  urldate	= {2023-10-03},
  abstract	= {The Internet of Things (IoT) consists in a variety of
		  smart connected objects, among which a category of low-end
		  devices based on micro-controllers. The orchestration of
		  low-end IoT devices is not straightforward because of the
		  lack of generic and holistic solutions articulating
		  cloud-based tools on one hand, and low-end IoT device
		  software on the other hand. In this paper, we describe such
		  a solution, combining a cloud-based IDE, graphical
		  programming, and automatic JavaScript generation. Scripts
		  are pushed over the Internet and over-the-air for the last
		  hop, updating runtime containers hosted on heterogeneous
		  low-end IoT devices running RIOT. We demonstrate a
		  prototype working on common off-the-shelf low-end IoT
		  hardware with as little as 32kB of memory.}
}

@InProceedings{	  balzer69,
  title		= {{{EXDAMS}}: Extendable Debugging and Monitoring System},
  shorttitle	= {{{EXDAMS}}},
  booktitle	= {Proceedings of the {{May}} 14-16, 1969, Spring Joint
		  Computer Conference},
  author	= {Balzer, R. M.},
  year		= {1969},
  month		= may,
  series	= {{{AFIPS}} '69 ({{Spring}})},
  pages		= {567--580},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1476793.1476881},
  urldate	= {2023-12-15},
  abstract	= {With the advent of the higher-level algebraic languages,
		  the computer industry expected to be relieved of the
		  detailed programming required at the assembly-language
		  level. This expectation has largely been realized. Many
		  systems are now being built in higher-level languages (most
		  notably MULTICS).},
  isbn		= {978-1-4503-7902-1}
}

@Article{	  barik19,
  title		= {Optimization of Swift Protocols},
  author	= {Barik, Rajkishore and Sridharan, Manu and Ramanathan,
		  Murali Krishna and Chabbi, Milind},
  year		= {2019},
  month		= oct,
  journal	= {Optimization of Swift Protocols},
  volume	= {3},
  number	= {OOPSLA},
  pages		= {164:1--164:27},
  doi		= {10.1145/3360590},
  urldate	= {2024-12-17},
  abstract	= {Swift, an increasingly-popular programming language,
		  advocates the use of protocols, which define a set of
		  required methods and properties for conforming types.
		  Protocols are commonly used in Swift programs for
		  abstracting away implementation details; e.g., in a large
		  industrial app from Uber, they are heavily used to enable
		  mock objects for unit testing. Unfortunately, heavy use of
		  protocols can result in significant performance overhead.
		  Beyond the dynamic dispatch often associated with such a
		  feature, Swift allows for both value and reference types to
		  conform to a protocol, leading to significant boxing and
		  unboxing overheads. In this paper, we describe three new
		  optimizations and transformations to reduce the overhead of
		  Swift protocols. Within a procedure, we define LocalVar, a
		  dataflow analysis and transformation to remove both dynamic
		  dispatch and boxing overheads. We also describe Param,
		  which optimizes the case of protocol-typed method
		  parameters using specialization. Finally, we describe
		  SoleType, a transformation that injects casts when a global
		  analysis (like type-hierarchy analysis) discovers some
		  protocol variable must have some concrete type. We also
		  describe how these optimizations work fruitfully together
		  and with existing Swift optimizations to deliver further
		  speedups. We perform elaborate experimentation and
		  demonstrate that our optimizations deliver an average 1.56x
		  speedup on a suite of Swift benchmarks that use protocols.
		  Further, we applied the optimizations to a production iOS
		  Swift application from Uber used by millions of customers
		  daily. For a set of performance spans defined by the
		  developers of the application, the optimized version showed
		  speedups ranging from 6.9\% to 55.49\%. A version of our
		  optimizations has been accepted as part of the official
		  Swift compiler distribution.}
}

@InProceedings{	  barthe14,
  title		= {System-Level {{Non-interference}} for {{Constant-time
		  Cryptography}}},
  booktitle	= {Proceedings of the 2014 {{ACM SIGSAC Conference}} on
		  {{Computer}} and {{Communications Security}}},
  author	= {Barthe, Gilles and Betarte, Gustavo and Campo, Juan and
		  Luna, Carlos and Pichardie, David},
  year		= {2014},
  month		= nov,
  series	= {{{CCS}} '14},
  pages		= {1267--1279},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2660267.2660283},
  urldate	= {2023-10-22},
  abstract	= {Cache-based attacks are a class of side-channel attacks
		  that are particularly effective in virtualized or
		  cloud-based environments, where they have been used to
		  recover secret keys from cryptographic implementations. One
		  common approach to thwart cache-based attacks is to use
		  constant-time implementations, i.e., which do not branch on
		  secrets and do not perform memory accesses that depend on
		  secrets. However, there is no rigorous proof that
		  constant-time implementations are protected against
		  concurrent cache-attacks in virtualization platforms with
		  shared cache; moreover, many prominent implementations are
		  not constant-time. An alternative approach is to rely on
		  system-level mechanisms. One recent such mechanism is
		  stealth memory, which provisions a small amount of private
		  cache for programs to carry potentially leaking
		  computations securely. Stealth memory induces a weak form
		  of constant-time, called S-constant-time, which encompasses
		  some widely used cryptographic implementations. However,
		  there is no rigorous analysis of stealth memory and
		  S-constant-time, and no tool support for checking if
		  applications are S-constant-time. We propose a new
		  information-flow analysis that checks if an x86 application
		  executes in constant-time, or in S-constant-time. Moreover,
		  we prove that constant-time (resp. S-constant-time)
		  programs do not leak confidential information through the
		  cache to other operating systems executing concurrently on
		  virtualization platforms (resp. platforms supporting
		  stealth memory). The soundness proofs are based on new
		  theorems of independent interest, including isolation
		  theorems for virtualization platforms (resp. platforms
		  supporting stealth memory), and proofs that constant-time
		  implementations (resp. S-constant-time implementations) are
		  non-interfering with respect to a strict information flow
		  policy which disallows that control flow and memory
		  accesses depend on secrets. We formalize our results using
		  the Coq proof assistant and we demonstrate the
		  effectiveness of our analyses on cryptographic
		  implementations, including PolarSSL AES, DES and RC4,
		  SHA256 and Salsa20.},
  isbn		= {978-1-4503-2957-6},
  keywords	= {cache-based attacks,constant-time
		  cryptography,coq,non-interference,stealth memory}
}

@Book{		  battagline21,
  title		= {The Art of {{WebAssembly}}: {{Build}} Secure, Portable,
		  High-Performance Applications},
  author	= {Battagline, R.},
  year		= {2021},
  publisher	= {No Starch Press},
  isbn		= {978-1-71850-144-7},
  lccn		= {2021930212}
}

@Article{	  bauman17,
  title		= {Sound Gradual Typing: Only Mostly Dead},
  shorttitle	= {Sound Gradual Typing},
  author	= {Bauman, Spenser and {Bolz-Tereick}, Carl Friedrich and
		  Siek, Jeremy and {Tobin-Hochstadt}, Sam},
  year		= {2017},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {1},
  number	= {OOPSLA},
  pages		= {54:1--54:24},
  doi		= {10.1145/3133878},
  urldate	= {2024-01-05},
  abstract	= {While gradual typing has proven itself attractive to
		  programmers, many systems have avoided sound gradual typing
		  due to the run time overhead of enforcement. In the context
		  of sound gradual typing, both anecdotal and systematic
		  evidence has suggested that run time costs are quite high,
		  and often unacceptable, casting doubt on the viability of
		  soundness as an approach. We show that these overheads are
		  not fundamental, and that with appropriate improvements,
		  just-in-time compilers can greatly reduce the overhead of
		  sound gradual typing. Our study takes benchmarks published
		  in a recent paper on gradual typing performance in Typed
		  Racket (Takikawa et al., POPL 2016) and evaluates them
		  using a experimental tracing JIT compiler for Racket,
		  called Pycket. On typical benchmarks, Pycket is able to
		  eliminate more than 90\% of the gradual typing overhead.
		  While our current results are not the final word in
		  optimizing gradual typing, we show that the situation is
		  not dire, and where more work is needed. Pycket's
		  performance comes from several sources, which we detail and
		  measure individually. First, we apply a sophisticated
		  tracing JIT compiler and optimizer, automatically generated
		  in Pycket using the RPython framework originally created
		  for PyPy. Second, we focus our optimization efforts on the
		  challenges posed by run time checks, implemented in Racket
		  by chaperones and impersonators. We introduce
		  representation improvements, including a novel use of
		  hidden classes to optimize these data structures.},
  keywords	= {Gradual Typing,Just-in-Time compilation,Performance
		  Evaluation}
}

@Article{	  bauwens20,
  title		= {Over-the-{{Air Software Updates}} in the {{Internet}} of
		  {{Things}}: {{An Overview}} of {{Key Principles}}},
  shorttitle	= {Over-the-{{Air Software Updates}} in the {{Internet}} of
		  {{Things}}},
  author	= {Bauwens, Jan and Ruckebusch, Peter and Giannoulis, Spilios
		  and Moerman, Ingrid and Poorter, Eli De},
  year		= {2020},
  month		= feb,
  journal	= {IEEE Communications Magazine},
  volume	= {58},
  number	= {2},
  pages		= {35--41},
  issn		= {1558-1896},
  doi		= {10.1109/MCOM.001.1900125},
  urldate	= {2023-10-25},
  abstract	= {Due to the fast pace at which IoT is evolving, there is an
		  increasing need to support over-theair software updates for
		  security updates, bug fixes, and software extensions. To
		  this end, multiple over-the-air techniques have been
		  proposed, each covering a specific aspect of the update
		  process, such as (partial) code updates, data
		  dissemination, and security. However, each technique
		  introduces overhead, especially in terms of energy
		  consumption, thereby impacting the operational lifetime of
		  the battery constrained devices. Until now, a comprehensive
		  overview describing the different update steps and
		  quantifying the impact of each step is missing in the
		  scientific literature, making it hard to assess the overall
		  feasibility of an over-the-air update. To remedy this, our
		  article analyzes which parts of an IoT operating system are
		  most updated after device deployment, proposes a
		  step-by-step approach to integrate software updates in IoT
		  solutions, and quantifies the energy cost of each of the
		  involved steps. The results show that besides the obvious
		  dissemination cost, other phases such as security also
		  introduce a significant overhead. For instance, a typical
		  firmware update requires 135.026 mJ, of which the main
		  portions are data dissemination (63.11 percent) and
		  encryption (5.29 percent). However, when modular updates
		  are used instead, the energy cost (e.g., for a MAC update)
		  is reduced to 26.743 mJ (48.69 percent for data
		  dissemination and 26.47 percent for encryption).}
}

@Article{	  bennett88,
  title		= {Notes on the History of Reversible Computation},
  author	= {Bennett, Charles H.},
  year		= {1988},
  month		= jan,
  journal	= {IBM Journal of Research and Development},
  volume	= {32},
  number	= {1},
  pages		= {16--23},
  issn		= {0018-8646},
  doi		= {10.1147/rd.321.0016},
  urldate	= {2024-11-09},
  abstract	= {We review the history of the thermodynamics of information
		  processing, beginning with the paradox of Maxwell's demon;
		  continuing through the efforts of Szilard, Brillouin, and
		  others to demonstrate a thermodynamic cost of information
		  acquisition; the discovery by Landauer of the thermodynamic
		  cost of information destruction; the development of the
		  theory of and classical models for reversible computation;
		  and ending with a brief survey of recent work on quantum
		  reversible computation.}
}

@InProceedings{	  benton02,
  title		= {Monads and {{Effects}}},
  booktitle	= {Applied {{Semantics}}},
  author	= {Benton, Nick and Hughes, John and Moggi, Eugenio},
  editor	= {Barthe, Gilles and Dybjer, Peter and Pinto, Lu{\'i}s and
		  Saraiva, Jo{\~a}o},
  year		= {2002},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {42--122},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-45699-6_2},
  abstract	= {A tension in language design has been between simple
		  semantics on the one hand, and rich possibilities for
		  side-effects, exception handling and so on on the other.
		  The introduction of monads has made a large step towards
		  reconciling these alternatives. First proposed by Moggi as
		  a way of structuring semantic descriptions, they were
		  adopted by Wadler to structure Haskell programs. Monads
		  have been used to solve long-standing problems such as
		  adding pointers and assignment, inter-language working, and
		  exception handling to Haskell, without compromising its
		  purely functional semantics. The course introduces monads,
		  effects, and exemplifies their applications in programming
		  (Haskell) and in compilation (MLj). The course presents
		  typed metalanguages for monads and related categorical
		  notions, and then describes how they can be further refined
		  by introducing effects.},
  isbn		= {978-3-540-45699-5},
  langid	= {english},
  keywords	= {Denotational Semantic,Functional Semantic,Intermediate
		  Language,Operational Semantic,Source Language}
}

@InProceedings{	  bernardo23,
  title		= {Causal {{Reversibility Implies Time Reversibility}}},
  booktitle	= {Quantitative {{Evaluation}} of {{Systems}}},
  author	= {Bernardo, Marco and Lanese, Ivan and Marin, Andrea and
		  Mezzina, Claudio A. and Rossi, Sabina and Sacerdoti Coen,
		  Claudio},
  editor	= {Jansen, Nils and Tribastone, Mirco},
  year		= {2023},
  pages		= {270--287},
  publisher	= {Springer Nature Switzerland},
  address	= {Cham},
  doi		= {10.1007/978-3-031-43835-6_19},
  abstract	= {Several notions of reversibility exist in the literature.
		  On the one hand, causal reversibility establishes that an
		  action can be undone provided that all of its consequences
		  have been undone already, thereby making it possible to
		  bring a system back to a past consistent state. On the
		  other hand, time reversibility stipulates that the
		  stochastic behavior of a system remains the same when the
		  direction of time is reversed, which supports efficient
		  performance evaluation. In this paper we show that causal
		  reversibility is a sufficient condition for time
		  reversibility. The study is conducted on extended labeled
		  transition systems. Firstly, they include a forward and a
		  backward transition relations obeying the loop property.
		  Secondly, their transitions feature an independence
		  relation as well as rates for their exponentially
		  distributed random durations. Our result can thus be
		  smoothly applied to concurrent and distributed models,
		  calculi, and languages that account for performance
		  aspects.},
  isbn		= {978-3-031-43835-6},
  langid	= {english}
}

@Article{	  besnard21,
  title		= {Unified Verification and Monitoring of Executable {{UML}}
		  Specifications},
  author	= {Besnard, Valentin and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Dhaussy, Philippe},
  year		= {2021},
  month		= dec,
  journal	= {Software and Systems Modeling},
  volume	= {20},
  number	= {6},
  pages		= {1825--1855},
  issn		= {1619-1374},
  doi		= {10.1007/s10270-021-00923-9},
  urldate	= {2023-09-26},
  abstract	= {The increasing complexity of embedded systems renders
		  software verification more complex, requiring monitoring
		  and formal techniques, like model-checking. However, to use
		  such techniques, system engineers usually need formal
		  expertise to express the software requirements in a formal
		  language. To facilitate the use of model-checking tools by
		  system engineers, our approach uses a UML model interpreter
		  through which the software requirements can directly be
		  expressed in UML as well. Formal requirements are encoded
		  as UML state machines with the transition guards written in
		  a specific observation language, which expresses predicates
		  on the execution of the system model. Each such executable
		  UML specification can model either a B{\"u}chi automaton or
		  an observer automaton, and is synchronously composed with
		  the system, to follow its execution during model-checking.
		  Formal verification can continue at runtime for all
		  deterministic observer automata used during offline
		  verification by deploying them on real embedded systems.
		  Our approach has been evaluated on multiple case studies
		  and is illustrated, in this paper, through the user
		  interface model of a cruise-control system. The
		  automata-based verification results are in line with the
		  verification of the equivalent LTL properties. The runtime
		  overhead during monitoring is proportional to the number of
		  monitors.},
  langid	= {english},
  keywords	= {Embedded software,Embedded systems,Interpreters,Model
		  checking,Model interpretation,Model-checking,Model-driven
		  software engineering,Monitoring,Observation
		  Language,Software verification,Synchronous Composition}
}

@InProceedings{	  bichhawat21,
  title		= {Gradual {{Security Types}} and {{Gradual Guarantees}}},
  booktitle	= {2021 {{IEEE}} 34th {{Computer Security Foundations
		  Symposium}} ({{CSF}})},
  author	= {Bichhawat, Abhishek and McCall, McKenna and Jia, Limin},
  year		= {2021},
  month		= jun,
  pages		= {1--16},
  issn		= {2374-8303},
  doi		= {10.1109/CSF51468.2021.00015},
  urldate	= {2024-12-18},
  abstract	= {Information flow type systems enforce the security
		  property of noninterference by detecting unauthorized data
		  flows at compile-time. However, they require precise type
		  annotations, making them difficult to use in practice as
		  much of the legacy infrastructure is written in untyped or
		  dynamically-typed languages. Gradual typing seamlessly
		  integrates static and dynamic typing, providing the best of
		  both approaches, and has been applied to information flow
		  control, where information flow monitors are derived from
		  gradual security types. Prior work on gradual information
		  flow typing uncovered tensions between noninterference and
		  the dynamic gradual guarantee--- the property that less
		  precise security type annotations in a program should not
		  cause more runtime errors.This paper re-examines the
		  connection between gradual information flow types and
		  information flow monitors to identify the root cause of the
		  tension between the gradual guarantees and noninterference.
		  We develop runtime semantics for a simple imperative
		  language with gradual information flow types that provides
		  both noninterference and gradual guarantees. We leverage a
		  proof technique developed for FlowML and reduce
		  noninterference proofs to preservation proofs.},
  keywords	= {Annotations,Computer security,gradual guarantees,gradual
		  typing,Information flow
		  control,Monitoring,noninterference,Refining,Runtime,Semantics}
}

@InProceedings{	  binder22,
  title		= {Structural Refinement Types},
  booktitle	= {Proceedings of the 7th {{ACM SIGPLAN International
		  Workshop}} on {{Type-Driven Development}}},
  author	= {Binder, David and Skupin, Ingo and L{\"a}wen, David and
		  Ostermann, Klaus},
  year		= {2022},
  month		= sep,
  series	= {{{TyDe}} 2022},
  pages		= {15--27},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3546196.3550163},
  urldate	= {2023-09-26},
  abstract	= {Static types are a great form of lightweight static
		  analysis. But sometimes a type like List is too coarse --
		  we would also like to work with its refinements like
		  non-empty lists, or lists containing exactly 42 elements.
		  Dependent types allow for this, but they impose a heavy
		  proof burden on the programmer. We want the checking and
		  inference of refinements to be fully automatic. In this
		  article we present a simple refinement type system and
		  inference algorithm which uses only variants of familiar
		  concepts from constraint-based type inference. Concretely,
		  we build on the algebraic subtyping approach and extend it
		  with typing rules which combine properties of nominal and
		  structural type systems in a novel way. Despite the
		  simplicity of our approach, the resulting type system is
		  very expressive and allows to specify and infer non-trivial
		  properties of programs.},
  isbn		= {978-1-4503-9439-0},
  keywords	= {Algebraic Subtyping,Nominal Types,Refinement
		  Types,Structural Types}
}

@InCollection{	  binkley04,
  title		= {A {{Survey}} of {{Empirical Results}} on {{Program
		  Slicing}}},
  booktitle	= {Advances in {{Computers}}},
  author	= {Binkley, David and Harman, Mark},
  year		= {2004},
  month		= jan,
  volume	= {62},
  pages		= {105--178},
  publisher	= {Elsevier},
  doi		= {10.1016/S0065-2458(03)62003-6},
  urldate	= {2023-11-30},
  abstract	= {A program slice extracts a semantically meaningful portion
		  of a program, based upon a user-selected slicing criterion.
		  As the study of program slicing has matured, a growing body
		  of empirical data has been gathered on the size of slices,
		  slicing tools and techniques, the applications of slicing,
		  and the beneficial psychological effects of slices on the
		  programmers who use them. Empirical work on these topics is
		  surveyed, highlighting trends and areas where additional
		  empirical investigation is desirable, either because of
		  contradictory findings or scarcity of results in the
		  existing body of empirical knowledge.}
}

@InProceedings{	  binkley14,
  title		= {{{ORBS}}: Language-Independent Program Slicing},
  shorttitle	= {{{ORBS}}},
  booktitle	= {Proceedings of the 22nd {{ACM SIGSOFT International
		  Symposium}} on {{Foundations}} of {{Software
		  Engineering}}},
  author	= {Binkley, David and Gold, Nicolas and Harman, Mark and
		  Islam, Syed and Krinke, Jens and Yoo, Shin},
  year		= {2014},
  month		= nov,
  series	= {{{FSE}} 2014},
  pages		= {109--120},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2635868.2635893},
  urldate	= {2023-11-29},
  abstract	= {Current slicing techniques cannot handle systems written
		  in multiple programming languages. Observation-Based
		  Slicing (ORBS) is a language-independent slicing technique
		  capable of slicing multi-language systems, including
		  systems which contain (third party) binary components. A
		  potential slice obtained through repeated statement
		  deletion is validated by observing the behaviour of the
		  program: if the slice and original program behave the same
		  under the slicing criterion, the deletion is accepted. The
		  resulting slice is similar to a dynamic slice. We evaluate
		  five variants of ORBS on ten programs of different sizes
		  and languages showing that it is less expensive than
		  similar existing techniques. We also evaluate it on bash
		  and four other systems to demonstrate feasible large-scale
		  operation in which a parallelised ORBS needs up to 82\%
		  less time when using four threads. The results show that an
		  ORBS slicer is simple to construct, effective at slicing,
		  and able to handle systems written in multiple languages
		  without specialist analysis tools.},
  isbn		= {978-1-4503-3056-5}
}

@Article{	  binkley19,
  title		= {A Comparison of Tree- and Line-Oriented Observational
		  Slicing},
  author	= {Binkley, David and Gold, Nicolas and Islam, Syed and
		  Krinke, Jens and Yoo, Shin},
  year		= {2019},
  month		= oct,
  journal	= {Empirical Software Engineering},
  volume	= {24},
  number	= {5},
  pages		= {3077--3113},
  issn		= {1573-7616},
  doi		= {10.1007/s10664-018-9675-9},
  urldate	= {2024-03-18},
  abstract	= {Observation-based slicing and its generalization
		  observational slicing are recently-introduced,
		  language-independent dynamic slicing techniques. They both
		  construct slices based on the dependencies observed during
		  program execution, rather than static or dynamic dependence
		  analysis. The original implementation of the
		  observation-based slicing algorithm used lines of source
		  code as its program representation. A recent variation,
		  developed to slice modelling languages (such as Simulink),
		  used an XML representation of an executable model. We
		  ported the XML slicer to source code by constructing a tree
		  representation of traditional source code through the use
		  of srcML. This work compares the tree- and line-based
		  slicers using four experiments involving twenty different
		  programs, ranging from classic benchmarks to million-line
		  production systems. The resulting slices are essentially
		  the same size for the majority of the programs and are
		  often identical. However, structural constraints imposed by
		  the tree representation sometimes force the slicer to
		  retain enclosing control structures. It can also ``bog
		  down'' trying to delete single-token subtrees. This
		  occasionally makes the tree-based slices larger and the
		  tree-based slicer slower than a parallelised version of the
		  line-based slicer. In addition, a Java versus C comparison
		  finds that the two languages lead to similar slices, but
		  Java code takes noticeably longer to slice. The initial
		  experiments suggest two improvements to the tree-based
		  slicer: the addition of a size threshold, for ignoring
		  small subtrees, and subtree replacement. The former enables
		  the slicer to run 3.4 times faster while producing slices
		  that are only about 9\% larger. At the same time the
		  subtree replacement reduces size by about 8--12\% and
		  allows the tree-based slicer to produce more natural
		  slices.},
  langid	= {english},
  keywords	= {Observational slicing,ORBS,Program slicing,XML}
}

@Article{	  blanvillain22,
  title		= {Type-Level Programming with Match Types},
  author	= {Blanvillain, Olivier and Brachth{\"a}user, Jonathan
		  Immanuel and Kjaer, Maxime and Odersky, Martin},
  year		= {2022},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {POPL},
  pages		= {37:1--37:24},
  doi		= {10.1145/3498698},
  urldate	= {2023-09-26},
  abstract	= {Type-level programming is becoming more and more popular
		  in the realm of functional programming. However, the
		  combination of type-level programming and subtyping remains
		  largely unexplored in practical programming languages. This
		  paper presents match types, a type-level equivalent of
		  pattern matching. Match types integrate seamlessly into
		  programming languages with subtyping and, despite their
		  simplicity, offer significant additional expressiveness. We
		  formalize the feature of match types in a calculus based on
		  System F sub and prove its soundness. We practically
		  evaluate our system by implementing match types in the
		  Scala 3 reference compiler, thus making type-level
		  programming readily available to a broad audience of
		  programmers.},
  keywords	= {Match types,Scala}
}

@InProceedings{	  bocchi22,
  title		= {The {{Reversible Temporal Process Language}}},
  booktitle	= {Formal {{Techniques}} for {{Distributed Objects}},
		  {{Components}}, and {{Systems}}},
  author	= {Bocchi, Laura and Lanese, Ivan and Mezzina, Claudio
		  Antares and Yuen, Shoji},
  editor	= {Mousavi, Mohammad Reza and Philippou, Anna},
  year		= {2022},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {31--49},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-031-08679-3_3},
  abstract	= {Reversible debuggers help programmers to quickly find the
		  causes of misbehaviours in concurrent programs. These
		  debuggers can be founded on the well-studied theory of
		  causal-consistent reversibility, which allows one to undo
		  any action provided that its consequences are undone
		  beforehand. Till now, causal-consistent reversibility never
		  considered time, a key aspect in real world applications.
		  Here, we study the interplay between reversibility and time
		  in concurrent systems via a process algebra. The Temporal
		  Process Language (TPL) by Hennessy and Regan is a
		  well-understood extension of CCS with discrete-time and a
		  timeout operator. We define \$\${\textbackslash}mathtt
		  \{revTPL\}\$\$revTPL, a reversible extension of TPL, and we
		  show that it satisfies the properties expected from a
		  causal-consistent reversible calculus. We show that,
		  alternatively, \$\${\textbackslash}mathtt
		  \{revTPL\}\$\$revTPLcan be interpreted as an extension of
		  reversible CCS with time.},
  isbn		= {978-3-031-08679-3},
  langid	= {english}
}

@InProceedings{	  boothe00,
  title		= {Efficient Algorithms for Bidirectional Debugging},
  booktitle	= {Proceedings of the {{ACM SIGPLAN}} 2000 Conference on
		  {{Programming}} Language Design and Implementation},
  author	= {Boothe, Bob},
  year		= {2000},
  month		= may,
  series	= {{{PLDI}} '00},
  pages		= {299--310},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/349299.349339},
  urldate	= {2023-12-13},
  abstract	= {This paper discusses our research into algorithms for
		  creating an efficient bidirectional debugger in which all
		  traditional forward movement commands can be performed with
		  equal ease in the reverse direction. We expect that adding
		  these backwards movement capabilities to a debugger will
		  greatly increase its efficacy as a programming tool. The
		  efficiency of our methods arises from our use of event
		  counters that are embedded into the program being debugged.
		  These counters are used to precisely identify the desired
		  target event on the fly as the target program executes.
		  This is in contrast to traditional debuggers that may trap
		  back to the debugger many times for some movements. For
		  reverse movements we re-execute the program (possibly using
		  two passes) to identify and stop at the desired earlier
		  point. Our counter based techniques are essential for these
		  reverse movements because they allow us to efficiently
		  execute through the millions of events encountered during
		  re-execution. Two other important components of this
		  debugger are its I/O logging and checkpointing. We log and
		  later replay the results of system calls to ensure
		  deterministic re-execution, and we use checkpointing to
		  bound the amount of re-execution used for reverse
		  movements. Short movements generally appear instantaneous,
		  and the time for longer movements is usually bounded within
		  a small constant factor of the temporal distance moved
		  back.},
  isbn		= {978-1-58113-199-4}
}

@Article{	  boruch-gruszecki23,
  title		= {Capturing {{Types}}},
  author	= {{Boruch-Gruszecki}, Aleksander and Odersky, Martin and
		  Lee, Edward and Lhot{\'a}k, Ond{\v r}ej and
		  Brachth{\"a}user, Jonathan},
  year		= {2023},
  month		= nov,
  journal	= {ACM Trans. Program. Lang. Syst.},
  volume	= {45},
  number	= {4},
  pages		= {21:1--21:52},
  issn		= {0164-0925},
  doi		= {10.1145/3618003},
  urldate	= {2024-12-18},
  abstract	= {Type systems usually characterize the shape of values but
		  not their free variables. However, many desirable safety
		  properties could be guaranteed if one knew the free
		  variables captured by values. We describe CC\&lt; :◻, a
		  calculus where such captured variables are succinctly
		  represented in types, and show it can be used to safely
		  implement effects and effect polymorphism via scoped
		  capabilities. We discuss how the decision to track captured
		  variables guides key aspects of the calculus, and show that
		  CC\&lt; :◻\&nbsp; admits simple and intuitive types for
		  common data structures and their typical usage patterns. We
		  demonstrate how these ideas can be used to guide the
		  implementation of capture checking in a practical
		  programming language.}
}

@InProceedings{	  bosamiya22,
  title		= {\{\vphantom\}{{Provably-Safe}}\vphantom\{\} {{Multilingual
		  Software Sandboxing}} Using \{\vphantom\}{{WebAssembly}}\vphantom\{\}},
  booktitle	= {31st {{USENIX Security Symposium}} ({{USENIX Security}}
		  22)},
  author	= {Bosamiya, Jay and Lim, Wen Shih and Parno, Bryan},
  year		= {2022},
  pages		= {1975--1992},
  urldate	= {2024-01-18},
  isbn		= {978-1-939133-31-1},
  langid	= {english}
}

@InProceedings{	  brus87,
  title		= {Clean --- {{A}} Language for Functional Graph Rewriting},
  booktitle	= {Functional {{Programming Languages}} and {{Computer
		  Architecture}}},
  author	= {Brus, T. H. and {van Eekelen}, M. C. J. D. and {van Leer},
		  M. O. and Plasmeijer, M. J.},
  editor	= {Kahn, Gilles},
  year		= {1987},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {364--384},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-18317-5_20},
  abstract	= {Clean is an experimental language for specifying
		  functional computations in terms of graph rewriting. It is
		  based on an extension of Term Rewriting Systems (TRS) in
		  which the terms are replaced by graphs. Such a Graph
		  Rewriting System (GRS) consists of a, possibly cyclic,
		  directed graph, called the data graph and graph rewrite
		  rules which specify how this data graph may be rewritten.
		  Clean is designed to provide a firm base for functional
		  programming. In particular, Clean is suitable as an
		  intermediate language between functional languages and
		  (parallel) target machine architectures. A sequential
		  implementation of Clean on a conventional machine is
		  described and its performance is compared with other
		  systems. The results show that Clean can be efficiently
		  implemented.},
  isbn		= {978-3-540-47879-9},
  langid	= {english},
  keywords	= {Data Graph,Function Symbol,Functional Language,Functional
		  Strategy,Normal Form}
}

@InProceedings{	  burchell23,
  title		= {Don't {{Trust Your Profiler}}: {{An Empirical Study}} on
		  the {{Precision}} and {{Accuracy}} of {{Java Profilers}}},
  shorttitle	= {Don't {{Trust Your Profiler}}},
  booktitle	= {Proceedings of the 20th {{ACM SIGPLAN International
		  Conference}} on {{Managed Programming Languages}} and
		  {{Runtimes}}},
  author	= {Burchell, Humphrey and Larose, Octave and Kaleba, Sophie
		  and Marr, Stefan},
  year		= {2023},
  month		= oct,
  series	= {{{MPLR}} 2023},
  pages		= {100--113},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3617651.3622985},
  urldate	= {2023-10-27},
  abstract	= {To identify optimisation opportunities, Java developers
		  often use sampling profilers that attribute a percentage of
		  run time to the methods of a program. Even so these
		  profilers use sampling, are probabilistic in nature, and
		  may suffer for instance from safepoint bias, they are
		  normally considered to be relatively reliable. However,
		  unreliable or inaccurate profiles may misdirect developers
		  in their quest to resolve performance issues by not
		  correctly identifying the program parts that would benefit
		  most from optimisations. With the wider adoption of
		  profilers such as async-profiler and Honest Profiler, which
		  are designed to avoid the safepoint bias, we wanted to
		  investigate how precise and accurate Java sampling
		  profilers are today. We investigate the precision,
		  reliability, accuracy, and overhead of async-profiler,
		  Honest Profiler, Java Flight Recorder, JProfiler, perf, and
		  YourKit, which are all actively maintained. We assess them
		  on the fully deterministic Are We Fast Yet benchmarks to
		  have a stable foundation for the probabilistic profilers.
		  We find that profilers are relatively reliable over 30 runs
		  and normally report the same hottest method. Unfortunately,
		  this is not true for all benchmarks, which suggests their
		  reliability may be application-specific. Different
		  profilers also report different methods as hottest and
		  cannot reliably agree on the set of top 5 hottest methods.
		  On the positive side, the average run time overhead is in
		  the range of 1\% to 5.4\% for the different profilers.
		  Future work should investigate how results can become more
		  reliable, perhaps by reducing the observer effect of
		  profilers by using optimisation decisions of unprofiled
		  runs or by developing a principled approach of combining
		  multiple profiles that explore different dynamic
		  optimisations.},
  isbn		= {9798400703805},
  keywords	= {Analysis tools,CPU sampling,Profiler comparison,Profiler
		  precision,Profiling}
}

@InProceedings{	  burg13,
  title		= {Interactive Record/Replay for Web Application Debugging},
  booktitle	= {Proceedings of the 26th Annual {{ACM}} Symposium on
		  {{User}} Interface Software and Technology},
  author	= {Burg, Brian and Bailey, Richard and Ko, Amy J. and Ernst,
		  Michael D.},
  year		= {2013},
  month		= oct,
  series	= {{{UIST}} '13},
  pages		= {473--484},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2501988.2502050},
  urldate	= {2024-02-28},
  abstract	= {During debugging, a developer must repeatedly and manually
		  reproduce faulty behavior in order to inspect different
		  facets of the program's execution. Existing tools for
		  reproducing such behaviors prevent the use of debugging
		  aids such as breakpoints and logging, and are not designed
		  for interactive, random-access exploration of recorded
		  behavior. This paper presents Timelapse, a tool for quickly
		  recording, reproducing, and debugging interactive behaviors
		  in web applications. Developers can use Timelapse to
		  browse, visualize, and seek within recorded program
		  executions while simultaneously using familiar debugging
		  tools such as breakpoints and logging. Testers and
		  end-users can use Timelapse to demonstrate failures in situ
		  and share recorded behaviors with developers, improving bug
		  report quality by obviating the need for detailed
		  reproduction steps. Timelapse is built on Dolos, a novel
		  record/replay infrastructure that ensures deterministic
		  execution by capturing and reusing program inputs both from
		  the user and from external sources such as the network.
		  Dolos introduces negligible overhead and does not interfere
		  with breakpoints and logging. In a small user evaluation,
		  participants used Timelapse to accelerate existing
		  reproduction activities, but were not significantly faster
		  or more successful in completing the larger tasks at hand.
		  Together, the Dolos infrastructure and Timelapse developer
		  tool support systematic bug reporting and debugging
		  practices.},
  isbn		= {978-1-4503-2268-3},
  keywords	= {debugging,deterministic replay,web applications}
}

@InProceedings{	  buskey06,
  title		= {Protected {{JTAG}}},
  booktitle	= {2006 {{International Conference}} on {{Parallel Processing
		  Workshops}} ({{ICPPW}}'06)},
  author	= {Buskey, R.F. and Frosik, B.B.},
  year		= {2006},
  month		= aug,
  pages		= {8 pp.-414},
  issn		= {2332-5690},
  doi		= {10.1109/ICPPW.2006.65},
  urldate	= {2024-11-15},
  abstract	= {In this paper, we consider a particular aspect of an
		  effort to define trusted computing solutions. One of the
		  hardware features of an embedded device is the JTAG (joint
		  test action group) port that allows easy access to a
		  processor for debugging purposes. This access is a
		  potential security threat in a high assurance environment.
		  This paper presents a solution of a protected JTAG. The
		  purpose of providing protected JTAG, as part of the trusted
		  computing platform, is to prevent access to private and
		  confidential information by unauthorized users and yet
		  allow debugging functions. The presented solution
		  introduces different levels of access. The level of user's
		  access is based on the user's permissions.},
  keywords	= {Access protocols,Circuits,Debugging,Hardware,Information
		  security,Internet,Mathematical
		  model,Protection,Registers,Testing}
}

@Article{	  campbell02,
  title		= {Deep {{Blue}}},
  author	= {Campbell, Murray and Hoane, A. Joseph and Hsu,
		  Feng-hsiung},
  year		= {2002},
  month		= jan,
  journal	= {Artificial Intelligence},
  volume	= {134},
  number	= {1},
  pages		= {57--83},
  issn		= {0004-3702},
  doi		= {10.1016/S0004-3702(01)00129-1},
  urldate	= {2024-03-11},
  abstract	= {Deep Blue is the chess machine that defeated then-reigning
		  World Chess Champion Garry Kasparov in a six-game match in
		  1997. There were a number of factors that contributed to
		  this success, including: {$\bullet$}a single-chip chess
		  search engine,{$\bullet$}a massively parallel system with
		  multiple levels of parallelism,{$\bullet$}a strong emphasis
		  on search extensions,{$\bullet$}a complex evaluation
		  function, and{$\bullet$}effective use of a Grandmaster game
		  database. This paper describes the Deep Blue system, and
		  gives some of the rationale that went into the design
		  decisions behind Deep Blue.},
  keywords	= {Computer chess,Evaluation function,Game tree
		  search,Parallel search,Search extensions,Selective search}
}

@Article{	  cartwright91,
  title		= {Soft Typing},
  author	= {Cartwright, Robert and Fagan, Mike},
  year		= {1991},
  month		= may,
  journal	= {ACM SIGPLAN Notices},
  volume	= {26},
  number	= {6},
  pages		= {278--292},
  issn		= {0362-1340},
  doi		= {10.1145/113446.113469},
  urldate	= {2023-10-20}
}

@Article{	  casadei22,
  title		= {{{ScaFi}}: {{A Scala DSL}} and {{Toolkit}} for {{Aggregate
		  Programming}}},
  shorttitle	= {{{ScaFi}}},
  author	= {Casadei, Roberto and Viroli, Mirko and Aguzzi, Gianluca
		  and Pianini, Danilo},
  year		= {2022},
  month		= dec,
  journal	= {SoftwareX},
  volume	= {20},
  pages		= {101248},
  issn		= {2352-7110},
  doi		= {10.1016/j.softx.2022.101248},
  urldate	= {2024-05-17},
  abstract	= {Supported by current socio-scientific trends, programming
		  the global behaviour of whole computational collectives
		  makes for great opportunities, but also significant
		  challenges. Recently, aggregate computing has emerged as a
		  prominent paradigm for so-called collective adaptive
		  systems programming. To shorten the gap between such
		  research endeavours and mainstream software development and
		  engineering, we present ScaFi, a Scala toolkit providing an
		  internal domain-specific language, libraries, a simulation
		  environment, and runtime support for practical aggregate
		  computing systems development.},
  keywords	= {Aggregate programming,Computational fields,Distributed
		  computing,Macro-level programming,Scala toolkit}
}

@InProceedings{	  chalupa21,
  title		= {Fast {{Computation}} of {{Strong Control Dependencies}}},
  booktitle	= {Computer {{Aided Verification}}},
  author	= {Chalupa, Marek and Kla{\u s}ka, David and Strej{\v c}ek,
		  Jan and Tomovi{\u c}, Luk{\'a}{\u s}},
  editor	= {Silva, Alexandra and Leino, K. Rustan M.},
  year		= {2021},
  pages		= {887--910},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-81688-9_41},
  abstract	= {We introduce new algorithms for computing non-termination
		  sensitive control dependence (NTSCD) and decisive order
		  dependence (DOD). These relations on vertices of a control
		  flow graph have many applications including program slicing
		  and compiler optimizations. Our algorithms are
		  asymptotically faster than the current algorithms. We also
		  show that the original algorithms for computing NTSCD and
		  DOD may produce incorrect results. We implemented the new
		  as well as fixed versions of the original algorithms for
		  the computation of NTSCD and DOD. Experimental evaluation
		  shows that our algorithms dramatically outperform the
		  original ones.},
  isbn		= {978-3-030-81688-9},
  langid	= {english}
}

@Article{	  chappe23,
  title		= {Choice {{Trees}}: {{Representing Nondeterministic}},
		  {{Recursive}}, and {{Impure Programs}} in {{Coq}}},
  shorttitle	= {Choice {{Trees}}},
  author	= {Chappe, Nicolas and He, Paul and Henrio, Ludovic and
		  Zakowski, Yannick and Zdancewic, Steve},
  year		= {2023},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {POPL},
  pages		= {61:1770--61:1800},
  doi		= {10.1145/3571254},
  urldate	= {2023-09-27},
  abstract	= {This paper introduces ctrees, a monad for modeling
		  nondeterministic, recursive, and impure programs in Coq.
		  Inspired by Xia et al.'s itrees, this novel data structure
		  embeds computations into coinductive trees with three kind
		  of nodes: external events, and two variants of
		  nondeterministic branching. This apparent redundancy allows
		  us to provide shallow embedding of denotational models with
		  internal choice in the style of CCS, while recovering an
		  inductive LTS view of the computation. ctrees inherit a
		  vast collection of bisimulation and refinement tools, with
		  respect to which we establish a rich equational theory. We
		  connect ctrees to the itree infrastructure by showing how a
		  monad morphism embedding the former into the latter permits
		  to use ctrees to implement nondeterministic effects. We
		  demonstrate the utility of ctrees by using them to model
		  concurrency semantics in two case studies: CCS and
		  cooperative multithreading.},
  keywords	= {Concurrency,Formal Semantics,Interaction
		  Trees,Nondeterminism}
}

@Article{	  chen01,
  title		= {Reversible Debugging Using Program Instrumentation},
  author	= {Chen, Shyh-Kwei and Fuchs, W.K. and Chung, Jen-Yao},
  year		= {2001},
  month		= aug,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {27},
  number	= {8},
  pages		= {715--727},
  issn		= {1939-3520},
  doi		= {10.1109/32.940726},
  urldate	= {2023-09-28},
  abstract	= {Reversible execution has not been fully exploited in
		  symbolic debuggers. Debuggers that can undo instructions
		  usually incur a significant performance penalty during a
		  debugging session. We describe an efficient reversible
		  debugging mechanism based on program instrumentation. The
		  approach enables repetitive debugging sessions with
		  selectable reversible routines and recording modes.
		  Experimental results indicate that the execution penalty
		  can be significantly reduced with moderate code growth.}
}

@Article{	  chen21,
  title		= {{{ALGEBRAIC INFORMATION EFFECTS}}},
  author	= {Chen, Chao-Hong},
  year		= {2021},
  month		= aug,
  publisher	= {[Bloomington, Ind.] : Indiana University},
  urldate	= {2023-09-29},
  abstract	= {From the informational perspective, programs that are
		  usually considered as pure have effects, for example, the
		  simply typed lambda calculus is considered as a pure
		  language. However, {$\beta$}--reduction does not preserve
		  information and embodies information effects. To capture
		  the idea about pure programs in the informational sense, a
		  new model of computation --- reversible computation was
		  proposed. This work focuses on type-theoretic approaches
		  for reversible effect handling. The main idea of this work
		  is inspired by compact closed categories. Compact closed
		  categories are categories equipped with a dual object for
		  every object. They are well-established as models of linear
		  logic, concurrency, and quantum computing. This work gives
		  computational interpretations of compact closed categories
		  for conventional product and sum types, where a negative
		  type represents a computational effect that ``reverses
		  execution flow'' and a fractional type represents a
		  computational effect that ``allocates/deallocates space''.},
  copyright	= {This work is under a CC-BY license. You are free to copy
		  and redistribute the material in any format, as well as
		  remix, transform, and build upon the material as long as
		  you give appropriate credit to the original creator,
		  provide a link to the license, and indicate any changes
		  made.},
  langid	= {english},
  annotation	= {Accepted: 2021-08-23T03:09:12Z}
}

@InProceedings{	  chowdhury18,
  title		= {Safe and {{Secure Automotive Over-the-Air Updates}}},
  booktitle	= {Computer {{Safety}}, {{Reliability}}, and {{Security}}},
  author	= {Chowdhury, Thomas and Lesiuta, Eric and Rikley, Kerianne
		  and Lin, Chung-Wei and Kang, Eunsuk and Kim, BaekGyu and
		  Shiraishi, Shinichi and Lawford, Mark and Wassyng, Alan},
  editor	= {Gallina, Barbara and Skavhaug, Amund and Bitsch,
		  Friedemann},
  year		= {2018},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {172--187},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-99130-6_12},
  abstract	= {Over-the-air updates have been used for years in the
		  software industry, allowing bug fixes and enhancements to
		  desktop, laptop, and mobile operating systems and
		  applications. Automotive vehicles now depend on software to
		  the extent that manufacturers are turning to over-the-air
		  updates for critical vehicle functionality. History shows
		  that our software systems are most vulnerable to lapses in
		  safety and dependability when they undergo change, and
		  performing an update over a communication channel adds a
		  significant security concern. This paper presents our ideas
		  on assuring integrated safety and security of over-the-air
		  updates through assurance case templates that comply with
		  both ISO 26262 (functional safety) and SAE J3061
		  (cyber-security). Wisely, the authors of SAE J3061
		  structured the guidebook so that it meshes well with ISO
		  26262, and we have been able to use principles we developed
		  for deriving an assurance case template from ISO 26262, to
		  help include compliance with SAE J3061 in the template. The
		  paper also demonstrates how a specialization of the
		  template helps guide us to pre-emptively mitigate against
		  potential vulnerabilities in over-the-air update
		  implementations.},
  isbn		= {978-3-319-99130-6},
  langid	= {english}
}

@InProceedings{	  coetzee15,
  title		= {Combining Reverse Debugging and Live Programming towards
		  Visual Thinking in Computer Programming},
  author	= {Coetzee, A.},
  year		= {2015},
  month		= mar,
  urldate	= {2023-09-26},
  abstract	= {Combining reverse debugging and live programming towards
		  visual thinking in computer programming}
}

@InProceedings{	  cousot02,
  title		= {Modular {{Static Program Analysis}}},
  booktitle	= {Compiler {{Construction}}},
  author	= {Cousot, Patrick and Cousot, Radhia},
  editor	= {Horspool, R. Nigel},
  year		= {2002},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {159--179},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-45937-5_13},
  abstract	= {The purpose of this paper is to present four basic methods
		  for compositional separate modular static analysis of
		  programs by abstract interpretation: - simplification-based
		  separate analysis; - worst-case separate analysis; -
		  separate analysis with (user-provided) interfaces; -
		  symbolic relational separate analysis; as well as a fifth
		  category which is essentially obtained by composition of
		  the above separate local analyses together with global
		  analysis methods.},
  isbn		= {978-3-540-45937-8},
  langid	= {english},
  keywords	= {Abstract Domain,Abstract Interpretation,Dependence
		  Graph,Logic Program,Program Part}
}

@InProceedings{	  crary99,
  title		= {Typed Memory Management in a Calculus of Capabilities},
  booktitle	= {Proceedings of the 26th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Crary, Karl and Walker, David and Morrisett, Greg},
  year		= {1999},
  month		= jan,
  series	= {{{POPL}} '99},
  pages		= {262--275},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/292540.292564},
  urldate	= {2023-12-01},
  abstract	= {An increasing number of systems rely on programming
		  language technology to ensure safety and security of
		  low-level code. Unfortunately, these systems typically rely
		  on a complex, trusted garbage collector. Region-based type
		  systems provide an alternative to garbage collection by
		  making memory management explicit but verifiably safe.
		  However, it has not been clear how to use regions in
		  low-level, type-safe code.We present a compiler
		  intermediate language, called the Capability Calculus, that
		  supports region-based memory management, enjoys a provably
		  safe type system, and is straightforward to compile to a
		  typed assembly language. Source languages may be compiled
		  to our language using known region inference algorithms.
		  Furthermore, region lifetimes need not be lexically scoped
		  in our language, yet the language may be checked for safety
		  without complex analyses. Finally, our soundness proof is
		  relatively simple, employing only standard techniques.The
		  central novelty is the use of static capabilities to
		  specify the permissibility of various operations, such as
		  memory access and deallocation. In order to ensure
		  capabilities are relinquished properly, the type system
		  tracks aliasing information using a form of bounded
		  quantification.},
  isbn		= {978-1-58113-095-9}
}

@Article{	  crescenzi00,
  title		= {Reversible {{Execution}} and {{Visualization}} of
		  {{Programs}} with {{LEONARDO}}},
  author	= {Crescenzi, {\relax PIERLUIGI} and Demetrescu, {\relax
		  CAMIL} and Finocchi, {\relax IRENE} and Petreschi, {\relax
		  ROSSELLA}},
  year		= {2000},
  month		= apr,
  journal	= {Journal of Visual Languages \& Computing},
  volume	= {11},
  number	= {2},
  pages		= {125--150},
  issn		= {1045-926X},
  doi		= {10.1006/jvlc.1999.0143},
  urldate	= {2024-02-29},
  abstract	= {In this paper we present LEONARDO, an integrated
		  environment for software visualization that allows the user
		  to edit, compile, execute, and animate general-purpose C
		  programs. LEONARDO relies on a logic-based approach to
		  visualization: a mapping between concrete and abstract data
		  structures can be declared through a logic visualization
		  language and animations are conceived as reflecting formal
		  properties of algorithms. LEONARDO is able to automatically
		  detect visual events during the execution of programs and
		  simplifies the creation of visualizations according to an
		  incremental approach. Moreover, it guarantees the complete
		  reversibility of computations, bounded only by the
		  potentiality of the working machine, and appears simple to
		  be used. The latest version of LEONARDO is currently
		  available over the Internet at the URLhttp:
		  //www.dis.uniroma1.it/{\textasciitilde}demetres/Leonardo/.}
}

@Article{	  cutler24,
  title		= {Stream {{Types}}},
  author	= {Cutler, Joseph W. and Watson, Christopher and Nkurumeh,
		  Emeka and Hilliard, Phillip and Goldstein, Harrison and
		  Stanford, Caleb and Pierce, Benjamin C.},
  year		= {2024},
  month		= jun,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {8},
  number	= {PLDI},
  pages		= {204:1412--204:1436},
  doi		= {10.1145/3656434},
  urldate	= {2024-12-18},
  abstract	= {We propose a rich foundational theory of typed data
		  streams and stream transformers, motivated by two
		  high-level goals. First, the type of a stream should be
		  able to express complex sequential patterns of events over
		  time. And second, it should describe the internal parallel
		  structure of the stream, to support deterministic stream
		  processing on parallel and distributed systems. To these
		  ends, we introduce stream types, with operators capturing
		  sequential composition, parallel composition, and
		  iteration, plus a core calculus {$\lambda$}ST of
		  transformers over typed streams that naturally supports a
		  number of common streaming idioms, including punctuation,
		  windowing, and parallel partitioning, as first-class
		  constructions. {$\lambda$}ST exploits a Curry-Howard-like
		  correspondence with an ordered variant of the Logic of
		  Bunched Implication to program with streams compositionally
		  and uses Brzozowski-style derivatives to enable an
		  incremental, prefix-based operational semantics. To
		  illustrate the programming style supported by the rich
		  types of {$\lambda$}ST, we present a number of examples
		  written in Delta, a prototype high-level language design
		  based on {$\lambda$}ST.}
}

@Article{	  damiani16,
  title		= {A Type-Sound Calculus of Computational Fields},
  author	= {Damiani, Ferruccio and Viroli, Mirko and Beal, Jacob},
  year		= {2016},
  month		= feb,
  journal	= {Science of Computer Programming},
  volume	= {117},
  pages		= {17--44},
  issn		= {0167-6423},
  doi		= {10.1016/j.scico.2015.11.005},
  urldate	= {2024-05-17},
  abstract	= {A number of recent works have investigated the notion of
		  ``computational fields'' as a means of coordinating systems
		  in distributed, dense and dynamic environments such as
		  pervasive computing, sensor networks, and robot swarms. We
		  introduce a minimal core calculus meant to capture the key
		  ingredients of languages that make use of computational
		  fields: functional composition of fields, functions over
		  fields, evolution of fields over time, construction of
		  fields of values from neighbours, and restriction of a
		  field computation to a sub-region of the network. We
		  formalise a notion of type soundness for the calculus that
		  encompasses the concept of domain alignment, and present a
		  sound static type inference system. This calculus and its
		  type inference system can act as a core for actual
		  implementation of coordination languages and models, as
		  well as to pave the way towards formal analysis of
		  properties concerning expressiveness, self-stabilisation,
		  topology independence, and relationships with the
		  continuous space--time semantics of spatial computations.},
  keywords	= {Computational field,Core calculus,Operational
		  semantics,Spatial computing,Type soundness}
}

@InProceedings{	  danos04,
  title		= {Reversible {{Communicating Systems}}},
  booktitle	= {{{CONCUR}} 2004 - {{Concurrency Theory}}},
  author	= {Danos, Vincent and Krivine, Jean},
  editor	= {Gardner, Philippa and Yoshida, Nobuko},
  year		= {2004},
  pages		= {292--307},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-540-28644-8_19},
  abstract	= {One obtains in this paper a process algebra RCCS, in the
		  style of CCS, where processes can backtrack. Backtrack,
		  just as plain forward computation, is seen as a
		  synchronization and incurs no additional cost on the
		  communication structure. It is shown that, given a past, a
		  computation step can be taken back if and only if it leads
		  to a causally equivalent past.},
  isbn		= {978-3-540-28644-8},
  langid	= {english}
}

@Article{	  dardinier24,
  title		= {Hyper {{Hoare Logic}}: ({{Dis-}}){{Proving Program
		  Hyperproperties}}},
  shorttitle	= {Hyper {{Hoare Logic}}},
  author	= {Dardinier, Thibault and M{\"u}ller, Peter},
  year		= {2024},
  month		= jun,
  journal	= {Hyper Hoare Logic: (Dis-)Proving Program Hyperproperties
		  (artifact)},
  volume	= {8},
  number	= {PLDI},
  pages		= {207:1485--207:1509},
  doi		= {10.1145/3656437},
  urldate	= {2024-12-13},
  abstract	= {Hoare logics are proof systems that allow one to formally
		  establish properties of computer programs. Traditional
		  Hoare logics prove properties of individual program
		  executions (such as functional correctness). Hoare logic
		  has been generalized to prove also properties of multiple
		  executions of a program (so-called hyperproperties, such as
		  determinism or non-interference). These program logics
		  prove the absence of (bad combinations of) executions. On
		  the other hand, program logics similar to Hoare logic have
		  been proposed to disprove program properties (e.g.,
		  Incorrectness Logic), by proving the existence of (bad
		  combinations of) executions. All of these logics have in
		  common that they specify program properties using
		  assertions over a fixed number of states, for instance, a
		  single pre- and post-state for functional properties or
		  pairs of pre- and post-states for non-interference. In this
		  paper, we present Hyper Hoare Logic, a generalization of
		  Hoare logic that lifts assertions to properties of
		  arbitrary sets of states. The resulting logic is simple yet
		  expressive: its judgments can express arbitrary program
		  hyperproperties, a particular class of hyperproperties over
		  the set of terminating executions of a program (including
		  properties of individual program executions). By allowing
		  assertions to reason about sets of states, Hyper Hoare
		  Logic can reason about both the absence and the existence
		  of (combinations of) executions, and, thereby, supports
		  both proving and disproving program (hyper-)properties
		  within the same logic, including (hyper-)properties that no
		  existing Hoare logic can express. We prove that Hyper Hoare
		  Logic is sound and complete, and demonstrate that it
		  captures important proof principles naturally. All our
		  technical results have been proved in Isabelle/HOL.}
}

@Article{	  dash23,
  title		= {Affine {{Monads}} and {{Lazy Structures}} for {{Bayesian
		  Programming}}},
  author	= {Dash, Swaraj and Kaddar, Younesse and Paquet, Hugo and
		  Staton, Sam},
  year		= {2023},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {POPL},
  pages		= {46:1338--46:1368},
  doi		= {10.1145/3571239},
  urldate	= {2023-09-27},
  abstract	= {We show that streams and lazy data structures are a
		  natural idiom for programming with infinite-dimensional
		  Bayesian methods such as Poisson processes, Gaussian
		  processes, jump processes, Dirichlet processes, and Beta
		  processes. The crucial semantic idea, inspired by
		  developments in synthetic probability theory, is to work
		  with two separate monads: an affine monad of probability,
		  which supports laziness, and a commutative, non-affine
		  monad of measures, which does not. (Affine means that
		  T(1){$\cong$} 1.) We show that the separation is important
		  from a decidability perspective, and that the recent model
		  of quasi-Borel spaces supports these two monads. To perform
		  Bayesian inference with these examples, we introduce new
		  inference methods that are specially adapted to laziness;
		  they are proven correct by reference to the
		  Metropolis-Hastings-Green method. Our theoretical
		  development is implemented as a Haskell library, LazyPPL.},
  keywords	= {Bayesian inference,categorical semantics,commutative
		  monads,functional
		  programming,Haskell,laziness,nonparametric
		  statistics,probabilistic programming,quasi-Borel
		  spaces,synthetic measure theory}
}

@Misc{		  datadog00,
  title		= {End to {{End Testing Automation}}},
  author	= {Datadog},
  year		= {00:00:00 +0000 UTC},
  journal	= {Datadog},
  urldate	= {2024-02-12},
  abstract	= {Learn how to create and configure robust end-to-end tests
		  with ease using automation.},
  howpublished	= {https://www.datadoghq.com/synthetics/end-to-end-testing-automation/},
  langid	= {english}
}

@InCollection{	  de-boer20,
  title		= {{{SymPaths}}: {{Symbolic Execution Meets Partial Order
		  Reduction}}},
  shorttitle	= {{{SymPaths}}},
  booktitle	= {Deductive {{Software Verification}}: {{Future
		  Perspectives}}: {{Reflections}} on the {{Occasion}} of 20
		  {{Years}} of {{KeY}}},
  author	= {{de Boer}, Frank S. and Bonsangue, Marcello and Johnsen,
		  Einar Broch and Pun, Violet Ka I. and Tapia Tarifa, S.
		  Lizeth and Tveito, Lars},
  editor	= {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard
		  and H{\"a}hnle, Reiner and Ulbrich, Mattias},
  year		= {2020},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {313--338},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-64354-6_13},
  urldate	= {2023-10-16},
  abstract	= {Symbolic execution is an important technique for software
		  analysis, which enables systematic model exploration by
		  following all possible execution paths for a given program.
		  For multithreaded shared variable programs, this technique
		  leads to a state space explosion. Partial order reduction
		  is a technique which allows equivalent execution paths to
		  be recognized, reducing the state space explosion problem.
		  This paper provides formal justifications for these
		  techniques in a multithreaded setting by proving the
		  correctness and completeness of symbolic execution for
		  multithreaded shared variable programs, with and without
		  the use of partial order reduction. We then show how these
		  formal justifications carry over to prove the soundness and
		  relative completeness of a proof system for such
		  multithreaded shared variable programs in dynamic logic,
		  such that partial order reduction can be used to simplify
		  the proof construction by mitigating the state space
		  explosion.},
  isbn		= {978-3-030-64354-6},
  langid	= {english}
}

@Article{	  de-boer21,
  title		= {Symbolic Execution Formally Explained},
  author	= {{de Boer}, Frank S. and Bonsangue, Marcello},
  year		= {2021},
  month		= aug,
  journal	= {Formal Aspects of Computing},
  volume	= {33},
  number	= {4},
  pages		= {617--636},
  issn		= {1433-299X},
  doi		= {10.1007/s00165-020-00527-y},
  urldate	= {2023-10-16},
  abstract	= {In this paper, we provide a formal explanation of symbolic
		  execution in terms of a symbolic transition system and
		  prove its correctness and completeness with respect to an
		  operational semantics which models the execution on
		  concrete values.We first introduce a formalmodel for a
		  basic programming languagewith a statically fixed number of
		  programming variables. This model is extended to a
		  programming language with recursive procedures which are
		  called by a call-by-value parameter mechanism. Finally, we
		  present a more general formal framework for proving the
		  soundness and completeness of the symbolic execution of a
		  basic object-oriented language which features dynamically
		  allocated variables.},
  langid	= {english}
}

@InProceedings{	  de-troyer18,
  title		= {Building {{IoT Systems Using Distributed First-Class
		  Reactive Programming}}},
  booktitle	= {2018 {{IEEE International Conference}} on {{Cloud
		  Computing Technology}} and {{Science}} ({{CloudCom}})},
  author	= {{de Troyer}, Christophe and Nicolay, Jens and {de Meuter},
		  Wolfgang},
  year		= {2018},
  month		= dec,
  pages		= {185--192},
  issn		= {2330-2186},
  doi		= {10.1109/CloudCom2018.2018.00045},
  urldate	= {2023-10-03},
  abstract	= {Contemporary IoT systems are challenging to develop,
		  deploy, and maintain. This is because of their
		  ever-increasing scale, dynamic network topologies,
		  heterogeneity and resource constraints of the involved
		  devices, and failures that may occur as a result of these
		  characteristics. Existing approaches are either not at the
		  right level of abstraction, require developers to learn
		  specialized languages, or miss certain key features to
		  address all these challenges in a uniform manner. In this
		  paper we leverage reactive programming and code mobility to
		  support the entire life-cycle of large-scale IoT systems.
		  Our approach is based on existing programming technologies
		  and offers simple and composable abstractions to
		  developers. We implemented our approach in a middleware
		  called Potato and used it to develop and deploy an IoT
		  application on a Raspberry Pi cluster. We found that using
		  Potato reduces much of the accidental complexity associated
		  with developing and deploying IoT systems, resulting in
		  clean and maintainable programs.}
}

@Article{	  de23,
  title		= {Evaluating Reliability against {{SEE}} of Embedded
		  Systems: {{A}} Comparison of {{RTOS}} and Bare-Metal
		  Approaches},
  shorttitle	= {Evaluating Reliability against {{SEE}} of Embedded
		  Systems},
  author	= {De Sio, C. and Azimi, S. and Sterpone, L.},
  year		= {2023},
  month		= oct,
  journal	= {Microelectronics Reliability},
  pages		= {115124},
  issn		= {0026-2714},
  doi		= {10.1016/j.microrel.2023.115124},
  urldate	= {2023-10-12},
  abstract	= {Embedded processors are widely used in critical
		  applications such as space missions, where reliability is
		  mandatory for the success of missions. Due to the
		  increasing application complexity, the number of systems
		  using Real-Time Operating Systems (RTOSs) is quickly
		  growing to manage the execution of multiple applications
		  and meet timing constraints. However, whether operating
		  systems or bare-metal applications provide higher
		  reliability is still being determined. We present a
		  comprehensive reliability analysis of software applications
		  running on a device with bare-metal and FreeRTOS against
		  the same faults based on fault models derived from a proton
		  test. Additionally, the FreeRTOS system has been evaluated
		  with a set of software applications dedicated to evaluating
		  specific RTOS functions, providing an additional evaluation
		  for operations crucial for a real-time operating system.},
  keywords	= {Baremetal,Embedded processors,Fault
		  injection,FreeRTOS,Multiple cell upset,Operating
		  system,Radiation effects,Reliability,RTOS,Single event
		  upset}
}

@InProceedings{	  decker18,
  title		= {Online Analysis of Debug Trace Data for Embedded Systems},
  booktitle	= {2018 {{Design}}, {{Automation}} \& {{Test}} in {{Europe
		  Conference}} \& {{Exhibition}} ({{DATE}})},
  author	= {Decker, Normann and Dreyer, Boris and Gottschling, Philip
		  and Hochberger, Christian and Lange, Alexander and Leucker,
		  Martin and Scheffel, Torben and Wegener, Simon and Weiss,
		  Alexander},
  year		= {2018},
  month		= mar,
  pages		= {851--856},
  issn		= {1558-1101},
  doi		= {10.23919/DATE.2018.8342124},
  urldate	= {2024-06-04},
  abstract	= {Modern multi-core Systems-on-Chip (SoC) provide very high
		  computational power. On the downside, they are hard to
		  debug and it is often very difficult to understand what is
		  going on in these chips because of the limited
		  observability inside the SoC. Chip manufacturers try to
		  compensate this difficulty by providing highly compressed
		  trace data from the individual cores. In the past, the
		  common way to deal with this data was storing it for later
		  offline analysis, which severely limits the time span that
		  can be observed. In this contribution, we present an
		  FPGA-based solution that is able to process the trace data
		  in real-time, enabling continuous observation of the state
		  of a core. Moreover, we discuss applications enabled by
		  this technology.},
  keywords	= {Bandwidth,Field programmable gate
		  arrays,Hardware,Instruments,Monitoring,Runtime,Software}
}

@InProceedings{	  deiner24,
  title		= {{{NuzzleBug}}: {{Debugging Block-Based Programs}} in
		  {{Scratch}}},
  shorttitle	= {{{NuzzleBug}}},
  booktitle	= {Proceedings of the 46th {{IEEE}}/{{ACM International
		  Conference}} on {{Software Engineering}}},
  author	= {Deiner, Adina and Fraser, Gordon},
  year		= {2024},
  month		= feb,
  pages		= {1--13},
  publisher	= {ACM},
  address	= {Lisbon, Portugal},
  doi		= {10.1145/3597503.3623331},
  isbn		= {9798400702174},
  langid	= {english}
}

@InProceedings{	  disselkoen19,
  title		= {Position {{Paper}}: {{Progressive Memory Safety}} for
		  {{WebAssembly}}},
  shorttitle	= {Position {{Paper}}},
  booktitle	= {Proceedings of the 8th {{International Workshop}} on
		  {{Hardware}} and {{Architectural Support}} for {{Security}}
		  and {{Privacy}}},
  author	= {Disselkoen, Craig and Renner, John and Watt, Conrad and
		  Garfinkel, Tal and Levy, Amit and Stefan, Deian},
  year		= {2019},
  month		= jun,
  series	= {{{HASP}} '19},
  pages		= {1--8},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3337167.3337171},
  urldate	= {2024-01-18},
  abstract	= {WebAssembly (Wasm) is a low-level platform-independent
		  bytecode language. Today, developers can compile C/C++ to
		  Wasm and run it everywhere, at almost native speeds.
		  Unfortunately, this compilation from C/C++ to Wasm also
		  preserves classic memory safety vulnerabilities, such as
		  buffer overflows and use-after-frees. New processor
		  features (e.g., tagged memory, pointer authentication, and
		  fine grain capabilities) are making it increasingly
		  possible to detect, mitigate, and prevent such
		  vulnerabilities with low overhead. Unfortunately, Wasm JITs
		  and compilers cannot exploit these features. Critical
		  high-level information---e.g., the size of an array---is
		  lost when lowering to Wasm. We present MS-Wasm, an
		  extension to Wasm that bridges this gap by allowing
		  developers to capture low-level C/C++ memory semantics such
		  as pointers and memory allocation in Wasm, at compile time.
		  At deployment time, Wasm compilers and JITs can leverage
		  these added semantics to enforce different models of memory
		  safety depending on user preferences and what hardware is
		  available on the target platform. This way, MS-Wasm offers
		  a range of security-performance trade-offs, and enables
		  users to move to progressively stronger models of memory
		  safety as hardware evolves.},
  isbn		= {978-1-4503-7226-8},
  keywords	= {memory safety,tagged memory,Wasm,WebAssembly}
}

@Article{	  doderlein24,
  title		= {{{LiveRec}}: {{Prototyping Probes}} by {{Framing Debug
		  Protocols}}},
  shorttitle	= {{{LiveRec}}},
  author	= {D{\"o}derlein, Jean-Baptiste and van Rozen, Riemer and van
		  der Storm, Tijs},
  year		= {2024},
  month		= feb,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {8},
  number	= {3},
  pages		= {16:1-16:36},
  publisher	= {AOSA, Inc.},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2024/8/16},
  urldate	= {2024-03-13},
  abstract	= {Context: In the first part of his 2012 presentation
		  ``Inventing on Principle'', Bret Victor gives a demo of a
		  live code editor for Javascript which shows the dynamic
		  history of values of variables in real time. This form of
		  live programming has become known as ``probes''. Probes
		  provide the programme...},
  langid	= {english}
}

@InProceedings{	  dupriez17,
  title		= {Analysis and Exploration for New Generation Debuggers},
  booktitle	= {Proceedings of the 12th Edition of the {{International
		  Workshop}} on {{Smalltalk Technologies}}},
  author	= {Dupriez, Thomas and Polito, Guillermo and Ducasse,
		  St{\'e}phane},
  year		= {2017},
  month		= sep,
  series	= {{{IWST}} '17},
  pages		= {1--6},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3139903.3139910},
  urldate	= {2023-09-25},
  abstract	= {Locating and fixing bugs is well-known to be a time
		  consuming task. Advanced approaches such as object-centric
		  or back-in-time debuggers have been proposed in the
		  literature. still in many scenarios developers are left
		  alone with generic tools such as manual breakpoints and
		  execution stepping that, while usable, cannot adapt to
		  specific debugging scenarios to make the life of developers
		  easier. In this position paper we explore several advanced
		  on-line debugging techniques such as contextual breakpoints
		  and on-line execution comparison, that could help
		  developers solve complex debugging scenarios. We analyse
		  the open research challenges these techniques pose, as well
		  as the underlying mechanisms they require. We present early
		  but promising prototypes we built using the Pharo
		  programming language. We finally identify future research
		  paths by analysing existing research and connecting it to
		  the techniques we presented before.},
  isbn		= {978-1-4503-5554-4},
  keywords	= {Breakpoint,Debugger,Stack,Tool,Watchpoint}
}

@InCollection{	  edelkamp12,
  title		= {Chapter 16 - {{Automated System Verification}}},
  booktitle	= {Heuristic {{Search}}},
  author	= {Edelkamp, Stefan and Schr{\"o}dl, Stefan},
  editor	= {Edelkamp, Stefan and Schr{\"o}dl, Stefan},
  year		= {2012},
  month		= jan,
  pages		= {701--736},
  publisher	= {Morgan Kaufmann},
  address	= {San Francisco},
  doi		= {10.1016/B978-0-12-372512-7.00016-X},
  urldate	= {2024-08-29},
  abstract	= {This chapter gives an introduction to search problems in
		  model checking, Petri nets, and graph transition systems.
		  It also introduces automated theorem proving and discusses
		  state space search for proof state-based theorem proving
		  and diagnosis problems. The presence of a vast number of
		  computing devices in our environment imposes a challenge
		  for designers to produce reliable software. In medicine,
		  aviation, finance, transportation, space technology, and
		  communication, we are more and more aware of the critical
		  role correct hardware and software play. Failure leads to
		  financial and commercial disaster, human suffering, and
		  fatalities. However, systems are harder to verify than in
		  earlier days. Testing if a system works as intended becomes
		  increasingly difficult. Nowadays, design groups spend 50\%
		  to 70\% of the design time on verification. The cost of the
		  late discovery of bugs is enormous, justifying the fact
		  that, for a typical microprocessor design project, up to
		  half of the overall resources spent are devoted to its
		  verification. Most of the work in heuristic search for
		  automated system verification concentrates on accelerated
		  falsification. With directed automated theorem proving,
		  algorithms like A* and greedy best-first search are
		  integrated in a deductive system.},
  isbn		= {978-0-12-372512-7},
  keywords	= {automated theorem proving,communication
		  protocol,diagnosis,directed model checking,general
		  diagnostic engine,graph transition system,knowledge base
		  anomaly,model checking,Petri net,priced timed
		  automaton,program model checking,real-time system,temporal
		  logic,timed automaton,trail-directed
		  search,validation,verification}
}

@InProceedings{	  edwards05,
  title		= {Subtext: Uncovering the Simplicity of Programming},
  shorttitle	= {Subtext},
  booktitle	= {Proceedings of the 20th Annual {{ACM SIGPLAN}} Conference
		  on {{Object-oriented}} Programming, Systems, Languages, and
		  Applications},
  author	= {Edwards, Jonathan},
  year		= {2005},
  month		= oct,
  series	= {{{OOPSLA}} '05},
  pages		= {505--518},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1094811.1094851},
  urldate	= {2024-10-30},
  abstract	= {Representing programs as text strings makes programming
		  harder then it has to be. The source text of a program is
		  far removed from its behavior. Bridging this conceptual
		  gulf is what makes programming so inhumanly difficult -- we
		  are not compilers. Subtext is a new medium in which the
		  representation of a program is the same thing as its
		  execution. Like a spreadsheet, a program is visible and
		  alive, constantly executing even as it is edited. Program
		  edits are coherent semantic transformations.The essence of
		  this new medium is copying. Programs are constructed by
		  copying and executed by copy flow: the projection of
		  changes through copies. The simple idea of copying develops
		  into a rich theory of higher-order continual copying of
		  trees. Notably absent are symbolic names, the workhorse of
		  textual notation, replaced by immediately-bound explicit
		  relationships. Subtext unifies traditionally distinct
		  programming tools and concepts, and enables some novel
		  ones. Ancestral structures are a new primitive data type
		  that combines the features of lists and records, along with
		  unproblematic multiple inheritance. Adaptive conditionals
		  use first-class program edits to dynamically adapt
		  behavior.A prototype implementation shows promise, but
		  calls for much further research. Subtext suggests that we
		  can make programming radically easier, if we are willing to
		  be radical.},
  isbn		= {978-1-59593-031-6}
}

@InProceedings{	  elliott97,
  title		= {Functional Reactive Animation},
  booktitle	= {Proceedings of the Second {{ACM SIGPLAN}} International
		  Conference on {{Functional}} Programming},
  author	= {Elliott, Conal and Hudak, Paul},
  year		= {1997},
  month		= aug,
  series	= {{{ICFP}} '97},
  pages		= {263--273},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/258948.258973},
  urldate	= {2024-04-02},
  abstract	= {Fran (Functional Reactive Animation) is a collection of
		  data types and functions for composing richly interactive,
		  multimedia animations. The key ideas in Fran are its
		  notions of behaviors and events. Behaviors are
		  time-varying, reactive values, while events are sets of
		  arbitrarily complex conditions, carrying possibly rich
		  information. Most traditional values can be treated as
		  behaviors, and when images are thus treated, they become
		  animations. Although these notions are captured as data
		  types rather than a programming language, we provide them
		  with a denotational semantics, including a proper treatment
		  of real time, to guide reasoning and implementation. A
		  method to effectively and efficiently perform event
		  detection using interval analysis is also described, which
		  relies on the partial information structure on the domain
		  of event times. Fran has been implemented in Hugs, yielding
		  surprisingly good performance for an interpreter-based
		  system. Several examples are given, including the ability
		  to describe physical phenomena involving gravity, springs,
		  velocity, acceleration, etc. using ordinary differential
		  equations.},
  isbn		= {978-0-89791-918-0}
}

@InProceedings{	  engblom12,
  title		= {A Review of Reverse Debugging},
  booktitle	= {Proceedings of the 2012 {{System}}, {{Software}}, {{SoC}}
		  and {{Silicon Debug Conference}}},
  author	= {Engblom, Jakob},
  year		= {2012},
  month		= sep,
  pages		= {1--6},
  issn		= {2114-3684},
  urldate	= {2023-12-13},
  abstract	= {Reverse debugging is the ability of a debugger to stop
		  after a failure in a program has been observed and go back
		  into the history of the execution to uncover the reason for
		  the failure. Long the dream of programmers, over the past
		  decade, reverse execution has become a practical technique
		  available in a number of free and commercial tools. This
		  article will review the history and techniques of reverse
		  debugging, as researched, implemented, and used from the
		  1970s until today. We will provide some personal insights
		  into reverse debugging, from our own practical use of one
		  such tool, Wind River Simics.}
}

@Article{	  eugster15,
  title		= {Debugging the {{Internet}} of {{Things}}: {{The Case}} of
		  {{Wireless Sensor Networks}}},
  shorttitle	= {Debugging the {{Internet}} of {{Things}}},
  author	= {Eugster, Patrick and Sundaram, Vinaitheerthan and Zhang,
		  Xiangyu},
  year		= {2015},
  month		= jan,
  journal	= {IEEE Software},
  volume	= {32},
  number	= {1},
  pages		= {38--49},
  issn		= {1937-4194},
  doi		= {10.1109/MS.2014.132},
  urldate	= {2024-02-29},
  abstract	= {The Internet of Things (IoT) has the strong potential to
		  support a human society interacting more symbiotically with
		  its physical environment. Indeed, the emergence of tiny
		  devices that sense environmental cues and trigger actuators
		  after consulting logic and human preferences promises a
		  more environmentally aware and less wasteful society.
		  However, the IoT inherently challenges software development
		  processes, particularly techniques for ensuring software
		  reliability. Researchers have developed debugging tools for
		  wireless sensor networks (WSNs), which can be viewed as the
		  enablers of perception in the IoT. These tools gather
		  run-time information on individual sensor node executions
		  and node interactions and then compress that information.},
  keywords	= {Computers,debugging,Debugging,Internet of things,Internet
		  of Things,Peer-to-peer computing,replay,Runtime,software
		  engineering,tracing,Wireless communication,wireless sensor
		  networks,Wireless sensor networks}
}

@Article{	  feldman88,
  title		= {{{IGOR}}: A System for Program Debugging via Reversible
		  Execution},
  shorttitle	= {{{IGOR}}},
  author	= {Feldman, Stuart I. and Brown, Channing B.},
  year		= {1988},
  month		= nov,
  journal	= {ACM SIGPLAN Notices},
  volume	= {24},
  number	= {1},
  pages		= {112--123},
  issn		= {0362-1340},
  doi		= {10.1145/69215.69226},
  urldate	= {2023-12-14},
  abstract	= {Typical debugging tools are insufficiently powerful to
		  find the most difficult types of program misbehaviors. We
		  have implemented a prototype of a new debugging system,
		  IGOR, which provides a great deal more useful information
		  and offers new abilities that are quite promising. The
		  system runs fast enough to be quite useful while providing
		  many features that are usually available only in an
		  interpreted environment. We describe here some improved
		  facilities (reverse execution, selective searching of
		  execution history, substitution of data and executable
		  parts of the programs) that are needed for serious
		  debugging and are not found in traditional single-thread
		  debugging tools. With a little help from the operating
		  system, we provide these capabilities at reasonable cost
		  without modifying the executable code and running fairly
		  close to full speed. The prototype runs under the DUNE
		  distributed operating system. The current system only
		  supports debugging of single-thread programs. The paper
		  describes planned extensions to make use of extra
		  processors to speed the system and for applying the
		  technique to multi-thread and time dependent executions.}
}

@Book{		  felleisen09,
  title		= {Semantics Engineering with {{PLT}} Redex},
  author	= {Felleisen, Matthias and Findler, Robert Bruce and Flatt,
		  Matthew},
  year		= {2009},
  publisher	= {Mit Press}
}

@Article{	  feltey18,
  title		= {Collapsible Contracts: Fixing a Pathology of Gradual
		  Typing},
  shorttitle	= {Collapsible Contracts},
  author	= {Feltey, Daniel and Greenman, Ben and Scholliers,
		  Christophe and Findler, Robert Bruce and {St-Amour},
		  Vincent},
  year		= {2018},
  month		= oct,
  journal	= {Artifact Virtual Machine Image for Collapsible Contracts:
		  Fixing a Pathology of Gradual Typing},
  volume	= {2},
  number	= {OOPSLA},
  pages		= {133:1--133:27},
  doi		= {10.1145/3276503},
  urldate	= {2024-12-16},
  abstract	= {The promise of gradual typing is that programmers should
		  get the best of both worlds: the static guarantees of
		  static types, and the dynamic flexibility of untyped
		  programming. This is an enticing benefit, but one that, in
		  practice, may carry significant costs. Significant enough,
		  in fact, to threaten the very practicality of gradual
		  typing; slowdowns as high as 120x are reported as arising
		  from gradual typing. If one examines these results closely,
		  though, it becomes clear that the costs of gradual typing
		  are not evenly distributed. Indeed, while mixing typed and
		  untyped code almost invariably carries non-trivial costs,
		  many truly deal-breaking slowdowns exhibit pathological
		  performance. Unfortunately, the very presence of these
		  pathological cases---and therefore the possibility of
		  hitting them during development---makes gradual typing a
		  risky proposition in any setting that even remotely cares
		  about performance. This work attacks one source of large
		  overheads in these pathological cases: an accumulation of
		  contract wrappers that perform redundant checks. The work
		  introduces a novel strategy for contract
		  checking---collapsible contracts---which eliminates this
		  redundancy for function and vector contracts and
		  drastically reduces the overhead of contract wrappers. We
		  implemented this checking strategy as part of the Racket
		  contract system, which is used in the Typed Racket gradual
		  typing system. Our experiments show that our strategy
		  successfully brings a class of pathological cases in line
		  with normal cases, while not introducing an undue overhead
		  to any of the other cases. Our results also show that the
		  performance of gradual typing in Racket remains prohibitive
		  for many programs, but that collapsible contracts are one
		  essential ingredient in reducing the cost of gradual
		  typing.}
}

@Article{	  ferrante87,
  title		= {The Program Dependence Graph and Its Use in Optimization},
  author	= {Ferrante, Jeanne and Ottenstein, Karl J. and Warren, Joe
		  D.},
  year		= {1987},
  month		= jul,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {9},
  number	= {3},
  pages		= {319--349},
  issn		= {0164-0925},
  doi		= {10.1145/24039.24041},
  urldate	= {2024-01-22},
  abstract	= {In this paper we present an intermediate program
		  representation, called the program dependence graph (PDG),
		  that makes explicit both the data and control dependences
		  for each operation in a program. Data dependences have been
		  used to represent only the relevant data flow relationships
		  of a program. Control dependences are introduced to
		  analogously represent only the essential control flow
		  relationships of a program. Control dependences are derived
		  from the usual control flow graph. Many traditional
		  optimizations operate more efficiently on the PDG. Since
		  dependences in the PDG connect computationally related
		  parts of the program, a single walk of these dependences is
		  sufficient to perform many optimizations. The PDG allows
		  transformations such as vectorization, that previously
		  required special treatment of control dependence, to be
		  performed in a manner that is uniform for both control and
		  data dependences. Program transformations that require
		  interaction of the two dependence types can also be easily
		  handled with our representation. As an example, an
		  incremental approach to modifying data dependences
		  resulting from branch deletion or loop unrolling is
		  introduced. The PDG supports incremental optimization,
		  permitting transformations to be triggered by one another
		  and applied only to affected dependences.}
}

@Article{	  ferrante87a,
  title		= {The Program Dependence Graph and Its Use in Optimization},
  author	= {Ferrante, Jeanne and Ottenstein, Karl J. and Warren, Joe
		  D.},
  year		= {1987},
  month		= jul,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {9},
  number	= {3},
  pages		= {319--349},
  issn		= {0164-0925},
  doi		= {10.1145/24039.24041},
  urldate	= {2024-03-18},
  abstract	= {In this paper we present an intermediate program
		  representation, called the program dependence graph (PDG),
		  that makes explicit both the data and control dependences
		  for each operation in a program. Data dependences have been
		  used to represent only the relevant data flow relationships
		  of a program. Control dependences are introduced to
		  analogously represent only the essential control flow
		  relationships of a program. Control dependences are derived
		  from the usual control flow graph. Many traditional
		  optimizations operate more efficiently on the PDG. Since
		  dependences in the PDG connect computationally related
		  parts of the program, a single walk of these dependences is
		  sufficient to perform many optimizations. The PDG allows
		  transformations such as vectorization, that previously
		  required special treatment of control dependence, to be
		  performed in a manner that is uniform for both control and
		  data dependences. Program transformations that require
		  interaction of the two dependence types can also be easily
		  handled with our representation. As an example, an
		  incremental approach to modifying data dependences
		  resulting from branch deletion or loop unrolling is
		  introduced. The PDG supports incremental optimization,
		  permitting transformations to be triggered by one another
		  and applied only to affected dependences.}
}

@Misc{		  ferreira24,
  title		= {Open {{Bot Brain}}},
  author	= {Ferreira Ruiz, Francisco and Collins, Ben and {al},
		  {\relax et}.},
  year		= {2024},
  abstract	= {Open Bot Brain is an educational project to develop open
		  hardware and software to control Mindstorm Lego motors and
		  sensors. It is developed on GitHub as open hardware and
		  open source software.}
}

@InCollection{	  frattini16,
  title		= {Reproducibility of {{Software Bugs}}},
  booktitle	= {Principles of {{Performance}} and {{Reliability Modeling}}
		  and {{Evaluation}}: {{Essays}} in {{Honor}} of {{Kishor
		  Trivedi}} on His 70th {{Birthday}}},
  author	= {Frattini, Flavio and Pietrantuono, Roberto and Russo,
		  Stefano},
  editor	= {Fiondella, Lance and Puliafito, Antonio},
  year		= {2016},
  pages		= {551--565},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-30599-8_21},
  urldate	= {2024-09-01},
  abstract	= {Understanding software bugs and their effects is important
		  in several engineering activities, including testing,
		  debugging, and design of fault containment or tolerance
		  methods. Dealing with hard-to-reproduce failures requires a
		  deep comprehension of the mechanisms leading from bug
		  activation to software failure. This chapter surveys
		  taxonomies and recent studies about bugs from the
		  perspective of their reproducibility, providing insights
		  into the process of bug manifestation and the factors
		  influencing it. These insights are based on the analysis of
		  thousands of bug reports of a widely used open-source
		  software, namely MySQL Server. Bug reports are
		  automatically classified according to reproducibility
		  characteristics, providing figures about the proportion of
		  hard to reproduce bug their features, and evolution over
		  releases.},
  isbn		= {978-3-319-30599-8},
  langid	= {english},
  keywords	= {Bug Reports,Concurrency Bugs,MySQL Server,Naive Bayes
		  (NB),Workload Requests}
}

@Article{	  freeman91,
  title		= {Refinement Types for {{ML}}},
  author	= {Freeman, Tim and Pfenning, Frank},
  year		= {1991},
  month		= may,
  journal	= {ACM SIGPLAN Notices},
  volume	= {26},
  number	= {6},
  pages		= {268--277},
  issn		= {0362-1340},
  doi		= {10.1145/113446.113468},
  urldate	= {2023-09-27}
}

@InProceedings{	  friedman84,
  title		= {Programming with {{Continuations}}},
  booktitle	= {Program {{Transformation}} and {{Programming
		  Environments}}},
  author	= {Friedman, Daniel P. and Haynes, Christopher T. and
		  Kohlbecker, Eugene},
  editor	= {Pepper, Peter},
  year		= {1984},
  series	= {{{NATO ASI Series}}},
  pages		= {263--274},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-46490-4_23},
  abstract	= {Progress in programming language design has often been
		  achieved by making an abstraction a ``first class object'',
		  one that can be passed to and returned from procedures and
		  entered in data structures. For example, the importance of
		  functional parameters has long been recognized, though it
		  is only more recently that actor semantics [2] and object
		  oriented programming have demonstrated the power of first
		  class functional objects. This paper illustrates, with a
		  novel example, the power of first class control objects,
		  called continuations.},
  isbn		= {978-3-642-46490-4},
  langid	= {english},
  keywords	= {Class Object,Common Lisp,Lambda Calculus,Lambda
		  Expression,Single Argument}
}

@Article{	  gait86,
  title		= {A Probe Effect in Concurrent Programs},
  author	= {Gait, Jason},
  year		= {1986},
  journal	= {Software: Practice and Experience},
  volume	= {16},
  number	= {3},
  pages		= {225--233},
  issn		= {1097-024X},
  doi		= {10.1002/spe.4380160304},
  urldate	= {2024-08-31},
  abstract	= {This paper reports on an experimental study of the probe
		  effect, defined as an alteration in the frequency of
		  run-time computational errors observed when delays are
		  introduced into concurrent programs. If the concurrent
		  program being studied has no synchronization errors, then
		  there is no probe effect. In the presence of
		  synchronization errors, the frequency of observable output
		  errors for a sample experimental program starts at a high
		  value for small delays, oscillates rapidly as the delay is
		  increased, and apparently settles at zero errors for larger
		  values of delay. Thus, for sufficiently large delays, the
		  probe effect can almost completely mask synchronization
		  errors in concurrent programs. For sufficiently large
		  concurrent process sets, even small values of embedded
		  delay may mask synchronization errors, provided side
		  effects in shared memory are not included in the
		  observation.},
  copyright	= {Copyright {\copyright} 1986 John Wiley \& Sons, Ltd},
  langid	= {english},
  keywords	= {Concurrent programming,Debugging concurrent
		  programs,Embedded delays,Probe effect,Shared-memory side
		  effect,Synchronization errors}
}

@Book{		  gamma94,
  title		= {Design Patterns: {{Elements}} of Reusable Object-Oriented
		  Software},
  author	= {Gamma, Erich and Vlissides, John and Helm, Richard and
		  Johnson, Ralph E.},
  year		= {1994}
}

@Article{	  geller24,
  title		= {Indexed {{Types}} for a {{Statically Safe WebAssembly}}},
  author	= {Geller, Adam T. and Frank, Justin and Bowman, William J.},
  year		= {2024},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {8},
  number	= {POPL},
  pages		= {80:2395--80:2424},
  doi		= {10.1145/3632922},
  urldate	= {2024-01-12},
  abstract	= {We present Wasm-prechk, a superset of WebAssembly (Wasm)
		  that uses indexed types to express and check simple
		  constraints over program values. This additional static
		  reasoning enables safely removing dynamic safety checks
		  from Wasm, such as memory bounds checks. We implement
		  Wasm-prechk as an extension of the Wasmtime compiler and
		  runtime, evaluate the run-time and compile-time performance
		  of Wasm-prechk vs WebAssembly configurations with explicit
		  dynamic checks, and find an average run-time performance
		  gain of 1.71x faster in the widely used PolyBenchC
		  benchmark suite, for a small overhead in binary size
		  (7.18\% larger) and type-checking time (1.4\% slower). We
		  also prove type and memory safety of Wasm-prechk, prove
		  Wasm safely embeds into Wasm-prechk ensuring backwards
		  compatibility, prove Wasm-prechk type-erases to Wasm, and
		  discuss design and implementation trade-offs.},
  keywords	= {Indexed Types,Optimization and Compiler Design,Program
		  Logics,Type Systems,WebAssembly}
}

@Article{	  ghica22,
  title		= {High-Level Effect Handlers in {{C}}++},
  author	= {Ghica, Dan and Lindley, Sam and Bravo, Marcos Maro{\~n}as
		  and Pir{\'o}g, Maciej},
  year		= {2022},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {OOPSLA2},
  pages		= {183:1639--183:1667},
  doi		= {10.1145/3563445},
  urldate	= {2023-12-08},
  abstract	= {Effect handlers allow the programmer to implement
		  computational effects, such as custom error handling,
		  various forms of lightweight concurrency, and dynamic
		  binding, inside the programming language. We introduce
		  cpp-effects, a C++ library for effect handlers with a typed
		  high-level, object-oriented interface. We demonstrate that
		  effect handlers can be successfully applied in imperative
		  systems programming languages with manual memory
		  management. Through a collection of examples, we explore
		  how to program effectively with effect handlers in C++,
		  discuss the intricacies and challenges of the
		  implementation, and show that despite its limitations,
		  cpp-effects performance is competitive and in some cases
		  even outperforms state-of-the-art approaches such as C++20
		  coroutines and the libmprompt library for multiprompt
		  delimited control.},
  keywords	= {algebraic effects,context switching,Effect
		  handlers,lightweight concurrency}
}

@InProceedings{	  giachino14,
  title		= {Causal-{{Consistent Reversible Debugging}}},
  booktitle	= {Fundamental {{Approaches}} to {{Software Engineering}}},
  author	= {Giachino, Elena and Lanese, Ivan and Mezzina, Claudio
		  Antares},
  editor	= {Gnesi, Stefania and Rensink, Arend},
  year		= {2014},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {370--384},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-54804-8_26},
  abstract	= {Reversible debugging provides developers with a way to
		  execute their applications both forward and backward,
		  seeking the cause of an unexpected or undesired event. In a
		  concurrent setting, reversing actions in the exact reverse
		  order in which they have been executed may lead to undo
		  many actions that were not related to the bug under
		  analysis. On the other hand, undoing actions in some order
		  that violates causal dependencies may lead to states that
		  could not be reached in a forward execution. We propose an
		  approach based on causal-consistent reversibility: each
		  action can be reversed if all its consequences have already
		  been reversed. The main feature of the approach is that it
		  allows the programmer to easily individuate and undo
		  exactly the actions that caused a given misbehavior till
		  the corresponding bug is reached. This paper major
		  contribution is the individuation of the appropriate
		  primitives for causal-consistent reversible debugging and
		  their prototype implementation in the CaReDeb tool. We also
		  show how to apply CaReDeb to individuate common real-world
		  concurrent bugs.},
  isbn		= {978-3-642-54804-8},
  langid	= {english},
  keywords	= {Atomicity Violation,Causal Dependency,Causality
		  Information,FIFO Queue,Port Result}
}

@InProceedings{	  giuffrida10,
  title		= {A {{Taxonomy}} of {{Live Updates}}},
  booktitle	= {Proceedings of the 16th {{Annual Conference}} of the
		  {{Advanced School}} for {{Computing}} and {{Imaging}}},
  author	= {Giuffrida, C. and Tanenbaum, A.S.},
  year		= {2010}
}

@Article{	  gluck16,
  title		= {A {{Linear-Time Self-Interpreter}} of a {{Reversible
		  Imperative Language}}},
  author	= {Gl{\"u}ck, Robert and Yokoyama, Tetsuo},
  year		= {2016},
  month		= sep,
  journal	= {Information and Media Technologies},
  pages		= {160--180},
  doi		= {10.11185/imt.11.160},
  abstract	= {A linear-time reversible self-interpreter in an r-Turing
		  complete reversible imperative language is presented. The
		  proposed imperative language has reversible structured
		  control ow operators and symbolic tree-structured data
		  (S-expressions). The latter data structures are dynamically
		  allocated and enable reversible simulation of programs of
		  arbitrary size and space consumption. As self-interpreters
		  are used to show a number of fundamental properties in
		  classic computability and complexity theory, the present
		  study of an efficient reversible self-interpreter is
		  intended as a basis for future work on reversible
		  computability and complexity theory as well as programming
		  language theory for reversible computing. Although the
		  proposed reversible interpreter consumes superlinear space,
		  the restriction of the number of variables in the source
		  language leads to linear-time reversible simulation.}
}

@Article{	  gluck23,
  title		= {Reversible Computing from a Programming Language
		  Perspective},
  author	= {Gl{\"u}ck, Robert and Yokoyama, Tetsuo},
  year		= {2023},
  month		= apr,
  journal	= {Theoretical Computer Science},
  volume	= {953},
  pages		= {113429},
  issn		= {0304-3975},
  doi		= {10.1016/j.tcs.2022.06.010},
  urldate	= {2023-09-28},
  abstract	= {Software plays a central role in all aspects of reversible
		  computing systems, and a variety of reversible programming
		  languages have been developed. This presentation highlights
		  the principles and main ideas of reversible computing
		  viewed from a programming language perspective with a focus
		  on clean reversible languages. They are the building
		  material for software that can reap the benefits of
		  reversible hardware and interesting in their own right.
		  Reversible computing is situated within programming
		  languages in general, and the relevant concepts are
		  elaborated, including computability, injectivization and
		  reversibilization. Features representative for many
		  reversible languages are presented, such as reversible
		  updates, reversible iterations, and access to a program's
		  inverse semantics. Metaprogramming methods of particular
		  importance to reversible programming, are introduced,
		  including program inversion and inverse interpretation. Our
		  presentation is independent of a particular language,
		  although primarily the reversible language, Janus, will be
		  used in examples.},
  keywords	= {Compute-uncompute,Function injectivization,Inverse
		  interpretation,Metacomputation,Program inversion,Program
		  reversibilization,Reversible computing,Reversible
		  programming}
}

@Article{	  graf20,
  title		= {Lower Your Guards: A Compositional Pattern-Match Coverage
		  Checker},
  shorttitle	= {Lower Your Guards},
  author	= {Graf, Sebastian and Peyton Jones, Simon and Scott, Ryan
		  G.},
  year		= {2020},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {ICFP},
  pages		= {107:1--107:30},
  doi		= {10.1145/3408989},
  urldate	= {2023-09-26},
  abstract	= {A compiler should warn if a function defined by pattern
		  matching does not cover its inputs---that is, if there are
		  missing or redundant patterns. Generating such warnings
		  accurately is difficult for modern languages due to the
		  myriad of language features that interact with pattern
		  matching. This is especially true in Haskell, a language
		  with a complicated pattern language that is made even more
		  complex by extensions offered by the Glasgow Haskell
		  Compiler (GHC). Although GHC has spent a significant amount
		  of effort towards improving its pattern-match coverage
		  warnings, there are still several cases where it reports
		  inaccurate warnings. We introduce a coverage checking
		  algorithm called Lower Your Guards, which boils down the
		  complexities of pattern matching into guard trees. While
		  the source language may have many exotic forms of patterns,
		  guard trees only have three different constructs, which
		  vastly simplifies the coverage checking process. Our
		  algorithm is modular, allowing for new forms of
		  source-language patterns to be handled with little changes
		  to the overall structure of the algorithm. We have
		  implemented the algorithm in GHC and demonstrate places
		  where it performs better than GHC's current coverage
		  checker, both in accuracy and performance.},
  keywords	= {guards,Haskell,pattern matching,strictness}
}

@InProceedings{	  graver89,
  title		= {A Type System for {{Smalltalk}}},
  booktitle	= {Proceedings of the 17th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Graver, Justin O. and Johnson, Ralph E.},
  year		= {1989},
  month		= dec,
  series	= {{{POPL}} '90},
  pages		= {136--150},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/96709.96722},
  urldate	= {2023-10-20},
  abstract	= {This paper describes a type system for Smalltalk that is
		  type-safe, that allows most Smalltalk programs to be
		  type-checked, and that can be used as the basis of an
		  optimizing compiler.},
  isbn		= {978-0-89791-343-0}
}

@Article{	  grigore17,
  title		= {Java Generics Are Turing Complete},
  author	= {Grigore, Radu},
  year		= {2017},
  month		= jan,
  journal	= {ACM SIGPLAN Notices},
  volume	= {52},
  number	= {1},
  pages		= {73--85},
  issn		= {0362-1340},
  doi		= {10.1145/3093333.3009871},
  urldate	= {2024-01-12},
  abstract	= {This paper describes a reduction from the halting problem
		  of Turing machines to subtype checking in Java. It follows
		  that subtype checking in Java is undecidable, which answers
		  a question posed by Kennedy and Pierce in 2007. It also
		  follows that Java's type checker can recognize any
		  recursive language, which improves a result of Gill and
		  Levy from 2016. The latter point is illustrated by a parser
		  generator for fluent interfaces.},
  keywords	= {decidability,fluent interface,Java,parser
		  generator,subtype checking,Turing machine}
}

@Book{		  gruber23,
  title		= {Debugging {{Flaky Tests}} Using {{Spectrum-based Fault
		  Localization}}},
  author	= {Gruber, Martin and Fraser, Gordon},
  year		= {2023},
  month		= may,
  pages		= {139},
  doi		= {10.1109/AST58925.2023.00017}
}

@Misc{		  gu23,
  title		= {Understanding and {{Supporting Debugging Workflows}} in
		  {{Multiverse Analysis}}},
  author	= {Gu, Ken and Jun, Eunice and Althoff, Tim},
  year		= {2023},
  month		= jun,
  number	= {arXiv:2210.03804},
  eprint	= {2210.03804},
  primaryclass	= {cs},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.2210.03804},
  urldate	= {2024-05-13},
  abstract	= {Multiverse analysis, a paradigm for statistical analysis
		  that considers all combinations of reasonable analysis
		  choices in parallel, promises to improve transparency and
		  reproducibility. Although recent tools help analysts
		  specify multiverse analyses, they remain difficult to use
		  in practice. In this work, we identify debugging as a key
		  barrier due to the latency from running analyses to
		  detecting bugs and the scale of metadata processing needed
		  to diagnose a bug. To address these challenges, we
		  prototype a command-line interface tool, Multiverse
		  Debugger, which helps diagnose bugs in the multiverse and
		  propagate fixes. In a qualitative lab study (n=13), we use
		  Multiverse Debugger as a probe to develop a model of
		  debugging workflows and identify specific challenges,
		  including difficulty in understanding the multiverse's
		  composition. We conclude with design implications for
		  future multiverse analysis authoring systems.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Human-Computer Interaction,Computer
		  Science - Software Engineering}
}

@Article{	  gupta96,
  title		= {A Formal Framework for On-Line Software Version Change},
  author	= {Gupta, D. and Jalote, P. and Barua, G.},
  year		= {1996},
  month		= feb,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {22},
  number	= {2},
  pages		= {120--131},
  issn		= {1939-3520},
  doi		= {10.1109/32.485222},
  urldate	= {2024-01-15},
  abstract	= {The usual way of installing a new version of a software
		  system is to shut down the running program and then install
		  the new version. This necessitates a sometimes unacceptable
		  delay during which service is denied to the users of the
		  software. An online software replacement system replaces
		  parts of the software while it is in execution, thus
		  eliminating the shutdown. While a number of implementations
		  of online version change systems have been described in the
		  literature, little investigation has been done on its
		  theoretical aspects. We describe a formal framework for
		  studying online software version change. We give a general
		  definition of validity of an online change, show that it is
		  in general undecidable and then develop sufficient
		  conditions for ensuring validity for a procedural
		  language.}
}

@InProceedings{	  gurdeep19,
  title		= {{{WARDuino}}: A Dynamic {{WebAssembly}} Virtual Machine
		  for Programming Microcontrollers},
  shorttitle	= {{{WARDuino}}},
  booktitle	= {Proceedings of the 16th {{ACM SIGPLAN International
		  Conference}} on {{Managed Programming Languages}} and
		  {{Runtimes}}},
  author	= {Gurdeep Singh, Robbert and Scholliers, Christophe},
  year		= {2019},
  month		= oct,
  series	= {{{MPLR}} 2019},
  pages		= {27--36},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3357390.3361029},
  urldate	= {2023-09-26},
  abstract	= {It is extremely hard and time-consuming to make correct
		  and efficient programs for microcontrollers. Usually
		  microcontrollers are programmed in a low level programming
		  language such as C which makes them hard to debug and
		  maintain. To raise the abstraction level, many high level
		  programming languages have provided support for programming
		  microcontrollers. Examples include Python, Lua, C\# and
		  JavaScript. Using these languages has the downside that
		  they are orders of magnitude slower than the low-level
		  languages. Moreover, they often provide no remote debugging
		  support. In this paper we investigate the feasibility of
		  using WebAssembly to program Arduino compatible
		  microcontrollers. Our experiments lead to extending the
		  standard WebAssembly VM with: 1) safe live code updates for
		  functions and data 2) remote debugging support at the VM
		  level 3) programmer configurable (Arduino) modules in order
		  to keep the virtual machine's footprint as small as
		  possible. The resulting WARDuino VM enables the programmer
		  to have better performance than an interpreted approach
		  while simultaneously increasing the ease of development. To
		  evaluate our approach, we implemented a simple breakout
		  game and conducted micro benchmarks which show that the VM
		  runs approximately 5 times faster than Espruino, a popular
		  JavaScript interpreter for the ESP32 microcontroller.},
  isbn		= {978-1-4503-6977-0},
  keywords	= {Arduino,Live Code Updates,Virtual Machine,WebAssembly}
}

@Article{	  gurdeep19a,
  title		= {Multiverse {{Debugging}}: {{Non-Deterministic Debugging}}
		  for {{Non-Deterministic Programs}} ({{Artifact}})},
  shorttitle	= {Multiverse {{Debugging}}},
  author	= {Gurdeep Singh, Robbert and Torres Lopez, Carmen and Marr,
		  Stefan and Gonzalez Boix, Elisa and Scholliers,
		  Christophe},
  year		= {2019},
  journal	= {Dagstuhl Artifacts Series},
  volume	= {5},
  number	= {2},
  pages		= {4:1-4:3},
  publisher	= {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  issn		= {2509-8195},
  doi		= {10.4230/DARTS.5.2.4},
  urldate	= {2024-11-12},
  abstract	= {Many of today's software systems are parallel or
		  concurrent. With the rise of Node.js and more generally
		  event-loop architectures, many systems need to handle
		  concurrency. However, their non-deterministic behavior
		  makes it hard to debug. Today's interactive debuggers
		  unfortunately do not support developers in debugging
		  non-deterministic issues. They only allow exploring a
		  single execution path. Therefore, some bugs may never be
		  reproduced in the debugging session, because the conditions
		  to trigger are not reached. As a solution, we propose
		  multiverse debugging, a new approach for debugging
		  non-deterministic programs that allow developers to observe
		  all possible execution paths of a parallel program and
		  debug it interactively. We introduce the concepts of
		  multiverse breakpoints and stepping, which can halt a
		  program in different execution paths, i.e. universes. We
		  apply multiverse debugging to AmbientTalk, an actor-based
		  language, resulting in Voyager, a proof of concept
		  multiverse debugger that takes as input Featherweight
		  AmbientTalk programs written in PLT-Redex, and allows
		  programmers to interactively browse all possible execution
		  states by means of multiverse breakpoints and stepping
		  commands. We provide a proof of non-interference, i.e we
		  prove that observing the behavior of a program by the
		  debugger does not affect the behavior of that program and
		  vice versa. Multiverse debugging establishes the foundation
		  for debugging non-deterministic programs interactively,
		  which we believe can aid the development of parallel and
		  concurrent systems.},
  copyright	= {https://creativecommons.org/licenses/by/3.0/de/legalcode},
  langid	= {english}
}

@PhDThesis{	  gurdeep22,
  title		= {Taming Nondeterminism : Programming Language Abstractions
		  and Tools for Dealing with Nondeterministic Programs},
  shorttitle	= {Taming Nondeterminism},
  author	= {Gurdeep Singh, Robbert},
  year		= {2022},
  urldate	= {2024-08-29},
  abstract	= {Computer programs need to deal with nondeterministic
		  environments. This nondeterminism may arise from many
		  sources, like user input and concurrency for example. If
		  program input were to be deterministic, there would be no
		  need for complex programs. A word processor with
		  deterministic input can simply present the user with their
		  envisioned written document without them having to type it.
		  Nondeterminism caused by concurrency stems from the unknown
		  speed of each thread, the possibility of lost messages and
		  so on. Although it leads to nondeterministic execution, we
		  sometimes need it to fulfill real-world demands such as
		  execution performance and high availability. If a program
		  is nondeterministic, the next state may be one of multiple
		  possibilities. When writing the program, the developer must
		  imagine all possible executions to prevent bugs. Even if
		  there are only two possibilities per program step, there
		  are 2{\textasciicircum}n possible executions of n steps.
		  This exponential state explosion is what makes working with
		  nondeterminism so difficult. If a failure occurs in one of
		  the myriad of execution traces, it is difficult to find its
		  root cause. Typical debuggers only allow users the debug
		  just one of the possible traces, while the failure may only
		  manifest in very rare execution traces. Both humans and
		  computers cannot deal with state explosion well.
		  Programming languages have nondeterminism introducing
		  constructs to facilitate working in nondeterministic
		  environments. There are constructs for acquiring input,
		  starting concurrent threads and so on. The chosen
		  constructs greatly impact the nondeterminism the programmer
		  has to deal with. In this dissertation we investigate the
		  tree main ways programming systems can work with
		  nondeterminism: embrace it, capture it, and avoid it.
		  First, to embrace nondeterminism we must have the tools to
		  deal with the state explosion it generates. In this
		  dissertation, we present a tool called GraphRedex, which
		  allows exploring the state space graph of nondeterministic
		  programs. Our tool contributes a novel exploration
		  technique for dealing with state explosion: interactive
		  exploration. We allow developers to choose what path in the
		  state space graph they want to follow. This helps
		  developers see the wood for the trees when visualizing all
		  possible execution paths of a program. We conducted a user
		  study to confirm GraphRedex is user friendly and helps
		  uncover bugs. Additionally, we used it to find errors in
		  published research. A second option is to capture the
		  nondeterminism. When something goes wrong in a program's
		  execution, it is often difficult to determine the exact
		  conditions that triggered a bug. By keeping track of the
		  nondeterministic choices the program makes during its
		  execution, we can replay them, even backwards. If the
		  program failed, stepping backwards can help find the bug
		  that caused the failure. We have implemented such a
		  backwards stepping functionality for a platform that is
		  notoriously difficult to debug or even write programs for:
		  microcontrollers. To do this, we created a WebAssembly
		  virtual machine (VM) for these devices. Our VM, WARDuino
		  allows programmers to use higher level languages to program
		  microcontrollers. A language interoperability layer ensures
		  that device peripherals are safely accessible. While higher
		  level languages alone already prevent bugs, WARDuino
		  additionally allows debugging applications remotely via a
		  VSCode plugin. We show that our novel event-based
		  out-of-place debugging technique reduces debugging latency
		  and permits backwards stepping. Additionally, we determine
		  that WARDuino is fast enough to implement IoT applications
		  by carrying out micro benchmarks. Third, nondeterminism can
		  be avoided by carefully selecting the provided language
		  constructs. As an example of this approach, this
		  dissertation presents Gaiwan. This is a general-purpose GPU
		  (GPGPU) programming language intended for processing time
		  series data. The language is based on a novel
		  size-polymorphic type system we designed and implemented
		  Additionally, Gaiwan only features race condition free
		  constructs. By using our language, non-expert GPGPU users
		  avoid two sources of nondeterminism: the nondeterministic
		  size of the input, and the nondeterminism arising from data
		  races on these extremely parallel devices. Gaiwan's type
		  system allows developers to use affine functions in one
		  variable to declare the effect parts of their program have
		  on data buffers. From this, our type system derives a set
		  of constraints to which the input should adhere for the
		  program to work. Inputs that do not satisfy these
		  constraints will be rejected. Gaiwan prevents data races by
		  only providing deterministic data race free language
		  constructs. We provide the standard correctness proofs for
		  our type system. Although our proof-of-concept evaluator is
		  not yet fully optimized, we also implement a bitonic
		  sorting algorithm in it and demonstrate that it only has a
		  25\% overhead compared to a handwritten OpenCL
		  implementation from Intel.},
  copyright	= {Creative Commons Attribution 4.0 International Public
		  License (CC-BY 4.0)},
  langid	= {english},
  school	= {Ghent University}
}

@InProceedings{	  haas17,
  title		= {Bringing the Web up to Speed with {{WebAssembly}}},
  booktitle	= {Proceedings of the 38th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Haas, Andreas and Rossberg, Andreas and Schuff, Derek L.
		  and Titzer, Ben L. and Holman, Michael and Gohman, Dan and
		  Wagner, Luke and Zakai, Alon and Bastien, {\relax JF}},
  year		= {2017},
  month		= jun,
  series	= {{{PLDI}} 2017},
  pages		= {185--200},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3062341.3062363},
  urldate	= {2023-10-03},
  abstract	= {The maturation of the Web platform has given rise to
		  sophisticated and demanding Web applications such as
		  interactive 3D visualization, audio and video software, and
		  games. With that, efficiency and security of code on the
		  Web has become more important than ever. Yet JavaScript as
		  the only built-in language of the Web is not well-equipped
		  to meet these requirements, especially as a compilation
		  target. Engineers from the four major browser vendors have
		  risen to the challenge and collaboratively designed a
		  portable low-level bytecode called WebAssembly. It offers
		  compact representation, efficient validation and
		  compilation, and safe low to no-overhead execution. Rather
		  than committing to a specific programming model,
		  WebAssembly is an abstraction over modern hardware, making
		  it language-, hardware-, and platform-independent, with use
		  cases beyond just the Web. WebAssembly has been designed
		  with a formal semantics from the start. We describe the
		  motivation, design and formal semantics of WebAssembly and
		  provide some preliminary experience with implementations.},
  isbn		= {978-1-4503-4988-8},
  keywords	= {assembly languages,just-in-time compilers,programming
		  languages,type systems,virtual machines}
}

@Article{	  hahm21,
  title		= {Reliable {{Real-Time Operating System}} for {{IoT
		  Devices}}},
  author	= {Hahm, Seong-Il and Kim, Jeongchan and Jeong, Ahreum and
		  Yi, Hyunjin and Chang, Sunghan and Kishore, Shobha Nanda
		  and Chauhan, Amandeep and Cherian, Siju Punnoose},
  year		= {2021},
  month		= mar,
  journal	= {IEEE Internet of Things Journal},
  volume	= {8},
  number	= {5},
  pages		= {3705--3716},
  issn		= {2327-4662},
  doi		= {10.1109/JIOT.2020.3025612},
  urldate	= {2023-10-12},
  abstract	= {Internet of Things (IoT) technologies have so deeply
		  penetrated our daily lives that IoT devices have been
		  everywhere. Not only do IoT devices provide basic means to
		  convenient living but they also offer intelligent services
		  tailored to diverse user needs. For instance, beyond
		  remotely turning ON and OFF small gadgets, such as lamps
		  and switches, users can now control appliances via
		  smartphones and also interact with them verbally. In the
		  backdrop of multifarious, complex IoT applications, their
		  reliability becomes of paramount importance. This article
		  focuses on achieving user-level reliability in an IoT
		  operating system (OS) that executes both real-time (RT) and
		  non-real-time (NRT) tasks concurrently. For example, smart
		  appliances typically run RT tasks such as a motor
		  controller, as well as NRT tasks such as Wi-Fi-based
		  network functions, concurrently. In general, RT tasks are
		  critical and should be protected from error-prone tasks.
		  Otherwise, a motor controller failure may cause appliances
		  to malfunction. To this end, we propose a novel, reliable
		  IoT OS, called TizenRT that achieves user-level reliability
		  through two key features, namely, fault isolation and fast
		  recovery, while maintaining RT constraints. Our evaluation
		  shows that TizenRT can isolate faulty tasks in memory
		  space, while guaranteeing normal RT tasks to complete their
		  missions within a required time, e.g., 50
		  {\textbackslash}mu {\textbackslash}texts . Moreover,
		  corrupted tasks can be recovered within a few milliseconds,
		  e.g., 10 ms, without the need for a system reboot. This
		  makes TizenRT a preferred choice for mission-critical IoT
		  applications.}
}

@InProceedings{	  hambarde14,
  title		= {The {{Survey}} of {{Real Time Operating System}}:
		  {{RTOS}}},
  shorttitle	= {The {{Survey}} of {{Real Time Operating System}}},
  booktitle	= {2014 {{International Conference}} on {{Electronic
		  Systems}}, {{Signal Processing}} and {{Computing
		  Technologies}}},
  author	= {Hambarde, Prasanna and Varma, Rachit and Jha, Shivani},
  year		= {2014},
  month		= jan,
  pages		= {34--39},
  doi		= {10.1109/ICESC.2014.15},
  urldate	= {2023-10-12},
  abstract	= {The paper discusses the literature survey of RTOS (Real
		  Time Operating Systems) and its contributions to the
		  embedded world. RTOS is defined as a system in which the
		  correctness of the system does not depend only on the
		  logical results of computation but also on the time at
		  which the results are produced. It has to perform critical
		  tasks on priority basis keeping the context switching time
		  minimum. It is often associated with few misconceptions \&
		  we have tried to throw some light on it. Since last 20
		  years, RTOS is undergoing continuous evolution and has
		  resulted into development of many commercial RTOS products.
		  We have selected few commercial RTOS of different
		  categories of real-time applications and have discussed its
		  real-time features. A comparison of the commercial RTOSs'
		  is presented. We conclude by discussing the results of the
		  survey and comparing the RTOS based on performance
		  parameters.}
}

@InProceedings{	  haulund17,
  title		= {Implementing {{Reversible Object-Oriented Language
		  Features}} on {{Reversible Machines}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Haulund, Tue and Mogensen, Torben {\AE}gidius and
		  Gl{\"u}ck, Robert},
  editor	= {Phillips, Iain and Rahaman, Hafizur},
  year		= {2017},
  pages		= {66--73},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-59936-6_5},
  abstract	= {We extend the reversible language Janus with support for
		  class-based object-oriented programming, class inheritance
		  and subtype-polymorphism. We describe how to implement
		  these features on reversible hardware - with emphasis on
		  the implementation of reversible dynamic dispatch using
		  virtual method tables. Our translation is effective (i.e.
		  garbage-free) and we demonstrate its practicality by
		  implementation of a fully-featured compiler targeting the
		  reversible assembly language PISA.},
  isbn		= {978-3-319-59936-6},
  langid	= {english},
  keywords	= {Class Field,Class Instance,Data Access Control,Method
		  Invocation,Virtual Method}
}

@InProceedings{	  hay-schmidt21,
  title		= {Towards a {{Unified Language Architecture}} for
		  {{Reversible Object-Oriented Programming}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {{Hay-Schmidt}, Lasse and Gl{\"u}ck, Robert and Cservenka,
		  Martin Holm and Haulund, Tue},
  editor	= {Yamashita, Shigeru and Yokoyama, Tetsuo},
  year		= {2021},
  pages		= {96--106},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-79837-6_6},
  abstract	= {A unified language architecture for an advanced reversible
		  object-oriented language is described. The design and
		  implementation choices made for a tree-walking interpreter
		  and source-language inverter are discussed, as well as the
		  integration with an existing monadic parser, type checker
		  and PISA compiler backend. A demonstration of the web
		  interface and the interactions required to interpret,
		  compile and invert reversible object-oriented programs is
		  given. Our aim is that this platform will make reversible
		  programming approachable to a wider community.},
  isbn		= {978-3-030-79837-6},
  langid	= {english}
}

@InProceedings{	  he23,
  title		= {Eunomia: {{Enabling User-Specified Fine-Grained Search}}
		  in {{Symbolically Executing WebAssembly Binaries}}},
  shorttitle	= {Eunomia},
  booktitle	= {Proceedings of the 32nd {{ACM SIGSOFT International
		  Symposium}} on {{Software Testing}} and {{Analysis}}},
  author	= {He, Ningyu and Zhao, Zhehao and Wang, Jikai and Hu, Yubin
		  and Guo, Shengjian and Wang, Haoyu and Liang, Guangtai and
		  Li, Ding and Chen, Xiangqun and Guo, Yao},
  year		= {2023},
  month		= jul,
  series	= {{{ISSTA}} 2023},
  pages		= {385--397},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3597926.3598064},
  urldate	= {2023-10-20},
  abstract	= {Although existing techniques have proposed automated
		  approaches to alleviate the path explosion problem of
		  symbolic execution, users still need to optimize symbolic
		  execution by applying various searching strategies
		  carefully. As existing approaches mainly support only
		  coarse-grained global searching strategies, they cannot
		  efficiently traverse through complex code structures. In
		  this paper, we propose Eunomia, a symbolic execution
		  technique that supports fine-grained search with local
		  domain knowledge. Eunomia uses Aes, a DSL that lets users
		  specify local searching strategies for different parts of
		  the program. Eunomia also isolates the context of variables
		  for different local searching strategies, avoiding
		  conflicts. We implement Eunomia for WebAssembly, which can
		  analyze applications written in various languages. Eunomia
		  is the first symbolic execution engine that supports the
		  full features of WebAssembly. We evaluate Eunomia with a
		  microbenchmark suite and six real-world applications. Our
		  evaluation shows that Eunomia improves bug detection by up
		  to three orders of magnitude. We also conduct a user study
		  that shows the benefits of using Aes. Moreover, Eunomia
		  verifies six known bugs and detects two new zero-day bugs
		  in Collections-C.},
  isbn		= {9798400702211},
  keywords	= {Domain Specific Language,Path Explosion,Symbolic
		  Execution,WebAssembly}
}

@Article{	  hentschel19,
  title		= {The {{Symbolic Execution Debugger}} ({{SED}}): A Platform
		  for Interactive Symbolic Execution, Debugging, Verification
		  and More},
  shorttitle	= {The {{Symbolic Execution Debugger}} ({{SED}})},
  author	= {Hentschel, Martin and Bubel, Richard and H{\"a}hnle,
		  Reiner},
  year		= {2019},
  month		= oct,
  journal	= {International Journal on Software Tools for Technology
		  Transfer},
  volume	= {21},
  number	= {5},
  pages		= {485--513},
  issn		= {1433-2787},
  doi		= {10.1007/s10009-018-0490-9},
  urldate	= {2024-03-18},
  abstract	= {The Symbolic Execution Debugger (SED), is an extension of
		  the debug platform for interactive debuggers based on
		  symbolic execution. The SED comes with a static symbolic
		  execution engine for sequential programs, but any
		  third-party symbolic execution engine can be integrated
		  into the SED. An interactive debugger based on symbolic
		  execution allows one like a traditional debugger to locate
		  defects in the source code. The difference is that all
		  feasible execution paths are explored at once, and thus
		  there is no need to know input values resulting in an
		  execution that exhibits the failure. In addition, such a
		  debugger can be used in code reviews and to guide and
		  present results of an analysis based on symbolic execution
		  such as, in our case, correctness proofs. Experimental
		  evaluations proved that the SED increases the effectiveness
		  of code reviews and proof understanding tasks.},
  langid	= {english},
  keywords	= {Debugging,Deductive program verification,Program
		  understanding,Slicing,Symbolic execution}
}

@InProceedings{	  herklotz23,
  title		= {Mechanised {{Semantics}} for {{Gated Static Single
		  Assignment}}},
  booktitle	= {Proceedings of the 12th {{ACM SIGPLAN International
		  Conference}} on {{Certified Programs}} and {{Proofs}}},
  author	= {Herklotz, Yann and Demange, Delphine and Blazy, Sandrine},
  year		= {2023},
  month		= jan,
  series	= {{{CPP}} 2023},
  pages		= {182--196},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3573105.3575681},
  urldate	= {2023-09-27},
  abstract	= {The Gated Static Single Assignment (GSA) form was proposed
		  by Ottenstein et al. in 1990, as an intermediate
		  representation for implementing advanced static analyses
		  and optimisation passes in compilers. Compared to SSA, GSA
		  records additional data dependencies and provides more
		  context, making optimisations more effective and allowing
		  one to reason about programs as data-flow graphs. Many
		  practical implementations have been proposed that follow,
		  more or less faithfully, Ottenstein et al.'s seminal paper.
		  But many discrepancies remain between these, depending on
		  the kind of dependencies they are supposed to track and to
		  leverage in analyses and code optimisations. In this paper,
		  we present a formal semantics for GSA, mechanised in Coq.
		  In particular, we clarify the nature and the purpose of
		  gates in GSA, and define control-flow insensitive semantics
		  for them. We provide a specification that can be used as a
		  reference description for GSA. We also specify a
		  translation from SSA to GSA and prove that this
		  specification is semantics-preserving. We demonstrate that
		  the approach is practical by implementing the specification
		  as a validated translation within the CompCertSSA verified
		  compiler.},
  isbn		= {9798400700262},
  keywords	= {Gated SSA,SSA,Verified Compilation}
}

@Article{	  heunen15,
  title		= {Reversible {{Monadic Computing}}},
  author	= {Heunen, Chris and Karvonen, Martti},
  year		= {2015},
  month		= dec,
  journal	= {Electronic Notes in Theoretical Computer Science},
  series	= {The 31st {{Conference}} on the {{Mathematical
		  Foundations}} of {{Programming Semantics}} ({{MFPS
		  XXXI}}).},
  volume	= {319},
  pages		= {217--237},
  issn		= {1571-0661},
  doi		= {10.1016/j.entcs.2015.12.014},
  urldate	= {2023-09-29},
  abstract	= {We extend categorical semantics of monadic programming to
		  reversible computing, by considering monoidal closed dagger
		  categories: the dagger gives reversibility, whereas closure
		  gives higher-order expressivity. We demonstrate that
		  Frobenius monads model the appropriate notion of coherence
		  between the dagger and closure by reinforcing Cayley's
		  theorem; by proving that effectful computations (Kleisli
		  morphisms) are reversible precisely when the monad is
		  Frobenius; by characterizing the largest reversible
		  subcategory of Eilenberg--Moore algebras; and by
		  identifying the latter algebras as measurements in our
		  leading example of quantum computing. Strong Frobenius
		  monads are characterized internally by Frobenius monoids.},
  keywords	= {dagger category,Frobenius monad,quantum
		  measurement,reversible computing}
}

@Article{	  hgskola01,
  title		= {Monitoring, {{Testing}} and {{Debugging}} of {{Distributed
		  Real-Time Systems}}},
  author	= {Hgskola, Chalmers and Thane, Henrik and Ab, Artes/ssf},
  year		= {2001},
  month		= mar,
  abstract	= {Testing is an important part of any software development
		  project, and can typically surpass more than half of the
		  development cost. For safety-critical computer based
		  systems, testing is even more important due to stringent
		  reliability and safety requirements. However, most
		  safety-critical computer based systems are real-time
		  systems, and the majority of current testing and debugging
		  techniques have been developed for sequential (non
		  real-time) programs. These techniques are not directly
		  applicable to real-time systems, since they disregard
		  issues of timing and concurrency. This means that existing
		  techniques for reproducible testing and debugging cannot be
		  used. Reproducibility is essential for regression testing
		  and cyclic debugging, where the same test cases are run
		  repeatedly with the intention of verifying modified program
		  code or to track down errors. The current trend of consumer
		  and industrial applications goes from single
		  micro-controllers to sets of distributed micro-controllers,
		  which are even more challenging than handling real-time
		  per-see, since multiple loci of observation and control
		  additionally must be considered. In this thesis we try to
		  remedy these problems by presenting an integrated approach
		  to monitoring, testing, and debugging of distributed
		  real-time systems.}
}

@Article{	  hillerstrom22,
  title		= {Foundations for Programming and Implementing Effect
		  Handlers},
  author	= {Hillerstr{\"o}m, Daniel},
  year		= {2022},
  month		= apr,
  publisher	= {The University of Edinburgh},
  doi		= {10.7488/era/2122},
  urldate	= {2023-12-07},
  abstract	= {First-class control operators provide programmers with an
		  expressive and efficient means for manipulating control
		  through reification of the current control state as a
		  first-class object, enabling programmers to implement their
		  own computational effects and control idioms as shareable
		  libraries. Effect handlers provide a particularly
		  structured approach to programming with first-class control
		  by naming control reifying operations and separating from
		  their handling. This thesis is composed of three strands of
		  work in which I develop operational foundations for
		  programming and implementing effect handlers as well as
		  exploring the expressive power of effect handlers. The
		  first strand develops a fine-grain call-by-value core
		  calculus of a statically typed programming language with a
		  structural notion of effect types, as opposed to the
		  nominal notion of effect types that dominates the
		  literature. With the structural approach, effects need not
		  be declared before use. The usual safety properties of
		  statically typed programming are retained by making crucial
		  use of row polymorphism to build and track effect
		  signatures. The calculus features three forms of handlers:
		  deep, shallow, and parameterised. They each offer a
		  different approach to manipulate the control state of
		  programs. Traditional deep handlers are defined by folds
		  over computation trees, and are the original con-struct
		  proposed by Plotkin and Pretnar. Shallow handlers are
		  defined by case splits (rather than folds) over computation
		  trees. Parameterised handlers are deep handlers extended
		  with a state value that is threaded through the folds over
		  computation trees. To demonstrate the usefulness of effects
		  and handlers as a practical programming abstraction I
		  implement the essence of a small UNIX-style operating
		  system complete with multi-user environment, time-sharing,
		  and file I/O. The second strand studies continuation
		  passing style (CPS) and abstract machine semantics, which
		  are foundational techniques that admit a unified basis for
		  implementing deep, shallow, and parameterised effect
		  handlers in the same environment. The CPS translation is
		  obtained through a series of refinements of a basic
		  first-order CPS translation for a fine-grain call-by-value
		  language into an untyped language. Each refinement moves
		  toward a more intensional representation of continuations
		  eventually arriving at the notion of generalised
		  continuation, which admit simultaneous support for deep,
		  shallow, and parameterised handlers. The initial refinement
		  adds support for deep handlers by representing stacks of
		  continuations and handlers as a curried sequence of
		  arguments. The image of the resulting translation is not
		  properly tail-recursive, meaning some function application
		  terms do not appear in tail position. To rectify this the
		  CPS translation is refined once more to obtain an uncurried
		  representation of stacks of continuations and handlers.
		  Finally, the translation is made higher-order in order to
		  contract administrative redexes at translation time. The
		  generalised continuation representation is used to
		  construct an abstract machine that provide simultaneous
		  support for deep, shallow, and parameterised effect
		  handlers. kinds of effect handlers. The third strand
		  explores the expressiveness of effect handlers. First, I
		  show that deep, shallow, and parameterised notions of
		  handlers are interdefinable by way of typed
		  macro-expressiveness, which provides a syntactic notion of
		  expressiveness that affirms the existence of encodings
		  between handlers, but it provides no information about the
		  computational content of the encodings. Second, using the
		  semantic notion of expressiveness I show that for a class
		  of programs a programming language with first-class control
		  (e.g. effect handlers) admits asymptotically faster
		  implementations than possible in a language without
		  first-class control.},
  langid	= {english},
  annotation	= {Accepted: 2022-04-12T12:40:37Z}
}

@Article{	  ho22,
  title		= {Aeneas: {{Rust}} Verification by Functional Translation},
  shorttitle	= {Aeneas},
  author	= {Ho, Son and Protzenko, Jonathan},
  year		= {2022},
  month		= aug,
  journal	= {Aeneas: Rust Verification by Functional Translation},
  volume	= {6},
  number	= {ICFP},
  pages		= {116:711--116:741},
  doi		= {10.1145/3547647},
  urldate	= {2024-12-18},
  abstract	= {We present Aeneas, a new verification toolchain for Rust
		  programs based on a lightweight functional translation. We
		  leverage Rust's rich region-based type system to eliminate
		  memory reasoning for a large class of Rust programs, as
		  long as they do not rely on interior mutability or unsafe
		  code. Doing so, we relieve the proof engineer of the burden
		  of memory-based reasoning, allowing them to instead focus
		  on functional properties of their code. The first
		  contribution of Aeneas is a new approach to borrows and
		  controlled aliasing. We propose a pure, functional
		  semantics for LLBC, a Low-Level Borrow Calculus that
		  captures a large subset of Rust programs. Our semantics is
		  value-based, meaning there is no notion of memory,
		  addresses or pointer arithmetic. Our semantics is also
		  ownership-centric, meaning that we enforce soundness of
		  borrows via a semantic criterion based on loans rather than
		  through a syntactic type-based lifetime discipline. We
		  claim that our semantics captures the essence of the borrow
		  mechanism rather than its current implementation in the
		  Rust compiler. The second contribution of Aeneas is a
		  translation from LLBC to a pure lambda-calculus. This
		  allows the user to reason about the original Rust program
		  through the theorem prover of their choice, and fulfills
		  our promise of enabling lightweight verification of Rust
		  programs. To deal with the well-known technical difficulty
		  of terminating a borrow, we rely on a novel approach, in
		  which we approximate the borrow graph in the presence of
		  function calls. This in turn allows us to perform the
		  translation using a new technical device called backward
		  functions. We implement our toolchain in a mixture of Rust
		  and OCaml; our chief case study is a low-level, resizing
		  hash table, for which we prove functional correctness, the
		  first such result in Rust. Our evaluation shows significant
		  gains of verification productivity for the programmer. This
		  paper therefore establishes a new point in the design space
		  of Rust verification toolchains, one that aims to verify
		  Rust programs simply, and at scale. Rust goes to great
		  lengths to enforce static control of aliasing; the proof
		  engineer should not waste any time on memory reasoning when
		  so much already comes ``for free''!}
}

@Article{	  ho24,
  title		= {Sound {{Borrow-Checking}} for {{Rust}} via {{Symbolic
		  Semantics}}},
  author	= {Ho, Son and Fromherz, Aymeric and Protzenko, Jonathan},
  year		= {2024},
  month		= aug,
  journal	= {Artifact for: Sound Borrow-Checking for Rust via Symbolic
		  Semantics},
  volume	= {8},
  number	= {ICFP},
  pages		= {251:426--251:454},
  doi		= {10.1145/3674640},
  urldate	= {2024-12-17},
  abstract	= {The Rust programming language continues to rise in
		  popularity, and as such, warrants the close attention of
		  the programming languages community. In this work, we
		  present a new foundational contribution towards the
		  theoretical understanding of Rust's semantics. We prove
		  that LLBC, a high-level, borrow-centric model previously
		  proposed for Rust's semantics and execution, is sound with
		  regards to a low-level pointer-based language {\`a} la
		  CompCert. Specifically, we prove the following: that LLBC
		  is a correct view over a traditional model of execution;
		  that LLBC's symbolic semantics are a correct abstraction of
		  LLBC programs; and that LLBC's symbolic semantics act as a
		  borrow-checker for LLBC, i.e. that symbolically-checked
		  LLBC programs do not get stuck when executed on a
		  heap-and-addresses model of execution. To prove these
		  results, we introduce a new proof style that considerably
		  simplifies our proofs of simulation, which relies on a
		  notion of hybrid states. Equipped with this reasoning
		  framework, we show that a new addition to LLBC's symbolic
		  semantics, namely a join operation, preserves the
		  abstraction and borrow-checking properties. This in turn
		  allows us to add support for loops to the Aeneas framework;
		  we show, using a series of examples and case studies, that
		  this unlocks new expressive power for Aeneas.}
}

@Misc{		  hoey18,
  title		= {Reversing {{Parallel Programs}} with {{Blocks}} and
		  {{Procedures}}},
  author	= {Hoey, James and Ulidowski, Irek and Yuen, Shoji},
  year		= {2018},
  month		= aug,
  number	= {arXiv:1808.08651},
  eprint	= {1808.08651},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.1808.08651},
  urldate	= {2024-11-10},
  abstract	= {We show how to reverse a while language extended with
		  blocks, local variables, procedures and the interleaving
		  parallel composition. Annotation is defined along with a
		  set of operational semantics capable of storing necessary
		  reversal information, and identifiers are introduced to
		  capture the interleaving order of an execution. Inversion
		  is defined with a set of operational semantics that use
		  saved information to undo an execution. We prove that
		  annotation does not alter the behaviour of the original
		  program, and that inversion correctly restores the initial
		  program state.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Programming Languages}
}

@InProceedings{	  hoey19,
  title		= {Reversible Imperative Parallel Programs and Debugging},
  booktitle	= {Reversible Computation},
  author	= {Hoey, James and Ulidowski, Irek},
  editor	= {Thomsen, Michael Kirkedal and Soeken, Mathias},
  year		= {2019},
  pages		= {108--127},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  abstract	= {We present a state-saving approach to reversible execution
		  of imperative programs containing parallel composition.
		  Given an original program, we produce an annotated version
		  of the program that both performs forwards execution and
		  all necessary state-saving of required reversal
		  information. We further produce an inverted version of our
		  program, capable of using this saved information to reverse
		  the effects of each step of the forwards execution. We show
		  that this process implements correct and garbage-free
		  inversion. We give examples of how our implementation of
		  reversible execution can be used for debugging, and
		  demonstrate how a simulation tool we have developed for our
		  approach can be used to examine the program state. Finally,
		  we evaluate the performance and overheads associated with
		  state-saving and inversion.},
  isbn		= {978-3-030-21500-2}
}

@Article{	  hogl06,
  title		= {Open On-Chip Debugger--Openocd--},
  author	= {H{\"o}gl, Hubert and Rath, Dominic},
  year		= {2006},
  journal	= {Fakultat fur Informatik, Tech. Rep},
  publisher	= {Citeseer}
}

@Book{		  homes24,
  title		= {Fundamentals of {{Software Testing}}},
  author	= {Hom{\`e}s, Bernard},
  year		= {2024},
  month		= jun,
  edition	= {2},
  publisher	= {John Wiley \& Sons},
  abstract	= {Software testing has greatly evolved since the first
		  edition of this book in 2011. Testers are now required to
		  work in "agile" teams and focus on automating test cases.
		  It has thus been necessary to update this work, in order to
		  provide fundamental knowledge that testers should have to
		  be effective and efficient in today's world. This book
		  describes the fundamental aspects of testing in the
		  different lifecycles, and how to implement and benefit from
		  reviews and static analysis. Multiple other techniques are
		  approached, such as equivalence partitioning, boundary
		  value analysis, use case testing, decision tables and state
		  transitions. This second edition also covers test
		  management, test progress monitoring and incident
		  management, in order to ensure that the testing information
		  is correctly provided to the stakeholders. This book
		  provides detailed course-study material for the 2023
		  version of the ISTQB Foundation level syllabus, including
		  sample questions to help prepare for exams.},
  googlebooks	= {uBAOEQAAQBAJ},
  isbn		= {978-1-394-29896-9},
  langid	= {english},
  keywords	= {Computers / Computer Engineering,Computers / Information
		  Technology,Computers / Software Development & Engineering /
		  Quality Assurance & Testing,Technology & Engineering /
		  Electronics / General}
}

@Article{	  horwitz88,
  title		= {Interprocedural Slicing Using Dependence Graphs},
  author	= {Horwitz, S. and Reps, T. and Binkley, D.},
  year		= {1988},
  month		= jun,
  journal	= {ACM SIGPLAN Notices},
  volume	= {23},
  number	= {7},
  pages		= {35--46},
  issn		= {0362-1340},
  doi		= {10.1145/960116.53994},
  urldate	= {2024-03-13},
  abstract	= {A slice of a program with respect to a program point p and
		  variable x consists of all statements of the program that
		  might affect the value of x at point p. This paper concerns
		  the problem of interprocedural slicing --- generating a
		  slice of an entire program, where the slice crosses the
		  boundaries of procedure calls. To solve this problem, we
		  introduce a new kind of graph to represent programs, called
		  a system dependence graph, which extends previous
		  dependence representations to incorporate collections of
		  procedures (with procedure calls) rather than just
		  monolithic programs. Our main result is an algorithm for
		  interprocedural slicing that uses the new representation.
		  The chief difficulty in interprocedural slicing is
		  correctly accounting for the calling context of a called
		  procedure. To handle this problem, system dependence graphs
		  include some data-dependence edges that represent
		  transitive dependencies due to the effects of procedure
		  calls, in addition to the conventional direct-dependence
		  edges. These edges are constructed with the aid of an
		  auxiliary structure that represents calling and
		  parameter-linkage relationships. This structure takes the
		  form of an attribute grammar. The step of computing the
		  required transitive-dependence edges is reduced to the
		  construction of the subordinate characteristic graphs for
		  the grammar's nonterminals.}
}

@InProceedings{	  irfan22,
  title		= {Testing {{Dafny}} (Experience Paper)},
  booktitle	= {Proceedings of the 31st {{ACM SIGSOFT International
		  Symposium}} on {{Software Testing}} and {{Analysis}}},
  author	= {Irfan, Ahmed and Porncharoenwase, Sorawee and
		  Rakamari{\'c}, Zvonimir and Rungta, Neha and Torlak, Emina},
  year		= {2022},
  month		= jul,
  series	= {{{ISSTA}} 2022},
  pages		= {556--567},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3533767.3534382},
  urldate	= {2023-09-26},
  abstract	= {Verification toolchains are widely used to prove the
		  correctness of critical software systems. To build
		  confidence in their results, it is important to develop
		  testing frameworks that help detect bugs in these
		  toolchains. Inspired by the success of fuzzing in finding
		  bugs in compilers and SMT solvers, we have built the first
		  fuzzing and differential testing framework for Dafny, a
		  high-level programming language with a Floyd-Hoare-style
		  program verifier and compilers to C\#, Java, Go, and
		  Javascript. This paper presents our experience building and
		  using XDsmith, a testing framework that targets the entire
		  Dafny toolchain, from verification to compilation. XDsmith
		  randomly generates annotated programs in a subset of Dafny
		  that is free of loops and heap-mutating operations. The
		  generated programs include preconditions, postconditions,
		  and assertions, and they have a known verification outcome.
		  These programs are used to test the soundness and precision
		  of the Dafny verifier, and to perform differential testing
		  on the four Dafny compilers. Using XDsmith, we uncovered 31
		  bugs across the Dafny verifier and compilers, each of which
		  has been confirmed by the Dafny developers. Moreover, 8 of
		  these bugs have been fixed in the mainline release of
		  Dafny.},
  isbn		= {978-1-4503-9379-9},
  keywords	= {differential testing,fuzzing,program verification}
}

@InProceedings{	  james13,
  title		= {Isomorphic {{Interpreters}} from {{Logically Reversible
		  Abstract Machines}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {James, Roshan P. and Sabry, Amr},
  editor	= {Gl{\"u}ck, Robert and Yokoyama, Tetsuo},
  year		= {2013},
  pages		= {57--71},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-36315-3_5},
  abstract	= {In our previous work, we developed a reversible
		  programming language and established that every computation
		  in it is a (partial) isomorphism that is reversible and
		  that preserves information. The language is founded on type
		  isomorphisms that have a clear categorical semantics but
		  that are awkward as a notation for writing actual programs,
		  especially recursive ones. This paper remedies this aspect
		  by presenting a systematic technique for developing a large
		  and expressive class of reversible recursive programs, that
		  of logically reversible small-step abstract machines. In
		  other words, this paper shows that once we have a logically
		  reversible machine in a notation of our choice, expressing
		  the machine as an isomorphic interpreter can be done
		  systematically and does not present any significant
		  conceptual difficulties. Concretely, we develop several
		  simple interpreters over numbers and addition, move on to
		  tree traversals, and finish with a meta-circular
		  interpreter for our reversible language. This gives us a
		  means of developing large reversible programs with the ease
		  of reasoning at the level of a conventional small-step
		  semantics.},
  isbn		= {978-3-642-36315-3},
  langid	= {english}
}

@InProceedings{	  jangda19,
  title		= {Not {{So Fast}}: {{Analyzing}} the {{Performance}} of
		  \{\vphantom\}{{WebAssembly}}\vphantom\{\} vs. {{Native Code}}},
  shorttitle	= {Not {{So Fast}}},
  booktitle	= {2019 {{USENIX Annual Technical Conference}} ({{USENIX
		  ATC}} 19)},
  author	= {Jangda, Abhinav and Powers, Bobby and Berger, Emery D. and
		  Guha, Arjun},
  year		= {2019},
  pages		= {107--120},
  urldate	= {2023-10-30},
  isbn		= {978-1-939133-03-8},
  langid	= {english}
}

@InProceedings{	  jin15,
  title		= {Concolic {{Metamorphic Debugging}}},
  booktitle	= {2015 {{IEEE}} 39th {{Annual Computer Software}} and
		  {{Applications Conference}}},
  author	= {Jin, Hao and Jiang, Yanyan and Liu, Na and Xu, Chang and
		  Ma, Xiaoxing and Lu, Jian},
  year		= {2015},
  month		= jul,
  volume	= {2},
  pages		= {232--241},
  issn		= {0730-3157},
  doi		= {10.1109/COMPSAC.2015.79},
  urldate	= {2024-03-28},
  abstract	= {Debugging is challenging and labor-intensive. Debugging
		  programs with weak or no oracle is even more difficult due
		  to lack of passing and failing test runs as well as their
		  comparisons. To address these challenges, we exploit
		  metamorphic relations to construct new programs that are
		  enhanced with synthesized oracle, and combine concolic
		  testing and branch-switching debugging to localize
		  potentially faulty places in original programs. We name our
		  approach concolic metamorphic debugging (or Comedy for
		  short). We experimentally evaluated Comedy with real-world
		  Java programs. The experimental results reported that
		  Comedy successfully generated debugging report for 88.4\%
		  of 2,330 faulty programs. The average branch distance
		  between the reported locations and the real fault places is
		  only 1.68. Besides, 36\% of the debugging reports precisely
		  locate the fault.},
  keywords	= {Arrays,Concrete,Debugging,Fault
		  localization,Java,Metamorphic
		  relation,Software,Switches,Testing}
}

@InProceedings{	  johnson13,
  title		= {Fast Condensation of the Program Dependence Graph},
  booktitle	= {Proceedings of the 34th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Johnson, Nick P. and Oh, Taewook and Zaks, Ayal and
		  August, David I.},
  year		= {2013},
  month		= jun,
  series	= {{{PLDI}} '13},
  pages		= {39--50},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2491956.2491960},
  urldate	= {2024-03-18},
  abstract	= {Aggressive compiler optimizations are formulated around
		  the Program Dependence Graph (PDG). Many techniques,
		  including loop fission and parallelization are concerned
		  primarily with dependence cycles in the PDG. The Directed
		  Acyclic Graph of Strongly Connected Components (DAGSCC)
		  represents these cycles directly. The naive method to
		  construct the DAGSCC first computes the full PDG. This
		  approach limits adoption of aggressive optimizations
		  because the number of analysis queries grows quadratically
		  with program size, making DAGSCC construction expensive.
		  Consequently, compilers optimize small scopes with weaker
		  but faster analyses. We observe that many PDG edges do not
		  affect the DAGSCC and that ignoring them cannot affect
		  clients of the DAGSCC. Exploiting this insight, we present
		  an algorithm to omit those analysis queries to compute the
		  DAGSCC efficiently. Across 366 hot loops from 20 SPEC2006
		  benchmarks, this method computes the DAGSCC in half of the
		  time using half as many queries.},
  isbn		= {978-1-4503-2014-6},
  keywords	= {demand-driven analysis,dependence analysis,program
		  dependence graph (pdg),strongly-connected components
		  (scc)}
}

@Article{	  jung17,
  title		= {{{RustBelt}}: Securing the Foundations of the {{Rust}}
		  Programming Language},
  shorttitle	= {{{RustBelt}}},
  author	= {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers,
		  Robbert and Dreyer, Derek},
  year		= {2017},
  month		= dec,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {2},
  number	= {POPL},
  pages		= {66:1--66:34},
  doi		= {10.1145/3158154},
  urldate	= {2024-11-27},
  abstract	= {Rust is a new systems programming language that promises
		  to overcome the seemingly fundamental tradeoff between
		  high-level safety guarantees and low-level control over
		  resource management. Unfortunately, none of Rust's safety
		  claims have been formally proven, and there is good reason
		  to question whether they actually hold. Specifically, Rust
		  employs a strong, ownership-based type system, but then
		  extends the expressive power of this core type system
		  through libraries that internally use unsafe features. In
		  this paper, we give the first formal (and machine-checked)
		  safety proof for a language representing a realistic subset
		  of Rust. Our proof is extensible in the sense that, for
		  each new Rust library that uses unsafe features, we can say
		  what verification condition it must satisfy in order for it
		  to be deemed a safe extension to the language. We have
		  carried out this verification for some of the most
		  important libraries that are used throughout the Rust
		  ecosystem.}
}

@Article{	  jungmair24,
  title		= {{{HiPy}}: {{Extracting High-Level Semantics}} from
		  {{Python Code}} for {{Data Processing}}},
  shorttitle	= {{{HiPy}}},
  author	= {Jungmair, Michael and Engelke, Alexis and Giceva, Jana},
  year		= {2024},
  month		= oct,
  journal	= {Artifact for "HiPy: Extracting High-Level Semantics From
		  Python Code For Data Processing"},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {297:736--297:762},
  doi		= {10.1145/3689737},
  urldate	= {2024-12-18},
  abstract	= {Data science workloads frequently include Python code, but
		  Python's dynamic nature makes efficient execution hard.
		  Traditional approaches either treat Python as a black box,
		  missing out on optimization potential, or are limited to a
		  narrow domain. However, a deep and efficient integration of
		  user-defined Python code into data processing systems
		  requires extracting the semantics of the entire Python
		  code. In this paper, we propose a novel approach for
		  extracting the high-level semantics by transforming general
		  Python functions into program generators that generate a
		  statically-typed IR when executed. The extracted IR then
		  allows for high-level, domain-specific optimizations and
		  the generation of efficient C++ code. With our prototype
		  implementation, HiPy, we achieve single-threaded speedups
		  of 2-20x for many workloads. Furthermore, HiPy is also
		  capable of accelerating Python code in other domains like
		  numerical data, where it can sometimes even outperform
		  specialized compilers.}
}

@Article{	  kakarla24,
  title		= {Diffy: {{Data-Driven Bug Finding}} for
		  {{Configurations}}},
  shorttitle	= {Diffy},
  author	= {Kakarla, Siva Kesava Reddy and Yan, Francis Y. and
		  Beckett, Ryan},
  year		= {2024},
  month		= jun,
  journal	= {Source code for article "Diffy: Data-Driven Bug Finding
		  for Configurations"},
  volume	= {8},
  number	= {PLDI},
  pages		= {155:199--155:222},
  doi		= {10.1145/3656385},
  urldate	= {2024-08-20},
  abstract	= {Configuration errors remain a major cause of system
		  failures and service outages. One promising approach to
		  identify configuration errors automatically is to learn
		  common usage patterns (and anti-patterns) using data-driven
		  methods. However, existing data-driven learning approaches
		  analyze only simple configurations (e.g., those with no
		  hierarchical structure), identify only simple types of
		  issues (e.g., type errors), or require extensive
		  domain-specific tuning. In this paper, we present Diffy,
		  the first push-button configuration analyzer that detects
		  likely bugs in structured configurations. From example
		  configurations, Diffy learns a common template, with
		  "holes" that capture their variation. It then applies
		  unsupervised learning to identify anomalous template
		  parameters as likely bugs. We evaluate Diffy on a large
		  cloud provider's wide-area network, an operational 5G
		  network testbed, and MySQL configurations, demonstrating
		  its versatility, performance, and accuracy. During Diffy's
		  development, it caught and prevented a bug in a
		  configuration timer value that had previously caused an
		  outage for the cloud provider.}
}

@Article{	  kelly81,
  title		= {Reversibility and Stochastic Networks / {{F}}.{{P}}.
		  {{Kelly}}},
  author	= {Kelly, F.P.},
  year		= {1981},
  month		= jun,
  journal	= {SERBIULA (sistema Librum 2.0)},
  volume	= {76},
  doi		= {10.2307/2287860},
  abstract	= {Incluye bibliograf{\'i}a e {\'i}ndice}
}

@InProceedings{	  kery17,
  title		= {Variolite: {{Supporting Exploratory Programming}} by
		  {{Data Scientists}}},
  shorttitle	= {Variolite},
  booktitle	= {Proceedings of the 2017 {{CHI Conference}} on {{Human
		  Factors}} in {{Computing Systems}}},
  author	= {Kery, Mary Beth and Horvath, Amber and Myers, Brad},
  year		= {2017},
  month		= may,
  series	= {{{CHI}} '17},
  pages		= {1265--1276},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3025453.3025626},
  urldate	= {2024-10-30},
  abstract	= {How do people ideate through code? Using semi-structured
		  interviews and a survey, we studied data scientists who
		  program, often with small scripts, to experiment with data.
		  These studies show that data scientists frequently code new
		  analysis ideas by building off of their code from a
		  previous idea. They often rely on informal versioning
		  interactions like copying code, keeping unused code, and
		  commenting out code to repurpose older analysis code while
		  attempting to keep those older analyses intact. Unlike
		  conventional version control, these informal practices
		  allow for fast versioning of any size code snippet, and
		  quick comparisons by interchanging which versions are run.
		  However, data scientists must maintain a strong mental map
		  of their code in order to distinguish versions, leading to
		  errors and confusion. We explore the needs for improving
		  version control tools for exploratory tasks, and
		  demonstrate a tool for lightweight local versioning, called
		  Variolite, which programmers found usable and desirable in
		  a preliminary usability study.},
  isbn		= {978-1-4503-4655-9}
}

@InProceedings{	  kery17a,
  title		= {Exploring Exploratory Programming},
  booktitle	= {2017 {{IEEE Symposium}} on {{Visual Languages}} and
		  {{Human-Centric Computing}} ({{VL}}/{{HCC}})},
  author	= {Kery, Mary Beth and Myers, Brad A.},
  year		= {2017},
  month		= oct,
  pages		= {25--29},
  issn		= {1943-6106},
  doi		= {10.1109/VLHCC.2017.8103446},
  urldate	= {2024-11-12},
  abstract	= {In open-ended tasks where a program's behavior cannot be
		  specified in advance, exploratory programming is a key
		  practice in which programmers actively experiment with
		  different possibilities using code. Exploratory programming
		  is highly relevant today to a variety of professional and
		  end-user programmer domains, including prototyping,
		  learning through play, digital art, and data science.
		  However, prior research has largely lacked clarity on what
		  exploratory programming is, and what behaviors are
		  characteristic of this practice. Drawing on this data and
		  prior literature, we provide an organized description of
		  what exploratory programming has meant historically and a
		  framework of four dimensions for studying exploratory
		  programming tasks: (1) applications, (2) required code
		  quality, (3) ease or difficulty of exploration, and (4) the
		  exploratory process. This provides a basis for better
		  analyzing tool support for exploratory programming.},
  keywords	= {Creativity Support,Debugging,End-user
		  programming,Exploratory Programming,Games,Programming
		  profession,Tools,Visualization}
}

@InProceedings{	  kery18,
  title		= {The {{Story}} in the {{Notebook}}: {{Exploratory Data
		  Science}} Using a {{Literate Programming Tool}}},
  shorttitle	= {The {{Story}} in the {{Notebook}}},
  booktitle	= {Proceedings of the 2018 {{CHI Conference}} on {{Human
		  Factors}} in {{Computing Systems}}},
  author	= {Kery, Mary Beth and Radensky, Marissa and Arya, Mahima and
		  John, Bonnie E. and Myers, Brad A.},
  year		= {2018},
  month		= apr,
  series	= {{{CHI}} '18},
  pages		= {1--11},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3173574.3173748},
  urldate	= {2024-11-11},
  abstract	= {Literate programming tools are used by millions of
		  programmers today, and are intended to facilitate
		  presenting data analyses in the form of a narrative. We
		  interviewed 21 data scientists to study coding behaviors in
		  a literate programming environment and how data scientists
		  kept track of variants they explored. For participants who
		  tried to keep a detailed history of their experimentation,
		  both informal and formal versioning attempts led to
		  problems, such as reduced notebook readability. During
		  iteration, participants actively curated their notebooks
		  into narratives, although primarily through cell structure
		  rather than markdown explanations. Next, we surveyed 45
		  data scientists and asked them to envision how they might
		  use their past history in an future version control system.
		  Based on these results, we give design guidance for future
		  literate programming tools, such as providing history
		  search based on how programmers recall their explorations,
		  through contextual details including images and
		  parameters.},
  isbn		= {978-1-4503-5620-6}
}

@Article{	  keshav07,
  title		= {How to Read a Paper},
  author	= {Keshav, S.},
  year		= {2007},
  month		= jul,
  journal	= {ACM SIGCOMM Computer Communication Review},
  volume	= {37},
  number	= {3},
  pages		= {83--84},
  issn		= {0146-4833},
  doi		= {10.1145/1273445.1273458},
  urldate	= {2023-09-27},
  abstract	= {Researchers spend a great deal of time reading research
		  papers. However, this skill is rarely taught, leading to
		  much wasted effort. This article outlines a practical and
		  efficient three-pass method for reading research papers. I
		  also describe how to use this method to do a literature
		  survey.},
  keywords	= {hints,paper,reading}
}

@Article{	  kessler12,
  title		= {Obama's Whopper about {{Rutherford B}}. {{Hayes}} and the
		  Telephone},
  author	= {Kessler, Glenn},
  year		= {2012},
  month		= mar,
  journal	= {Washington Post},
  urldate	= {2024-04-18},
  abstract	= {FACT CHECKER {\textbar} The president gets his history
		  about the 19th president and the telephone wrong. Very
		  wrong. FACT CHECKER {\textbar} President Obama gets his
		  history about the 19th president and the telephone wrong.
		  Very wrong. How many Pinnochios does he earn?FACT CHECKER
		  {\textbar} The president gets history about the 19th
		  president and the phone wrong.},
  langid	= {american}
}

@Article{	  ketkar24,
  title		= {A {{Lightweight Polyglot Code Transformation Language}}},
  author	= {Ketkar, Ameya and Ramos, Daniel and Clapp, Lazaro and
		  Barik, Raj and Ramanathan, Murali Krishna},
  year		= {2024},
  month		= jun,
  journal	= {Replication of A Lightweight Polyglot Code Transformation
		  Language},
  volume	= {8},
  number	= {PLDI},
  pages		= {199:1288--199:1312},
  doi		= {10.1145/3656429},
  urldate	= {2024-08-20},
  abstract	= {In today's software industry, large-scale, multi-language
		  codebases are the norm. This brings substantial challenges
		  in developing automated tools for code maintenance tasks
		  such as API migration or dead code cleanup. Tool builders
		  often find themselves caught between two less-than-ideal
		  tooling options: (1) language-specific code rewriting tools
		  or (2) generic, lightweight match-replace transformation
		  tools with limited expressiveness. The former leads to tool
		  fragmentation and a steep learning curve for each language,
		  while the latter forces developers to create ad-hoc,
		  throwaway scripts to handle realistic tasks. To fill this
		  gap, we introduce a new declarative domain-specific
		  language (DSL) for expressing interdependent multi-language
		  code transformations. Our key insight is that we can
		  increase the expressiveness and applicability of
		  lightweight match-replace tools by extending them to
		  support for composition, ordering, and flow. We implemented
		  an open-source tool for our language, called
		  PolyglotPiranha, and deployed it in an industrial setting.
		  We demonstrate its effectiveness through three case
		  studies, where it deleted 210K lines of dead code and
		  migrated 20K lines, across 1611 pull requests. We compare
		  our DSL against state-of-the-art alternatives, and show
		  that the tools we developed are faster, more concise, and
		  easier to maintain.}
}

@Article{	  kim18,
  title		= {{{IoT-TaaS}}: {{Towards}} a {{Prospective IoT Testing
		  Framework}}},
  shorttitle	= {{{IoT-TaaS}}},
  author	= {Kim, Hiun and Ahmad, Abbas and Hwang, Jaeyoung and Baqa,
		  Hamza and Le Gall, Franck and Reina Ortega, Miguel Angel
		  and Song, JaeSeung},
  year		= {2018},
  journal	= {IEEE Access},
  volume	= {6},
  pages		= {15480--15493},
  issn		= {2169-3536},
  doi		= {10.1109/ACCESS.2018.2802489},
  urldate	= {2024-02-12},
  abstract	= {The Internet of Things (IoT) aims to change many aspects
		  of people's daily lives by extending the scope of computing
		  to the physical world, and thus shift the environment of
		  computing more to a distributed and decentralized form. The
		  amount of IoT devices and their collaborative behavior
		  causes new challenges to the scalability of traditional
		  software testing, and the heterogeneity of IoT devices
		  increases costs and the complexity of coordination of
		  testing due to the number of variables. In this paper, we
		  introduce IoT Testing as a Service-IoT-TaaS, a novel
		  service-based approach for an automated IoT testing
		  framework aims to resolve constraints regarding
		  coordination, costs, and scalability issues of traditional
		  software testing in the context of standards-based
		  development of IoT devices, and explore its design and
		  implementation. IoT-TaaS is composed of remote distributed
		  interoperability testing, scalable automated conformance
		  testing, and semantics validation testing components
		  adequate for testing IoT devices. To provide a conceptual
		  overview, we analyze its technical and systemic advancement
		  and compare it to traditional testing with concrete
		  examples.},
  keywords	= {automated testing,conformance testing,Internet of
		  Things,Interoperability,interoperability
		  testing,Protocols,semantic
		  testing,Semantics,Software,Software testing,Standards,test
		  as a service}
}

@Article{	  king76,
  title		= {Symbolic Execution and Program Testing},
  author	= {King, James C.},
  year		= {1976},
  month		= jul,
  journal	= {Communications of the ACM},
  volume	= {19},
  number	= {7},
  pages		= {385--394},
  issn		= {0001-0782},
  doi		= {10.1145/360248.360252},
  urldate	= {2023-10-24},
  abstract	= {This paper describes the symbolic execution of programs.
		  Instead of supplying the normal inputs to a program (e.g.
		  numbers) one supplies symbols representing arbitrary
		  values. The execution proceeds as in a normal execution
		  except that values may be symbolic formulas over the input
		  symbols. The difficult, yet interesting issues arise during
		  the symbolic execution of conditional branch type
		  statements. A particular system called EFFIGY which
		  provides symbolic execution for program testing and
		  debugging is also described. It interpretively executes
		  programs written in a simple PL/I style programming
		  language. It includes many standard debugging features, the
		  ability to manage and to prove things about symbolic
		  expressions, a simple program testing manager, and a
		  program verifier. A brief discussion of the relationship
		  between symbolic execution and program proving is also
		  included.},
  keywords	= {program debugging,program proving,program testing,program
		  verification,symbolic execution,symbolic interpretation}
}

@Article{	  kirk23,
  title		= {A Formal Framework for Security Testing of Automotive
		  Over-the-Air Update Systems},
  author	= {Kirk, Rhys and Nguyen, Hoang Nga and Bryans, Jeremy and
		  Shaikh, Siraj Ahmed and Wartnaby, Charles},
  year		= {2023},
  month		= jan,
  journal	= {Journal of Logical and Algebraic Methods in Programming},
  volume	= {130},
  pages		= {100812},
  issn		= {2352-2208},
  doi		= {10.1016/j.jlamp.2022.100812},
  urldate	= {2023-10-25},
  abstract	= {Modern vehicles are comparable to desktop computers due to
		  the increase in connectivity. This fact also extends to
		  potential cyber-attacks. A solution for preventing and
		  mitigating cyber attacks is Over-The-Air (OTA) updates.
		  This solution has also been used for both desktops and
		  mobile phones. The current de facto OTA security system for
		  vehicles is Uptane, which is developed to solve the unique
		  issues vehicles face. The Uptane system needs to have a
		  secure method of updating; otherwise, attackers will
		  exploit it. To this end, we have developed a comprehensive
		  and model-based security testing approach by translating
		  Uptane and our attack model into formal models in
		  Communicating Sequential Processes (CSP). These are
		  combined and verified to generate an exhaustive list of
		  test cases to see to which attacks Uptane may be
		  susceptible. Security testing is then conducted based on
		  these generated test cases, on a test-bed running an
		  implementation of Uptane. The security testing result
		  enables us to validate the security design of Uptane and
		  some vulnerabilities to which it is subject.},
  keywords	= {Automotive cybersecurity,Automotive OTA,CSP,Security
		  testing,Uptane}
}

@Article{	  knuth81,
  title		= {Breaking Paragraphs into Lines},
  author	= {Knuth, Donald E. and Plass, Michael F.},
  year		= {1981},
  month		= nov,
  journal	= {Software: Practice and Experience},
  volume	= {11},
  number	= {11},
  pages		= {1119--1184},
  issn		= {0038-0644, 1097-024X},
  doi		= {10.1002/spe.4380111102},
  urldate	= {2024-01-09},
  abstract	= {Abstract This paper discusses a new approach to the
		  problem of dividing the text of a paragraph into lines of
		  approximately equal length. Instead of simply making
		  decisions one line at a time, the method considers the
		  paragraph as a whole, so that the final appearance of a
		  given line might be influenced by the text on succeeding
		  lines. A system based on three simple primitive concepts
		  called `boxes', `glue', and `penalties' provides the
		  ability to deal satisfactorily with a wide variety of
		  typesetting problems in a unified framework, using a single
		  algorithm that determines optimum breakpoints. The
		  algorithm avoids backtracking by a judicious use of the
		  techniques of dynamic programming. Extensive computational
		  experience confirms that the approach is both efficient and
		  effective in producing high-quality output. The paper
		  concludes with a brief history of line-breaking methods,
		  and an appendix presents a simplified algorithm that
		  requires comparatively few resources.},
  langid	= {english}
}

@Article{	  kramer90,
  title		= {The Evolving Philosophers Problem: Dynamic Change
		  Management},
  shorttitle	= {The Evolving Philosophers Problem},
  author	= {Kramer, J. and Magee, J.},
  year		= {1990},
  month		= nov,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {16},
  number	= {11},
  pages		= {1293--1306},
  issn		= {1939-3520},
  doi		= {10.1109/32.60317},
  urldate	= {2024-01-16},
  abstract	= {A model for dynamic change management which separates
		  structural concerns from component application concerns is
		  presented. This separation of concerns permits the
		  formulation of general structural rules for change at the
		  configuration level without the need to consider
		  application state, and the specification of application
		  component actions without prior knowledge of the actual
		  structural changes which may be introduced. In addition,
		  the changes can be applied in such a way so as to leave the
		  modified system in a consistent state, and cause no
		  disturbance to the unaffected part of the operational
		  system. The model is applied to an example problem,
		  'evolving philosophers'. The principles of this model have
		  been implemented and tested in the Conic environment for
		  distributed systems.{$<>$}}
}

@InProceedings{	  krebs23,
  title		= {Probe {{Log}}: {{Visualizing}} the {{Control Flow}} of
		  {{Babylonian Programming}}},
  shorttitle	= {Probe {{Log}}},
  booktitle	= {Companion {{Proceedings}} of the 7th {{International
		  Conference}} on the {{Art}}, {{Science}}, and
		  {{Engineering}} of {{Programming}}},
  author	= {Krebs, Eva and Rein, Patrick and Bergsiek, Joana and
		  Urban, Lina and Hirschfeld, Robert},
  year		= {2023},
  month		= sep,
  series	= {Programming '23},
  pages		= {61--67},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3594671.3594679},
  urldate	= {2024-03-13},
  abstract	= {Code itself is abstract, which makes it often difficult to
		  understand -- sometimes even by the programmers that wrote
		  it. When working with or thinking about code, programmers
		  thus often resort to concrete values and execution traces
		  to make the abstract more tangible. Such approaches like
		  exploration scripts in a workspace or unit tests of a test
		  suite are already very helpful, but still lack a convenient
		  conceptual and technical integration into core development
		  tools, leaving such examples and the code they refer to too
		  far apart. Example-based programming like Babylonian
		  Programming aims at offering the benefits of concrete, live
		  examples directly in program editors, interleaved with the
		  code it supports, to shorten feedback loops and reduce the
		  need for context switches coming with changing tools.
		  However, Babylonian Programming and its tools currently
		  focus on a local perspective on code exploration, but do
		  not yet extend to messages sent outside a particular unit
		  of code and with that do not yet directly support feedback
		  on more dynamic properties of a running program / system.
		  We developed Probe Log, a Babylonian Programming tool that
		  extends the benefits of example-based programming to
		  scenarios that span across multiple procedures. It provides
		  a linear view on the dynamics of evolving examples beyond a
		  local perspective.},
  isbn		= {9798400707551},
  keywords	= {babylonian programming,example-based
		  programming,examples,exploratory programming,live
		  programming,smalltalk,squeak}
}

@InProceedings{	  krinke04,
  title		= {Visualization of Program Dependence and Slices},
  booktitle	= {20th {{IEEE International Conference}} on {{Software
		  Maintenance}}, 2004. {{Proceedings}}.},
  author	= {Krinke, J.},
  year		= {2004},
  month		= sep,
  pages		= {168--177},
  issn		= {1063-6773},
  doi		= {10.1109/ICSM.2004.1357801},
  urldate	= {2024-03-14},
  abstract	= {The program dependence graph (PDG) itself and the computed
		  slices within the program dependence graph are results that
		  should be presented to the user in a comprehensible form,
		  if not used in subsequent analyses. A graphical
		  presentation would be preferred as it is usually more
		  intuitive than textual ones. This work describes how a
		  layout for the PDGs can be generated to enable an appealing
		  presentation. However, experience shows that the graphical
		  presentation is less helpful than expected and a textual
		  presentation is superior. Therefore, this work contains an
		  approach to textually present slices of PDGs in source
		  code. The innovation of this approach is the fine-grained
		  visualization of arbitrary node sets based on tokens and
		  not on complete lines like in other approaches.
		  Furthermore, a major obstacle in visualization and
		  comprehension of slices is the loss of locality. Thus, this
		  work presents a simple, yet effective, approach to limit
		  the range of a slice. This approach enables a visualization
		  of slices where the local effects stand out against the
		  more global effects. A second, more sophisticated approach
		  visualizes the influence range of chops for variables and
		  procedures. This enables a visualization of the impact of
		  procedures and variables on the complete system.},
  keywords	= {Application software,Area measurement,Data flow
		  computing,Iterative methods,Layout,Software
		  maintenance,Software measurement,Software
		  testing,Technological innovation,Visualization}
}

@InProceedings{	  lami24,
  title		= {A {{Small-Step Semantics}} for~{{Janus}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Lami, Pietro and Lanese, Ivan and Stefani, Jean-Bernard},
  editor	= {Mogensen, Torben {\AE}gidius and Mikulski, {\L}ukasz},
  year		= {2024},
  pages		= {105--123},
  publisher	= {Springer Nature Switzerland},
  address	= {Cham},
  doi		= {10.1007/978-3-031-62076-8_8},
  abstract	= {Janus is an imperative, sequential language for
		  reversibility. While heavily studied in the reversibility
		  literature, to the best of our knowledge, no small-step
		  semantics for it exists. Hence, we propose a small-step
		  semantics for Janus and we prove it equivalent to a
		  big-step semantics from the literature, for programs that
		  have no runtime errors and no divergence. Our main
		  motivation is to enable a future extension of Janus with
		  concurrency primitives, which is more easily defined on top
		  of a small-step semantics. As additional feature, a
		  small-step semantics allows one to more easily distinguish
		  between failing and non-terminating computations.},
  isbn		= {978-3-031-62076-8},
  langid	= {english}
}

@InProceedings{	  lanese13,
  title		= {Concurrent {{Flexible Reversibility}}},
  booktitle	= {Programming {{Languages}} and {{Systems}}},
  author	= {Lanese, Ivan and Lienhardt, Michael and Mezzina, Claudio
		  Antares and Schmitt, Alan and Stefani, Jean-Bernard},
  editor	= {Felleisen, Matthias and Gardner, Philippa},
  year		= {2013},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {370--390},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-37036-6_21},
  abstract	= {Concurrent reversibility has been studied in different
		  areas, such as biological or dependable distributed
		  systems. However, only ``rigid'' reversibility has been
		  considered, allowing to go back to a past state and restart
		  the exact same computation, possibly leading to divergence.
		  In this paper, we present croll-{$\pi$}, a concurrent
		  calculus featuring flexible reversibility, allowing the
		  specification of alternatives to a computation to be used
		  upon rollback. Alternatives in croll-{$\pi$} are attached
		  to messages. We show the robustness of this mechanism by
		  encoding more complex idioms for specifying flexible
		  reversibility, and we illustrate the benefits of our
		  approach by encoding a calculus of communicating
		  transactions.},
  isbn		= {978-3-642-37036-6},
  langid	= {english},
  keywords	= {Causal Dependence,Parallel Composition,Past
		  State,Reduction Rule,Transactional Memory}
}

@Article{	  lanese14,
  title		= {Causal-{{Consistent Reversibility}}},
  author	= {Lanese, Ivan and Mezzina, Claudio and Tiezzi, Francesco},
  year		= {2014},
  month		= nov,
  abstract	= {Reversible computing allows one to execute programs both
		  in the standard , forward direction, and backward, going
		  back to past states. In a concurrent scenario, the correct
		  notion of reversibility is causal-consistent
		  re-versibility: any action can be undone, provided that all
		  its consequences (if any) are undone beforehand. In this
		  paper we present an overview of the main approaches,
		  results, and applications of causal-consistent
		  reversibility.}
}

@InProceedings{	  lanese18,
  title		= {{{CauDEr}}: {{A Causal-Consistent Reversible Debugger}}
		  for {{Erlang}}},
  shorttitle	= {{{CauDEr}}},
  booktitle	= {Functional and {{Logic Programming}}},
  author	= {Lanese, Ivan and Nishida, Naoki and Palacios, Adri{\'a}n
		  and Vidal, Germ{\'a}n},
  editor	= {Gallagher, John P. and Sulzmann, Martin},
  year		= {2018},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {247--263},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-90686-7_16},
  abstract	= {Programming languages based on the actor model, such as
		  Erlang, avoid some concurrency bugs by design. However,
		  other concurrency bugs, such as message order violations
		  and livelocks, can still show up in programs. These
		  hard-to-find bugs can be more easily detected by using
		  causal-consistent reversible debugging, a debugging
		  technique that allows one to traverse a computation both
		  forward and backward. Most notably, causal consistency
		  implies that, when going backward, an action can only be
		  undone provided that its consequences, if any, have been
		  undone beforehand. To the best of our knowledge, we present
		  the first causal-consistent reversible debugger for Erlang,
		  which may help programmers to detect and fix various kinds
		  of bugs, including message order violations and
		  livelocks.},
  isbn		= {978-3-319-90686-7},
  langid	= {english},
  keywords	= {Backward Derivative,Concurrency Bugs,Core Erlang,Reverse
		  Debugging,Rollback Request}
}

@InProceedings{	  lanese18a,
  title		= {From {{Reversible Semantics}} to {{Reversible
		  Debugging}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Lanese, Ivan},
  editor	= {Kari, Jarkko and Ulidowski, Irek},
  year		= {2018},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {34--46},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-99498-7_2},
  abstract	= {This paper presents a line of research in reversible
		  computing for concurrent systems. This line of research
		  started in 2004 with the definition of the first reversible
		  extensions for concurrent process calculi such as CCS, and
		  is currently heading to the production of practical
		  reversible debuggers for concurrent languages such as
		  Erlang. Main questions that had to be answered during the
		  research include the following. Which is the correct notion
		  of reversibility for concurrent systems? Which history
		  information needs to be stored? How to control the basic
		  reversibility mechanism? How to exploit reversibility for
		  debugging? How to apply reversible debugging to real
		  languages?},
  isbn		= {978-3-319-99498-7},
  langid	= {english}
}

@Article{	  lanese21,
  title		= {Reversible {{Execution}} for {{Robustness}} in {{Embodied
		  AI}} and {{Industrial Robots}}},
  author	= {Lanese, Ivan and Schultz, Ulrik P. and Ulidowski, Irek},
  year		= {2021},
  month		= may,
  journal	= {IT Professional},
  volume	= {23},
  number	= {3},
  pages		= {12--17},
  issn		= {1941-045X},
  doi		= {10.1109/MITP.2021.3073757},
  urldate	= {2024-11-11},
  abstract	= {Reversible computation is a computing paradigm where
		  execution can progress backward as well as in the usual,
		  forward direction. It has found applications in many areas
		  of computer science, such as circuit design, programming
		  languages, simulation, modeling of chemical reactions,
		  debugging, and robotics. In this article, we give an
		  overview of reversible computation focusing on its use in
		  robotics. We present an example of programming industrial
		  robots for assembly operations where we combine classical
		  AI planning with reversibility and embodied AI to increase
		  the robustness and versatility of industrial robots.},
  keywords	= {Artificial intelligence,Backtracking,Computational
		  modeling,Integrated circuit modeling,Robotic
		  assembly,Robustness,Service robots}
}

@Article{	  laursen18,
  title		= {Modelling Reversible Execution of Robotic Assembly},
  author	= {Laursen, Johan Sund and Ellekilde, Lars-Peter and Schultz,
		  Ulrik Pagh},
  year		= {2018},
  month		= may,
  journal	= {Robotica},
  volume	= {36},
  number	= {5},
  pages		= {625--654},
  issn		= {0263-5747, 1469-8668},
  doi		= {10.1017/S0263574717000613},
  urldate	= {2024-11-11},
  abstract	= {SUMMARY Programming robotic assembly for industrial
		  small-batch production is challenging; hence, it is vital
		  to increase robustness and reduce development effort in
		  order to achieve flexible robotic automation. A human who
		  has made an assembly error will often simply undo the
		  process until the error is undone and then restart the
		  assembly. Conceptually, robots could do the same. This
		  paper introduces a programming model that enables robot
		  assembly programs to be executed in reverse. We investigate
		  the challenges in running robot programs backwards and
		  present a classification of reversibility characteristics.
		  We demonstrate how temporarily switching the direction of
		  program execution can be an efficient error recovery
		  mechanism. Moreover, we demonstrate additional benefits
		  arising from supporting reversibility in an assembly
		  language, such as increased code reuse and automatically
		  derived disassembly sequences. As a default approach to
		  reversibility, we use program inversion and statement-level
		  inversion of commands, but with a novel override option
		  providing alternative sequences for asymmetric reverse
		  actions. To efficiently program for this model, this paper
		  introduces a new domain-specific language, SCP-RASQ (Simple
		  C++ Reversible Assembly SeQuences). In initial experiments,
		  where 200 consecutive assemblies of two industrial cases
		  were performed, 18 of 22 errors were corrected
		  automatically using only the trial-and-error capabilities
		  that come from reverse execution.},
  copyright	= {https://www.cambridge.org/core/terms},
  langid	= {english}
}

@InProceedings{	  lauwaerts22,
  title		= {Event-{{Based Out-of-Place Debugging}}},
  booktitle	= {Proceedings of the 19th {{International Conference}} on
		  {{Managed Programming Languages}} and {{Runtimes}}},
  author	= {Lauwaerts, Tom and Castillo, Carlos Rojas and Singh,
		  Robbert Gurdeep and Marra, Matteo and Scholliers,
		  Christophe and Gonzalez Boix, Elisa},
  year		= {2022},
  month		= nov,
  series	= {{{MPLR}} '22},
  pages		= {85--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3546918.3546920},
  urldate	= {2023-09-26},
  abstract	= {Debugging IoT applications is challenging due to the
		  hardware constraints of IoT devices, making advanced
		  techniques like record-replay debugging impractical. As a
		  result, programmers often rely on manual resets or
		  inefficient and time-consuming debugging techniques such as
		  printf. Although simulators can help in that regard, their
		  applicability is limited because they fall short of
		  accurately simulating and reproducing the runtime
		  conditions where bugs appear. In this work, we explore a
		  novel debugging approach called event-based out-of-place
		  debugging in which developers can capture a remotely
		  running program and debug it locally on a (more powerful)
		  machine. Our approach thus provides rich debugging features
		  (e.g., step-back) that normally would not run on the
		  hardware restricted devices. Two different strategies are
		  offered to deal with resources which cannot be easily
		  transferred (e.g., sensors): pull-based (akin to remote
		  debugging), or push-based (where data updates are pushed to
		  developer's machine during the debug session). We present
		  EDWARD, an event-based out-of-place debugger prototype,
		  implemented by extending the WARDuino WebAssembly
		  microcontroller Virtual Machine, that has been integrated
		  into Visual Studio Code. To validate our approach, we show
		  how our debugger helps uncover IoT bugs representative of
		  real-world applications through several use-case
		  applications. Initial benchmarks show that event-based
		  out-of-place debugging can drastically reduce debugging
		  latency.},
  isbn		= {978-1-4503-9696-7},
  keywords	= {Debugger,Internet-of-Things,Out-of-place debugging,Virtual
		  Machine,WARDuino,WebAssembly}
}

@Article{	  lauwaerts24,
  title		= {{{WARDuino}}: {{An}} Embedded {{WebAssembly}} Virtual
		  Machine},
  shorttitle	= {{{WARDuino}}},
  author	= {Lauwaerts, Tom and Singh, Robbert Gurdeep and Scholliers,
		  Christophe},
  year		= {2024},
  month		= feb,
  journal	= {Journal of Computer Languages},
  pages		= {101268},
  issn		= {2590-1184},
  doi		= {10.1016/j.cola.2024.101268},
  urldate	= {2024-02-13},
  abstract	= {Creating IoT programs for resource-constrained
		  microcontrollers differs significantly from conventional
		  computer programming. Microcontrollers are traditionally
		  programmed using low-level programming languages with poor
		  debugging facilities. By contrast, general-purpose systems
		  can be programmed with high-level languages, which make
		  programming easier by providing many useful tools such as
		  advanced debuggers, strong type systems, and/or automatic
		  memory management. Most existing solutions for programming
		  microcontrollers with high-level languages are strongly
		  tied to a specific microcontroller architecture, which
		  makes porting code difficult or impossible. In addition,
		  compiling and flashing software onto a microcontroller is
		  time-consuming, slowing down development. To solve these
		  problems we present WARDuino, a WebAssembly virtual machine
		  that runs on microcontrollers and provides WebAssembly
		  primitives to control embedded hardware and IoT
		  functionality. WARDuino runs programs written in a plethora
		  of high-level languages that compile to WebAssembly. We
		  give a general approach for language integration libraries
		  to expose the peripherals and networking capabilities of
		  the device following the idioms of the host language. To
		  ease development, we extend WebAssembly with support for
		  remote debugging and over-the-air reprogramming. WARDuino
		  can remotely instruct a microcontroller to pause, to step,
		  or to dump its state, and to replace local variables,
		  functions or even the entire running program. We use the
		  remote debugger of the virtual machine to create a visual
		  debugging environment in VS Code for WARDuino, that can
		  debug WebAssembly and AssemblyScript. Aside from these
		  important tools, we provide a novel mechanism to handle
		  asynchronous interrupts in WebAssembly, a fundamental
		  building block for responsive embedded applications. Our
		  extensions are implemented in the WARDuino virtual machine
		  and presented as formal extensions to the WebAssembly
		  operational semantics. We use the formalization to proof
		  observational equivalence for the core debugger semantics.
		  We compared the computational performance and memory size
		  with native C code, Espruino, and WASM3 which compiles
		  WebAssembly ahead-of-time. The comparison shows that
		  WARDuino's performance is acceptable. Although WARDuino is
		  on average 425.93 times slower than native code and 37.96
		  times slower than WASM3, it outperforms the popular
		  Espruino runtime by a factor of 11.66. Additionally, we
		  show that WARDuino is fast enough to program traditional
		  IoT applications that handle network and device interrupts
		  with a classic smart lamp application written in
		  AssemblyScript.},
  keywords	= {Internet-of-Things,Language symbiosis,Virtual
		  machine,WARDuino,WebAssembly}
}

@InProceedings{	  lechenet18,
  title		= {Fast {{Computation}} of {{Arbitrary Control
		  Dependencies}}},
  booktitle	= {Fundamental {{Approaches}} to {{Software Engineering}}},
  author	= {L{\'e}chenet, Jean-Christophe and Kosmatov, Nikolai and Le
		  Gall, Pascale},
  editor	= {Russo, Alessandra and Sch{\"u}rr, Andy},
  year		= {2018},
  pages		= {207--224},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-89363-1_12},
  abstract	= {In 2011, Danicic et al. introduced an elegant
		  generalization of the notion of control dependence for any
		  directed graph. They also proposed an algorithm computing
		  the weak control-closure of a subset of graph vertices and
		  performed a paper-and-pencil proof of its correctness. We
		  have performed its proof in the Coq proof assistant. This
		  paper also presents a novel, more efficient algorithm to
		  compute weak control-closure taking benefit of intermediate
		  propagation results of previous iterations in order to
		  accelerate the following ones. This optimization makes the
		  design and proof of the algorithm more complex and requires
		  subtle loop invariants. The new algorithm has been
		  formalized and mechanically proven in the Why3 verification
		  tool. Experiments on arbitrary generated graphs with up~to
		  thousands of vertices demonstrate that the proposed
		  algorithm remains practical for real-life programs and
		  significantly outperforms Danicic's initial technique.},
  isbn		= {978-3-319-89363-1},
  langid	= {english}
}

@InProceedings{	  lee16,
  title		= {A {{Brief Review}} on {{JTAG Security}}},
  booktitle	= {2016 10th {{International Conference}} on {{Innovative
		  Mobile}} and {{Internet Services}} in {{Ubiquitous
		  Computing}} ({{IMIS}})},
  author	= {Lee, Kyungroul and Lee, Yeunsu and Lee, Hyeji and Yim,
		  Kangbin},
  year		= {2016},
  month		= jul,
  pages		= {486--490},
  doi		= {10.1109/IMIS.2016.102},
  urldate	= {2024-11-13},
  abstract	= {In this paper, we outline security issues on IEEE 1149.1
		  JTAG. The JTAG interface is provided for its beneficial
		  features, such as debugging and downloading firmware, but
		  attackers are abusing it by reverse engineering and by
		  modifying firmware. Hence, they are able to steal
		  confidential information in the system or are able clone
		  the embedded system. In order to solve this problem, a
		  variety of security techniques are proposed to improve
		  safety. These are classified based on the circuitry, the
		  authority, the integrity, the confidentiality, the access
		  control, and the authentication.},
  keywords	= {access control,authentication,Computer
		  architecture,Debugging,JTAG,Microprocessors,Microprogramming,Pins,Program
		  processors,Security}
}

@InProceedings{	  lee17,
  title		= {Taming Undefined Behavior in {{LLVM}}},
  booktitle	= {Proceedings of the 38th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Lee, Juneyoung and Kim, Yoonseung and Song, Youngju and
		  Hur, Chung-Kil and Das, Sanjoy and Majnemer, David and
		  Regehr, John and Lopes, Nuno P.},
  year		= {2017},
  month		= jun,
  series	= {{{PLDI}} 2017},
  pages		= {633--647},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3062341.3062343},
  urldate	= {2024-12-18},
  abstract	= {A central concern for an optimizing compiler is the design
		  of its intermediate representation (IR) for code. The IR
		  should make it easy to perform transformations, and should
		  also afford efficient and precise static analysis. In this
		  paper we study an aspect of IR design that has received
		  little attention: the role of undefined behavior. The IR
		  for every optimizing compiler we have looked at, including
		  GCC, LLVM, Intel's, and Microsoft's, supports one or more
		  forms of undefined behavior (UB), not only to reflect the
		  semantics of UB-heavy programming languages such as C and
		  C++, but also to model inherently unsafe low-level
		  operations such as memory stores and to avoid
		  over-constraining IR semantics to the point that desirable
		  transformations become illegal. The current semantics of
		  LLVM's IR fails to justify some cases of loop unswitching,
		  global value numbering, and other important "textbook"
		  optimizations, causing long-standing bugs. We present
		  solutions to the problems we have identified in LLVM's IR
		  and show that most optimizations currently in LLVM remain
		  sound, and that some desirable new transformations become
		  permissible. Our solutions do not degrade compile time or
		  performance of generated code.},
  isbn		= {978-1-4503-4988-8}
}

@Article{	  leeman86,
  title		= {A Formal Approach to Undo Operations in Programming
		  Languages},
  author	= {Leeman, George B.},
  year		= {1986},
  month		= jan,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {8},
  number	= {1},
  pages		= {50--87},
  issn		= {0164-0925},
  doi		= {10.1145/5001.5005},
  urldate	= {2023-09-26},
  abstract	= {A framework is presented for adding a general Undo
		  facility to programming languages. A discussion of relevant
		  literature is provided to show that the idea of Undoing
		  pervades several areas in computer science, and even other
		  disciplines. A simple model of computation is introduced,
		  and it is augmented with a minimal amount of additional
		  structure needed for recovery and reversal. Two different
		  interpretations of Undo are motivated with examples. Then,
		  four primitives are defined in a language-independent
		  manner; they are sufficient to support a wide range of Undo
		  capability. Two of these primitives carry out state saving,
		  and the others mirror the two versions of the Undo
		  operation. Properties of and relationships between these
		  primitives are explored, and there are some preliminary
		  remarks on how one could implement a system based on this
		  formalism. The main conclusion is that the notions of
		  recovery and reversal of actions can become part of the
		  programming process.}
}

@Article{	  leeman86a,
  title		= {A Formal Approach to Undo Operations in Programming
		  Languages},
  author	= {Leeman, George B.},
  year		= {1986},
  month		= jan,
  journal	= {ACM Trans. Program. Lang. Syst.},
  volume	= {8},
  number	= {1},
  pages		= {50--87},
  issn		= {0164-0925},
  doi		= {10.1145/5001.5005},
  urldate	= {2024-11-11},
  abstract	= {A framework is presented for adding a general Undo
		  facility to programming languages. A discussion of relevant
		  literature is provided to show that the idea of Undoing
		  pervades several areas in computer science, and even other
		  disciplines. A simple model of computation is introduced,
		  and it is augmented with a minimal amount of additional
		  structure needed for recovery and reversal. Two different
		  interpretations of Undo are motivated with examples. Then,
		  four primitives are defined in a language-independent
		  manner; they are sufficient to support a wide range of Undo
		  capability. Two of these primitives carry out state saving,
		  and the others mirror the two versions of the Undo
		  operation. Properties of and relationships between these
		  primitives are explored, and there are some preliminary
		  remarks on how one could implement a system based on this
		  formalism. The main conclusion is that the notions of
		  recovery and reversal of actions can become part of the
		  programming process.}
}

@InProceedings{	  lehmann19,
  title		= {Wasabi: {{A Framework}} for {{Dynamically Analyzing
		  WebAssembly}}},
  shorttitle	= {Wasabi},
  booktitle	= {Proceedings of the {{Twenty-Fourth International
		  Conference}} on {{Architectural Support}} for {{Programming
		  Languages}} and {{Operating Systems}}},
  author	= {Lehmann, Daniel and Pradel, Michael},
  year		= {2019},
  month		= apr,
  series	= {{{ASPLOS}} '19},
  pages		= {1045--1058},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3297858.3304068},
  urldate	= {2023-11-08},
  abstract	= {WebAssembly is the new low-level language for the web and
		  has now been implemented in all major browsers since over a
		  year. To ensure the security, performance, and correctness
		  of future web applications, there is a strong need for
		  dynamic analysis tools for WebAssembly. However, building
		  such tools from scratch requires knowledge of low-level
		  details of the language and its runtime environment. This
		  paper presents Wasabi, the first general-purpose framework
		  for dynamically analyzing WebAssembly. Wasabi provides an
		  easy-to-use, high-level API that supports heavyweight
		  dynamic analyses. It is based on binary instrumentation,
		  which inserts calls to analysis functions written in
		  JavaScript into a WebAssembly binary. Dynamically analyzing
		  WebAssembly comes with several unique challenges, such as
		  the problem of tracing type-polymorphic instructions with
		  analysis functions that have a fixed type, which we address
		  through on-demand monomorphization. Our evaluation on
		  compute-intensive benchmarks and real-world applications
		  shows that Wasabi (i) faithfully preserves the original
		  program behavior, (ii) imposes an overhead that is
		  reasonable for heavyweight dynamic analysis, and (iii)
		  makes it straightforward to implement various dynamic
		  analyses, including instruction counting, call graph
		  extraction, memory access tracing, and taint analysis.},
  isbn		= {978-1-4503-6240-5}
}

@InProceedings{	  levis02,
  title		= {Mat{\'e}: A Tiny Virtual Machine for Sensor Networks},
  shorttitle	= {Mat{\'e}},
  booktitle	= {Proceedings of the 10th International Conference on
		  {{Architectural}} Support for Programming Languages and
		  Operating Systems},
  author	= {Levis, Philip and Culler, David},
  year		= {2002},
  month		= oct,
  series	= {{{ASPLOS X}}},
  pages		= {85--95},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/605397.605407},
  urldate	= {2023-10-03},
  abstract	= {Composed of tens of thousands of tiny devices with very
		  limited resources ("motes"), sensor networks are subject to
		  novel systems problems and constraints. The large number of
		  motes in a sensor network means that there will often be
		  some failing nodes; networks must be easy to repopulate.
		  Often there is no feasible method to recharge motes, so
		  energy is a precious resource. Once deployed, a network
		  must be reprogrammable although physically unreachable, and
		  this reprogramming can be a significant energy cost.We
		  present Mat{\'e}, a tiny communication-centric virtual
		  machine designed for sensor networks. Mat{\'e}'s high-level
		  interface allows complex programs to be very short (under
		  100 bytes), reducing the energy cost of transmitting new
		  programs. Code is broken up into small capsules of 24
		  instructions, which can self-replicate through the network.
		  Packet sending and reception capsules enable the deployment
		  of ad-hoc routing and data aggregation algorithms.
		  Mat{\'e}'s concise, high-level program representation
		  simplifies programming and allows large networks to be
		  frequently reprogrammed in an energy-efficient manner; in
		  addition, its safe execution environment suggests a use of
		  virtual machines to provide the user/kernel boundary on
		  motes that have no hardware protection mechanisms.},
  isbn		= {978-1-58113-574-9}
}

@Article{	  levy03,
  title		= {Modelling Environments in Call-by-Value Programming
		  Languages},
  author	= {Levy, PaulBlain and Power, John and Thielecke, Hayo},
  year		= {2003},
  month		= sep,
  journal	= {Information and Computation},
  volume	= {185},
  number	= {2},
  pages		= {182--210},
  issn		= {0890-5401},
  doi		= {10.1016/S0890-5401(03)00088-9},
  urldate	= {2023-12-07},
  abstract	= {In categorical semantics, there have traditionally been
		  two approaches to modelling environments, one by use of
		  finite products in cartesian closed categories, the other
		  by use of the base categories of indexed categories with
		  structure. Each requires modifications in order to account
		  for environments in call-by-value programming languages.
		  There have been two more general definitions along both of
		  these lines: the first generalising from cartesian to
		  symmetric premonoidal categories, the second generalising
		  from indexed categories with specified structure to
		  {$\kappa$}-categories. In this paper, we investigate
		  environments in call-by-value languages by analysing a
		  fine-grain variant of Moggi's computational
		  {$\lambda$}-calculus, giving two equivalent sound and
		  complete classes of models: one given by closed Freyd
		  categories, which are based on symmetric premonoidal
		  categories, the other given by closed {$\kappa$}-categories.}
}

@Misc{		  lewis03,
  title		= {Debugging {{Backwards}} in {{Time}}},
  author	= {Lewis, Bil},
  year		= {2003},
  month		= oct,
  number	= {arXiv:cs/0310016},
  eprint	= {cs/0310016},
  publisher	= {arXiv},
  doi		= {10.48550/arXiv.cs/0310016},
  urldate	= {2024-11-12},
  abstract	= {By recording every state change in the run of a program,
		  it is possible to present the programmer every bit of
		  information that might be desired. Essentially, it becomes
		  possible to debug the program by going ``backwards in
		  time,'' vastly simplifying the process of debugging. An
		  implementation of this idea, the ``Omniscient Debugger,''
		  is used to demonstrate its viability and has been used
		  successfully on a number of large programs. Integration
		  with an event analysis engine for searching and control is
		  presented. Several small-scale user studies provide
		  encouraging results. Finally performance issues and
		  implementation are discussed along with possible
		  optimizations. This paper makes three contributions of
		  interest: the concept and technique of ``going backwards in
		  time,'' the GUI which presents a global view of the program
		  state and has a formal notion of ``navigation through
		  time,'' and the integration with an event analyzer.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Software Engineering}
}

@InProceedings{	  li09,
  title		= {Research of ``{{Stub}}'' Remote Debugging Technique},
  booktitle	= {2009 4th {{International Conference}} on {{Computer
		  Science}} \& {{Education}}},
  author	= {Li, Hongwei and Xu, Yaping and Wu, Fangsheng and Yin,
		  Changhong},
  year		= {2009},
  month		= jul,
  pages		= {990--994},
  doi		= {10.1109/ICCSE.2009.5228140},
  urldate	= {2024-11-12},
  abstract	= {Any application software will inevitably contain bugs
		  during the development cycle. In order to correct these
		  software flaws, developers need access to powerful
		  debugging tools that allow them to be more efficient as
		  well as be able to dig into the detailed operation of their
		  application. Therefore, the debugger is a comparatively
		  important tool in software development, particularly in the
		  embedded software development. The paper analyses and
		  studies the embedded debugging technique of stub mode. It
		  adopts the remote serial communication protocol of GNU GDB,
		  and takes over all exception handlers by software to
		  implement debugging and tracking of object program. It
		  realizes to read and to write memory units and registers,
		  to set breakpoint, single step and to continue running.
		  Stub mode is applied to RTEMS embedded real-time operating
		  system and application program for debugging based on
		  ARM.},
  keywords	= {Application software,breakpoint,Computer bugs,Embedded
		  software,embedded system,Programming,Protocols,Read-write
		  memory,Real time systems,Registers,remote
		  debugging,Software debugging,Software tools,step,stub}
}

@InProceedings{	  li23,
  title		= {An {{Empirical Study}} on {{Concurrency Bugs}} in
		  {{Interrupt-Driven Embedded Software}}},
  booktitle	= {Proceedings of the 32nd {{ACM SIGSOFT International
		  Symposium}} on {{Software Testing}} and {{Analysis}}},
  author	= {Li, Chao and Chen, Rui and Wang, Boxiang and Wang, Zhixuan
		  and Yu, Tingting and Jiang, Yunsong and Gu, Bin and Yang,
		  Mengfei},
  year		= {2023},
  month		= jul,
  series	= {{{ISSTA}} 2023},
  pages		= {1345--1356},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3597926.3598140},
  urldate	= {2023-09-27},
  abstract	= {Interrupt-driven embedded software is widely used in
		  aerospace, automotive electronics, medical equipment, IoT,
		  and other industrial fields. This type of software is
		  usually programmed with interrupts to interact with
		  hardware and respond to external stimuli on time. However,
		  uncertain interleaving execution of interrupts may cause
		  concurrency bugs, resulting in task failure or serious
		  safety issues. A deep understanding of real-world
		  concurrency bugs in embedded software will significantly
		  improve the ability of techniques in combating concurrency
		  bugs, such as bug detection, testing and fixing. This paper
		  performs the first comprehensive and large-scale empirical
		  study on concurrency bugs in industrial interrupt-driven
		  embedded software. A total number of 132 real-world
		  concurrency bugs in 102 industrial embedded software have
		  been rigorously analyzed. Not only have the root causes,
		  impacts and fix strategies of bugs been studied, but also
		  the manifestation, including triggering scopes, racing
		  variables, access interleaving patterns, and variables
		  correlations. This study reveals several significant
		  findings, which can guide future research in developing
		  techniques and tools to combat concurrency bugs for
		  interrupt-driven embedded software.},
  isbn		= {9798400702211},
  keywords	= {concurrency bugs,embedded software,empirical
		  study,interrupt-driven programs}
}

@Article{	  li24,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}}},
  author	= {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
  year		= {2024},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {8},
  number	= {PLDI},
  pages		= {223--245},
  issn		= {2475-1421},
  doi		= {10.1145/3656386},
  urldate	= {2024-08-20},
  abstract	= {We introduce a novel approach for testing optimizing
		  compilers with code from real-world applications. The main
		  idea is to construct well-formed programs by fusing
		  multiple code snippets from various real-world projects.
		  The key insight is backed by the fact that the large volume
		  of real-world code exercises rich syntactical and semantic
		  language features, which current engineering-intensive
		  approaches like random program generators are hard to fully
		  support. To construct well-formed programs from real-world
		  code, our approach works by (1) extracting real-world code
		  at the granularity of function, (2) injecting function
		  calls into seed programs, and (3) leveraging dynamic
		  execution information to maintain the semantics and build
		  complex data dependencies between injected functions and
		  the seed program. With this idea, our approach complements
		  the existing generators by boosting their expressiveness
		  via fusing real-world code in a semantics-preserving way.
		  We implement our idea in a tool, Creal, to test C
		  compilers. In a nine-month testing period, we have reported
		  132 bugs to GCC and LLVM, two of the most popular and
		  well-tested C compilers. At the time of writing, 121 of
		  them have been confirmed as unknown bugs, and 101 of them
		  have been fixed. Most of these bugs were miscompilations,
		  and many were recognized as long-latent and critical. Our
		  evaluation results evidently demonstrate the significant
		  advantage of using real-world code to stress-test
		  compilers. We believe this idea will benefit the general
		  compiler testing direction and will be directly applicable
		  to other compilers.},
  langid	= {english}
}

@Article{	  li24a,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}}},
  author	= {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
  year		= {2024},
  month		= jun,
  journal	= {Artifact for PLDI'2024 paper "Boosting Compiler Testing by
		  Injecting Real-world Code"},
  volume	= {8},
  number	= {PLDI},
  pages		= {156:223--156:245},
  doi		= {10.1145/3656386},
  urldate	= {2024-08-20},
  abstract	= {We introduce a novel approach for testing optimizing
		  compilers with code from real-world applications. The main
		  idea is to construct well-formed programs by fusing
		  multiple code snippets from various real-world projects.
		  The key insight is backed by the fact that the large volume
		  of real-world code exercises rich syntactical and semantic
		  language features, which current engineering-intensive
		  approaches like random program generators are hard to fully
		  support. To construct well-formed programs from real-world
		  code, our approach works by (1) extracting real-world code
		  at the granularity of function, (2) injecting function
		  calls into seed programs, and (3) leveraging dynamic
		  execution information to maintain the semantics and build
		  complex data dependencies between injected functions and
		  the seed program. With this idea, our approach complements
		  the existing generators by boosting their expressiveness
		  via fusing real-world code in a semantics-preserving way.
		  We implement our idea in a tool, Creal, to test C
		  compilers. In a nine-month testing period, we have reported
		  132 bugs to GCC and LLVM, two of the most popular and
		  well-tested C compilers. At the time of writing, 121 of
		  them have been confirmed as unknown bugs, and 101 of them
		  have been fixed. Most of these bugs were miscompilations,
		  and many were recognized as long-latent and critical. Our
		  evaluation results evidently demonstrate the significant
		  advantage of using real-world code to stress-test
		  compilers. We believe this idea will benefit the general
		  compiler testing direction and will be directly applicable
		  to other compilers.}
}

@Article{	  li24b,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}}},
  author	= {Li, Shaohua and Theodoridis, Theodoros and Su, Zhendong},
  year		= {2024},
  month		= jun,
  journal	= {Artifact for PLDI'2024 paper "Boosting Compiler Testing by
		  Injecting Real-world Code"},
  volume	= {8},
  number	= {PLDI},
  pages		= {156:223--156:245},
  doi		= {10.1145/3656386},
  urldate	= {2024-08-20},
  abstract	= {We introduce a novel approach for testing optimizing
		  compilers with code from real-world applications. The main
		  idea is to construct well-formed programs by fusing
		  multiple code snippets from various real-world projects.
		  The key insight is backed by the fact that the large volume
		  of real-world code exercises rich syntactical and semantic
		  language features, which current engineering-intensive
		  approaches like random program generators are hard to fully
		  support. To construct well-formed programs from real-world
		  code, our approach works by (1) extracting real-world code
		  at the granularity of function, (2) injecting function
		  calls into seed programs, and (3) leveraging dynamic
		  execution information to maintain the semantics and build
		  complex data dependencies between injected functions and
		  the seed program. With this idea, our approach complements
		  the existing generators by boosting their expressiveness
		  via fusing real-world code in a semantics-preserving way.
		  We implement our idea in a tool, Creal, to test C
		  compilers. In a nine-month testing period, we have reported
		  132 bugs to GCC and LLVM, two of the most popular and
		  well-tested C compilers. At the time of writing, 121 of
		  them have been confirmed as unknown bugs, and 101 of them
		  have been fixed. Most of these bugs were miscompilations,
		  and many were recognized as long-latent and critical. Our
		  evaluation results evidently demonstrate the significant
		  advantage of using real-world code to stress-test
		  compilers. We believe this idea will benefit the general
		  compiler testing direction and will be directly applicable
		  to other compilers.}
}

@Article{	  lieberman97,
  title		= {{{ZStep}} 95: {{A}} Reversible, Animated Source Code
		  Stepper},
  author	= {Lieberman, Henry},
  year		= {1997},
  journal	= {Software Visualization: Programming as a Multimedia
		  Experience},
  publisher	= {MIT Press}
}

@Article{	  liell-cock24,
  title		= {Let a {{Thousand Flowers Bloom}}: {{An Algebraic
		  Representation}} for {{Edge Graphs}}},
  shorttitle	= {Let a {{Thousand Flowers Bloom}}},
  author	= {{Liell-Cock}, Jack and Schrijvers, Tom},
  year		= {2024},
  month		= feb,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {8},
  number	= {3},
  eprint	= {2403.02273},
  primaryclass	= {cs},
  pages		= {9},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2024/8/9},
  urldate	= {2024-03-11},
  abstract	= {Context: Edge graphs are graphs whose edges are labelled
		  with identifiers, and nodes can have multiple edges between
		  them. They are used to model a wide range of systems,
		  including networks with distances or degrees of connection
		  and complex relational data. Inquiry: Unfortunately, the
		  homogeneity of this graph structure prevents an effective
		  representation in (functional) programs. Either their
		  interface is riddled with partial functions, or the
		  representations are computationally inefficient to process.
		  Approach: We present a novel data type for edge graphs,
		  based on total and recursive definitions, that prevents
		  usage errors from partial APIs and promotes structurally
		  recursive computations. We follow an algebraic approach and
		  provide a set of primitive constructors and combinators,
		  along with equational laws that identify semantically
		  equivalent constructions. Knowledge: This algebra
		  translates directly into an implementation using algebraic
		  data types, and its homomorphisms give rise to functions
		  for manipulating and transforming these edge graphs.
		  Grounding: We exploit the fact that many common graph
		  algorithms are such homomorphisms to implement them in our
		  framework. Importance: In giving a theoretical grounding
		  for the edge graph data type, we can formalise properties
		  such as soundness and completeness of the representation
		  while also minimising usage errors and maximising
		  re-usability.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Programming Languages}
}

@InProceedings{	  lindley17,
  title		= {Do Be Do Be Do},
  booktitle	= {Proceedings of the 44th {{ACM SIGPLAN Symposium}} on
		  {{Principles}} of {{Programming Languages}}},
  author	= {Lindley, Sam and McBride, Conor and McLaughlin, Craig},
  year		= {2017},
  month		= jan,
  series	= {{{POPL}} '17},
  pages		= {500--514},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3009837.3009897},
  urldate	= {2023-12-07},
  abstract	= {We explore the design and implementation of Frank, a
		  strict functional programming language with a bidirectional
		  effect type system designed from the ground up around a
		  novel variant of Plotkin and Pretnar's effect handler
		  abstraction. Effect handlers provide an abstraction for
		  modular effectful programming: a handler acts as an
		  interpreter for a collection of commands whose interfaces
		  are statically tracked by the type system. However, Frank
		  eliminates the need for an additional effect handling
		  construct by generalising the basic mechanism of functional
		  abstraction itself. A function is simply the special case
		  of a Frank operator that interprets no commands. Moreover,
		  Frank's operators can be multihandlers which simultaneously
		  interpret commands from several sources at once, without
		  disturbing the direct style of functional programming with
		  values. Effect typing in Frank employs a novel form of
		  effect polymorphism which avoid mentioning effect variables
		  in source code. This is achieved by propagating an ambient
		  ability inwards, rather than accumulating unions of
		  potential effects outwards. We introduce Frank by example,
		  and then give a formal account of the Frank type system and
		  its semantics. We introduce Core Frank by elaborating Frank
		  operators into functions, case expressions, and unary
		  handlers, and then give a sound small-step operational
		  semantics for Core Frank. Programming with effects and
		  handlers is in its infancy. We contribute an exploration of
		  future possibilities, particularly in combination with
		  other forms of rich type system.},
  isbn		= {978-1-4503-4660-3},
  keywords	= {algebraic effects,bidirectional
		  typing,call-by-push-value,continuations,effect
		  handlers,effect polymorphism,pattern matching}
}

@Article{	  liu21,
  title		= {Boba: {{Authoring}} and {{Visualizing Multiverse
		  Analyses}}},
  shorttitle	= {Boba},
  author	= {Liu, Yang and Kale, Alex and Althoff, Tim and Heer,
		  Jeffrey},
  year		= {2021},
  month		= feb,
  journal	= {IEEE Transactions on Visualization and Computer Graphics},
  volume	= {27},
  number	= {2},
  pages		= {1753--1763},
  issn		= {1941-0506},
  doi		= {10.1109/TVCG.2020.3028985},
  urldate	= {2024-10-30},
  abstract	= {Multiverse analysis is an approach to data analysis in
		  which all ``reasonable'' analytic decisions are evaluated
		  in parallel and interpreted collectively, in order to
		  foster robustness and transparency. However, specifying a
		  multiverse is demanding because analysts must manage myriad
		  variants from a cross-product of analytic decisions, and
		  the results require nuanced interpretation. We contribute
		  Baba: an integrated domain-specific language (DSL) and
		  visual analysis system for authoring and reviewing
		  multiverse analyses. With the Boba DSL, analysts write the
		  shared portion of analysis code only once, alongside local
		  variations defining alternative decisions, from which the
		  compiler generates a multiplex of scripts representing all
		  possible analysis paths. The Boba Visualizer provides
		  linked views of model results and the multiverse decision
		  space to enable rapid, systematic assessment of
		  consequential decisions and robustness, including sampling
		  uncertainty and model fit. We demonstrate Boba's utility
		  through two data analysis case studies, and reflect on
		  challenges and design opportunities for multiverse analysis
		  software.},
  keywords	= {Analytic Decisions,Analytical models,Computational
		  modeling,Data models,DSL,Load modeling,Multiverse
		  Analysis,Reproducibility,Robustness,Statistical
		  Analysis,Tools}
}

@InProceedings{	  loregian08,
  title		= {An {{Experimental Analysis}} of {{Undo}} in {{Ubiquitous
		  Computing Environments}}},
  booktitle	= {Ubiquitous {{Intelligence}} and {{Computing}}},
  author	= {Loregian, Marco and Locatelli, Marco P.},
  editor	= {Sandnes, Frode Eika and Zhang, Yan and Rong, Chunming and
		  Yang, Laurence T. and Ma, Jianhua},
  year		= {2008},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {505--519},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-540-69293-5_40},
  abstract	= {All personal computer application are provided with an
		  undo functionality, which can implement any of the models
		  available in literature. Users are generally aware of what
		  the undo function is expected to do, depending on the
		  application in use. Ubiquitous computing systems are
		  beginning to be understood and deployed in real life
		  situations, but little attention has been paid to what
		  users expect themselves to be able to do and undo in such
		  systems. In this paper, we present the results of a survey
		  we made to evaluate the perception of undo mechanisms with
		  respect to a simple ubiquitous-computing environment. Our
		  study shows that users already have a complex vision of
		  undo encompassing advanced features such as context
		  awareness and compensation.},
  isbn		= {978-3-540-69293-5},
  langid	= {english},
  keywords	= {Business Process Management,Completion Time,Context
		  Awareness,Smart Home,Ubiquitous Computing}
}

@Article{	  loring17,
  title		= {Semantics of Asynchronous {{JavaScript}}},
  author	= {Loring, Matthew C. and Marron, Mark and Leijen, Daan},
  year		= {2017},
  month		= oct,
  journal	= {ACM SIGPLAN Notices},
  volume	= {52},
  number	= {11},
  pages		= {51--62},
  issn		= {0362-1340},
  doi		= {10.1145/3170472.3133846},
  urldate	= {2023-09-26},
  abstract	= {JavaScript code running in the Node.js runtime is a major
		  platform for developers building cloud, mobile, or IoT
		  applications. A fundamental concept in Node.js programming
		  is the use of asynchronous callbacks and event loops to
		  provide highly responsive applications. While conceptually
		  simple, this programming model contains numerous subtleties
		  and behaviors that are defined implicitly by the current
		  Node.js implementation. This paper presents the first
		  comprehensive formalization of the Node.js asynchronous
		  execution model and defines a high-level notion of
		  async-contexts to formalize fundamental relationships
		  between asynchronous executions in an application. These
		  formalizations provide a foundation for the construction of
		  static or dynamic program analysis tools, support the
		  exploration of alternative Node.js event loop
		  implementations, and provide a high-level conceptual
		  framework for reasoning about relationships between the
		  execution of asynchronous callbacks in a Node.js
		  application.},
  keywords	= {Asynchrony,JavaScript}
}

@InProceedings{	  lowther23,
  title		= {Morello {{MicroPython}}: {{A Python Interpreter}} for
		  {{CHERI}}},
  shorttitle	= {Morello {{MicroPython}}},
  booktitle	= {Proceedings of the 20th {{ACM SIGPLAN International
		  Conference}} on {{Managed Programming Languages}} and
		  {{Runtimes}}},
  author	= {Lowther, Duncan and Jacob, Dejice and Singer, Jeremy},
  year		= {2023},
  month		= oct,
  series	= {{{MPLR}} 2023},
  pages		= {62--69},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3617651.3622991},
  urldate	= {2024-01-18},
  abstract	= {Arm Morello is a prototype system that supports CHERI
		  hardware capabilities for improving runtime security. As
		  Morello becomes more widely available, there is a growing
		  effort to port open source code projects to this novel
		  platform. Although high-level applications generally need
		  minimal code refactoring for CHERI compatibility, low-level
		  systems code bases require significant modification to
		  comply with the stringent memory safety constraints that
		  are dynamically enforced by Morello. In this paper, we
		  describe our work on porting the MicroPython interpreter to
		  Morello with the CheriBSD OS. Our key contribution is to
		  present a set of generic lessons for adapting managed
		  runtime execution environments to CHERI, including (1) a
		  characterization of necessary source code changes, (2) an
		  evaluation of runtime performance of the interpreter on
		  Morello, and (3) a demonstration of pragmatic memory safety
		  bug detection. Although MicroPython is a lightweight
		  interpreter, mostly written in C, we believe that the
		  changes we have implemented and the lessons we have learned
		  are more widely applicable. To the best of our knowledge,
		  this is the first published description of meaningful
		  experience for scripting language runtime engineering with
		  CHERI and Morello.},
  isbn		= {9798400703805},
  keywords	= {capabilities,CHERI,software implementation}
}

@InProceedings{	  lowther23a,
  title		= {{{CHERI Performance Enhancement}} for a {{Bytecode
		  Interpreter}}},
  booktitle	= {Proceedings of the 15th {{ACM SIGPLAN International
		  Workshop}} on {{Virtual Machines}} and {{Intermediate
		  Languages}}},
  author	= {Lowther, Duncan and Jacob, Dejice and Singer, Jeremy},
  year		= {2023},
  month		= oct,
  series	= {{{VMIL}} 2023},
  pages		= {1--10},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3623507.3623552},
  urldate	= {2024-01-18},
  abstract	= {During our port of the MicroPython bytecode interpreter to
		  the CHERI-based Arm Morello platform, we encountered a
		  number of serious performance degradations. This paper
		  explores several of these performance issues in detail, in
		  each case we characterize the cause of the problem, the
		  fix, and the corresponding interpreter performance
		  improvement over a set of standard Python benchmarks. While
		  we recognize that Morello is a prototypical physical
		  instantiation of the CHERI concept, we show that it is
		  possible to eliminate certain kinds of software-induced
		  runtime overhead that occur due to the larger size of CHERI
		  capabilities (128 bits) relative to native pointers
		  (generally 64 bits). In our case, we reduce a geometric
		  mean benchmark slowdown from 5x (before optimization) to
		  1.7x (after optimization) relative to AArch64,
		  non-capability, execution. The worst-case slowdowns are
		  greatly improved, from 100x (before optimization) to 2x
		  (after optimization). The key insight is that implicit
		  pointer size presuppositions pervade systems code; whereas
		  previous CHERI porting projects highlighted compile-time
		  and execution-time errors exposed by pointer size
		  assumptions, we instead focus on the performance
		  implications of such assumptions.},
  isbn		= {9798400704017},
  keywords	= {Capabilities,Morello,Python,software implementation}
}

@InProceedings{	  lubbers21,
  title		= {Interpreting Task Oriented Programs on Tiny Computers},
  booktitle	= {Proceedings of the 31st {{Symposium}} on
		  {{Implementation}} and {{Application}} of {{Functional
		  Languages}}},
  author	= {Lubbers, Mart and Koopman, Pieter and Plasmeijer, Rinus},
  year		= {2021},
  month		= jul,
  series	= {{{IFL}} '19},
  pages		= {1--12},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3412932.3412936},
  urldate	= {2023-10-03},
  abstract	= {Small Microcontroller Units (MCUs) drive the omnipresent
		  Internet of Things (IoT). These devices are small, cheap,
		  and energy efficient. However, they are not very powerful
		  and lack an Operating System. Hence it is difficult to
		  apply high level abstractions and write software that stays
		  close to the design. Task Oriented Programming (TOP) is a
		  paradigm for creating multi-user collaborative systems. A
		  program consists of tasks---descriptions of what needs to
		  be done. The tasks represent the actual work and a task
		  value is observable during execution. Furthermore, tasks
		  can be combined and transformed using combinators. mTask is
		  an embedded Domain Specific Language (eDSL) to program MCUs
		  following the TOP paradigm. Previous work has described the
		  mTask language, a static C code generator, and how to
		  integrate mTask with TOP servers. This paper shows that for
		  dynamic IOT applications, tasks must be sent at runtime to
		  the devices for interpretation. It describes in detail how
		  to compile specialized IOT TOP tasks to bytecode and how to
		  interpret them on devices with very little memory. These
		  additions allow the creation of complete, dynamic IOT
		  applications arising from a single source using a mix of
		  iTasks and mTask tasks. Details such as serialization and
		  communication are captured in simple abstractions.},
  isbn		= {978-1-4503-7562-7},
  keywords	= {clean,distributed applications,functional
		  programming,internet of things,task oriented programming}
}

@Article{	  lunzer08,
  title		= {Subjunctive Interfaces: {{Extending}} Applications to
		  Support Parallel Setup, Viewing and Control of Alternative
		  Scenarios},
  shorttitle	= {Subjunctive Interfaces},
  author	= {Lunzer, Aran and Hornb{\ae}k, Kasper},
  year		= {2008},
  month		= jan,
  journal	= {ACM Trans. Comput.-Hum. Interact.},
  volume	= {14},
  number	= {4},
  pages		= {17:1--17:44},
  issn		= {1073-0516},
  doi		= {10.1145/1314683.1314685},
  urldate	= {2024-10-30},
  abstract	= {Many applications require exploration of alternative
		  scenarios; most support it poorly. Subjunctive interfaces
		  provide mechanisms for the parallel setup, viewing and
		  control of scenarios, aiming to support users' thinking
		  about and interaction with their choices. We illustrate how
		  applications for information access, real-time simulation,
		  and document design may be extended with these mechanisms.
		  To investigate the usability of this form of extension, we
		  compare a simple census browser against a version with a
		  subjunctive interface. In the first of three studies,
		  subjects reported higher satisfaction with the subjunctive
		  interface, and relied less on interim marks on paper. No
		  reduction in task completion time was found, however,
		  mainly because some subjects encountered problems in
		  setting up and controlling scenarios. At the end of a
		  second, five-session study, users of a redesigned interface
		  completed tasks 27\% more quickly than with the simple
		  interface. In the third study we examined how subjects
		  reasoned about multiple-scenario setups in pursuing
		  complex, open-ended data explorations. Our main observation
		  was that subjects treated scenarios as information holders,
		  using them creatively in various ways to facilitate task
		  completion.}
}

@InProceedings{	  luo14,
  title		= {An Empirical Analysis of Flaky Tests},
  booktitle	= {Proceedings of the 22nd {{ACM SIGSOFT International
		  Symposium}} on {{Foundations}} of {{Software
		  Engineering}}},
  author	= {Luo, Qingzhou and Hariri, Farah and Eloussi, Lamyaa and
		  Marinov, Darko},
  year		= {2014},
  month		= nov,
  series	= {{{FSE}} 2014},
  pages		= {643--653},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2635868.2635920},
  urldate	= {2024-11-10},
  abstract	= {Regression testing is a crucial part of software
		  development. It checks that software changes do not break
		  existing functionality. An important assumption of
		  regression testing is that test outcomes are deterministic:
		  an unmodified test is expected to either always pass or
		  always fail for the same code under test. Unfortunately, in
		  practice, some tests often called flaky tests---have
		  non-deterministic outcomes. Such tests undermine the
		  regression testing as they make it difficult to rely on
		  test results. We present the first extensive study of flaky
		  tests. We study in detail a total of 201 commits that
		  likely fix flaky tests in 51 open-source projects. We
		  classify the most common root causes of flaky tests,
		  identify approaches that could manifest flaky behavior, and
		  describe common strategies that developers use to fix flaky
		  tests. We believe that our insights and implications can
		  help guide future research on the important topic of
		  (avoiding) flaky tests.},
  isbn		= {978-1-4503-3056-5}
}

@Article{	  lutz86,
  title		= {Janus: A Time-Reversible Language},
  author	= {Lutz, Christopher and Derby, Howard},
  year		= {1986},
  journal	= {Letter to R. Landauer},
  volume	= {2}
}

@InCollection{	  ma15,
  title		= {Chapter 8 - {{Secure Development Life Cycle}}},
  booktitle	= {Smart {{Grid Security}}},
  author	= {Ma, Zhendong and Kupzog, Friederich and Murdock, Paul},
  editor	= {Skopik, Florian and Smith, Paul},
  year		= {2015},
  month		= jan,
  pages		= {219--245},
  publisher	= {Syngress},
  address	= {Boston},
  doi		= {10.1016/B978-0-12-802122-4.00008-0},
  urldate	= {2024-08-29},
  abstract	= {A sound security architecture and the implementing
		  technologies that have been discussed in previous chapters
		  address only part of the challenge. To ensure security in
		  Smart Grid, from development via roll-out to operation,
		  proven development processes and management are needed to
		  minimize or eliminate security vulnerabilities that are
		  introduced in the development lifecycle. As a system of
		  systems, the Smart Grid consists of software components
		  that have varied security and assurance levels, and diverse
		  origins and development processes. Building security into
		  Smart Grid from the component to the system level requires
		  appropriate methods and techniques to rigorously address
		  many heterogeneous security issues in all phases of the
		  software and system development lifecycle. This chapter
		  examines security considerations in all phases of the Smart
		  Grid system development lifecycle, identifying industrial
		  best practices and research activities, and describes a
		  system development lifecycle process with existing and
		  emerging methods and techniques for Smart Grid security.},
  isbn		= {978-0-12-802122-4},
  keywords	= {best practice,coding,Secure development lifecycle,Smart
		  Grid,software,standard}
}

@Article{	  macqueen20,
  title		= {The History of {{Standard ML}}},
  author	= {MacQueen, David and Harper, Robert and Reppy, John},
  year		= {2020},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {HOPL},
  pages		= {86:1--86:100},
  doi		= {10.1145/3386336},
  urldate	= {2023-09-26},
  abstract	= {The ML family of strict functional languages, which
		  includes F\#, OCaml, and Standard ML, evolved from the Meta
		  Language of the LCF theorem proving system developed by
		  Robin Milner and his research group at the University of
		  Edinburgh in the 1970s. This paper focuses on the history
		  of Standard ML, which plays a central role in this family
		  of languages, as it was the first to include the complete
		  set of features that we now associate with the name ``ML''
		  (i.e., polymorphic type inference, datatypes with pattern
		  matching, modules, exceptions, and mutable state). Standard
		  ML, and the ML family of languages, have had enormous
		  influence on the world of programming language design and
		  theory. ML is the foremost exemplar of a functional
		  programming language with strict evaluation (call-by-value)
		  and static typing. The use of parametric polymorphism in
		  its type system, together with the automatic inference of
		  such types, has influenced a wide variety of modern
		  languages (where polymorphism is often referred to as
		  generics). It has popularized the idea of datatypes with
		  associated case analysis by pattern matching. The module
		  system of Standard ML extends the notion of type-level
		  parameterization to large-scale programming with the notion
		  of parametric modules, or functors. Standard ML also set a
		  precedent by being a language whose design included a
		  formal definition with an associated metatheory of
		  mathematical proofs (such as soundness of the type system).
		  A formal definition was one of the explicit goals from the
		  beginning of the project. While some previous languages had
		  rigorous definitions, these definitions were not integral
		  to the design process, and the formal part was limited to
		  the language syntax and possibly dynamic semantics or
		  static semantics, but not both. The paper covers the early
		  history of ML, the subsequent efforts to define a standard
		  ML language, and the development of its major features and
		  its formal definition. We also review the impact that the
		  language had on programming-language research.},
  keywords	= {Language design,Operational semantics,Standard ML,Type
		  checking}
}

@InProceedings{	  maksimovic14,
  title		= {Raspberry {{Pi}} as {{Internet}} of {{Things}} Hardware:
		  {{Performances}} and {{Constraints}}},
  shorttitle	= {Raspberry {{Pi}} as {{Internet}} of {{Things}} Hardware},
  booktitle	= {Proceedings of the 1st {{International Conference}} on
		  {{Electrical}}, {{Electronic}} and {{Computing
		  Engineering}}},
  author	= {Maksimovic, Mirjana and Vujovic, Vladimir and
		  Davidovi{\'c}, Nikola and Milosevic, Vladimir and Perisic,
		  Branko},
  year		= {2014},
  month		= jun,
  abstract	= {The Internet of Things (IoT) ideology can be looked as a
		  highly dynamic and radically distributed networked system
		  composed of a very large number of identifiable smart
		  objects. These objects are able to communicate and to
		  interact among themselves, with end-users or other entities
		  in the network. Entering the era of Internet of Things, the
		  use of small, cheap and flexible computer hardware that
		  allow end-user programming become present. One of them,
		  considered in this paper, is the Raspberry Pi, fully
		  customizable and programmable small computer board.
		  Comparative analysis of its key elements and performances
		  with some of current existing IoT prototype platforms have
		  shown that despite few disadvantages, the Raspberry Pi
		  remains an inexpensive computer with its very successfully
		  usage in diverse range of research applications in IoT
		  vision.}
}

@Article{	  maloney10,
  title		= {The {{Scratch Programming Language}} and {{Environment}}},
  author	= {Maloney, John and Resnick, Mitchel and Rusk, Natalie and
		  Silverman, Brian and Eastmond, Evelyn},
  year		= {2010},
  month		= nov,
  journal	= {ACM Transactions on Computing Education},
  volume	= {10},
  number	= {4},
  pages		= {1--15},
  issn		= {1946-6226},
  doi		= {10.1145/1868358.1868363},
  langid	= {english},
  keywords	= {programming environment,programming
		  language,Scratch,visual programming language}
}

@Article{	  manhaeve21,
  title		= {Neural Probabilistic Logic Programming in
		  {{DeepProbLog}}},
  author	= {Manhaeve, Robin and Duman{\v c}i{\'c}, Sebastijan and
		  Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
  year		= {2021},
  month		= sep,
  journal	= {Artificial Intelligence},
  volume	= {298},
  pages		= {103504},
  issn		= {0004-3702},
  doi		= {10.1016/j.artint.2021.103504},
  urldate	= {2024-11-20},
  abstract	= {We introduce DeepProbLog, a neural probabilistic logic
		  programming language that incorporates deep learning by
		  means of neural predicates. We show how existing inference
		  and learning techniques of the underlying probabilistic
		  logic programming language ProbLog can be adapted for the
		  new language. We theoretically and experimentally
		  demonstrate that DeepProbLog supports (i) both symbolic and
		  subsymbolic representations and inference, (ii) program
		  induction, (iii) probabilistic (logic) programming, and
		  (iv) (deep) learning from examples. To the best of our
		  knowledge, this work is the first to propose a framework
		  where general-purpose neural networks and expressive
		  probabilistic-logical modeling and reasoning are integrated
		  in a way that exploits the full expressiveness and
		  strengths of both worlds and can be trained end-to-end
		  based on examples.},
  keywords	= {Learning and reasoning,Logic,Neural
		  networks,Neuro-symbolic integration,Probabilistic logic
		  programming,Probability}
}

@InProceedings{	  marques22,
  title		= {Concolic {{Execution}} for {{WebAssembly}}},
  booktitle	= {36th {{European Conference}} on {{Object-Oriented
		  Programming}} ({{ECOOP}} 2022)},
  author	= {Marques, Filipe and Fragoso Santos, Jos{\'e} and Santos,
		  Nuno and Ad{\~a}o, Pedro},
  editor	= {Ali, Karim and Vitek, Jan},
  year		= {2022},
  series	= {Leibniz {{International Proceedings}} in {{Informatics}}
		  ({{LIPIcs}})},
  volume	= {222},
  pages		= {11:1--11:29},
  publisher	= {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address	= {Dagstuhl, Germany},
  issn		= {1868-8969},
  doi		= {10.4230/LIPIcs.ECOOP.2022.11},
  urldate	= {2023-10-13},
  isbn		= {978-3-95977-225-9},
  keywords	= {Concolic Testing,Test-Generation,Testing C
		  Programs,WebAssembly}
}

@Article{	  marra18,
  title		= {Out-{{Of-Place}} Debugging: A Debugging Architecture to
		  Reduce Debugging Interference},
  shorttitle	= {Out-{{Of-Place}} Debugging},
  author	= {Marra, Matteo and Polito, Guillermo and Gonzalez Boix,
		  Elisa},
  year		= {2018},
  month		= nov,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {3},
  number	= {2},
  pages		= {3:1-3:29},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2019/3/3},
  urldate	= {2023-11-22},
  abstract	= {Context. Recent studies show that developers spend most of
		  their programming time testing, verifying and debugging
		  software. As applicati...},
  langid	= {english}
}

@Article{	  marra20,
  title		= {A Debugging Approach for Live {{Big Data}} Applications},
  author	= {Marra, Matteo and Polito, Guillermo and Gonzalez Boix,
		  Elisa},
  year		= {2020},
  month		= aug,
  journal	= {Science of Computer Programming},
  volume	= {194},
  pages		= {102460},
  issn		= {0167-6423},
  doi		= {10.1016/j.scico.2020.102460},
  urldate	= {2024-11-20},
  abstract	= {Many frameworks exist for programmers to develop and
		  deploy Big Data applications such as Hadoop Map/Reduce and
		  Apache Spark. However, very little debugging support is
		  currently provided in those frameworks. When an error
		  occurs, developers are lost in trying to understand what
		  has happened from the information provided in log files.
		  Recently, new solutions allow developers to record \&
		  replay the application execution, but replaying is not
		  always affordable when hours of computation need to be
		  re-executed. In this paper, we present an online approach
		  that allows developers to debug Big Data applications in
		  isolation by moving the debugging session to an external
		  process when a halting point is reached. We introduce
		  IDRAMR, our prototype implementation in Pharo. IDRAMR
		  centralizes the debugging of parallel applications by
		  introducing novel debugging concepts, such as composite
		  debugging events, and the ability to dynamically update
		  both the code of the debugged application and the same
		  configuration of the running framework. We validate our
		  approach by debugging both application and configuration
		  failures for two driving scenarios. The scenarios are
		  implemented and executed using Port, our Map/Reduce
		  framework for Pharo, also introduced in this paper.},
  keywords	= {Big Data,Live programming,Map/reduce,Online debugging}
}

@Article{	  matsuda20,
  title		= {Sparcl: A Language for Partially-Invertible Computation},
  shorttitle	= {Sparcl},
  author	= {Matsuda, Kazutaka and Wang, Meng},
  year		= {2020},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {ICFP},
  pages		= {118:1--118:31},
  doi		= {10.1145/3409000},
  urldate	= {2024-04-03},
  abstract	= {Invertibility is a fundamental concept in computer
		  science, with various manifestations in software
		  development (serializer/deserializer, parser/printer,
		  redo/undo, compressor/decompressor, and so on). Full
		  invertibility necessarily requires bijectivity, but the
		  direct approach of composing bijective functions to develop
		  invertible programs is too restrictive to be useful. In
		  this paper, we take a different approach by focusing on
		  partially-invertible functions---functions that become
		  invertible if some of their arguments are fixed. The
		  simplest example of such is addition, which becomes
		  invertible when fixing one of the operands. More involved
		  examples include entropy-based compression methods (e.g.,
		  Huffman coding), which carry the occurrence frequency of
		  input symbols (in certain formats such as Huffman tree),
		  and fixing this frequency information makes the compression
		  methods invertible. We develop a language Sparcl for
		  programming such functions in a natural way, where
		  partial-invertibility is the norm and bijectivity is a
		  special case, hence gaining significant expressiveness
		  without compromising correctness. The challenge in
		  designing such a language is to allow ordinary programming
		  (the ``partially'' part) to interact with the invertible
		  part freely, and yet guarantee invertibility by
		  construction. The language Sparcl is linear-typed, and has
		  a type constructor to distinguish data that are subject to
		  invertible computation and those that are not. We present
		  the syntax, type system, and semantics of the language, and
		  prove that Sparcl correctly guarantees invertibility for
		  its programs. We demonstrate the expressiveness of Sparcl
		  with examples including tree rebuilding from preorder and
		  inorder traversals and Huffman coding.},
  keywords	= {linear types,reversible computation}
}

@InProceedings{	  maulana15,
  title		= {Inverse Kinematic Implementation of Four-Wheels Mecanum
		  Drive Mobile Robot Using Stepper Motors},
  booktitle	= {2015 {{International Seminar}} on {{Intelligent
		  Technology}} and {{Its Applications}} ({{ISITIA}})},
  author	= {Maulana, Eka and Muslim, M. Aziz and Hendrayawan, Veri},
  year		= {2015},
  month		= may,
  pages		= {51--56},
  doi		= {10.1109/ISITIA.2015.7219952},
  urldate	= {2024-09-12},
  abstract	= {An implementation of inverse kinematic model is applied
		  for the mobile robot using four-wheels mecanum drive. The
		  implementation is designed for omni-directional movement
		  without changes the robot position on a facing direction.
		  Four stepper motors are used to drive the mecanum wheels
		  due to these types have a good precision. This speed
		  control feedback is not necessary. The radius of the mobile
		  robot dimension is defined by the same distance of a and b
		  length between wheel axis and body center of 170 mm. The
		  inverse kinematic is conducted to control the mobile robot
		  movement and to convert the robot velocity component of vx,
		  vy, and {$\omega$} toward angular velocity each wheels of
		  {$\omega$}1, {$\omega$}2, {$\omega$}3, {$\omega$}4 and
		  wheel turn direction. Kinematic calculation and control
		  mechanism are proceed by a master microcontroller and
		  multi-slave microcontrollers which connected using SPI
		  communication protocol. The theta angle {\texttheta} is
		  described by vx and vy vector velocity direction toward
		  center point of the mobile robot. The movement capabilities
		  are performed by linear direction according to the certain
		  angle of the robot movement {\texttheta} of 0{$^\circ$} to
		  each multiples of 45{$^\circ$} thus obtained wheel velocity
		  and angle movement average errors.},
  keywords	= {Conferences,Four-Wheel,Inverse Kinematics,Measurement
		  uncertainty,Mecanum Drive,Mobile communication,Mobile
		  Robot,Mobile robots,Navigation,Wheels}
}

@Article{	  mcdowell89,
  title		= {Debugging Concurrent Programs},
  author	= {McDowell, Charles E. and Helmbold, David P.},
  year		= {1989},
  month		= dec,
  journal	= {ACM Comput. Surv.},
  volume	= {21},
  number	= {4},
  pages		= {593--622},
  issn		= {0360-0300},
  doi		= {10.1145/76894.76897},
  urldate	= {2024-08-30},
  abstract	= {The main problems associated with debugging concurrent
		  programs are increased complexity, the "probe effect,"
		  nonrepeatability, and the lack of a synchronized global
		  clock. The probe effect refers to the fact that any attempt
		  to observe the behavior of a distributed system may change
		  the behavior of that system. For some parallel programs,
		  different executions with the same data will result in
		  different results even without any attempt to observe the
		  behavior. Even when the behavior can be observed, in many
		  systems the lack of a synchronized global clock makes the
		  results of the observation difficult to interpret. This
		  paper discusses these and other problems related to
		  debugging concurrent programs and presents a survey of
		  current techniques used in debugging concurrent programs.
		  Systems using three general techniques are described:
		  traditional or breakpoint style debuggers, event monitoring
		  systems, and static analysis systems. In addition,
		  techniques for limiting, organizing, and displaying a large
		  amount of data produced by the debugging systems are
		  discussed.}
}

@InProceedings{	  mensing19,
  title		= {From Definitional Interpreter to Symbolic Executor},
  booktitle	= {Proceedings of the 4th {{ACM SIGPLAN International
		  Workshop}} on {{Meta-Programming Techniques}} and
		  {{Reflection}}},
  author	= {Mensing, Adrian D. and {van Antwerpen}, Hendrik and Bach
		  Poulsen, Casper and Visser, Eelco},
  year		= {2019},
  month		= oct,
  series	= {{{META}} 2019},
  pages		= {11--20},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3358502.3361269},
  urldate	= {2023-11-22},
  abstract	= {Symbolic execution is a technique for automatic software
		  validation and verification. New symbolic executors
		  regularly appear for both existing and new languages and
		  such symbolic executors are generally manually
		  (re)implemented each time we want to support a new
		  language. We propose to automatically generate symbolic
		  executors from language definitions, and present a
		  technique for mechanically (but as yet, manually) deriving
		  a symbolic executor from a definitional interpreter. The
		  idea is that language designers define their language as a
		  monadic definitional interpreter, where the monad of the
		  interpreter defines the meaning of branch points.
		  Developing a symbolic executor for a language is a matter
		  of changing the monadic interpretation of branch points. In
		  this paper, we illustrate the technique on a language with
		  recursive functions and pattern matching, and use the
		  derived symbolic executor to automatically generate test
		  cases for definitional interpreters implemented in our
		  defined language.},
  isbn		= {978-1-4503-6985-5},
  keywords	= {Definitional Interpreter,Haskell,Monads,Symbolic
		  Execution}
}

@InCollection{	  mezzina20,
  title		= {Software and {{Reversible Systems}}: {{A~Survey}} of
		  {{Recent Activities}}},
  shorttitle	= {Software and {{Reversible Systems}}},
  booktitle	= {Reversible {{Computation}}: {{Extending Horizons}} of
		  {{Computing}}: {{Selected Results}} of the {{COST Action
		  IC1405}}},
  author	= {Mezzina, Claudio Antares and Schlatte, Rudolf and
		  Gl{\"u}ck, Robert and Haulund, Tue and Hoey, James and Holm
		  Cservenka, Martin and Lanese, Ivan and Mogensen, Torben
		  {\AE}. and Siljak, Harun and Schultz, Ulrik P. and
		  Ulidowski, Irek},
  editor	= {Ulidowski, Irek and Lanese, Ivan and Schultz, Ulrik Pagh
		  and Ferreira, Carla},
  year		= {2020},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {41--59},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-47361-7_2},
  urldate	= {2023-09-28},
  abstract	= {Software plays a central role in all aspects of reversible
		  computing. We survey the breadth of topics and recent
		  activities on reversible software and systems including
		  behavioural types, recovery, debugging, concurrency, and
		  object-oriented programming. These have the potential to
		  provide linguistic abstractions and tools that will lead to
		  safer and more reliable reversible computing
		  applications.},
  isbn		= {978-3-030-47361-7},
  langid	= {english}
}

@InCollection{	  mezzina20a,
  title		= {Software and {{Reversible Systems}}: {{A~Survey}} of
		  {{Recent Activities}}},
  shorttitle	= {Software and {{Reversible Systems}}},
  booktitle	= {Reversible {{Computation}}: {{Extending Horizons}} of
		  {{Computing}}: {{Selected Results}} of the {{COST Action
		  IC1405}}},
  author	= {Mezzina, Claudio Antares and Schlatte, Rudolf and
		  Gl{\"u}ck, Robert and Haulund, Tue and Hoey, James and Holm
		  Cservenka, Martin and Lanese, Ivan and Mogensen, Torben
		  {\AE}. and Siljak, Harun and Schultz, Ulrik P. and
		  Ulidowski, Irek},
  editor	= {Ulidowski, Irek and Lanese, Ivan and Schultz, Ulrik Pagh
		  and Ferreira, Carla},
  year		= {2020},
  pages		= {41--59},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-47361-7_2},
  urldate	= {2024-11-10},
  abstract	= {Software plays a central role in all aspects of reversible
		  computing. We survey the breadth of topics and recent
		  activities on reversible software and systems including
		  behavioural types, recovery, debugging, concurrency, and
		  object-oriented programming. These have the potential to
		  provide linguistic abstractions and tools that will lead to
		  safer and more reliable reversible computing
		  applications.},
  isbn		= {978-3-030-47361-7},
  langid	= {english}
}

@Article{	  michael23,
  title		= {{{MSWasm}}: {{Soundly Enforcing Memory-Safe Execution}} of
		  {{Unsafe Code}}},
  shorttitle	= {{{MSWasm}}},
  author	= {Michael, Alexandra E. and Gollamudi, Anitha and Bosamiya,
		  Jay and Johnson, Evan and Denlinger, Aidan and Disselkoen,
		  Craig and Watt, Conrad and Parno, Bryan and Patrignani,
		  Marco and Vassena, Marco and Stefan, Deian},
  year		= {2023},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {POPL},
  pages		= {15:425--15:454},
  doi		= {10.1145/3571208},
  urldate	= {2024-01-18},
  abstract	= {Most programs compiled to WebAssembly (Wasm) today are
		  written in unsafe languages like C and C++. Unfortunately,
		  memory-unsafe C code remains unsafe when compiled to
		  Wasm---and attackers can exploit buffer overflows and
		  use-after-frees in Wasm almost as easily as they can on
		  native platforms. Memory- Safe WebAssembly (MSWasm)
		  proposes to extend Wasm with language-level memory-safety
		  abstractions to precisely address this problem. In this
		  paper, we build on the original MSWasm position paper to
		  realize this vision. We give a precise and formal semantics
		  of MSWasm, and prove that well-typed MSWasm programs are,
		  by construction, robustly memory safe. To this end, we
		  develop a novel, language-independent memory-safety
		  property based on colored memory locations and pointers.
		  This property also lets us reason about the security
		  guarantees of a formal C-to-MSWasm compiler---and prove
		  that it always produces memory-safe programs (and preserves
		  the semantics of safe programs). We use these formal
		  results to then guide several implementations: Two
		  compilers of MSWasm to native code, and a C-to-MSWasm
		  compiler (that extends Clang). Our MSWasm compilers support
		  different enforcement mechanisms, allowing developers to
		  make security-performance trade-offs according to their
		  needs. Our evaluation shows that on the PolyBenchC suite,
		  the overhead of enforcing memory safety in software ranges
		  from 22\% (enforcing spatial safety alone) to 198\%
		  (enforcing full memory safety), and 51.7\% when using
		  hardware memory capabilities for spatial safety and pointer
		  integrity. More importantly, MSWasm's design makes it easy
		  to swap between enforcement mechanisms; as fast (especially
		  hardware-based) enforcement techniques become available,
		  MSWasm will be able to take advantage of these advances
		  almost for free.},
  keywords	= {Memory-safety,Secure Compilation,Semantics,WebAssembly}
}

@Article{	  milner78,
  title		= {A Theory of Type Polymorphism in Programming},
  author	= {Milner, Robin},
  year		= {1978},
  month		= dec,
  journal	= {Journal of Computer and System Sciences},
  volume	= {17},
  number	= {3},
  pages		= {348--375},
  issn		= {0022-0000},
  doi		= {10.1016/0022-0000(78)90014-4},
  urldate	= {2023-09-26},
  abstract	= {The aim of this work is largely a practical one. A widely
		  employed style of programming, particularly in
		  structure-processing languages which impose no discipline
		  of types, entails defining procedures which work well on
		  objects of a wide variety. We present a formal type
		  discipline for such polymorphic procedures in the context
		  of a simple programming language, and a compile time
		  type-checking algorithm W which enforces the discipline. A
		  Semantic Soundness Theorem (based on a formal semantics for
		  the language) states that well-type programs cannot ``go
		  wrong'' and a Syntactic Soundness Theorem states that if W
		  accepts a program then it is well typed. We also discuss
		  extending these results to richer languages; a
		  type-checking algorithm based on W is in fact already
		  implemented and working, for the metalanguage ML in the
		  Edinburgh LCF system.}
}

@Article{	  mishra20,
  title		= {The {{Use}} of {{MQTT}} in {{M2M}} and {{IoT Systems}}:
		  {{A Survey}}},
  shorttitle	= {The {{Use}} of {{MQTT}} in {{M2M}} and {{IoT Systems}}},
  author	= {Mishra, Biswajeeban and Kertesz, Attila},
  year		= {2020},
  journal	= {IEEE Access},
  volume	= {8},
  pages		= {201071--201086},
  issn		= {2169-3536},
  doi		= {10.1109/ACCESS.2020.3035849},
  urldate	= {2023-10-03},
  abstract	= {Nowadays billions of smart devices or things are present
		  in Internet of Things (IoT) environments, such as homes,
		  hospitals, factories, and vehicles, all around the world.
		  As a result, the number of interconnected devices is
		  continuously and rapidly growing. These devices communicate
		  with each other and with other services using various
		  communication protocols for the transportation of sensor or
		  event data. These protocols enable applications to collect,
		  store, process, describe, and analyze data to solve a
		  variety of problems. IoT also aims to provide secure,
		  bi-directional communication between interconnected
		  devices, such as sensors, actuators, microcontrollers or
		  smart appliances, and corresponding cloud services. In this
		  paper we analyze the growth of M2M protocol research (MQTT,
		  AMQP, and CoAP) over the past 20 years, and show how the
		  growth in MQTT research stands out from the rest. We also
		  gather relevant application areas of MQTT, as the most
		  widespread M2M/IoT protocol, by performing a detailed
		  literature search in major digital research archives. Our
		  quantitative evaluation presents some of the important
		  MQTT-related studies published in the past five years,
		  which we compare to discuss the main features, advantages,
		  and limitations of the MQTT protocol. We also propose a
		  taxonomy to compare the properties and features of various
		  MQTT implementations, i.e. brokers and libraries currently
		  available in the public domain to help researchers and
		  end-users to efficiently choose a broker or client library
		  based on their requirements. Finally, we discuss the
		  relevant findings of our comparison and highlight open
		  issues that need further research and attention.}
}

@InProceedings{	  moggi89,
  title		= {Computational Lambda-Calculus and Monads},
  booktitle	= {[1989] {{Proceedings}}. {{Fourth Annual Symposium}} on
		  {{Logic}} in {{Computer Science}}},
  author	= {Moggi, E.},
  year		= {1989},
  month		= jun,
  pages		= {14--23},
  doi		= {10.1109/LICS.1989.39155},
  urldate	= {2023-10-02},
  abstract	= {The lambda -calculus is considered a useful mathematical
		  tool in the study of programming languages. However, if one
		  uses beta eta -conversion to prove equivalence of programs,
		  then a gross simplification is introduced. The author gives
		  a calculus based on a categorical semantics for
		  computations, which provides a correct basis for proving
		  equivalence of programs, independent from any specific
		  computational model.{$<>$}}
}

@Article{	  moggi91,
  title		= {Notions of Computation and Monads},
  author	= {Moggi, Eugenio},
  year		= {1991},
  month		= jul,
  journal	= {Information and Computation},
  series	= {Selections from 1989 {{IEEE Symposium}} on {{Logic}} in
		  {{Computer Science}}},
  volume	= {93},
  number	= {1},
  pages		= {55--92},
  issn		= {0890-5401},
  doi		= {10.1016/0890-5401(91)90052-4},
  urldate	= {2023-10-02},
  abstract	= {The {$\lambda$}-calculus is considered a useful
		  mathematical tool in the study of programming languages,
		  since programs can be identified with {$\lambda$}-terms.
		  However, if one goes further and uses
		  {$\beta\eta$}-conversion to prove equivalence of programs,
		  then a gross simplification is introduced (programs are
		  identified with total functions from values to values) that
		  may jeopardise the applicability of theoretical results. In
		  this paper we introduce calculi, based on a categorical
		  semantics for computations, that provide a correct basis
		  for proving equivalence of programs for a wide range of
		  notions of computation.}
}

@Article{	  moore08,
  title		= {High-Level Small-Step Operational Semantics for
		  Transactions},
  author	= {Moore, Katherine F. and Grossman, Dan},
  year		= {2008},
  month		= jan,
  journal	= {SIGPLAN Not.},
  volume	= {43},
  number	= {1},
  pages		= {51--62},
  issn		= {0362-1340},
  doi		= {10.1145/1328897.1328448},
  urldate	= {2024-09-11},
  abstract	= {Software transactions have received significant attention
		  as a way to simplify shared-memory concurrent programming,
		  but insufficient focus has been given to the precise
		  meaning of software transactions or their interaction with
		  other language features. This work begins to rectify that
		  situation by presenting a family of formal languages that
		  model a wide variety of behaviors for software
		  transactions. These languages abstract away implementation
		  details of transactional memory, providing high-level
		  definitions suitable for programming languages. We use
		  small-step semantics in order to represent explicitly the
		  interleaved execution of threads that is necessary to
		  investigate pertinent issues.We demonstrate the value of
		  our core approach to modeling transactions by investigating
		  two issues in depth. First, we consider parallel nesting,
		  in which parallelism and transactions can nest arbitrarily.
		  Second, we present multiple models for weak isolation, in
		  which nontransactional code can violate the isolation of a
		  transaction. For both, type-and-effect systems let us
		  soundly and statically restrict what computation can occur
		  inside or outside a transaction. We prove some key
		  language-equivalence theorems to confirm that under
		  sufficient static restrictions, in particular that each
		  mutable memory location is used outside transactions or
		  inside transactions (but not both), no program can
		  determine whether the language implementation uses weak
		  isolation or strong isolation.}
}

@Article{	  moore65,
  title		= {Moore's Law},
  author	= {Moore, Gordon},
  year		= {1965},
  journal	= {Electronics Magazine},
  volume	= {38},
  number	= {8},
  pages		= {114}
}

@Article{	  morrisett99,
  title		= {From System {{F}} to Typed Assembly Language},
  author	= {Morrisett, Greg and Walker, David and Crary, Karl and
		  Glew, Neal},
  year		= {1999},
  month		= may,
  journal	= {ACM Transactions on Programming Languages and Systems},
  volume	= {21},
  number	= {3},
  pages		= {527--568},
  issn		= {0164-0925},
  doi		= {10.1145/319301.319345},
  urldate	= {2023-10-20},
  abstract	= {We motivate the design of typed assembly language (TAL)
		  and present a type-preserving ttranslation from Systemn F
		  to TAL. The typed assembly language we pressent is based on
		  a conventional RISC assembly language, but its static type
		  sytem provides support for enforcing high-level language
		  abstratctions, such as closures, tuples, and user-defined
		  abstract data types. The type system ensures that
		  well-typed programs cannot violatet these abstractionsl In
		  addition, the typing constructs admit many low-level
		  compiler optimiztaions. Our translation to TAL is specified
		  as a sequence of type-preserving transformations, including
		  CPS and closure conversion phases; type-correct source
		  programs are mapped to type-correct assembly language. A
		  key contribution is an approach to polymorphic closure
		  conversion that is considerably simpler than previous work.
		  The compiler and typed assembly lanugage provide a fully
		  automatic way to produce certified code, suitable for use
		  in systems where unstrusted and potentially malicious code
		  must be checked for safety before execution.},
  keywords	= {certified code,closure conversion,secure extensible
		  systems,type-directed compilation,typed assembly
		  language,typed intermediate languages}
}

@Article{	  muller23,
  title		= {Responsive {{Parallelism}} with {{Synchronization}}},
  author	= {Muller, Stefan K. and Singer, Kyle and Keeney, Devyn Terra
		  and Neth, Andrew and Agrawal, Kunal and Lee, I-Ting
		  Angelina and Acar, Umut A.},
  year		= {2023},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {PLDI},
  pages		= {135:712--135:735},
  doi		= {10.1145/3591249},
  urldate	= {2023-10-20},
  abstract	= {Many concurrent programs assign priorities to threads to
		  improve responsiveness. When used in conjunction with
		  synchronization mechanisms such as mutexes and condition
		  variables, however, priorities can lead to priority
		  inversions, in which high-priority threads are delayed by
		  low-priority ones. Priority inversions in the use of
		  mutexes are easily handled using dynamic techniques such as
		  priority inheritance, but priority inversions in the use of
		  condition variables are not well-studied and dynamic
		  techniques are not suitable. In this work, we use a
		  combination of static and dynamic techniques to prevent
		  priority inversion in code that uses mutexes and condition
		  variables. A type system ensures that condition variables
		  are used safely, even while dynamic techniques change
		  thread priorities at runtime to eliminate priority
		  inversions in the use of mutexes. We prove the soundness of
		  our system, using a model of priority inversions based on
		  cost models for parallel programs. To show that the type
		  system is practical to implement, we encode it within the
		  type systems of Rust and C++, and show that the
		  restrictions are not overly burdensome by writing sizeable
		  case studies using these encodings, including porting the
		  Memcached object server to use our C++ implementation.},
  keywords	= {condition variables,cost semantics,priority
		  inversions,type systems}
}

@Article{	  nandi18,
  title		= {Functional Programming for Compiling and Decompiling
		  Computer-Aided Design},
  author	= {Nandi, Chandrakana and Wilcox, James R. and Panchekha,
		  Pavel and Blau, Taylor and Grossman, Dan and Tatlock,
		  Zachary},
  year		= {2018},
  month		= jul,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {2},
  number	= {ICFP},
  pages		= {99:1--99:31},
  doi		= {10.1145/3236794},
  urldate	= {2023-12-01},
  abstract	= {Desktop-manufacturing techniques like 3D printing are
		  increasingly popular because they reduce the cost and
		  complexity of producing customized objects on demand.
		  Unfortunately, the vibrant communities of early adopters,
		  often referred to as "makers," are not well-served by
		  currently available software pipelines. Users today must
		  compose idiosyncratic sequences of tools which are
		  typically repurposed variants of proprietary software
		  originally designed for expert specialists. This paper
		  proposes fundamental programming-languages techniques to
		  bring improved rigor, reduced complexity, and new
		  functionality to the computer-aided design (CAD) software
		  pipeline for applications like 3D-printing.
		  Compositionality, denotational semantics, compiler
		  correctness, and program synthesis all play key roles in
		  our approach, starting from the perspective that solid
		  geometry is a programming language. Specifically, we define
		  a purely functional language for CAD called LambdaCAD and a
		  polygon surface-mesh intermediate representation. We then
		  define denotational semantics of both languages to 3D
		  solids and a compiler from CAD to mesh accompanied by a
		  proof of semantics preservation. We illustrate the utility
		  of this foundation by developing a novel synthesis
		  algorithm based on evaluation contexts to "reverse compile"
		  difficult-to-edit meshes downloaded from online maker
		  communities back to more-editable CAD programs. All our
		  prototypes have been implemented in OCaml to enable further
		  exploration of functional programming for desktop
		  manufacturing.},
  keywords	= {3D printing,denotational semantics,language design,program
		  synthesis}
}

@Article{	  new23,
  title		= {Gradual {{Typing}} for {{Effect Handlers}}},
  author	= {New, Max S. and Giovannini, Eric and Licata, Daniel R.},
  year		= {2023},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {OOPSLA2},
  pages		= {284:1758--284:1786},
  doi		= {10.1145/3622860},
  urldate	= {2024-01-09},
  abstract	= {We present a gradually typed language, GrEff, with effects
		  and handlers that supports migration from unchecked to
		  checked effect typing. This serves as a simple model of the
		  integration of an effect typing discipline with an existing
		  effectful typed language that does not track fine-grained
		  effect information. Our language supports a simple module
		  system to model the programming model of gradual migration
		  from unchecked to checked effect typing in the style of
		  Typed Racket. The surface language GrEff is given semantics
		  by elaboration to a core language Core GrEff. We equip Core
		  GrEff with an inequational theory for reasoning about the
		  semantic error ordering and desired program equivalences
		  for programming with effects and handlers. We derive an
		  operational semantics for the language from the equations
		  provable in the theory. We then show that the theory is
		  sound by constructing an operational logical relations
		  model to prove the graduality theorem. This extends prior
		  work on embedding-projection pair models of gradual typing
		  to handle effect typing and subtyping.},
  keywords	= {effect handlers,gradual typing,graduality,logical
		  relation,operational semantics}
}

@InProceedings{	  nielsen23,
  title		= {Formalising {{Decentralised Exchanges}} in {{Coq}}},
  booktitle	= {Proceedings of the 12th {{ACM SIGPLAN International
		  Conference}} on {{Certified Programs}} and {{Proofs}}},
  author	= {Nielsen, Eske Hoy and Annenkov, Danil and Spitters, Bas},
  year		= {2023},
  month		= jan,
  pages		= {290--302},
  publisher	= {ACM},
  address	= {Boston MA USA},
  doi		= {10.1145/3573105.3575685},
  urldate	= {2023-09-27},
  isbn		= {9798400700262},
  langid	= {english}
}

@InProceedings{	  niephaus20,
  title		= {Example-Based Live Programming for Everyone: Building
		  Language-Agnostic Tools for Live Programming with {{LSP}}
		  and {{GraalVM}}},
  shorttitle	= {Example-Based Live Programming for Everyone},
  booktitle	= {Proceedings of the 2020 {{ACM SIGPLAN International
		  Symposium}} on {{New Ideas}}, {{New Paradigms}}, and
		  {{Reflections}} on {{Programming}} and {{Software}}},
  author	= {Niephaus, Fabio and Rein, Patrick and Edding, Jakob and
		  Hering, Jonas and K{\"o}nig, Bastian and Opahle, Kolya and
		  Scordialo, Nico and Hirschfeld, Robert},
  year		= {2020},
  month		= nov,
  series	= {Onward! 2020},
  pages		= {1--17},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3426428.3426919},
  urldate	= {2024-10-30},
  abstract	= {Our community has explored various approaches to improve
		  the programming experience. Although many of them, such as
		  Example-Based Live Programming (ELP), have shown to be
		  effective, they are still not widespread in conventional
		  programming environments. A reason for that is the effort
		  required to provide sophisticated tools that rely on
		  run-time information. To target multiple language
		  ecosystems, it is often necessary to implement the same
		  concepts, but for different languages and runtimes. Two
		  emerging technologies present an opportunity to reduce this
		  effort significantly: the Language Server Protocol (LSP)
		  and language implementation frameworks such as GraalVM's
		  Truffle. In this paper, we show how an ELP system can be
		  built in a language-agnostic way by leveraging these two
		  technologies. Based on our approach, we implemented the
		  Babylonian Programming system, an ELP system that has
		  previously only been implemented for exploratory
		  ecosystems. Our system, on the other hand, brings ELP for
		  all languages supported by the GraalVM to Visual Studio
		  Code (VS Code). Moreover, we outline what a
		  language-agnostic infrastructure needs to provide and how
		  the LSP could be extended to support ELP also independently
		  from programming environments. Further, we demonstrate how
		  our approach enables the use of ELP in the context of
		  polyglot programming. We illustrate the consequences of our
		  approach by discussing its advantages and limitations and
		  by comparing the features of our system to other ELP
		  systems. Moreover, we give an outlook of how tools that
		  rely on run-time information could be built in the future.
		  This in turn might motivate future tool builders and
		  researchers to consider implementing more tools in a
		  language-agnostic way from the start to make them available
		  to a broader audience.},
  isbn		= {978-1-4503-8178-9}
}

@Article{	  ottenstein84,
  title		= {The Program Dependence Graph in a Software Development
		  Environment},
  author	= {Ottenstein, Karl J. and Ottenstein, Linda M.},
  year		= {1984},
  month		= apr,
  journal	= {ACM SIGPLAN Notices},
  volume	= {19},
  number	= {5},
  pages		= {177--184},
  issn		= {0362-1340},
  doi		= {10.1145/390011.808263},
  urldate	= {2024-01-22},
  abstract	= {The internal program representation chosen for a software
		  development environment plays a critical role in the nature
		  of that environment. A form should facilitate
		  implementation and contribute to the responsiveness of the
		  environment to the user. The program dependence graph (PDG)
		  may be a suitable internal form. It allows programs to be
		  sliced in linear time for debugging and for use by
		  language-directed editors. The slices obtained are more
		  accurate than those obtained with existing methods because
		  I/O is accounted for correctly and irrelevant statements on
		  multi-statement lines are not displayed. The PDG may be
		  interpreted in a data driven fashion or may have highly
		  optimized (including vectorized) code produced from it. It
		  is amenable to incremental data flow analysis, improving
		  response time to the user in an interactive environment and
		  facilitating debugging through data flow anomaly detection.
		  It may also offer a good basis for software complexity
		  metrics, adding to the completeness of an environment based
		  on it.}
}

@InProceedings{	  ottenstein84a,
  title		= {The Program Dependence Graph in a Software Development
		  Environment},
  booktitle	= {Proceedings of the First {{ACM SIGSOFT}}/{{SIGPLAN}}
		  Software Engineering Symposium on {{Practical}} Software
		  Development Environments},
  author	= {Ottenstein, Karl J. and Ottenstein, Linda M.},
  year		= {1984},
  month		= apr,
  series	= {{{SDE}} 1},
  pages		= {177--184},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/800020.808263},
  urldate	= {2024-03-18},
  abstract	= {The internal program representation chosen for a software
		  development environment plays a critical role in the nature
		  of that environment. A form should facilitate
		  implementation and contribute to the responsiveness of the
		  environment to the user. The program dependence graph (PDG)
		  may be a suitable internal form. It allows programs to be
		  sliced in linear time for debugging and for use by
		  language-directed editors. The slices obtained are more
		  accurate than those obtained with existing methods because
		  I/O is accounted for correctly and irrelevant statements on
		  multi-statement lines are not displayed. The PDG may be
		  interpreted in a data driven fashion or may have highly
		  optimized (including vectorized) code produced from it. It
		  is amenable to incremental data flow analysis, improving
		  response time to the user in an interactive environment and
		  facilitating debugging through data flow anomaly detection.
		  It may also offer a good basis for software complexity
		  metrics, adding to the completeness of an environment based
		  on it.},
  isbn		= {978-0-89791-131-3},
  keywords	= {Code optimization,Control flow,Data
		  flow,Debugging,Internal program
		  representation,Interpreter,Program slice,Software
		  complexity metrics}
}

@Article{	  parreaux20,
  title		= {The Simple Essence of Algebraic Subtyping: Principal Type
		  Inference with Subtyping Made Easy (Functional Pearl)},
  shorttitle	= {The Simple Essence of Algebraic Subtyping},
  author	= {Parreaux, Lionel},
  year		= {2020},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {4},
  number	= {ICFP},
  pages		= {124:1--124:28},
  doi		= {10.1145/3409006},
  urldate	= {2023-11-27},
  abstract	= {MLsub extends traditional Hindley-Milner type inference
		  with subtyping while preserving compact principal types, an
		  exciting new development. However, its specification in
		  terms of biunification is difficult to understand, relying
		  on the new concepts of bisubstitution and polar types, and
		  making use of advanced notions from abstract algebra. In
		  this paper, we show that these are in fact not essential to
		  understanding the mechanisms at play in MLsub. We propose
		  an alternative algorithm called Simple-sub, which can be
		  implemented efficiently in under 500 lines of code
		  (including parsing, simplification, and pretty-printing),
		  looks more familiar, and is easier to understand. We
		  present an experimental evaluation of Simple-sub against
		  MLsub on a million randomly-generated well-scoped
		  expressions, showing that the two systems agree. The
		  mutable automaton-based implementation of MLsub is quite
		  far from its algebraic specification, leaving a lot of
		  space for errors; in fact, our evaluation uncovered several
		  bugs in it. We sketch more straightforward soundness and
		  completeness arguments for Simple-sub, based on a syntactic
		  specification of the type system. This paper is meant to be
		  light in formalism, rich in insights, and easy to consume
		  for prospective designers of new type systems and
		  programming languages. In particular, no abstract algebra
		  is inflicted on readers.},
  keywords	= {principal types,subtyping,type inference}
}

@InProceedings{	  pasquier22,
  title		= {Practical Multiverse Debugging through User-Defined
		  Reductions: Application to {{UML}} Models},
  shorttitle	= {Practical Multiverse Debugging through User-Defined
		  Reductions},
  booktitle	= {Proceedings of the 25th {{International Conference}} on
		  {{Model Driven Engineering Languages}} and {{Systems}}},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Roux, Luka Le and
		  Lagadec, Lo{\"i}c},
  year		= {2022},
  month		= oct,
  series	= {{{MODELS}} '22},
  pages		= {87--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3550355.3552447},
  urldate	= {2023-09-25},
  abstract	= {Multiverse debugging is an extension of classical
		  debugging methods, particularly adapted to
		  non-deterministic systems. Recently, a language-independent
		  formalization was proposed. Moreover, multiverse debugging
		  is particularly beneficial for specification and design
		  languages, such as UML. However, this method suffers from
		  scalability issues during breakpoint lookup. This problem
		  arises due to the exhaustive exploration performed on the
		  potentially infinite state-space of the system. In this
		  paper, we tackle this problem by introducing Reduced
		  Multiverse Debugging, an extension proposing a way for the
		  user to define reduction policies used during breakpoint
		  lookup. We enrich the formalization of multiverse debugging
		  with a modular breakpoint lookup strategy, which allows the
		  integration of the reduction policy. We validate our
		  approach by implementing a practical UML Statechart
		  debugger in the AnimUML web framework. We show several ways
		  the reduction can be applied, using methods such as
		  predicate abstraction for breakpoint lookup on an infinite
		  state-space, removing irrelevant variables, or creating
		  classes of equivalent values. Moreover, we show the
		  possibility to integrate probabilistic reduction
		  strategies. Relying on hash collisions, these strategies
		  can be iteratively refined to increase precision.},
  isbn		= {978-1-4503-9466-6},
  keywords	= {abstraction,concurrency,model analysis,multiverse
		  debugging}
}

@InProceedings{	  pasquier22a,
  title		= {Practical Multiverse Debugging through User-Defined
		  Reductions: Application to {{UML}} Models},
  shorttitle	= {Practical Multiverse Debugging through User-Defined
		  Reductions},
  booktitle	= {Proceedings of the 25th {{International Conference}} on
		  {{Model Driven Engineering Languages}} and {{Systems}}},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Roux, Luka Le and
		  Lagadec, Lo{\"i}c},
  year		= {2022},
  month		= oct,
  series	= {{{MODELS}} '22},
  pages		= {87--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3550355.3552447},
  urldate	= {2024-05-13},
  abstract	= {Multiverse debugging is an extension of classical
		  debugging methods, particularly adapted to
		  non-deterministic systems. Recently, a language-independent
		  formalization was proposed. Moreover, multiverse debugging
		  is particularly beneficial for specification and design
		  languages, such as UML. However, this method suffers from
		  scalability issues during breakpoint lookup. This problem
		  arises due to the exhaustive exploration performed on the
		  potentially infinite state-space of the system. In this
		  paper, we tackle this problem by introducing Reduced
		  Multiverse Debugging, an extension proposing a way for the
		  user to define reduction policies used during breakpoint
		  lookup. We enrich the formalization of multiverse debugging
		  with a modular breakpoint lookup strategy, which allows the
		  integration of the reduction policy. We validate our
		  approach by implementing a practical UML Statechart
		  debugger in the AnimUML web framework. We show several ways
		  the reduction can be applied, using methods such as
		  predicate abstraction for breakpoint lookup on an infinite
		  state-space, removing irrelevant variables, or creating
		  classes of equivalent values. Moreover, we show the
		  possibility to integrate probabilistic reduction
		  strategies. Relying on hash collisions, these strategies
		  can be iteratively refined to increase precision.},
  isbn		= {978-1-4503-9466-6},
  keywords	= {abstraction,concurrency,model analysis,multiverse
		  debugging}
}

@InProceedings{	  pasquier23,
  title		= {Temporal {{Breakpoints}} for {{Multiverse Debugging}}},
  booktitle	= {Proceedings of the 16th {{ACM SIGPLAN International
		  Conference}} on {{Software Language Engineering}}},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Le Roux, Luka and
		  Lagadec, Lo{\"i}c},
  year		= {2023},
  month		= oct,
  series	= {{{SLE}} 2023},
  pages		= {125--137},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3623476.3623526},
  urldate	= {2023-10-24},
  abstract	= {Multiverse debugging extends classical and omniscient
		  debugging to allow the exhaustive exploration of
		  non-deterministic and concurrent systems during debug
		  sessions. The introduction of user-defined reductions
		  significantly improves the scalability of the approach.
		  However, the literature fails to recognize the importance
		  of using more expressive logics, besides local-state
		  predicates, to express breakpoints. In this article, we
		  address this problem by introducing temporal breakpoints
		  for multiverse debugging. Temporal breakpoints greatly
		  enhance the expressivity of conditional breakpoints,
		  allowing users to reason about the past and future of
		  computations in the multiverse. Moreover, we show that it
		  is relatively straightforward to extend a language-agnostic
		  multiverse debugger semantics with temporal breakpoints,
		  while preserving its generality. To show the elegance and
		  practicability of our approach, we have implemented a
		  multiverse debugger for the AnimUML modeling environment
		  that supports 3 different temporal breakpoint formalisms:
		  regular-expressions, statecharts, and statechart-based
		  B{\"u}chi automata.},
  isbn		= {9798400703966},
  keywords	= {breakpoint,concurrency,multiverse debugging,temporal
		  logic}
}

@InProceedings{	  pasquier23a,
  title		= {Debugging {{Paxos}} in the {{UML Multiverse}}},
  booktitle	= {2023 {{ACM}}/{{IEEE International Conference}} on {{Model
		  Driven Engineering Languages}} and {{Systems Companion}}
		  ({{MODELS-C}})},
  author	= {Pasquier, Matthias and Teodorov, Ciprian and Jouault,
		  Fr{\'e}d{\'e}ric and Brun, Matthias and Lagadec, Lo{\"i}c},
  year		= {2023},
  month		= oct,
  pages		= {811--820},
  doi		= {10.1109/MODELS-C59198.2023.00130},
  urldate	= {2024-08-29},
  abstract	= {In this paper, we present experience feedback on the use
		  of animation and debugging tools to build, improve, and
		  verify a UML model of the Paxos consensus algorithm. The
		  need for consensus appears in our IoT industrial context,
		  where we need to switch between several service providers
		  for message passing, depending on their availability and
		  quality of service. However, Paxos is notoriously difficult
		  to understand, and as we plan to expand on the original
		  idea to adapt it to our needs, we have to make sure that
		  the base model is correct as well as fully understood by
		  the developers. To this end, we developed an AnimUML model
		  of Paxos, making it interactive and thus easier to work
		  with. During its construction, we tried to understand how
		  to verify that our requirements are met. By replicating
		  existing scenarios step by step, we found that our model
		  was incomplete. To validate how further model modifications
		  changed this, we wanted to write breakpoints to reach these
		  specific situations, but we found that configuration-based
		  breakpoints were not sufficient in this regard. This led us
		  to leverage the possibilities offered by a temporal
		  multiverse debugger, allowing the creation of temporal
		  breakpoints breaking on scenarios described by different
		  languages of temporal logic. With these tools, we can not
		  only correct the model faster, but also prove that some
		  scenarios are possible or not, allowing for a first step in
		  the model formal verification while keeping it accessible
		  to non-experts of the domain.},
  keywords	= {Adaptation models,consensus,Consensus
		  algorithm,debugging,Debugging,Message passing,model
		  analysis,Quality of service,Switches,temporal logic,Unified
		  modeling language}
}

@InProceedings{	  pedroza11,
  title		= {A {{Formal Methodology Applied}} to {{Secure Over-the-Air
		  Automotive Applications}}},
  booktitle	= {2011 {{IEEE Vehicular Technology Conference}} ({{VTC
		  Fall}})},
  author	= {Pedroza, Gabriel and Idrees, Muhammad Sabir and Apvrille,
		  Ludovic and Roudier, Yves},
  year		= {2011},
  month		= sep,
  pages		= {1--5},
  issn		= {1090-3038},
  doi		= {10.1109/VETECF.2011.6093061},
  urldate	= {2023-10-25},
  abstract	= {The expected high complexity in future automotive
		  applications will require to frequently update electronic
		  devices supporting those applications. Even if in-car
		  devices are trusted, potential attacks on over the air
		  exchanges impose stringent requirements on both safety and
		  security. To address the formal verification of safety
		  properties, we have previously introduced the AVATAR UML
		  profile whose methodology covers requirement, analysis,
		  design, and formal verification stages [1]. We now propose
		  to extend AVATAR to support both safety and security during
		  all methodological stages, and in the same models. The
		  paper applies the extended AVATAR to an over the-air
		  protocol for trusted firmware updates of in-car control
		  units, with a special focus on design and formal
		  verification stages.}
}

@InProceedings{	  perera16,
  title		= {Causally {{Consistent Dynamic Slicing}}},
  booktitle	= {27th {{International Conference}} on {{Concurrency
		  Theory}} ({{CONCUR}} 2016)},
  author	= {Perera, Roly and Garg, Deepak and Cheney, James},
  editor	= {Desharnais, Jos{\'e}e and Jagadeesan, Radha},
  year		= {2016},
  series	= {Leibniz {{International Proceedings}} in {{Informatics}}
		  ({{LIPIcs}})},
  volume	= {59},
  pages		= {18:1--18:15},
  publisher	= {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address	= {Dagstuhl, Germany},
  issn		= {1868-8969},
  doi		= {10.4230/LIPIcs.CONCUR.2016.18},
  urldate	= {2023-10-24},
  isbn		= {978-3-95977-017-0},
  keywords	= {pi-calculus; dynamic slicing; causal equivalence; Galois
		  connection}
}

@Article{	  perera22,
  title		= {Linked Visualisations via {{Galois}} Dependencies},
  author	= {Perera, Roly and Nguyen, Minh and Petricek, Tomas and
		  Wang, Meng},
  year		= {2022},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {POPL},
  pages		= {7:1--7:29},
  doi		= {10.1145/3498668},
  urldate	= {2023-09-26},
  abstract	= {We present new language-based dynamic analysis techniques
		  for linking visualisations and other structured outputs to
		  data in a fine-grained way, allowing users to explore how
		  data attributes and visual or other output elements are
		  related by selecting (focusing on) substructures of
		  interest. Our approach builds on bidirectional program
		  slicing techiques based on Galois connections, which
		  provide desirable round-tripping properties. Unlike the
		  prior work, our approach allows selections to be negated,
		  equipping the bidirectional analysis with a De Morgan dual
		  which can be used to link different outputs generated from
		  the same input. This offers a principled language-based
		  foundation for a popular view coordination feature called
		  brushing and linking where selections in one chart
		  automatically select corresponding elements in another
		  related chart.},
  keywords	= {data provenance,Galois connections}
}

@Article{	  perez07,
  title		= {{{IPython}}: {{A System}} for {{Interactive Scientific
		  Computing}}},
  shorttitle	= {{{IPython}}},
  author	= {Perez, Fernando and Granger, Brian E.},
  year		= {2007},
  month		= may,
  journal	= {Computing in Science \& Engineering},
  volume	= {9},
  number	= {3},
  pages		= {21--29},
  issn		= {1558-366X},
  doi		= {10.1109/MCSE.2007.53},
  urldate	= {2024-11-12},
  abstract	= {Python offers basic facilities for interactive work and a
		  comprehensive library on top of which more sophisticated
		  systems can be built. The IPython project provides on
		  enhanced interactive environment that includes, among other
		  features, support for data visualization and facilities for
		  distributed and parallel computation},
  keywords	= {computer languages,Data analysis,Data
		  visualization,Hardware,Libraries,Parallel
		  processing,Production,Python,scientific
		  computing,Scientific computing,scientific
		  programming,Spine,Supercomputers,Testing}
}

@Book{		  perumalla13,
  title		= {Introduction to {{Reversible Computing}}},
  author	= {Perumalla, Kalyan S.},
  year		= {2013},
  month		= sep,
  edition	= {1st},
  publisher	= {Chapman \& Hall},
  urldate	= {2024-09-11},
  abstract	= {Few books comprehensively cover the software and
		  programming aspects of reversible computing. Filling this
		  gap, Introduction to Reversible Computing offers an
		  expanded view of the field that includes the traditional
		  energy-motivated hardware viewpoint as well as the emerging
		  application-motivated software approach. Collecting
		  scattered knowledge into one coherent account, the book
		  provides a compendium of both classical and recently
		  developed results on reversible computing. It explores
		  up-and},
  isbn		= {978-1-4398-7340-3},
  langid	= {english}
}

@InProceedings{	  philips14,
  title		= {Towards {{Tierless Web Development}} without {{Tierless
		  Languages}}},
  booktitle	= {Proceedings of the 2014 {{ACM International Symposium}} on
		  {{New Ideas}}, {{New Paradigms}}, and {{Reflections}} on
		  {{Programming}} \& {{Software}}},
  author	= {Philips, Laure and De Roover, Coen and Van Cutsem, Tom and
		  De Meuter, Wolfgang},
  year		= {2014},
  month		= oct,
  series	= {Onward! 2014},
  pages		= {69--81},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2661136.2661146},
  urldate	= {2023-11-07},
  abstract	= {Tierless programming languages enable developing the
		  typical server, client and database tiers of a web
		  application as a single mono-linguistic program. This
		  development style is in stark contrast to the current
		  practice which requires combining multiple technologies and
		  programming languages. A myriad of tierless programming
		  languages has already been proposed, often featuring a
		  JavaScript-like syntax. Instead of introducing yet another,
		  we advocate that it should be possible to develop tierless
		  web applications in existing general-purpose languages.
		  This not only reduces the complexity that developers are
		  exposed to, but also precludes the need for new development
		  tools. We concretize this novel approach to tierless
		  programming by discussing requirements on its future
		  instantiations. We explore the design space of the program
		  analysis for determining and the program transformation for
		  realizing the tier split respectively. The former
		  corresponds to new adaptations of an old familiar, program
		  slicing, for tier splitting. The latter includes several
		  strategies for handling cross-tier function calls and data
		  accesses. Using a prototype instantiation for JavaScript,
		  we demonstrate the feasibility of our approach on an
		  example web application. We conclude with a discussion of
		  open questions and challenges for future research.},
  isbn		= {978-1-4503-3210-1},
  keywords	= {javascript,program slicing,tier splitting,tierless
		  programming}
}

@Article{	  phipps-costin23,
  title		= {Continuing {{WebAssembly}} with {{Effect Handlers}}},
  author	= {{Phipps-Costin}, Luna and Rossberg, Andreas and Guha,
		  Arjun and Leijen, Daan and Hillerstr{\"o}m, Daniel and
		  Sivaramakrishnan, {\relax KC} and Pretnar, Matija and
		  Lindley, Sam},
  year		= {2023},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {OOPSLA2},
  pages		= {238:460--238:485},
  doi		= {10.1145/3622814},
  urldate	= {2023-12-06},
  abstract	= {WebAssembly (Wasm) is a low-level portable code format
		  offering near native performance. It is intended as a
		  compilation target for a wide variety of source languages.
		  However, Wasm provides no direct support for non-local
		  control flow features such as async/await,
		  generators/iterators, lightweight threads, first-class
		  continuations, etc. This means that compilers for source
		  languages with such features must ceremoniously transform
		  whole source programs in order to target Wasm. We present
		  WasmFX an extension to Wasm which provides a universal
		  target for non-local control features via effect handlers,
		  enabling compilers to translate such features directly into
		  Wasm. Our extension is minimal and only adds three main
		  instructions for creating, suspending, and resuming
		  continuations. Moreover, our primitive instructions are
		  type-safe providing typed continuations which are
		  well-aligned with the design principles of Wasm whose
		  stacks are typed. We present a formal specification of
		  WasmFX and show that the extension is sound. We have
		  implemented WasmFX as an extension to the Wasm reference
		  interpreter and also built a prototype WasmFX extension for
		  Wasmtime, a production-grade Wasm engine, piggybacking on
		  Wasmtime's existing fibers API. The preliminary performance
		  results for our prototype are encouraging, and we outline
		  future plans to realise a native implementation.},
  keywords	= {effect handlers,stack switching,WebAssembly}
}

@InProceedings{	  plasmeijer12,
  title		= {Task-Oriented Programming in a Pure Functional Language},
  booktitle	= {Proceedings of the 14th Symposium on {{Principles}} and
		  Practice of Declarative Programming},
  author	= {Plasmeijer, Rinus and Lijnse, Bas and Michels, Steffen and
		  Achten, Peter and Koopman, Pieter},
  year		= {2012},
  month		= sep,
  series	= {{{PPDP}} '12},
  pages		= {195--206},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2370776.2370801},
  urldate	= {2023-10-18},
  abstract	= {Task-Oriented Programming (TOP) is a novel programming
		  paradigm for the construction of distributed systems where
		  users work together on the internet. When multiple users
		  collaborate, they need to interact with each other
		  frequently. TOP supports the definition of tasks that react
		  to the progress made by others. With TOP, complex
		  multi-user interactions can be programmed in a declarative
		  style just by defining the tasks that have to be
		  accomplished, thus eliminating the need to worry about the
		  implementation detail that commonly frustrates the
		  development of applications for this domain. TOP builds on
		  four core concepts: tasks that represent computations or
		  work to do which have an observable value that may change
		  over time, data sharing enabling tasks to observe each
		  other while the work is in progress, generic type driven
		  generation of user interaction, and special combinators for
		  sequential and parallel task composition. The semantics of
		  these core concepts is defined in this paper. As an example
		  we present the iTask3 framework, which embeds TOP in the
		  functional programming language Clean.},
  isbn		= {978-1-4503-1522-7},
  keywords	= {clean,task-oriented programming}
}

@InProceedings{	  plotkin09,
  title		= {Handlers of {{Algebraic Effects}}},
  booktitle	= {Programming {{Languages}} and {{Systems}}},
  author	= {Plotkin, Gordon and Pretnar, Matija},
  editor	= {Castagna, Giuseppe},
  year		= {2009},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {80--94},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-00590-9_7},
  abstract	= {We present an algebraic treatment of exception handlers
		  and, more generally, introduce handlers for other
		  computational effects representable by an algebraic theory.
		  These include nondeterminism, interactive input/output,
		  concurrency, state, time, and their combinations; in all
		  cases the computation monad is the free-model monad of the
		  theory. Each such handler corresponds to a model of the
		  theory for the effects at hand. The handling construct,
		  which applies a handler to a computation, is based on the
		  one introduced by Benton and Kennedy, and is interpreted
		  using the homomorphism induced by the universal property of
		  the free model. This general construct can be used to
		  describe previously unrelated concepts from both theory and
		  practice.},
  isbn		= {978-3-642-00590-9},
  langid	= {english},
  keywords	= {Algebraic Theory,Base Signature,Base Type,Function
		  Symbol,Relation Symbol}
}

@Article{	  pothier07,
  title		= {Scalable Omniscient Debugging},
  author	= {Pothier, Guillaume and Tanter, {\'E}ric and Piquer,
		  Jos{\'e}},
  year		= {2007},
  month		= oct,
  journal	= {SIGPLAN Not.},
  volume	= {42},
  number	= {10},
  pages		= {535--552},
  issn		= {0362-1340},
  doi		= {10.1145/1297105.1297067},
  urldate	= {2024-11-12},
  abstract	= {Omniscient debuggers make it possible to navigate
		  backwards in time within a program execution trace,
		  drastically improving the task of debugging complex
		  applications. Still, they are mostly ignored in practice
		  due to the challenges raised by the potentially huge size
		  of the execution traces. This paper shows that omniscient
		  debugging can be realistically realized through the use of
		  different techniques addressing efficiency, scalability and
		  usability. We present TOD, a portable Trace-Oriented
		  Debugger for Java, which combines an efficient
		  instrumentation for event generation, a specialized
		  distributed database for scalable storage and efficient
		  querying, support for partial traces in order to reduce the
		  trace volume to relevant events, and innovative interface
		  components for interactive trace navigation and analysis in
		  the development environment. Provided a reasonable
		  infrastructure, the performance of TOD allows a responsive
		  debugging experience in the face of large programs.}
}

@Article{	  pothier09,
  title		= {Back to the {{Future}}: {{Omniscient Debugging}}},
  shorttitle	= {Back to the {{Future}}},
  author	= {Pothier, Guillaume and Tanter, {\'E}ric},
  year		= {2009},
  month		= nov,
  journal	= {IEEE Software},
  volume	= {26},
  number	= {6},
  pages		= {78--85},
  issn		= {1937-4194},
  doi		= {10.1109/MS.2009.169},
  urldate	= {2023-12-13},
  abstract	= {This article presents TOD (trace oriented debugger), a
		  prototype scalable omniscient debugger for Java, which aims
		  at making omniscient debugging practical, at last.
		  Omniscient debuggers, also known as back-in-time or
		  reversible debuggers, record the whole history, or
		  execution trace, of a debugged program and let the user
		  freely explore it. This approach combines the advantages of
		  both log-based (past activity is never lost) and breakpoint
		  based debugging (interactive navigation, step-by-step
		  execution, and complete stack inspection). Omniscient
		  debuggers simulate step-by-step execution both forward and
		  backward, avoiding having to rerun the whole program many
		  times to pinpoint the bug's root cause. More importantly,
		  they make it possible to navigate through the history of a
		  program by following causal links, so questions that would
		  otherwise require a significant effort can be answered
		  instantly for instance, "When was variable x assigned a
		  null value?" or "What was the state of object o when it was
		  passed as an argument to method foo?".}
}

@InProceedings{	  potsch17,
  title		= {Advanced Remote Debugging of {{LoRa-enabled IoT}} Sensor
		  Nodes},
  booktitle	= {Proceedings of the {{Seventh International Conference}} on
		  the {{Internet}} of {{Things}}},
  author	= {P{\"o}tsch, Albert and Haslhofer, Florian and Springer,
		  Andreas},
  year		= {2017},
  month		= oct,
  series	= {{{IoT}} '17},
  pages		= {1--2},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3131542.3140259},
  urldate	= {2024-11-10},
  abstract	= {This work demonstrates a complete setup of a distributed
		  LoRaWAN-based data-acquisition system where individual LoRa
		  end-devices can be supervised by a remote debugging
		  environment. We present the whole chain of data processing
		  from an embedded Indoor Air Quality (IAQ) monitoring sensor
		  in the field up to the data-storage and visualization for
		  human end-users connected over the cloud. In particular, we
		  focus on the development-process of the low-power sensor
		  node itself, which plays a key role in every IoT scenario.
		  The sensor node's hardware is realized with a low-cost
		  resource-constrained microcontroller unit (MCU) which
		  executes the sensor-application as well as the embedded
		  LoRaWAN stack. We demonstrate the possibility of remote
		  incircuit-debugging of the embedded wireless node's
		  firmware during operation in the field. Together with the
		  possibility to analyze the power consumption and the
		  radio-frequency spectrum of the wireless node as well as
		  undesired RF interferer the ability to remotely update and
		  debug the MCU's firmware allows to optimize the sensor node
		  for the specific usage scenario and the place of its final
		  operation.},
  isbn		= {978-1-4503-5318-2}
}

@Article{	  pretnar15,
  title		= {An {{Introduction}} to {{Algebraic Effects}} and
		  {{Handlers}}. {{Invited}} Tutorial Paper},
  author	= {Pretnar, Matija},
  year		= {2015},
  month		= dec,
  journal	= {Electronic Notes in Theoretical Computer Science},
  series	= {The 31st {{Conference}} on the {{Mathematical
		  Foundations}} of {{Programming Semantics}} ({{MFPS
		  XXXI}}).},
  volume	= {319},
  pages		= {19--35},
  issn		= {1571-0661},
  doi		= {10.1016/j.entcs.2015.12.003},
  urldate	= {2023-09-29},
  abstract	= {This paper is a tutorial on algebraic effects and
		  handlers. In it, we explain what algebraic effects are,
		  give ample examples to explain how handlers work, define an
		  operational semantics and a type \& effect system, show how
		  one can reason about effects, and give pointers for further
		  reading.},
  keywords	= {algebraic effects,effect
		  system,handlers,logic,semantics,tutorial}
}

@Article{	  prokopec19,
  title		= {On {{Evaluating}} the {{Renaissance Benchmarking Suite}}:
		  {{Variety}}, {{Performance}}, and {{Complexity}}},
  shorttitle	= {On {{Evaluating}} the {{Renaissance Benchmarking Suite}}},
  author	= {Prokopec, Aleksandar and Ros{\`a}, Andrea and
		  Leopoldseder, David and Duboscq, Gilles and T{\r u}ma, P.
		  and Studener, Martin and Bulej, L. and Zheng, Y. and
		  Villaz{\'o}n, A. and Simon, Doug and W{\"u}rthinger, Thomas
		  and Binder, Walter},
  year		= {2019},
  month		= mar,
  journal	= {ArXiv},
  urldate	= {2024-09-10},
  abstract	= {The recently proposed Renaissance suite is composed of
		  modern, real-world, concurrent, and object-oriented
		  workloads that exercise various concurrency primitives of
		  the JVM. Renaissance was used to compare performance of two
		  stateof-the-art, production-quality JIT compilers (HotSpot
		  C2 and Graal), and to show that the performance differences
		  are more significant than on existing suites such as DaCapo
		  and SPECjvm2008. In this technical report, we give an
		  overview of the experimental setup that we used to assess
		  the variety and complexity of the Renaissance suite, as
		  well as its amenability to new compiler optimizations. We
		  then present the obtained measurements in detail.}
}

@InProceedings{	  psarris92,
  title		= {On Exact Data Dependence Analysis},
  booktitle	= {Proceedings of the 6th International Conference on
		  {{Supercomputing}}},
  author	= {Psarris, Kleanthis},
  year		= {1992},
  month		= aug,
  series	= {{{ICS}} '92},
  pages		= {303--312},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/143369.143424},
  urldate	= {2024-01-22},
  abstract	= {The GCD test and the Banerjee-Wolfe test are the two tests
		  traditionally used to determine statement data dependence,
		  subject to direction vectors, in automatic vectorization /
		  parallelization of loops. In an earlier study [14] a
		  sufficient condition for the accuracy of the Banerjee-Wolfe
		  test was stated and proved. In the original presentation
		  only the case of general data dependence was considered,
		  i.e., the case of data dependence without direction vector
		  information. In this paper we extend the previous work to
		  the case of data dependence subject to an arbitrary
		  direction vector. We also state and prove a sufficient
		  condition for the accuracy of a combination of the GCD and
		  the Banerjee-Wolfe test. Finally, we demonstrate how these
		  results can be used in actual practice to obtain exact data
		  dependence information.},
  isbn		= {978-0-89791-485-7}
}

@InProceedings{	  racordon20,
  title		= {Solving {{Schedulability}} as a {{Search Space Problem}}
		  with {{Decision Diagrams}}},
  booktitle	= {Search-{{Based Software Engineering}}},
  author	= {Racordon, Dimitri and Coet, Aur{\'e}lien and Stachtiari,
		  Emmanouela and Buchs, Didier},
  editor	= {Aleti, Aldeida and Panichella, Annibale},
  year		= {2020},
  pages		= {73--87},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-59762-7_6},
  abstract	= {Real-time system design involves proving the
		  schedulability of a set of tasks with hard timing and other
		  constraints that should run on one or several cores. When
		  those requirements are known at design time, it is possible
		  to compute a fixed scheduling of tasks before deployment.
		  This approach avoids the overhead induced by an online
		  scheduler and allows the designer to verify the
		  schedulability of the taskset design under normal and
		  degraded conditions, such as core failures. In this
		  context, we propose to solve the schedulability problem as
		  a state space exploration problem. We represent the
		  schedulings as partial functions that map each task to a
		  core and a point in time. Partial functions can be
		  efficiently encoded using a new variant of decision
		  diagrams, called Map-Family Decision Diagrams (MFDDs). Our
		  setting allows first to create the MFDD of all possible
		  schedulings and then apply homomorphic operations directly
		  on it, in order to obtain the schedulings that respect the
		  constraints of the taskset.},
  isbn		= {978-3-030-59762-7},
  langid	= {english},
  keywords	= {Decision diagrams,Multi-core architectures,Real-time
		  systems,Resilient systems,Schedulability,Search problems}
}

@Article{	  rao23,
  title		= {Iris-{{Wasm}}: {{Robust}} and {{Modular Verification}} of
		  {{WebAssembly Programs}}},
  shorttitle	= {Iris-{{Wasm}}},
  author	= {Rao, Xiaojia and Georges, A{\"i}na Linn and Legoupil,
		  Maxime and Watt, Conrad and {Pichon-Pharabod}, Jean and
		  Gardner, Philippa and Birkedal, Lars},
  year		= {2023},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {PLDI},
  pages		= {151:1096--151:1120},
  doi		= {10.1145/3591265},
  urldate	= {2023-12-06},
  abstract	= {WebAssembly makes it possible to run C/C++ applications on
		  the web with near-native performance. A WebAssembly program
		  is expressed as a collection of higher-order ML-like
		  modules, which are composed together through a system of
		  explicit imports and exports using a host language,
		  enabling a form of higher- order modular programming. We
		  present Iris-Wasm, a mechanized higher-order separation
		  logic building on a specification of Wasm 1.0 mechanized in
		  Coq and the Iris framework. Using Iris-Wasm, we are able to
		  specify and verify individual modules separately, and then
		  compose them modularly in a simple host language featuring
		  the core operations of the WebAssembly JavaScript
		  Interface. Building on Iris-Wasm, we develop a logical
		  relation that enforces robust safety: unknown, adversarial
		  code can only affect other modules through the functions
		  that they explicitly export. Together, the program logic
		  and the logical relation allow us to formally verify
		  functional correctness of WebAssembly programs, even when
		  they invoke and are invoked by unknown code, thereby
		  demonstrating that WebAssembly enforces strong isolation
		  between modules.},
  keywords	= {formal verification,higher-order logic,separation
		  logic,WebAssembly}
}

@Article{	  rauch19,
  title		= {Babylonian-Style {{Programming}}},
  author	= {Rauch, David and Rein, Patrick and Ramson, Stefan and
		  Lincke, Jens and Hirschfeld, Robert},
  year		= {2019},
  month		= feb,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {3},
  number	= {3},
  pages		= {9:1-9:39},
  publisher	= {AOSA, Inc.},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2019/3/9},
  urldate	= {2024-03-11},
  abstract	= {When working on a program, developers traditionally have
		  to simulate the behavior of the abstract code in their
		  heads until they can execute the application. Live
		  programming aims to support the development and
		  comprehension of programs by providing more immediate
		  feedback on program behavior, bu...},
  langid	= {english}
}

@Article{	  reingold81,
  title		= {Tidier {{Drawings}} of {{Trees}}},
  author	= {Reingold, E.M. and Tilford, J.S.},
  year		= {1981},
  month		= mar,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {SE-7},
  number	= {2},
  pages		= {223--228},
  issn		= {1939-3520},
  doi		= {10.1109/TSE.1981.234519},
  urldate	= {2024-09-10},
  abstract	= {Various algorithms have been proposed for producing tidy
		  drawings of trees--drawings that are aesthetically pleasing
		  and use minimum drawing space. We show that these
		  algorithms contain some difficulties that lead to
		  aesthetically unpleasing, wider than necessary drawings. We
		  then present a new algorithm with comparable time and
		  storage requirements that produces tidier drawings.
		  Generalizations to forests and m-ary trees are discussed,
		  as are some problems in discretization when alphanumeric
		  output devices are used.},
  keywords	= {Binary trees,Computer science,Data structures,Engineering
		  drawings,Printing,Software algorithms,Tree data
		  structures,tree structures,trees}
}

@InProceedings{	  rodrigues22,
  title		= {Aspect-{{Oriented Webassembly Transformation}}},
  booktitle	= {2022 17th {{Iberian Conference}} on {{Information
		  Systems}} and {{Technologies}} ({{CISTI}})},
  author	= {Rodrigues, Jo{\~a}o and Barreiros, Jorge},
  year		= {2022},
  month		= jun,
  pages		= {1--6},
  issn		= {2166-0727},
  doi		= {10.23919/CISTI54924.2022.9820136},
  urldate	= {2023-11-08},
  abstract	= {There are scenarios where it can be useful or necessary to
		  directly transform and instrument compiled code, rather
		  than resorting to source code changes with subsequent
		  compilation. These transformations can be motivated by
		  several reasons, such as: immediate repair of problems
		  encountered in production, neutralization of potentially
		  malicious code, performance improvements, instrumentation
		  for profiling and inspection purposes, fault injection, or
		  unavailability of source code. While tools are available
		  for conducting this kind of transformations for many
		  different software ecosystems and languages, there is a
		  limited set of options for doing so for WebAssembly
		  applications. In this paper, we present a novel tool and
		  language, the WasmManipulator/WmrLang, for manipulating
		  WebAssembly code, which allows you to perform code
		  transformations, using an aspect-oriented approach for
		  specifying code locations, and code insertion, replacement,
		  or deletion to be executed at those locations. In addition,
		  because WebAssembly routines can be heavily interdependent
		  on the JavaScript code that uses them, the tool has certain
		  features that allow you to take advantage of and exploit
		  this dependency. This includes defining additional types in
		  WASM code, and interpreting/executing expressions at
		  runtime.}
}

@Article{	  rojas22,
  title		= {Out-of-{{Things Debugging}}: {{A Live Debugging Approach}}
		  for {{Internet}} of {{Things}}},
  shorttitle	= {Out-of-{{Things Debugging}}},
  author	= {Rojas Castillo, Carlos and Marra, Matteo and Bauwens, Jim
		  and Gonzalez Boix, Elisa},
  year		= {2022},
  month		= oct,
  journal	= {The Art, Science, and Engineering of Programming},
  volume	= {7},
  number	= {2},
  pages		= {5:1-5:33},
  issn		= {2473-7321},
  doi		= {10.22152/programming-journal.org/2023/7/5},
  urldate	= {2024-01-09},
  abstract	= {Context Internet of Things (IoT) has become an important
		  kind of distributed systems thanks to the wide-spread of
		  cheap embedded devices ...},
  langid	= {english}
}

@InProceedings{	  rondon08,
  title		= {Liquid Types},
  booktitle	= {Proceedings of the 29th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Rondon, Patrick M. and Kawaguci, Ming and Jhala, Ranjit},
  year		= {2008},
  month		= jun,
  series	= {{{PLDI}} '08},
  pages		= {159--169},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1375581.1375602},
  urldate	= {2023-09-26},
  abstract	= {We present Logically Qualified Data Types, abbreviated to
		  Liquid Types, a system that combines Hindley-Milner type
		  inference with Predicate Abstraction to automatically infer
		  dependent types precise enough to prove a variety of safety
		  properties. Liquid types allow programmers to reap many of
		  the benefits of dependent types, namely static verification
		  of critical properties and the elimination of expensive
		  run-time checks, without the heavy price of manual
		  annotation. We have implemented liquid type inference in
		  DSOLVE, which takes as input an OCAML program and a set of
		  logical qualifiers and infers dependent types for the
		  expressions in the OCAML program. To demonstrate the
		  utility of our approach, we describe experiments using
		  DSOLVE to statically verify the safety of array accesses on
		  a set of OCAML benchmarks that were previously annotated
		  with dependent types as part of the DML project. We show
		  that when used in conjunction with a fixed set of array
		  bounds checking qualifiers, DSOLVE reduces the amount of
		  manual annotation required for proving safety from 31\% of
		  program text to under 1\%.},
  isbn		= {978-1-59593-860-2},
  keywords	= {dependent types,hindley-milner,predicate abstraction,type
		  inference}
}

@Article{	  ronsse99,
  title		= {{{RecPlay}}: A Fully Integrated Practical Record/Replay
		  System},
  shorttitle	= {{{RecPlay}}},
  author	= {Ronsse, Michiel and De Bosschere, Koen},
  year		= {1999},
  month		= may,
  journal	= {ACM Transactions on Computer Systems},
  volume	= {17},
  number	= {2},
  pages		= {133--152},
  issn		= {0734-2071},
  doi		= {10.1145/312203.312214},
  urldate	= {2023-12-14},
  abstract	= {This article presents a practical solution for the cyclic
		  debugging of nondeterministic parallel programs. The
		  solution consists of a combination of record/replay with
		  automatic on-the-fly data race detection. This combination
		  enables us to limit the record phase to the more efficient
		  recording of the synchronization operations, while
		  deferring the time-consuming data race detection to the
		  replay phase. As the record phase is highly efficient,
		  there is no need to switch it off, hereby eliminating the
		  possibility of Heisenbugs because tracing can be left on
		  all the time. This article describes an implementation of
		  the tools needed to support RecPlay.},
  keywords	= {binary code modification,multithreaded programming,race
		  detection}
}

@Article{	  root24,
  title		= {Compilation of {{Shape Operators}} on {{Sparse Arrays}}},
  author	= {Root, Alexander J and Yan, Bobby and Liu, Peiming and
		  Gyurgyik, Christophe and Bik, Aart J.C. and Kjolstad,
		  Fredrik},
  year		= {2024},
  month		= oct,
  journal	= {Artifact for OOPSLA 2024 Paper: Compilation of Shape
		  Operators on Sparse Arrays},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {312:1162--312:1188},
  doi		= {10.1145/3689752},
  urldate	= {2024-12-16},
  abstract	= {We show how to build a compiler for a sparse array
		  language that supports shape operators such as reshaping or
		  concatenating arrays, in addition to compute operators.
		  Existing sparse array programming systems implement generic
		  shape operators for only some sparse data structures,
		  reduce shape operators on other data structures to those,
		  and do not support fusion. Our system compiles sparse array
		  expressions to code that efficiently iterates over reshaped
		  views of irregular sparse data structures, without needing
		  to materialize temporary storage for intermediates. Our
		  evaluation shows that our approach generates sparse array
		  code competitive with popular sparse array libraries: our
		  generated shape operators achieve geometric mean speed-ups
		  of 1.66{\texttimes}--15.3{\texttimes} when compared to
		  hand-written kernels in scipy.sparse and
		  1.67{\texttimes}--651{\texttimes} when compared to generic
		  implementations in pydata/sparse. For operators that
		  require data structure conversions in these libraries, our
		  generated code achieves geometric mean speed-ups of
		  7.29{\texttimes}--13.0{\texttimes} when compared to
		  scipy.sparse and 21.3{\texttimes}--511{\texttimes} when
		  compared to pydata/sparse. Finally, our evaluation
		  demonstrates that fusing shape and compute operators
		  improves the performance of several expressions by
		  geometric mean speed-ups of 1.22{\texttimes}--2.23{\texttimes}.}
}

@Book{		  rosenberg96,
  title		= {How Debuggers Work: Algorithms, Data Structures, and
		  Architecture},
  shorttitle	= {How Debuggers Work},
  author	= {Rosenberg, Jonathan B.},
  year		= {1996},
  month		= oct,
  publisher	= {John Wiley \& Sons, Inc.},
  address	= {USA},
  isbn		= {978-0-471-14966-8}
}

@Article{	  roska90,
  title		= {Limitations and Complexity of Digital Hardware Simulators
		  Used for Large-Scale Analogue Circuit and System Dynamics},
  author	= {Roska, Tam{\'a}s},
  year		= {1990},
  journal	= {International Journal of Circuit Theory and Applications},
  volume	= {18},
  number	= {1},
  pages		= {11--21},
  issn		= {1097-007X},
  doi		= {10.1002/cta.4490180104},
  urldate	= {2024-08-31},
  abstract	= {Large-scale electronic circuits and systems are considered
		  with increasing complexity measured in terms of the number
		  of circuit or system elements. the dynamics will be
		  calculated by a digital prototype hardware simulator
		  exploiting parallelism, pipelining and look-up table
		  techniques to realize minimum solution time. Our
		  `canonical' conceptual prototype digital simulator (PDS) is
		  given and its parts are analysed in detail, including a
		  minimal memory realization of a multivariable non-linear
		  mapping (look-up table). It is shown that if the increase
		  of the complexity of the simulator does not exceed the
		  increase of the complexity of the circuit or system to be
		  simulated, then the simulation complexity (measured in
		  terms of the accumulated time of basic calculation steps)
		  will not decrease, but instead will increase. Hence there
		  is an inherent limitation in the digital simulation of
		  analogue operators. This result suggests at the same time
		  that the digital method of data and signal processing has
		  some inherent limitations, a striking example of overcoming
		  it being the neural circuit. the speeding up of the digital
		  hardware due to the scaling down of feature sizes in
		  integrated circuits and the reduction of the time step due
		  to the increase in system size are also taken into
		  account.},
  copyright	= {Copyright {\copyright} 1990 John Wiley \& Sons, Ltd.},
  langid	= {english}
}

@Article{	  rospocher14,
  title		= {An Ontology for the Business Process Modelling Notation},
  author	= {Rospocher, M. and Ghidini, Chiara and Serafini, Luciano},
  year		= {2014},
  month		= jan,
  journal	= {Frontiers in Artificial Intelligence and Applications},
  volume	= {267},
  pages		= {133--146},
  doi		= {10.3233/978-1-61499-438-1-133},
  abstract	= {In this paper we describe a formal ontological description
		  of the Business Process Modelling Notation (BPMN), one of
		  the most popular languages for business process modelling.
		  The proposed ontology (the BPMN Ontology) provides a
		  classification of all the elements of BPMN, together with
		  the formal description of the attributes and conditions
		  describing how the elements can be combined in a BPMN
		  business process description. Using the classes and
		  properties defined in the BPMN Ontology any BPMN diagram
		  can be represented as an A-box (i.e., a set of instances
		  and assertions on them) of the ontology: this allows the
		  exploitation of ontological reasoning services such as
		  consistency checking and query answering to investigate the
		  compliance of a process with the BPMN Specification as well
		  as other structural property of the process. The paper also
		  presents the modelling process followed for the creation of
		  the BPMN Ontology, and describes some application scenarios
		  exploiting the BPMN Ontology.}
}

@Misc{		  rossberg19,
  title		= {{{WebAssembly}} ({{Release}} 1.0)},
  author	= {Rossberg, Andreas},
  year		= {2019},
  urldate	= {2020-01-01},
  howpublished	= {https://webassembly.github.io/spec/}
}

@Misc{		  rossberg23,
  title		= {{{WebAssembly}} ({{Release}} 2.0)},
  author	= {Rossberg, Andreas},
  year		= {2023},
  urldate	= {2023-02-20},
  howpublished	= {https://webassembly.github.io/spec/}
}

@Article{	  saeedi13,
  title		= {Synthesis and Optimization of Reversible Circuits---a
		  Survey},
  author	= {Saeedi, Mehdi and Markov, Igor L.},
  year		= {2013},
  month		= mar,
  journal	= {ACM Comput. Surv.},
  volume	= {45},
  number	= {2},
  pages		= {21:1--21:34},
  issn		= {0360-0300},
  doi		= {10.1145/2431211.2431220},
  urldate	= {2024-11-09},
  abstract	= {Reversible logic circuits have been historically motivated
		  by theoretical research in low-power electronics as well as
		  practical improvement of bit manipulation transforms in
		  cryptography and computer graphics. Recently, reversible
		  circuits have attracted interest as components of quantum
		  algorithms, as well as in photonic and nano-computing
		  technologies where some switching devices offer no signal
		  gain. Research in generating reversible logic distinguishes
		  between circuit synthesis, postsynthesis optimization, and
		  technology mapping. In this survey, we review algorithmic
		  paradigms---search based, cycle based, transformation
		  based, and BDD based---as well as specific algorithms for
		  reversible synthesis, both exact and heuristic. We conclude
		  the survey by outlining key open challenges in synthesis of
		  reversible and quantum logic, as well as most common
		  misconceptions.}
}

@Article{	  scholliers24,
  title		= {{{WebPie}}: {{A Tiny Slice}} of {{Dependent Typing}}},
  shorttitle	= {{{WebPie}}},
  author	= {Scholliers, Christophe},
  year		= {2024},
  month		= apr,
  journal	= {Electronic Proceedings in Theoretical Computer Science},
  volume	= {400},
  eprint	= {2404.05457},
  primaryclass	= {cs},
  pages		= {2--27},
  issn		= {2075-2180},
  doi		= {10.4204/EPTCS.400.2},
  urldate	= {2024-04-18},
  abstract	= {Dependently typed programming languages have become
		  increasingly relevant in recent years. They have been
		  adopted in industrial strength programming languages and
		  have been extremely successful as the basis for theorem
		  provers. There are however, very few entry level
		  introductions to the theory of language constructs for
		  dependently typed languages, and even less sources on
		  didactical implementations. In this paper, we present a
		  small dependently typed programming language called WebPie.
		  The main features of the language are inductive types,
		  recursion and case matching. While none of these features
		  are new, we believe this article can provide a step forward
		  towards the understanding and systematic construction of
		  dependently typed languages for researchers new to
		  dependent types.},
  archiveprefix	= {arXiv},
  keywords	= {Computer Science - Logic in Computer Science,Computer
		  Science - Programming Languages,Computer Science - Symbolic
		  Computation}
}

@InProceedings{	  schordan16,
  title		= {Automatic {{Generation}} of {{Reversible C}}++ {{Code}}
		  and {{Its Performance}} in a {{Scalable Kinetic Monte-Carlo
		  Application}}},
  booktitle	= {Proceedings of the 2016 {{ACM SIGSIM Conference}} on
		  {{Principles}} of {{Advanced Discrete Simulation}}},
  author	= {Schordan, Markus and Oppelstrup, Tomas and Jefferson,
		  David and Barnes, Peter D. and Quinlan, Dan},
  year		= {2016},
  month		= may,
  series	= {{{SIGSIM-PADS}} '16},
  pages		= {111--122},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2901378.2901394},
  urldate	= {2024-11-10},
  abstract	= {The fully automatic generation of code that establishes
		  the reversibility of arbitrary C/C++ code has been a target
		  of research and engineering for more than a decade as
		  reverse computation has become a central notion in large
		  scale parallel discrete event simulation (PDES). The
		  simulation models that are implemented for PDES are of
		  increasing complexity and size and require various language
		  features to support abstraction, encapsulation, and
		  composition when building a simulation model. In this paper
		  we focus on parallel simulation models that are written in
		  C++ and present an approach and an evaluation for a fully
		  automatically generated reversible code for a kinetic
		  Monte-Carlo application implemented in C++. Although a
		  significant runtime overhead is introduced with our
		  technique, the assurance that the reverse code is generated
		  automatically and correctly, is an enormous win that allows
		  simulation model developers to write forward event code
		  using the entire C++ language, and have that code
		  automatically transformed into reversible code to enable
		  parallel execution with the Rensselaer's Optimistic
		  Simulation System (ROSS).},
  isbn		= {978-1-4503-3742-7}
}

@InProceedings{	  schultz16,
  title		= {Elements of a {{Reversible Object-Oriented Language}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Schultz, Ulrik Pagh and Axelsen, Holger Bock},
  editor	= {Devitt, Simon and Lanese, Ivan},
  year		= {2016},
  pages		= {153--159},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-319-40578-0_10},
  abstract	= {This paper presents initial ideas for the design and
		  implementation of a reversible object-oriented language
		  based on extending Janus with object-oriented concepts such
		  as classes that encapsulate behavior and state,
		  inheritance, virtual dispatching, as well as constructors.
		  We show that virtual dispatching is a reversible decision
		  mechanism easily translatable to a standard reversible
		  programming model such as Janus, and we argue that
		  reversible management of state can be accomplished using
		  reversible constructors. The language is implemented in
		  terms of translation to standard Janus programs.},
  isbn		= {978-3-319-40578-0},
  langid	= {english},
  keywords	= {Memory Management,Modern Programming Language,Object
		  Reference,Runtime Type,Virtual Method}
}

@InCollection{	  schultz20,
  title		= {Reversible {{Control}} of {{Robots}}},
  booktitle	= {Reversible {{Computation}}: {{Extending Horizons}} of
		  {{Computing}}: {{Selected Results}} of the {{COST Action
		  IC1405}}},
  author	= {Schultz, Ulrik Pagh},
  editor	= {Ulidowski, Irek and Lanese, Ivan and Schultz, Ulrik Pagh
		  and Ferreira, Carla},
  year		= {2020},
  pages		= {177--186},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-47361-7_8},
  urldate	= {2024-11-10},
  abstract	= {Programming industrial robots is challenging due to the
		  difficulty of precisely specifying general yet robust
		  operations. As the complexity of these operations
		  increases, so does the likelihood of errors. Certain
		  classes of errors during industrial robot operations can
		  however be addressed using reverse execution, allowing the
		  robot to temporarily back out of an erroneous situation,
		  after which the operation can be automatically retried.
		  Moreover reverse execution permits automatically deriving
		  programs that physically reverse the operations of an
		  industrial robot. This can be useful in industrial
		  assembly, where a disassembly program can be automatically
		  derived from the assembly program.},
  isbn		= {978-3-030-47361-7},
  langid	= {english}
}

@InProceedings{	  seelemann95,
  title		= {Limiting the Probe Effect in Debugging Concurrent
		  Object-Oriented Programs},
  booktitle	= {Proceedings of the 1995 Conference of the {{Centre}} for
		  {{Advanced Studies}} on {{Collaborative}} Research},
  author	= {Seelemann, Ilene},
  year		= {1995},
  month		= nov,
  series	= {{{CASCON}} '95},
  pages		= {56},
  publisher	= {IBM Press},
  address	= {Toronto, Ontario, Canada},
  urldate	= {2024-11-18},
  abstract	= {Event-based tracers for visualizing distributed
		  applications use process-time diagrams for demonstrating
		  interaction among processes. Object-oriented programs can
		  also benefit from a similar presentation in which
		  object-time diagrams are drawn and the interaction between
		  objects represents method invocations. In this type of
		  diagram, it is necessary to identify the objects and
		  methods involved.This paper presents an approach for
		  resolving and storing class and method names at debug time
		  instead of run time. In a sequential environment, this
		  approach has the benefit of preserving class layouts. In a
		  distributed object-oriented environment, it has the further
		  benefit of minimizing the probe effect by separating
		  resolution of naming information from program execution.
		  Extensions were made to Poet , a partial-order event
		  tracer, to display programs written using ABC++, a class
		  library for adding concurrency to C++.}
}

@InProceedings{	  shibanai17,
  title		= {Actoverse: A Reversible Debugger for Actors},
  shorttitle	= {Actoverse},
  booktitle	= {Proceedings of the 7th {{ACM SIGPLAN International
		  Workshop}} on {{Programming Based}} on {{Actors}},
		  {{Agents}}, and {{Decentralized Control}}},
  author	= {Shibanai, Kazuhiro and Watanabe, Takuo},
  year		= {2017},
  month		= oct,
  series	= {{{AGERE}} 2017},
  pages		= {50--57},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3141834.3141840},
  urldate	= {2024-02-28},
  abstract	= {The Actor model is a concurrent computation model based on
		  asynchronous message passing and shared-nothing principle.
		  These characteristics and the absence of locks guarantee
		  that actor-based programs can avoid simple concurrency bugs
		  such as data races and deadlocks. However, they are not
		  completely free from application level concurrency bugs
		  that occur, for example, due to the indeterminate arrival
		  order of messages. To assist discovering such bugs in
		  actor-based systems, we designed and implemented Actoverse,
		  a debugger that adopts reverse debugging and provides an
		  interactive aid for controlling the arrival order of
		  messages upon re-execution. This paper briefly presents its
		  architecture and utilization in Akka-based applications.},
  isbn		= {978-1-4503-5516-2},
  keywords	= {Actor model,Debugging,Reverse Debugging,Visualization}
}

@InCollection{	  short,
  title		= {Answers to the {{Questions}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {327--329},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch9},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Answers to the end
		  of chapter questions Correct answers to the sample paper
		  questions},
  chapter	= {9},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InCollection{	  shorta,
  title		= {Bibliography},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {331--333},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.biblio},
  urldate	= {2024-12-04},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InCollection{	  shortb,
  title		= {Index},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {335--342},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.index},
  urldate	= {2024-12-04},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InCollection{	  shortc,
  title		= {Fundamentals of {{Testing}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {1--41},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch1},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Why is testing
		  necessary? (FL 1.1) What is testing? (FL 1.2) Paradoxes and
		  main principles (FL 1.3) Fundamental test process (FL 1.4)
		  Psychology of testing (FL 1.5) Testers and code of ethics
		  (FL 1.6) Synopsis of this chapter Sample exam questions},
  chapter	= {1},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Association for Computing Machinery (ACM),International
		  Software Testing Qualifications Board (ISTQB),National
		  Aeronautics and Space Administration (NASA's),Random-access
		  memory (RAM),Service level agreement (SLA),Software
		  systems}
}

@InCollection{	  shortd,
  title		= {Front {{Matter}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {i-xxix},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.fmatter},
  urldate	= {2024-12-04},
  abstract	= {The prelims comprise: Half-Title Page Dedication Title
		  Page Copyright Page Table of Contents Preface Glossary},
  isbn		= {978-1-118-60227-0},
  langid	= {english}
}

@InCollection{	  shorte,
  title		= {Mock {{Exam}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {301--314},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch7},
  urldate	= {2024-12-04},
  chapter	= {7},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Black-box design techniques,Integration
		  testing,International Software Testing Qualifications Board
		  (ISTQB),Software testing,Test cases (TC)}
}

@InCollection{	  shortf,
  title		= {Static {{Techniques}} ({{FL}} 3.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {91--136},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch3},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Static techniques
		  and the test process (FL 3.1) Review process (FL 3.2)
		  Static analysis by tools (FL 3.3) Added value of static
		  activities Synopsis of this chapter Sample exam questions},
  chapter	= {3},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Architecture analysis,Data flow analysis,International
		  Software Testing Qualifications Board (ISTQB),Static
		  techniques,Unified modeling language (UML)}
}

@InCollection{	  shortg,
  title		= {Templates and {{Models}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {315--326},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch8},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Master test plan
		  Test plan Test design document Test case Test procedure
		  Test log Defect report Test report},
  chapter	= {8},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Customization,Documentation templates,Institute for
		  Electrical and Electronic Engineers (IEEE),Master test
		  plan,Test cases (TC)}
}

@InCollection{	  shorth,
  title		= {Test {{Design Techniques}} ({{FL}} 4.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {137--207},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch4},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: The test
		  development process (FL 4.1) Categories of test design
		  techniques (FL 4.2) Black-box techniques (FL 4.3)
		  Structure-based techniques (FL 4.4) Experience-based
		  techniques (FL 4.5) Choosing test techniques (FL 4.6)
		  Synopsis of this chapter Sample exam questions},
  chapter	= {4},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Black-box techniques,Equivalence partitioning,Exploratory
		  testing,Orthogonal arrays testing,Reliability management
		  theories,State transition testing,Structure-based
		  techniques,Test design techniques,Unified modeling language
		  (UML),Vectors and matrix processing}
}

@InCollection{	  shorti,
  title		= {Test {{Management}} ({{FL}} 5.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {209--276},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch5},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Test organization
		  (FL 5.1) Test planning and estimation (FL 5.2) Test
		  progress monitoring and control (FL 5.3) Reporting
		  Transverse processes and activities Risks management (FL
		  5.5) Defect management (FL 5.6) Synopsis of this chapter
		  Sample exam questions},
  chapter	= {5},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Configuration management,Estimation methods,Failure mode
		  and effect analysis (FMEA),Hazard analysis,International
		  Software Testing Qualifications Board (ISTQB),Risk-based
		  testing method,Scrum model,Test management,Uniform test
		  distribution}
}

@InCollection{	  shortj,
  title		= {Testing {{Throughout}} the {{Software Life Cycle}}},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {43--90},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch2},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Software
		  development models (FL 2.1) Test levels (FL 2.2) Types of
		  tests (FL 2.3) Test and maintenance (FL 2.4) Oracles
		  Specific cases Synopsis of this chapter Sample exam
		  questions},
  chapter	= {2},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Agile development models,Capability Maturity Model
		  Integration (CMMI),Code instrumentation,International
		  Software Testing Qualifications Board (ISTQB),Oracle,Rapid
		  application development (RAD) model,Regression
		  testing,Sequential models,Software life cycle,Test driven
		  development (TDD)}
}

@InCollection{	  shortk,
  title		= {Tools Support for {{Testing}} ({{FL}} 6.0)},
  booktitle	= {Fundamentals of {{Software Testing}}},
  year		= {2012},
  pages		= {277--299},
  publisher	= {John Wiley \& Sons, Ltd},
  doi		= {10.1002/9781118602270.ch6},
  urldate	= {2024-12-04},
  abstract	= {This chapter contains sections titled: Types of test tools
		  (FL 6.1) Assumptions and limitations of test tools (FL 6.2)
		  Selecting and introducing tools in an organization (FL 6.3)
		  Synopsis of this chapter Sample exam questions},
  chapter	= {6},
  isbn		= {978-1-118-60227-0},
  langid	= {english},
  keywords	= {Application programming interfaces (API),Central
		  processing unit (CPU),Configuration management,Economic
		  analysis,International Software Testing Qualifications
		  Board (ISTQB),Network simulators,Regression tests,Static
		  analysis tools,Test management tools}
}

@Misc{		  shortl,
  title		= {Wasm3/Wasm-Debug},
  year		= {2023},
  month		= oct,
  urldate	= {2023-11-17},
  abstract	= {Direct, source-level WebAssembly debugger},
  copyright	= {MIT},
  howpublished	= {Wasm3 Labs},
  keywords	= {debugger,gdb,lldb,remote-debugger,webassembly}
}

@Misc{		  shortm,
  title		= {Awaitility},
  author	= {Haleby, Johan},
  urldate	= {2024-02-09},
  abstract	= {Testing asynchronous systems is hard. Not only does it
		  require handling threads, timeouts and concurrency issues,
		  but the intent of the test code can be obscured by all
		  these details. Awaitility is a DSL that allows you to
		  express expectations of an asynchronous system in a concise
		  and easy to read manner.},
  howpublished	= {http://www.awaitility.org/}
}

@Article{	  shortn,
  title		= {{{IEEE Standard}} for {{Test Access Port}} and
		  {{Boundary-Scan Architecture}}},
  year		= {2013},
  month		= may,
  journal	= {IEEE Std 1149.1-2013 (Revision of IEEE Std 1149.1-2001)},
  pages		= {1--444},
  doi		= {10.1109/IEEESTD.2013.6515989},
  urldate	= {2024-11-13},
  abstract	= {Circuitry that may be built into an integrated circuit to
		  assist in the test, maintenance and support of assembled
		  printed circuit boards and the test of internal circuits is
		  defined. The circuitry includes a standard interface
		  through which instructions and test data are communicated.
		  A set of test features is defined, including a
		  boundary-scan register, such that the component is able to
		  respond to a minimum set of instructions designed to assist
		  with testing of assembled printed circuit boards. Also, a
		  language is defined that allows rigorous structural
		  description of the component-specific aspects of such
		  testability features, and a second language is defined that
		  allows rigorous procedural description of how the
		  testability features may be used.},
  keywords	= {boundary scan,Boundary value problems,boundary-scan
		  architecture,boundary-scan boundary scan,Boundary-Scan
		  Description Language,Boundary-Scan Description Language
		  (BSDL),boundary-scan register,circuit boards,circuitry,IEEE
		  1149.1,IEEE standards,integrated circuit,Integrated
		  circuits,printed circuit boards,Printed circuits,Procedural
		  Description Language (PDL),test,test access port
		  (TAP),Testing,very high speed integrated circuit
		  (VHSIC),Very high speed integrated circuits,VHSIC Hardware
		  Description Language (VHDL)}
}

@Misc{		  shorto,
  title		= {Mocha - the Fun, Simple, Flexible {{JavaScript}} Test
		  Framework},
  author	= {{OpenJS Foundation}},
  urldate	= {2024-02-09},
  howpublished	= {https://mochajs.org/}
}

@Misc{		  shortp,
  title		= {Test {{Framework}} --- {{Zephyr Project Documentation}}},
  author	= {Peress, Yuval and Nashif, Anas and Brunnen, Manoel and
		  Andersen, Henrik Brix and Emeltchenko, Andrei and Massey,
		  Aaron E. and Bolivar, Marti and Olivares, Ivan Herrera and
		  Escolar, Alberto},
  urldate	= {2024-02-13},
  howpublished	= {https://docs.zephyrproject.org/latest/develop/test/ztest.html}
}

@Misc{		  shortq,
  title		= {Doctest --- {{Test}} Interactive {{Python}} Examples},
  author	= {{Python Software Foundation}},
  journal	= {Python documentation},
  urldate	= {2024-02-09},
  abstract	= {Source code: Lib/doctest.py The doctest module searches
		  for pieces of text that look like interactive Python
		  sessions, and then executes those sessions to verify that
		  they work exactly as shown. Th...},
  howpublished	= {https://docs.python.org/3/library/doctest.html},
  langid	= {english}
}

@Misc{		  shortr,
  title		= {{{JUnit}} 5},
  author	= {{The JUnit Team}},
  urldate	= {2024-02-09},
  howpublished	= {https://junit.org/junit5/}
}

@Misc{		  shorts,
  title		= {[{{PDF}}] {{Exploring IOT Application Using Raspberry Pi}}
		  {\textbar} {{Semantic Scholar}}},
  urldate	= {2023-10-18},
  howpublished	= {https://www.semanticscholar.org/paper/Exploring-IOT-Application-Using-Raspberry-Pi-Zhao-Jegatheesan/ac8b8cf9dd6dcacd4963da40200abcc56ce8ba49}
}

@Misc{		  shortt,
  title		= {{{AppOptics}} -- {{APM}} and {{Infrastructure Tool}}
		  {\textbar} {{SolarWinds AppOptics}}},
  urldate	= {2024-02-12},
  abstract	= {Get visibility into modern application and infrastructure
		  performance using one APM tool. Out-of-the-box dashboards,
		  metrics, and analytics. Try a free 14-day trial!},
  howpublished	= {https://www.solarwinds.com/appoptics},
  langid	= {american}
}

@Misc{		  shortu,
  title		= {Debugging the {{Internet}} of {{Things}}: {{The Case}} of
		  {{Wireless Sensor Networks}} {\textbar} {{IEEE Journals}}
		  \& {{Magazine}} {\textbar} {{IEEE Xplore}}},
  urldate	= {2024-02-29},
  howpublished	= {https://ieeexplore.ieee.org/abstract/document/6914470}
}

@Misc{		  shortv,
  title		= {Scalable Omniscient Debugging {\textbar} {{ACM SIGPLAN
		  Notices}}},
  urldate	= {2024-04-18},
  howpublished	= {https://dl.acm.org/doi/10.1145/1297105.1297067}
}

@Misc{		  shortw,
  title		= {Boosting {{Compiler Testing}} by {{Injecting Real-World
		  Code}} {\textbar} {{Proceedings}} of the {{ACM}} on
		  {{Programming Languages}}},
  urldate	= {2024-08-20},
  howpublished	= {https://dl.acm.org/doi/10.1145/3656386}
}

@Misc{		  shortx,
  title		= {Automated {{System Verification}} - {{ScienceDirect}}},
  urldate	= {2024-08-29},
  howpublished	= {https://www.sciencedirect.com/science/article/pii/B978012372512700016X}
}

@Misc{		  shorty,
  title		= {Automated {{System Verification}} - {{ScienceDirect}}},
  urldate	= {2024-08-29},
  howpublished	= {https://www.sciencedirect.com/science/article/pii/B978012372512700016X}
}

@Misc{		  shortz,
  title		= {Optimization of Swift Protocols {\textbar} {{Proceedings}}
		  of the {{ACM}} on {{Programming Languages}}},
  urldate	= {2024-12-17},
  howpublished	= {https://dl.acm.org/doi/10.1145/3360590}
}

@Book{		  siek06,
  title		= {Gradual Typing for Functional Languages},
  author	= {Siek, Jeremy and Taha, Walid},
  year		= {2006},
  month		= jan,
  journal	= {Scheme and Functional Programming},
  abstract	= {Static and dynamic type systems have well-known strengths
		  and weaknesses, and each is better suited for different
		  programming tasks. There have been many efforts to
		  integrate static and dynamic typing and thereby combine the
		  benefits of both typing disciplines in the same language.
		  The flexibility of static typing can be im- proved by
		  adding a type Dynamic and a typecase form. The safety and
		  performance of dynamic typing can be improved by adding
		  optional type annotations or by performing type inference
		  (as in soft typing). However, there has been little formal
		  work on type systems that allow a programmer-controlled
		  migration between dy- namic and static typing. Thatte
		  proposed Quasi-Static Typing, but it does not statically
		  catch all type errors in completely annotated programs.
		  Anderson and Drossopoulou defined a nominal type sys- tem
		  for an object-oriented language with optional type
		  annotations. However, developing a sound, gradual type
		  system for functional languages with structural types is an
		  open problem. In this paper we present a solution based on
		  the intuition that the structure of a type may be partially
		  known/unknown at compile- time and the job of the type
		  system is to catch incompatibilities between the known
		  parts of types. We define the static and dynamic semantics
		  of a -calculus with optional type annotations and we prove
		  that its type system is sound with respect to the
		  simply-typed -calculus for fully-annotated terms. We prove
		  that this calculus is type safe and that the cost of
		  dynamism is "pay-as-you-go".}
}

@InProceedings{	  skvar-c24,
  title		= {In-{{Field Debugging}} of {{Automotive Microcontrollers}}
		  for {{Highest System Availability}}},
  booktitle	= {Proceedings of the 2nd {{ACM International Workshop}} on
		  {{Future Debugging Techniques}}},
  author	= {Skvar{\v c} Bo{\v z}i{\v c}, Ga{\v s}per and Irigoyen
		  Ceberio, Ibai and Mayer, Albrecht},
  year		= {2024},
  month		= sep,
  series	= {{{DEBT}} 2024},
  pages		= {2--8},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3678720.3685314},
  urldate	= {2024-11-10},
  abstract	= {The software content in vehicles is increasing, including
		  their system complexity, which leads to a higher
		  probability of bugs appearing in a production vehicle.
		  Consequently, there is an increasing need to observe what
		  the production system is doing also once it is already in
		  the field. This paper introduces an emerging topic of
		  in-field diagnosis of microcontrollers in the automotive
		  domain. This includes the architecture and how to address
		  the safety and security challenges. We describe the
		  necessary components of an in-field diagnosis architecture,
		  including the required properties of an on-chip debug
		  monitor. We provide several ways an on-chip debug monitor
		  can be implemented by utilizing the available and, in some
		  cases, unused system resources. With the described
		  approach, we can utilize the same debug concepts and tools
		  for local, remote, and in-field diagnosis, enabling runtime
		  verification throughout a system's lifecycle.},
  isbn		= {9798400711107}
}

@Misc{		  soderby24,
  title		= {Debugging with the Arduino {{IDE}} 2.0},
  author	= {S{\"o}derby, Karl and De Feo, Ubi},
  year		= {2024},
  month		= nov,
  urldate	= {2024-11-12},
  howpublished	= {https://docs.arduino.cc/software/ide-v2/tutorials/ide-v2-debugger},
  lastaccessed	= {November 12, 2024}
}

@InProceedings{	  song14,
  title		= {On the Existence of Probe Effect in Multi-Threaded
		  Embedded Programs},
  booktitle	= {Proceedings of the 14th {{International Conference}} on
		  {{Embedded Software}}},
  author	= {Song, Young Wn and Lee, Yann-Hang},
  year		= {2014},
  month		= oct,
  series	= {{{EMSOFT}} '14},
  pages		= {1--9},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2656045.2656062},
  urldate	= {2024-11-18},
  abstract	= {Software instrumentation has been a convenient and
		  portable approach for dynamic analysis, debugging, or
		  profiling of program execution. Unfortunately,
		  instrumentation may change the temporal behavior of
		  multi-threaded program execution and result in different
		  ordering of thread operations, which is called probe
		  effect. While the approaches to reduce instrumentation
		  overhead, to enable reproducible execution, and to enforce
		  deterministic threading have been studied, no research has
		  yet answered if an instrumented execution has the same
		  behavior as the program execution without any
		  instrumentation and how the execution gets changed if there
		  were any. In this paper, we propose a simulation-based
		  analysis to detect the changes of execution event ordering
		  that are induced by instrumentation operations. The
		  execution model of a program is constructed from the trace
		  of instrumented program execution and is used in a
		  simulation analysis where instrumentation overhead is
		  removed. As a consequence, we can infer the ordering of
		  events in the original program execution and verify the
		  existence of probe effect resulted from instrumentation.},
  isbn		= {978-1-4503-3052-7}
}

@InProceedings{	  stansifer88,
  title		= {Type Inference with Subtypes},
  booktitle	= {Proceedings of the 15th {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Stansifer, R.},
  year		= {1988},
  month		= jan,
  series	= {{{POPL}} '88},
  pages		= {88--97},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/73560.73568},
  urldate	= {2023-10-20},
  abstract	= {We give an algorithm for type inference in a language with
		  functions, records, and variant records. A similar language
		  was studied by Cardelli who gave a type checking algorithm.
		  This language is interesting because it captures aspects of
		  object-oriented programming using subtype polymorphism. We
		  give a type system for deriving types of expressions in the
		  language and prove the type inference algorithm is sound,
		  i.e., it returns a type derivable from the proof system. We
		  also prove that the type the algorithm finds is a
		  ``principal'' type, i.e., one which characterizes all
		  others. The approach taken here is due to Milner for
		  universal polymorphism. The result is a synthesis of
		  subtype polymorphism and universal polymorphism.},
  isbn		= {978-0-89791-252-5}
}

@Article{	  steegen16,
  title		= {Increasing {{Transparency Through}} a {{Multiverse
		  Analysis}}},
  author	= {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew
		  and Vanpaemel, Wolf},
  year		= {2016},
  month		= sep,
  journal	= {Perspectives on Psychological Science},
  volume	= {11},
  number	= {5},
  pages		= {702--712},
  publisher	= {SAGE Publications Inc},
  issn		= {1745-6916},
  doi		= {10.1177/1745691616658637},
  urldate	= {2024-11-10},
  abstract	= {Empirical research inevitably includes constructing a data
		  set by processing raw data into a form ready for
		  statistical analysis. Data processing often involves
		  choices among several reasonable options for excluding,
		  transforming, and coding data. We suggest that instead of
		  performing only one analysis, researchers could perform a
		  multiverse analysis, which involves performing all analyses
		  across the whole set of alternatively processed data sets
		  corresponding to a large set of reasonable scenarios. Using
		  an example focusing on the effect of fertility on
		  religiosity and political attitudes, we show that analyzing
		  a single data set can be misleading and propose a
		  multiverse analysis as an alternative practice. A
		  multiverse analysis offers an idea of how much the
		  conclusions change because of arbitrary choices in data
		  construction and gives pointers as to which choices are
		  most consequential in the fragility of the result.},
  langid	= {english}
}

@Article{	  steinert12,
  title		= {{{CoExist}}: Overcoming Aversion to Change},
  shorttitle	= {{{CoExist}}},
  author	= {Steinert, Bastian and Cassou, Damien and Hirschfeld,
		  Robert},
  year		= {2012},
  month		= oct,
  journal	= {SIGPLAN Not.},
  volume	= {48},
  number	= {2},
  pages		= {107--118},
  issn		= {0362-1340},
  doi		= {10.1145/2480360.2384591},
  urldate	= {2024-10-30},
  abstract	= {Programmers make many changes to the program to eventually
		  find a good solution for a given task. In this course of
		  change, every intermediate development state can of value,
		  when, for example, a promising ideas suddenly turn out
		  inappropriate or the interplay of objects turns out more
		  complex than initially expected before making changes.
		  Programmers would benefit from tool support that provides
		  immediate access to source code and run-time of previous
		  development states of interest. We present IDE extensions,
		  implemented for Squeak/Smalltalk, to preserve, retrieve,
		  and work with this information. With such tool support,
		  programmers can work without worries because they can rely
		  on tools that help them with whatever their explorations
		  will reveal. They no longer have to follow certain best
		  practices only to avoid undesired consequences of hanging
		  code.}
}

@InProceedings{	  stievenart20,
  title		= {Compositional {{Information Flow Analysis}} for
		  {{WebAssembly Programs}}},
  booktitle	= {2020 {{IEEE}} 20th {{International Working Conference}} on
		  {{Source Code Analysis}} and {{Manipulation}} ({{SCAM}})},
  author	= {Sti{\'e}venart, Quentin and Roover, Coen De},
  year		= {2020},
  month		= sep,
  pages		= {13--24},
  issn		= {2470-6892},
  doi		= {10.1109/SCAM51674.2020.00007},
  urldate	= {2023-11-22},
  abstract	= {WebAssembly is a new W3C standard, providing a portable
		  target for compilation for various languages. All major
		  browsers can run WebAssembly programs, and its use extends
		  beyond the web: there is interest in compiling
		  cross-platform desktop applications, server applications,
		  IoT and embedded applications to WebAssembly because of the
		  performance and security guarantees it aims to provide.
		  Indeed, WebAssembly has been carefully designed with
		  security in mind. In particular, WebAssembly applications
		  are sandboxed from their host environment. However, recent
		  works have brought to light several limitations that expose
		  WebAssembly to traditional attack vectors. Visitors of
		  websites using WebAssembly have been exposed to malicious
		  code as a result. In this paper, we propose an automated
		  static program analysis to address these security concerns.
		  Our analysis is focused on information flow and is
		  compositional. For every WebAssembly function, it first
		  computes a summary that describes in a sound manner where
		  the information from its parameters and the global program
		  state can flow to. These summaries can then be applied
		  during the subsequent analysis of function calls. Through a
		  classical fixed-point formulation, one obtains an
		  approximation of the information flow in the WebAssembly
		  program. This results in the first compositional static
		  analysis for WebAssembly. On a set of 34 benchmark programs
		  spanning 196kLOC of WebAssembly, we compute at least 64\%
		  of the function summaries precisely in less than a minute
		  in total.}
}

@InProceedings{	  stievenart22,
  title		= {Static Stack-Preserving Intra-Procedural Slicing of
		  Webassembly Binaries},
  booktitle	= {Proceedings of the 44th {{International Conference}} on
		  {{Software Engineering}}},
  author	= {Sti{\'e}venart, Quentin and Binkley, David W. and De
		  Roover, Coen},
  year		= {2022},
  month		= jul,
  series	= {{{ICSE}} '22},
  pages		= {2031--2042},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3510003.3510070},
  urldate	= {2023-12-01},
  abstract	= {The recently introduced WebAssembly standard aims to be a
		  portable compilation target, enabling the cross-platform
		  distribution of programs written in a variety of languages.
		  We propose an approach to slice WebAssembly programs in
		  order to enable applications in reverse engineering, code
		  comprehension, and security among others. Given a program
		  and a location in that program, program slicing produces a
		  minimal version of the program that preserves the behavior
		  at the given location. Specifically, our approach is a
		  static, intra-procedural, backward slicing approach that
		  takes into account WebAssembly-specific dependences to
		  identify the instructions of the slice. To do so it must
		  correctly overcome the considerable challenges of
		  performing dependence analysis at the binary level.
		  Furthermore, for the slice to be executable, the approach
		  needs to ensure that the stack behavior of its output
		  complies with WebAssembly's validation requirements. We
		  implemented and evaluated our approach on a suite of 8 386
		  real-world WebAssembly binaries, finding that the average
		  size of the 495 204 868 slices computed is 53\% of the
		  original code, an improvement over the 60\% attained by
		  related work slicing ARM binaries. To gain a more
		  qualitative understanding of the slices produced by our
		  approach, we compared them to 1 956 source-level slices of
		  benchmark C programs. This inspection helps to illustrate
		  the slicer's strengths and to uncover potential future
		  improvements.},
  isbn		= {978-1-4503-9221-1},
  keywords	= {binary analysis,static program slicing,webassembly}
}

@Article{	  stievenart23,
  title		= {Dynamic {{Slicing}} of {{WebAssembly Binaries}}: 39th
		  {{IEEE International Conference}} on {{Software
		  Maintenance}} and {{Evolution}}},
  shorttitle	= {Dynamic {{Slicing}} of {{WebAssembly Binaries}}},
  author	= {Sti{\'e}venart, Quentin and Binkley, Dave and De Roover,
		  Coen},
  year		= {2023},
  journal	= {Proceedings of the 39th IEEE International Conference on
		  Software Maintenance and Evolution (ICSME 2023)},
  pages		= {84--96},
  publisher	= {IEEE},
  doi		= {10.1109/ICSME58846.2023.00020},
  abstract	= {The recently introduced WebAssembly standard aims to form
		  a portable compilation target, enabling the cross-platform
		  distribution of programs written in a variety of languages.
		  In this paper, we propose and investigate the first dynamic
		  slicing approaches for WebAssembly. Given a program and a
		  location in that program, a program slice is a reduced
		  version of the program that preserves the behavior at the
		  given location. Slicing has numerous applications in
		  software maintenance and evolution, including reverse
		  engineering, code comprehension, and quality assurance.Our
		  dynamic approaches are built on Observational-Based Slicing
		  (ORBS). We explore the design space for instantiating ORBS
		  for WebAssembly: for example, it can be applied to the
		  whole program or to only the function containing the
		  slicing criterion, and it can be applied before compilation
		  to WebAssembly or afterwards. We evaluate the slices
		  produced quantitatively and qualitatively, and compare them
		  to those obtained by a state-of-the-art static slicer for
		  WebAssembly. Our evaluation reveals that dynamic slicing at
		  the level of a function from a WebAssembly binary finds a
		  sweet spot in terms of slice time and slice size.},
  keywords	= {dynamic program slicing,program analysis,WebAssembly}
}

@Article{	  strijbol24,
  title		= {Blink: {{An}} Educational Software Debugger for
		  {{Scratch}}},
  shorttitle	= {Blink},
  author	= {Strijbol, Niko and De Proft, Robbe and Goethals, Klaas and
		  Mesuere, Bart and Dawyndt, Peter and Scholliers,
		  Christophe},
  year		= {2024},
  month		= feb,
  journal	= {SoftwareX},
  volume	= {25},
  pages		= {101617},
  issn		= {2352-7110},
  doi		= {10.1016/j.softx.2023.101617},
  urldate	= {2024-02-13},
  abstract	= {The process of teaching children to code is often slowed
		  down by the delay in providing feedback on each student's
		  code. Especially in larger classrooms, teachers often lack
		  the time to give individual feedback to each student. That
		  is why it is important to equip children with tools that
		  can provide immediate feedback and thus enhance their
		  independent learning skills. This article presents Blink, a
		  debugging tool specifically designed for Scratch, the most
		  commonly taught programming language for children. Blink
		  comes with basic debugging features such as `step' and
		  `pause', allowing precise monitoring of the execution of
		  Scratch programs. It also provides users with more advanced
		  debugging options, such as back-in-time debugging and
		  programmable pause. A group of children attending an
		  extracurricular coding class have been testing the
		  usefulness of Blink. Feedback from these young users
		  indicates that Blink helps them pinpoint programming errors
		  more accurately, and they have expressed an overall
		  positive view of the tool.},
  keywords	= {Block-based programming,Debugging,Programming,Scratch}
}

@InProceedings{	  sulzmann06,
  title		= {A {{Framework}} for {{Extended Algebraic Data Types}}},
  booktitle	= {Functional and {{Logic Programming}}},
  author	= {Sulzmann, Martin and Wazny, Jeremy and Stuckey, Peter J.},
  editor	= {Hagiya, Masami and Wadler, Philip},
  year		= {2006},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {47--64},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/11737414_5},
  abstract	= {There are a number of extended forms of algebraic data
		  types such as type classes with existential types and
		  generalized algebraic data types. Such extensions are
		  highly useful but their interaction has not been studied
		  formally so far. Here, we present a unifying framework for
		  these extensions. We show that the combination of type
		  classes and generalized algebraic data types allows us to
		  express a number of interesting properties which are
		  desired by programmers. We support type checking based on a
		  novel constraint solver. Our results show that our system
		  is practical and greatly extends the expressive power of
		  languages such as Haskell and ML.},
  isbn		= {978-3-540-33439-2},
  langid	= {english},
  keywords	= {Functional Dependency,Type Check,Type Class,Type
		  Inference,Typing Rule}
}

@Article{	  sundaram13,
  title		= {Diagnostic Tracing for Wireless Sensor Networks},
  author	= {Sundaram, Vinaitheerthan and Eugster, Patrick and Zhang,
		  Xiangyu and Addanki, Vamsidhar},
  year		= {2013},
  month		= jul,
  journal	= {ACM Transactions on Sensor Networks},
  volume	= {9},
  number	= {4},
  pages		= {38:1--38:41},
  issn		= {1550-4859},
  doi		= {10.1145/2489253.2489255},
  urldate	= {2024-02-29},
  abstract	= {Wireless sensor networks are typically deployed in harsh
		  environments, thus post-deployment failures are not
		  infrequent. An execution trace containing events in their
		  order of execution could play a crucial role in postmortem
		  diagnosis of these failures. Obtaining such a trace however
		  is challenging due to stringent resource constraints. We
		  propose an efficient approach to intraprocedural and
		  interprocedural control-flow tracing that generates traces
		  of all interleaving concurrent events and of the
		  control-flow paths taken inside those events. We
		  demonstrate the effectiveness of our approach with the help
		  of case studies and illustrate its low overhead through
		  measurements and simulations.},
  keywords	= {diagnosis,Embedded debugging,tracing,wireless sensor
		  networks}
}

@InProceedings{	  tabar22,
  title		= {Automatic Loop Invariant Generation for Data Dependence
		  Analysis},
  booktitle	= {Proceedings of the {{IEEE}}/{{ACM}} 10th {{International
		  Conference}} on {{Formal Methods}} in {{Software
		  Engineering}}},
  author	= {Tabar, Asmae Heydari and Bubel, Richard and H{\"a}hnle,
		  Reiner},
  year		= {2022},
  month		= jul,
  series	= {{{FormaliSE}} '22},
  pages		= {34--45},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3524482.3527649},
  urldate	= {2024-01-22},
  abstract	= {Parallelization of programs relies on sound and precise
		  analysis of data dependences in the code, specifically,
		  when dealing with loops. State-of-art tools are based on
		  dynamic profiling and static analysis. They tend to over-
		  and, occasionally, to under-approximate dependences. The
		  former misses parallelization opportunities, the latter can
		  change the behavior of the parallelized program. In this
		  paper we present a sound and highly precise approach to
		  generate data dependences based on deductive verification.
		  The central technique is to infer a specific form of loop
		  invariant tailored to express dependences. To achieve full
		  automation, we adapt predicate abstraction in a suitable
		  manner. To retain as much precision as possible, we
		  generalized logic-based symbolic execution to compute
		  abstract dependence predicates. We implemented our approach
		  for Java on top of a deductive verification tool. The
		  evaluation shows that our approach can generate highly
		  precise data dependences for representative code taken from
		  HPC applications.},
  isbn		= {978-1-4503-9287-7},
  keywords	= {data dependence analysis,loop invariant
		  generation,predicate abstraction}
}

@InProceedings{	  tan09,
  title		= {Real-Time Operating System ({{RTOS}}) for Small (16-Bit)
		  Microcontroller},
  booktitle	= {2009 {{IEEE}} 13th {{International Symposium}} on
		  {{Consumer Electronics}}},
  author	= {Tan, Su-Lim and Anh, Tran Nguyen Bao},
  year		= {2009},
  month		= may,
  pages		= {1007--1011},
  issn		= {2159-1423},
  doi		= {10.1109/ISCE.2009.5156833},
  urldate	= {2023-10-12},
  abstract	= {Real-time operating system (RTOS) is gaining increasing
		  use not only in 32-bit systems but also in 16-bit systems.
		  RTOS is different from generic OS by several unique
		  characteristics and the use of RTOS in embedded system
		  development proves to be more advantageous. In this paper,
		  9 RTOSes targeting smaller processors have been evaluated
		  and four of the RTOSes have been selected for performance
		  benchmarking on the same M16/62P microcontroller platform
		  to avoid bias. Based on the comparison, the {$\mu$}TKernel
		  RTOS is chosen for porting to the H8S/2377 16-bit
		  microcontroller to demonstrate the ease of RTOS platform
		  migration. The same version of {$\mu$}TKernel RTOS running
		  on different platforms are then compared. Lastly, an
		  application is developed with the RTOS to demonstrate the
		  ease of multi-task application development on such
		  microcontroller platform.}
}

@InProceedings{	  terry02,
  title		= {Side Views: Persistent, on-Demand Previews for Open-Ended
		  Tasks},
  shorttitle	= {Side Views},
  booktitle	= {Proceedings of the 15th Annual {{ACM}} Symposium on
		  {{User}} Interface Software and Technology},
  author	= {Terry, Michael and Mynatt, Elizabeth D.},
  year		= {2002},
  month		= oct,
  series	= {{{UIST}} '02},
  pages		= {71--80},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/571985.571996},
  urldate	= {2024-10-30},
  abstract	= {We introduce Side Views, a user interface mechanism that
		  provides on-demand, persistent, and dynamic previews of
		  commands. Side Views are designed to explicitly support the
		  practices and needs of expert users engaged in openended
		  tasks. In this paper, we summarize results from field
		  studies of expert users that motivated this work, then
		  discuss the design of Side Views in detail. We show how
		  Side Views' design affords their use as tools for
		  clarifying, comparing, and contrasting commands; generating
		  alternative visualizations; experimenting without modifying
		  the original data (i.e., "what-if" tools); and as tools
		  that support the serendipitous discovery of viable
		  alternatives. We then convey lessons learned from
		  implementing Side Views in two sample applications, a rich
		  text editor and an image manipulation application. These
		  contributions include a discussion of how to implement Side
		  Views for commands with parameters, for commands that
		  require direct user input (such as mouse strokes for a
		  paint program), and for computationally-intensive
		  commands.},
  isbn		= {978-1-58113-488-9}
}

@InProceedings{	  terry04,
  title		= {Variation in Element and Action: Supporting Simultaneous
		  Development of Alternative Solutions},
  shorttitle	= {Variation in Element and Action},
  booktitle	= {Proceedings of the {{SIGCHI Conference}} on {{Human
		  Factors}} in {{Computing Systems}}},
  author	= {Terry, Michael and Mynatt, Elizabeth D. and Nakakoji,
		  Kumiyo and Yamamoto, Yasuhiro},
  year		= {2004},
  month		= apr,
  series	= {{{CHI}} '04},
  pages		= {711--718},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/985692.985782},
  urldate	= {2024-10-30},
  abstract	= {The complexity of many problems necessitates creating and
		  exploring multiple, alternative solutions. However, current
		  user interfaces do not cleanly support creating
		  alternatives at a time when they are likely to be
		  discovered: as users interactively modify data. This paper
		  presents Parallel Paths, a novel model of interaction that
		  facilitates generating, manipulating, and comparing
		  alternative solutions. In contrast to existing approaches
		  such as automated history capture tools, Parallel Paths
		  emphasizes the active, simultaneous development of
		  multiple, alternative solutions. We demonstrate this model
		  of interaction in Parallel Pies, a user interface mechanism
		  developed for image manipulation tasks that allows users
		  to: easily create solution alternatives as they interact
		  with a command; embed the alternatives in the same
		  workspace; manipulate the alternatives independently or
		  simultaneously as if they were the same object; and perform
		  side-by-side comparisons of each. Results from an initial
		  evaluation are presented, along with implications for
		  future designs.},
  isbn		= {978-1-58113-702-6}
}

@InProceedings{	  tiks24,
  title		= {A {{Reversible Debugger}} for {{MPI Applications}}},
  booktitle	= {Proceedings of the 2nd {{ACM International Workshop}} on
		  {{Future Debugging Techniques}}},
  author	= {Tiks, Mihkel and Martens, Ott-Kaarel and Vainikko, Eero
		  and Kuhn, Stefan},
  year		= {2024},
  month		= sep,
  series	= {{{DEBT}} 2024},
  pages		= {16--21},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3678720.3685316},
  urldate	= {2024-11-13},
  abstract	= {Cluster machines are gaining importance, for example in
		  high-performance computing and eScience. For this, programs
		  need to be parallelized and run with appropriate tools,
		  typically MPI (Message Passing Interface) in a scientific
		  context. Since writing programs for parallel computation is
		  significantly more difficult than programming for
		  sequential execution, debugging tools, which are considered
		  a necessary part of the toolset of software developers, are
		  of even higher importance there. Reversibility, providing
		  the ability to progress backwards in the program execution
		  in some form, has been added to some debuggers and is a
		  useful feature for debugging MPI applications as well. This
		  paper presents a debugger for MPI applications which offers
		  reversible debugging commands. This is done using a
		  checkpoint-restore mechanism. We demonstrate the viability
		  of this approach to enable reversible debugging for
		  parallel computation.},
  isbn		= {9798400711107}
}

@InProceedings{	  toffoli80,
  title		= {Reversible Computing},
  booktitle	= {Automata, {{Languages}} and {{Programming}}},
  author	= {Toffoli, Tommaso},
  editor	= {{de Bakker}, Jaco and {van Leeuwen}, Jan},
  year		= {1980},
  pages		= {632--644},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-10003-2_104},
  abstract	= {The theory of reversible computing is based on invertible
		  primitives and composition rules that preserve
		  invertibility. With these constraints, one can still
		  satisfactorily deal with both functional and structural
		  aspects of computing processes; at the same time, one
		  attains a closer correspondence between the behavior of
		  abstract computing systems and the microscopic physical
		  laws (which are presumed to be strictly reversible) that
		  underly any concrete implementation of such systems.},
  isbn		= {978-3-540-39346-7},
  langid	= {english}
}

@Article{	  tolmach95,
  title		= {A {{Debugger}} for {{Standard ML}}},
  author	= {Tolmach, Andrew and Appel, Andrew W.},
  year		= {1995},
  month		= apr,
  journal	= {Journal of Functional Programming},
  volume	= {5},
  number	= {2},
  pages		= {155--200},
  publisher	= {Cambridge University Press},
  issn		= {1469-7653, 0956-7968},
  doi		= {10.1017/S0956796800001313},
  urldate	= {2023-09-28},
  abstract	= {We have built a portable, instrumentation-based, replay
		  debugger for the Standard ML of New Jersey compiler.
		  Traditional `source-level' debuggers for compiled languages
		  actually operate at machine level, which makes them
		  complex, difficult to port, and intolerant of compiler
		  optimization. For secure languages like ML, however,
		  debugging support can be provided without reference to the
		  underlying machine, by adding instrumentation to program
		  source code before compilation. Because instrumented code
		  is (almost) ordinary source, it can be processed by the
		  ordinary compiler. Our debugger is thus independent from
		  the underlying hardware and runtime system, and from the
		  optimization strategies used by the compiler. The debugger
		  also provides reverse execution, both as a user feature and
		  an internal mechanism. Reverse execution is implemented
		  using a checkpoint and replay system; checkpoints are
		  represented primarily by first-class continuations.},
  langid	= {english}
}

@InProceedings{	  torres19,
  title		= {Multiverse {{Debugging}}: {{Non-Deterministic Debugging}}
		  for {{Non-Deterministic Programs}} ({{Brave New Idea
		  Paper}})},
  shorttitle	= {Multiverse {{Debugging}}},
  booktitle	= {{{DROPS-IDN}}/v2/Document/10.4230/{{LIPIcs}}.{{ECOOP}}.2019.27},
  author	= {Torres Lopez, Carmen and Gurdeep Singh, Robbert and Marr,
		  Stefan and Gonzalez Boix, Elisa and Scholliers,
		  Christophe},
  year		= {2019},
  publisher	= {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  doi		= {10.4230/LIPIcs.ECOOP.2019.27},
  urldate	= {2024-03-11},
  abstract	= {Many of today's software systems are parallel or
		  concurrent. With the rise of Node.js and more generally
		  event-loop architectures, many systems need to handle
		  concurrency. However, its non-deterministic behavior makes
		  it hard to reproduce bugs. Today's interactive debuggers
		  unfortunately do not support developers in debugging
		  non-deterministic issues. They only allow us to explore a
		  single execution path. Therefore, some bugs may never be
		  reproduced in the debugging session, because the right
		  conditions are not triggered. As a solution, we propose
		  multiverse debugging, a new approach for debugging
		  non-deterministic programs that allows developers to
		  observe all possible execution paths of a parallel program
		  and debug it interactively. We introduce the concepts of
		  multiverse breakpoints and stepping, which can halt a
		  program in different execution paths, i.e. universes. We
		  apply multiverse debugging to AmbientTalk, an actor-based
		  language, resulting in Voyager, a multiverse debugger
		  implemented on top of the AmbientTalk operational
		  semantics. We provide a proof of non-interference, i.e., we
		  prove that observing the behavior of a program by the
		  debugger does not affect the behavior of that program and
		  vice versa. Multiverse debugging establishes the foundation
		  for debugging non-deterministic programs interactively,
		  which we believe can aid the development of parallel and
		  concurrent systems.},
  copyright	= {https://creativecommons.org/licenses/by/3.0/legalcode},
  langid	= {english}
}

@Book{		  torres21,
  title		= {Advanced {{Debugging Techniques}} to {{Handle Concurrency
		  Bugs}} in {{Actor-based Applications}}},
  author	= {Torres L{\'o}pez, Carmen},
  year		= {2021},
  month		= jun,
  isbn		= {978-94-93079-89-2},
  langid	= {english}
}

@InProceedings{	  tso13,
  title		= {The {{Glasgow Raspberry Pi Cloud}}: {{A Scale Model}} for
		  {{Cloud Computing Infrastructures}}},
  shorttitle	= {The {{Glasgow Raspberry Pi Cloud}}},
  booktitle	= {2013 {{IEEE}} 33rd {{International Conference}} on
		  {{Distributed Computing Systems Workshops}}},
  author	= {Tso, Fung Po and White, David R. and Jouet, Simon and
		  Singer, Jeremy and Pezaros, Dimitrios P.},
  year		= {2013},
  month		= jul,
  pages		= {108--112},
  issn		= {2332-5666},
  doi		= {10.1109/ICDCSW.2013.25},
  urldate	= {2024-01-18},
  abstract	= {Data Centers (DC) used to support Cloud services often
		  consist of tens of thousands of networked machines under a
		  single roof. The significant capital outlay required to
		  replicate such infrastructures constitutes a major obstacle
		  to practical implementation and evaluation of research in
		  this domain. Currently, most research into Cloud computing
		  relies on either limited software simulation, or the use of
		  a testbed environments with a handful of machines. The
		  recent introduction of the Raspberry Pi, a low-cost,
		  low-power single-board computer, has made the construction
		  of a miniature Cloud DCs more affordable. In this paper, we
		  present the Glasgow Raspberry Pi Cloud (PiCloud), a scale
		  model of a DC composed of clusters of Raspberry Pi devices.
		  The PiCloud emulates every layer of a Cloud stack, ranging
		  from resource virtualisation to network behaviour,
		  providing a full-featured Cloud Computing research and
		  educational environment.}
}

@Article{	  turing37,
  title		= {On {{Computable Numbers}}, with an {{Application}} to the
		  {{Entscheidungsproblem}}},
  author	= {Turing, A. M.},
  year		= {1937},
  journal	= {Proceedings of the London Mathematical Society},
  volume	= {s2-42},
  number	= {1},
  pages		= {230--265},
  issn		= {1460-244X},
  doi		= {10.1112/plms/s2-42.1.230},
  urldate	= {2023-12-01},
  copyright	= {{\copyright} 1937 London Mathematical Society},
  langid	= {english}
}

@Article{	  tyler23,
  title		= {{{UCCA}}: {{A Verified Architecture}} for
		  {{Compartmentalization}} of {{Untrusted Code Sections}} in
		  {{Resource-Constrained Devices}}},
  shorttitle	= {{{UCCA}}},
  author	= {Tyler, Liam and Nunes, Ivan De Oliveira},
  year		= {2023},
  publisher	= {arXiv},
  doi		= {10.48550/ARXIV.2312.02348},
  urldate	= {2024-01-18},
  abstract	= {Micro-controller units (MCUs) implement the de facto
		  interface between the physical and digital worlds. As a
		  consequence, they appear in a variety of sensing/actuation
		  applications, from smart personal spaces to complex
		  industrial control systems and safety-critical medical
		  equipment. While many of these devices perform safety- and
		  time-critical tasks, they often lack support for security
		  features compatible with their importance to overall system
		  functions. This lack of architectural support leaves them
		  vulnerable to run-time attacks that can remotely alter
		  their intended behavior, with potentially catastrophic
		  consequences. In particular, we note that MCU software
		  often includes untrusted third-party libraries (some of
		  them closed-source) that are blindly used within MCU
		  programs, without proper isolation from the rest of the
		  system. In turn, a single vulnerability (or intentional
		  backdoor) in one such third-party software can often
		  compromise the entire MCU software state. In this paper, we
		  tackle this problem by proposing, demonstrating security,
		  and formally verifying the implementation of UCCA: an
		  Untrusted Code Compartment Architecture. UCCA provides
		  flexible hardware-enforced isolation of untrusted code
		  sections (e.g., third-party software modules) in
		  resource-constrained and time-critical MCUs. To demonstrate
		  UCCA's practicality, we implement an open-source version of
		  the design on a real resource-constrained MCU: the
		  well-known TI MSP430. Our evaluation shows that UCCA incurs
		  little overhead and is affordable even to lowest-end MCUs,
		  requiring significantly less overhead and assumptions than
		  prior related work.},
  copyright	= {arXiv.org perpetual, non-exclusive license},
  keywords	= {Cryptography and Security (cs.CR),FOS: Computer and
		  information sciences}
}

@InCollection{	  valmari98,
  title		= {The State Explosion Problem},
  booktitle	= {Lectures on {{Petri Nets I}}: {{Basic Models}}:
		  {{Advances}} in {{Petri Nets}}},
  author	= {Valmari, Antti},
  editor	= {Reisig, Wolfgang and Rozenberg, Grzegorz},
  year		= {1998},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {429--528},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/3-540-65306-6_21},
  urldate	= {2023-12-13},
  abstract	= {State space methods are one of the most important
		  approaches to computer-aided analysis and verification of
		  the behaviour of concurrent systems. In their basic form,
		  they consist of enumerating and analysing the set of the
		  states the system can ever reach. Unfortunately, the number
		  of states of even a relatively small system is often far
		  greater than can be handled in a realistic computer. The
		  goal of this article is to analyse this state explosion
		  problem from several perspectives. Many advanced state
		  space methods alleviate the problem by using a subset or an
		  abstraction of the set of states. Unfortunately, their use
		  tends to restrict the set of analysis or verification
		  questions that can be answered, making it impossible to
		  discuss the methods without some taxonomy of the questions.
		  Therefore, the article contains a lengthy discussion on
		  alternative ways of stating analysis and verification
		  questions, and algorithms for answering them. After that,
		  many advanced state space methods are briefly described.
		  The state explosion problem is investigated also from the
		  computational complexity point of view.},
  isbn		= {978-3-540-49442-3},
  langid	= {english},
  keywords	= {Communicate Sequential Process,Coverability Graph,Linear
		  Temporal Logic,Liveness Property,Model Check}
}

@Article{	  vandewoude07,
  title		= {Tranquility: {{A Low Disruptive Alternative}} to
		  {{Quiescence}} for {{Ensuring Safe Dynamic Updates}}},
  shorttitle	= {Tranquility},
  author	= {Vandewoude, Yves and Ebraert, Peter and Berbers, Yolande
		  and D'Hondt, Theo},
  year		= {2007},
  month		= dec,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {33},
  number	= {12},
  pages		= {856--868},
  issn		= {1939-3520},
  doi		= {10.1109/TSE.2007.70733},
  urldate	= {2024-01-16},
  abstract	= {This paper revisits a problem that was identified by
		  Kramer and Magee: placing a system in a consistent state
		  before and after runtime changes. We show that their notion
		  of quiescence as a necessary and sufficient condition for
		  safe runtime changes is too strict and results in a
		  significant disruption in the application being updated. In
		  this paper, we introduce a weaker condition: tranquillity.
		  We show that tranquillity is easier to obtain and less
		  disruptive for the running application but still a
		  sufficient condition to ensure application consistency. We
		  present an implementation of our approach on a component
		  middleware platform and experimentally verify the validity
		  and practical applicability of our approach using data
		  retrieved from a case study.}
}

@Book{		  vansickle01,
  title		= {Programming {{Microcontrollers}} in {{C}}},
  author	= {VanSickle, Ted},
  year		= {2001},
  publisher	= {Newnes},
  abstract	= {Ted Van Sickle spent over fifteen years at Motorola as a
		  microcontroller specialist. He now consults and teaches
		  classes on software design and programming for
		  microcontroller systems. He holds a MSEE from the
		  University of Michigan. Introduces microcontrollers and
		  describes their programming environment, offering tips on
		  coding for microcontrollersDescribes techniques to get
		  maximum performance from your codeDiscusses the differences
		  between 8-bit and larger microcontrollers, giving
		  application examples and providing details on using
		  different compilers},
  googlebooks	= {i62vDVOJ3YgC},
  isbn		= {978-1-878707-57-4},
  langid	= {english},
  keywords	= {Computers / Hardware / Chips & Processors,Technology &
		  Engineering / Electronics / General,Technology &
		  Engineering / Electronics / Microelectronics}
}

@InProceedings{	  vekris16,
  title		= {Refinement Types for {{TypeScript}}},
  booktitle	= {Proceedings of the 37th {{ACM SIGPLAN Conference}} on
		  {{Programming Language Design}} and {{Implementation}}},
  author	= {Vekris, Panagiotis and Cosman, Benjamin and Jhala,
		  Ranjit},
  year		= {2016},
  month		= jun,
  series	= {{{PLDI}} '16},
  pages		= {310--325},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/2908080.2908110},
  urldate	= {2024-12-18},
  abstract	= {We present Refined TypeScript (RSC), a lightweight
		  refinement type system for TypeScript, that enables static
		  verification of higher-order, imperative programs. We
		  develop a formal system for RSC that delineates the
		  interaction between refinement types and mutability, and
		  enables flow-sensitive reasoning by translating input
		  programs to an equivalent intermediate SSA form. By
		  establishing type safety for the intermediate form, we
		  prove safety for the input programs. Next, we extend the
		  core to account for imperative and dynamic features of
		  TypeScript, including overloading, type reflection, ad hoc
		  type hierarchies and object initialization. Finally, we
		  evaluate RSC on a set of real-world benchmarks, including
		  parts of the Octane benchmarks, D3, Transducers, and the
		  TypeScript compiler. We show how RSC successfully
		  establishes a number of value dependent properties, such as
		  the safety of array accesses and downcasts, while incurring
		  a modest overhead in type annotations and code
		  restructuring.},
  isbn		= {978-1-4503-4261-2}
}

@Article{	  venkatesh91,
  title		= {The Semantic Approach to Program Slicing},
  author	= {Venkatesh, G. A.},
  year		= {1991},
  month		= may,
  journal	= {ACM SIGPLAN Notices},
  volume	= {26},
  number	= {6},
  pages		= {107--119},
  issn		= {0362-1340},
  doi		= {10.1145/113446.113455},
  urldate	= {2023-11-07}
}

@InProceedings{	  villegas19,
  title		= {A Study of Over-the-Air ({{OTA}}) Update Systems for
		  {{CPS}} and {{IoT}} Operating Systems},
  booktitle	= {Proceedings of the 13th {{European Conference}} on
		  {{Software Architecture}} - {{Volume}} 2},
  author	= {Villegas, M{\'o}nica M. and Orellana, Cristian and
		  Astudillo, Hern{\'a}n},
  year		= {2019},
  month		= sep,
  series	= {{{ECSA}} '19},
  pages		= {269--272},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3344948.3344972},
  urldate	= {2024-01-16},
  abstract	= {There is growing use of Internet-of-Things (IoT) and
		  Cyber-Physical Systems (CPS) in industry, homes, cars, and
		  other environments, and several operating systems have been
		  proposed to manage these environments. The growing use of
		  long-lived IoT and CPS has made them susceptible to
		  obsolescence and change, just like "normal" software,
		  demanding systematic support for periodic updates of their
		  embedded software. However, there is little empirical data
		  about the structure, architecture, specifications, and
		  dependencies of these subsystems. This article presents an
		  analysis of over-the-air (OTA) update support in 26
		  existing open-source IoT/CPS operating systems and embedded
		  software projects, performed primarily by examining their
		  documentation and supplementing with occasional source code
		  examination. We found that seven projects give details of
		  an OTA update mechanism; four projects do not report
		  details of OTA update mechanisms, but third-party
		  developers implemented specific solutions to support OTA
		  updates using these projects; and the remaining 15 projects
		  do not report a particular update capability at all in
		  their documentation. This study will allow extending,
		  organize, and compare OTA update capabilities of future
		  IoT/CPS operating systems.},
  isbn		= {978-1-4503-7142-1},
  keywords	= {cyber-physical systems,IoT,operating systems,OTA updates}
}

@Article{	  vishwakarma18,
  title		= {Exploiting {{JTAG}} and {{Its Mitigation}} in {{IOT}}: {{A
		  Survey}}},
  shorttitle	= {Exploiting {{JTAG}} and {{Its Mitigation}} in {{IOT}}},
  author	= {Vishwakarma, Gopal and Lee, Wonjun},
  year		= {2018},
  month		= dec,
  journal	= {Future Internet},
  volume	= {10},
  number	= {12},
  pages		= {121},
  publisher	= {Multidisciplinary Digital Publishing Institute},
  issn		= {1999-5903},
  doi		= {10.3390/fi10120121},
  urldate	= {2024-11-13},
  abstract	= {Nowadays, companies are heavily investing in the
		  development of ``Internet of Things(IoT)'' products. These
		  companies usually and obviously hunt for lucrative business
		  models. Currently, each person owns at least 3--4 devices
		  (such as mobiles, personal computers, Google Assistant,
		  Alexa, etc.) that are connected to the Internet 24/7.
		  However, in the future, there might be hundreds of devices
		  that will be constantly online behind each person, keeping
		  track of body health, banking transactions, status of
		  personal devices, etc. to make one's life more efficient
		  and streamlined. Thus, it is very crucial that each device
		  should be highly secure since one's life will become
		  dependent on these devices. However, the current security
		  of IoT devices is mainly focused on resiliency of device.
		  In addition, less complex node devices are easily
		  accessible to the public resulting in higher vulnerability.
		  JTAG is an IEEE standard that has been defined to test
		  proper mounting of components on PCBs (printed circuit
		  boards) and has been extensively used by PCB manufacturers
		  to date. This JTAG interface can be used as a backdoor
		  entry to access and exploit devices, also defined as a
		  physical attack. This attack can be used to make products
		  malfunction, modify data, or, in the worst case, stop
		  working. This paper reviews previous successful JTAG
		  exploitations of well-known devices operating online and
		  also reviews some proposed possible solutions to see how
		  they can affect IoT products in a broader sense.},
  copyright	= {http://creativecommons.org/licenses/by/3.0/},
  langid	= {english},
  keywords	= {a survey,exploitation,Internet of
		  Things,IOT,JTAG,mitigation}
}

@InProceedings{	  vouillon04,
  title		= {Semantic Types: A Fresh Look at the Ideal Model for
		  Types},
  shorttitle	= {Semantic Types},
  booktitle	= {Proceedings of the 31st {{ACM SIGPLAN-SIGACT}} Symposium
		  on {{Principles}} of Programming Languages},
  author	= {Vouillon, Jerome and Melli{\`e}s, Paul-Andr{\'e}},
  year		= {2004},
  month		= jan,
  series	= {{{POPL}} '04},
  pages		= {52--63},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/964001.964006},
  urldate	= {2023-09-26},
  abstract	= {We present a generalization of the ideal model for
		  recursive polymorphic types. Types are defined as sets of
		  terms instead of sets of elements of a semantic domain. Our
		  proof of the existence of types (computed by fixpoint of a
		  typing operator) does not rely on metric properties, but on
		  the fact that the identity is the limit of a sequence of
		  projection terms. This establishes a connection with the
		  work of Pitts on relational properties of domains. This
		  also suggests that ideals are better understood as closed
		  sets of terms defined by orthogonality with respect to a
		  set of contexts.},
  isbn		= {978-1-58113-729-3},
  keywords	= {ideal model,inductive/coinductive
		  principle,polymorphism,realizability,recursive
		  types,subtyping}
}

@InProceedings{	  ward03,
  title		= {Slicing the {{SCAM}} Mug: A Case Study in Semantic
		  Slicing},
  shorttitle	= {Slicing the {{SCAM}} Mug},
  booktitle	= {Proceedings {{Third IEEE International Workshop}} on
		  {{Source Code Analysis}} and {{Manipulation}}},
  author	= {Ward, M.P.},
  year		= {2003},
  month		= sep,
  pages		= {88--97},
  doi		= {10.1109/SCAM.2003.1238035},
  urldate	= {2023-11-30},
  abstract	= {We describe an improved formalisation of slicing in WSL
		  transformation theory and apply the result to a
		  particularly challenging slicing problem: the SCAM mug
		  (Anon, 2001). We present both syntactic and semantic slices
		  of the mug program and give semantic slices for various
		  generalisations of the program. Although there is no
		  algorithm for constructing a minimal syntactic slice, we
		  show that it is possible, in the WSL language, to derive a
		  minimal semantic slice for any program and any slicing
		  criteria.}
}

@InProceedings{	  watson15,
  title		= {{{CHERI}}: {{A Hybrid Capability-System Architecture}} for
		  {{Scalable Software Compartmentalization}}},
  shorttitle	= {{{CHERI}}},
  booktitle	= {2015 {{IEEE Symposium}} on {{Security}} and {{Privacy}}},
  author	= {Watson, Robert N.M. and Woodruff, Jonathan and Neumann,
		  Peter G. and Moore, Simon W. and Anderson, Jonathan and
		  Chisnall, David and Dave, Nirav and Davis, Brooks and
		  Gudka, Khilan and Laurie, Ben and Murdoch, Steven J. and
		  Norton, Robert and Roe, Michael and Son, Stacey and Vadera,
		  Munraj},
  year		= {2015},
  month		= may,
  pages		= {20--37},
  issn		= {2375-1207},
  doi		= {10.1109/SP.2015.9},
  urldate	= {2024-01-18},
  abstract	= {CHERI extends a conventional RISC Instruction-Set
		  Architecture, compiler, and operating system to support
		  fine-grained, capability-based memory protection to
		  mitigate memory-related vulnerabilities in C-language TCBs.
		  We describe how CHERI capabilities can also underpin a
		  hardware-software object-capability model for application
		  compartmentalization that can mitigate broader classes of
		  attack. Prototyped as an extension to the open-source
		  64-bit BERI RISC FPGA soft-core processor, Free BSD
		  operating system, and LLVM compiler, we demonstrate
		  multiple orders-of-magnitude improvement in scalability,
		  simplified programmability, and resulting tangible security
		  benefits as compared to compartmentalization based on pure
		  Memory-Management Unit (MMU) designs. We evaluate
		  incrementally deployable CHERI-based compartmentalization
		  using several real-world UNIX libraries and applications.}
}

@Article{	  watt19,
  title		= {Weakening {{WebAssembly}}},
  author	= {Watt, Conrad and Rossberg, Andreas and {Pichon-Pharabod},
		  Jean},
  year		= {2019},
  month		= oct,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {3},
  number	= {OOPSLA},
  pages		= {133:1--133:28},
  doi		= {10.1145/3360559},
  urldate	= {2023-12-06},
  abstract	= {WebAssembly (Wasm) is a safe, portable virtual instruction
		  set that can be hosted in a wide range of environments,
		  such as a Web browser. It is a low-level language whose
		  instructions are intended to compile directly to bare
		  hardware. While the initial version of Wasm focussed on
		  single-threaded computation, a recent proposal extends it
		  with low-level support for multiple threads and atomic
		  instructions for synchronised access to shared memory. To
		  support the correct compilation of concurrent programs, it
		  is necessary to give a suitable specification of its memory
		  model. Wasm's language definition is based on a fully
		  formalised specification that carefully avoids undefined
		  behaviour. We present a substantial extension to this
		  semantics, incorporating a relaxed memory model, along with
		  a few proposed extensions. Wasm's memory model is unique in
		  that its linear address space can be dynamically grown
		  during execution, while all accesses are bounds-checked.
		  This leads to the novel problem of specifying how
		  observations about the size of the memory can propagate
		  between threads. We argue that, considering desirable
		  compilation schemes, we cannot give a sequentially
		  consistent semantics to memory growth. We show that our
		  model provides sequential consistency for data-race-free
		  executions (SC-DRF). However, because Wasm is to run on the
		  Web, we must also consider interoperability of its model
		  with that of JavaScript. We show, by counter-example, that
		  JavaScript's memory model is not SC-DRF, in contrast to
		  what is claimed in its specification. We propose two
		  axiomatic conditions that should be added to the JavaScript
		  model to correct this difference. We also describe a
		  prototype SMT-based litmus tool which acts as an oracle for
		  our axiomatic model, visualising its behaviours, including
		  memory resizing.},
  keywords	= {assembly languages,just-in-time compilers,programming
		  languages,type systems,Virtual machines}
}

@InProceedings{	  watt21,
  title		= {Two {{Mechanisations}} of {{WebAssembly}} 1.0},
  booktitle	= {Formal {{Methods}}},
  author	= {Watt, Conrad and Rao, Xiaojia and {Pichon-Pharabod}, Jean
		  and Bodin, Martin and Gardner, Philippa},
  editor	= {Huisman, Marieke and P{\u a}s{\u a}reanu, Corina and Zhan,
		  Naijun},
  year		= {2021},
  series	= {Lecture {{Notes}} in {{Computer Science}}},
  pages		= {61--79},
  publisher	= {Springer International Publishing},
  address	= {Cham},
  doi		= {10.1007/978-3-030-90870-6_4},
  abstract	= {WebAssembly (Wasm) is a new bytecode language supported by
		  all major Web browsers, designed primarily to be an
		  efficient compilation target for low-level languages such
		  as C/C++ and Rust. It is unusual in that it is officially
		  specified through a formal semantics. An initial draft
		  specification was published in 2017~[14], with an
		  associated mechanised specification in Isabelle/HOL
		  published by Watt that found bugs in the original
		  specification, fixed before its publication~[37].},
  isbn		= {978-3-030-90870-6},
  langid	= {english},
  keywords	= {Mechanised specification,Type soundness,WasmCert}
}

@Article{	  webbers24,
  title		= {Refinement {{Type Refutations}}},
  author	= {Webbers, Robin and {von Gleissenthall}, Klaus and Jhala,
		  Ranjit},
  year		= {2024},
  month		= oct,
  journal	= {Proc. ACM Program. Lang.},
  volume	= {8},
  number	= {OOPSLA2},
  pages		= {305:962--305:987},
  doi		= {10.1145/3689745},
  urldate	= {2024-12-17},
  abstract	= {Refinement types combine SMT decidable constraints with a
		  compositional, syntax-directed type system to provide a
		  convenient way to statically and automatically check
		  properties of programs. However, when type checking fails,
		  programmers must use cryptic error messages that, at best,
		  point out the code location where a subtyping constraint
		  failed to determine the root cause of the failure. In this
		  paper, we introduce refinement type refutations, a new
		  approach to explaining why refinement type checking fails,
		  which mirrors the compositional way in which refinement
		  type checking is carried out. First, we show how to
		  systematically transform standard bidirectional type
		  checking rules to obtain refutations. Second, we extend the
		  approach to account for global constraint-based refinement
		  inference via the notion of a must-instantiation: a set of
		  concrete inhabitants of the types of subterms that suffice
		  to demonstrate why typing fails. Third, we implement our
		  method in HayStack---an extension to LiqidHaskell which
		  automatically finds type-refutations when refinement type
		  checking fails, and helps users understand refutations via
		  an interactive user-interface. Finally, we present an
		  empirical evaluation of HayStack using the regression
		  benchmark-set of LiqidHaskell, and the benchmark set of G2,
		  a previous method that searches for (non-compositional)
		  counterexample traces by symbolically executing Haskell
		  source. We show that HayStack can find refutations for
		  99.7\% of benchmarks, including those with complex typing
		  constructs (e.g., abstract and bounded refinements, and
		  reflection), and does so, an order of magnitude faster than
		  G2.}
}

@Article{	  weirich17,
  title		= {A Specification for Dependent Types in {{Haskell}}},
  author	= {Weirich, Stephanie and Voizard, Antoine and {de Amorim},
		  Pedro Henrique Azevedo and Eisenberg, Richard A.},
  year		= {2017},
  month		= aug,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {1},
  number	= {ICFP},
  pages		= {31:1--31:29},
  doi		= {10.1145/3110275},
  urldate	= {2024-01-10},
  abstract	= {We propose a core semantics for Dependent Haskell, an
		  extension of Haskell with full-spectrum dependent types.
		  Our semantics consists of two related languages. The first
		  is a Curry-style dependently-typed language with
		  nontermination, irrelevant arguments, and equality
		  abstraction. The second, inspired by the Glasgow Haskell
		  Compiler's core language FC, is its explicitly-typed
		  analogue, suitable for implementation in GHC. All of our
		  results---chiefly, type safety, along with theorems that
		  relate these two languages---have been formalized using the
		  Coq proof assistant. Because our work is backwards
		  compatible with Haskell, our type safety proof holds in the
		  presence of nonterminating computation. However, unlike
		  other full-spectrum dependently-typed languages, such as
		  Coq, Agda or Idris, because of this nontermination,
		  Haskell's term language does not correspond to a consistent
		  logic.},
  keywords	= {Dependent Types,Haskell}
}

@InProceedings{	  weiser81,
  title		= {Program Slicing},
  booktitle	= {Proceedings of the 5th International Conference on
		  {{Software}} Engineering},
  author	= {Weiser, Mark},
  year		= {1981},
  month		= mar,
  series	= {{{ICSE}} '81},
  pages		= {439--449},
  publisher	= {IEEE Press},
  address	= {San Diego, California, USA},
  urldate	= {2023-11-29},
  abstract	= {Program slicing is a method used by experienced computer
		  programmers for abstracting from programs. Starting from a
		  subset of a program's behavior, slicing reduces that
		  program to a minimal form which still produces that
		  behavior. The reduced program, called a ``slice'', is an
		  independent program guaranteed to faithfully represent the
		  original program within the domain of the specified subset
		  of behavior. Finding a slice is in general unsolvable. A
		  dataflow algorithm is presented for approximating slices
		  when the behavior subset is specified as the values of a
		  set of variables at a statement. Experimental evidence is
		  presented that these slices are used by programmers during
		  debugging. Experience with two automatic slicing tools is
		  summarized. New measures of program complexity are
		  suggested based on the organization of a program's
		  slices.},
  isbn		= {978-0-89791-146-7},
  keywords	= {Data flow analysis,Debugging,Human factors,Program
		  maintenance,Program metrics,Software tools}
}

@Article{	  weiser99,
  title		= {The Computer for the 21st Century},
  author	= {Weiser, Mark},
  year		= {1999},
  month		= jul,
  journal	= {ACM SIGMOBILE Mobile Computing and Communications Review},
  volume	= {3},
  number	= {3},
  pages		= {3--11},
  issn		= {1559-1662},
  doi		= {10.1145/329124.329126},
  urldate	= {2024-02-11},
  abstract	= {Specialized elements of hardware and software, connected
		  by wires, radio waves and infrared, will be so ubiquitous
		  that no one will notice their presence.}
}

@Article{	  weiss75,
  title		= {Time-Reversibility of Linear Stochastic Processes},
  author	= {Weiss, Gideon},
  year		= {1975},
  month		= dec,
  journal	= {Journal of Applied Probability},
  volume	= {12},
  number	= {4},
  pages		= {831--836},
  issn		= {0021-9002, 1475-6072},
  doi		= {10.2307/3212735},
  urldate	= {2024-11-11},
  abstract	= {Time-reversibility is defined for a process X(t) as the
		  property that \{X(t1), {\dots}, X(tn)\} and \{X(-- t1),
		  {\dots}, X(-- tn)\} have the same joint probability
		  distribution. It is shown that, for discrete mixed
		  autoregressive moving-average processes, this is a unique
		  property of Gaussian processes.},
  langid	= {english},
  keywords	= {CHARACTERISATIONS OF THE NORMAL DISTRIBUTION,SHOT
		  NOISE,STOCHASTIC PROCESSES,TIME SERIES,TIME-REVERSIBILITY}
}

@InProceedings{	  wolinski19,
  title		= {Globally Optimal Page Breaking with Column Balancing: A
		  Case Study},
  shorttitle	= {Globally Optimal Page Breaking with Column Balancing},
  booktitle	= {Proceedings of the {{ACM Symposium}} on {{Document
		  Engineering}} 2019},
  author	= {Woli{\'n}ski, Marcin},
  year		= {2019},
  month		= sep,
  series	= {{{DocEng}} '19},
  pages		= {1--4},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3342558.3345405},
  urldate	= {2024-01-09},
  abstract	= {The paper presents a dynamic programming algorithm that
		  finds the globally optimal sequence of page breaks for a
		  book avoiding widows and orphans when the only source of
		  variation is the possibility to break selected paragraphs
		  into varying number of lines by skillful selection of line
		  breaks. The text is set in two-columns, on each last page
		  of a chapter the columns must be balanced. We show how the
		  balancing process can be included in the global
		  optimization. The algorithm is applied to a real-life
		  problem of typesetting a small-format two-column 800 pages
		  long dictionary. We analyze the typesetting process
		  including the proofing phase where local changes in the
		  text can globally influence page breaks. This problem
		  provides an ideal test-bed for global optimization since
		  the typographic model involved is relatively easy - the
		  material processed is merely a stream of paragraphs. On the
		  other hand, breaking the book under these conditions is a
		  very tedious and frustrating job for a human typesetter, as
		  it typically requires hours of trial and error.},
  isbn		= {978-1-4503-6887-2},
  keywords	= {automatic layout,global optimization,page
		  breaking,typesetting}
}

@Article{	  woodruff14,
  title		= {The {{CHERI}} Capability Model: Revisiting {{RISC}} in an
		  Age of Risk},
  shorttitle	= {The {{CHERI}} Capability Model},
  author	= {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall,
		  David and Moore, Simon W. and Anderson, Jonathan and Davis,
		  Brooks and Laurie, Ben and Neumann, Peter G. and Norton,
		  Robert and Roe, Michael},
  year		= {2014},
  month		= jun,
  journal	= {ACM SIGARCH Computer Architecture News},
  volume	= {42},
  number	= {3},
  pages		= {457--468},
  issn		= {0163-5964},
  doi		= {10.1145/2678373.2665740},
  urldate	= {2024-01-18},
  abstract	= {Motivated by contemporary security challenges, we
		  reevaluate and refine capability-based addressing for the
		  RISC era. We present CHERI, a hybrid capability model that
		  extends the 64-bit MIPS ISA with byte-granularity memory
		  protection. We demonstrate that CHERI enables language
		  memory model enforcement and fault isolation in hardware
		  rather than software, and that the CHERI mechanisms are
		  easily adopted by existing programs for efficient
		  in-program memory safety. In contrast to past capability
		  models, CHERI complements, rather than replaces, the
		  ubiquitous page-based protection mechanism, providing a
		  migration path towards deconflating data-structure
		  protection and OS memory management. Furthermore, CHERI
		  adheres to a strict RISC philosophy: it maintains a
		  load-store architecture and requires only singlecycle
		  instructions, and supplies protection primitives to the
		  compiler, language runtime, and operating system. We
		  demonstrate a mature FPGA implementation that runs the
		  FreeBSD operating system with a full range of software and
		  an open-source application suite compiled with an extended
		  LLVM to use CHERI memory protection. A limit study compares
		  published memory safety mechanisms in terms of instruction
		  count and memory overheads. The study illustrates that
		  CHERI is performance-competitive even while providing
		  assurance and greater flexibility with simpler hardware}
}

@Article{	  xie19,
  title		= {Automatic {{Loop Summarization}} via {{Path Dependency
		  Analysis}}},
  author	= {Xie, Xiaofei and Chen, Bihuan and Zou, Liang and Liu, Yang
		  and Le, Wei and Li, Xiaohong},
  year		= {2019},
  month		= jun,
  journal	= {IEEE Transactions on Software Engineering},
  volume	= {45},
  number	= {6},
  pages		= {537--557},
  issn		= {1939-3520},
  doi		= {10.1109/TSE.2017.2788018},
  urldate	= {2024-03-18},
  abstract	= {Analyzing loops is very important for various software
		  engineering tasks such as bug detection, test case
		  generation and program optimization. However, loops are
		  very challenging structures for program analysis,
		  especially when (nested) loops contain multiple paths that
		  have complex interleaving relationships. In this paper, we
		  propose the path dependency automaton (PDA) to capture the
		  dependencies among the multiple paths in a loop. Based on
		  the PDA, we first propose a loop classification to
		  understand the complexity of loop summarization. Then, we
		  propose a loop analysis framework, named Proteus, which
		  takes a loop program and a set of variables of interest as
		  inputs and summarizes path-sensitive loop effects (i.e.,
		  disjunctive loop summary) on the variables of interest. An
		  algorithm is proposed to traverse the PDA to summarize the
		  effect for all possible executions in the loop. We have
		  evaluated Proteus using loops from five open-source
		  projects and two well-known benchmarks and applying the
		  disjunctive loop summary to three applications: loop bound
		  analysis, program verification and test case generation.
		  The evaluation results have demonstrated that Proteus can
		  compute a more precise bound than the existing loop bound
		  analysis techniques; Proteus can significantly outperform
		  the state-of-the-art tools for loop program verification;
		  and Proteus can help generate test cases for deep loops
		  within one second, while symbolic execution tools KLEE and
		  Pex either need much more time or fail.},
  keywords	= {Automata,Benchmark testing,Debugging,Disjunctive loop
		  summary,path dependency automaton,path interleaving,Public
		  domain software}
}

@Article{	  ye22,
  title		= {Oblivious Algebraic Data Types},
  author	= {Ye, Qianchuan and Delaware, Benjamin},
  year		= {2022},
  month		= jan,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {6},
  number	= {POPL},
  pages		= {51:1--51:29},
  doi		= {10.1145/3498713},
  urldate	= {2023-10-17},
  abstract	= {Secure computation allows multiple parties to compute
		  joint functions over private data without leaking any
		  sensitive data, typically using powerful cryptographic
		  techniques. Writing secure applications using these
		  techniques directly can be challenging, resulting in the
		  development of several programming languages and compilers
		  that aim to make secure computation accessible.
		  Unfortunately, many of these languages either lack or have
		  limited support for rich recursive data structures, like
		  trees. In this paper, we propose a novel representation of
		  structured data types, which we call oblivious algebraic
		  data types, and a language for writing secure computations
		  using them. This language combines dependent types with
		  constructs for oblivious computation, and provides a
		  security-type system which ensures that adversaries can
		  learn nothing more than the result of a computation. Using
		  this language, authors can write a single function over
		  private data, and then easily build an equivalent secure
		  computation according to a desired public view of their
		  data.},
  keywords	= {Algebraic Data Types,Dependent Types,Multiparty
		  Computation,Oblivious Computation}
}

@Article{	  yi24,
  title		= {Compatible {{Branch Coverage Driven Symbolic Execution}}
		  for {{Efficient Bug Finding}}},
  author	= {Yi, Qiuping and Yu, Yifan and Yang, Guowei},
  year		= {2024},
  month		= jun,
  journal	= {Reproduction Package For Article `Compatible Branch
		  Coverage Driven Symbolic Execution for Efficient Bug
		  Finding`},
  volume	= {8},
  number	= {PLDI},
  pages		= {213:1633--213:1655},
  doi		= {10.1145/3656443},
  urldate	= {2024-08-20},
  abstract	= {Symbolic execution is a powerful technique for bug finding
		  by generating test inputs to systematically explore all
		  feasible paths within a given threshold. However, its
		  practical usage is often limited by the path explosion
		  problem. In this paper, we propose compatible branch
		  coverage driven symbolic execution for efficient bug
		  finding. Our new technique owns a novel path-pruning
		  strategy obtained from program dependency analysis to
		  effectively avoid unnecessary explorations. Specifically,
		  based on a Compatible Branch Set, our technique directs
		  symbolic execution to explore feasible branches while
		  soundly pruning redundant paths that have no new
		  contributions to branch coverage. We have implemented our
		  approach atop KLEE and conducted experiments on a set of
		  programs from Siemens Suite, GNU Coreutils, and other
		  real-world programs. Experimental results show that,
		  compared with the state-of-the-art symbolic execution
		  techniques, our approach always uses significantly less
		  time to reproduce bugs while achieving the same or better
		  branch coverage. On average, our approach got over 45\%
		  path reduction and 3x speedup on the GNU Coreutils
		  programs.}
}

@InProceedings{	  yokoyama07,
  title		= {A Reversible Programming Language and Its Invertible
		  Self-Interpreter},
  booktitle	= {Proceedings of the 2007 {{ACM SIGPLAN}} Symposium on
		  {{Partial}} Evaluation and Semantics-Based Program
		  Manipulation},
  author	= {Yokoyama, Tetsuo and Gl{\"u}ck, Robert},
  year		= {2007},
  month		= jan,
  series	= {{{PEPM}} '07},
  pages		= {144--153},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1244381.1244404},
  urldate	= {2024-11-09},
  abstract	= {A reversible programming language supports deterministic
		  forward and backward computation. We formalize the
		  programming language Janus and prove its reversibility. We
		  provide a program inverter for the language and implement a
		  self-interpreter that achieves deterministic forward and
		  backward interpretation of Janus programs without using a
		  computation history. As the self-interpreter is implemented
		  in a reversible language, it is invertible using local
		  program inversion. Many physical phenomena are reversible
		  and we demonstrate the power of Janus by implementing a
		  reversible program for discrete simulation of the
		  Schr{\"o}dinger wave equation that can be inverted as well
		  as run forward and backward.},
  isbn		= {978-1-59593-620-2}
}

@InProceedings{	  yokoyama08,
  title		= {Principles of a Reversible Programming Language},
  booktitle	= {Proceedings of the 5th Conference on {{Computing}}
		  Frontiers},
  author	= {Yokoyama, Tetsuo and Axelsen, Holger Bock and Gl{\"u}ck,
		  Robert},
  year		= {2008},
  month		= may,
  series	= {{{CF}} '08},
  pages		= {43--54},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/1366230.1366239},
  urldate	= {2024-11-10},
  abstract	= {The principles of reversible programming languages are
		  explicated and illustrated with reference to the design of
		  a high-level imperative language, Janus. The fundamental
		  properties for such languages include backward as well as
		  forward determinism and reversible updates of data. The
		  unique design features of the language include explicit
		  post-condition assertions, direct access to an inverse
		  semantics and the possibility of clean
		  (\{{\textbackslash}ie\}, garbage-free) computation of
		  injective functions. We suggest the clean simulation of
		  reversible Turing machines as a criterion for computing
		  strength of reversible languages, and demonstrate this for
		  Janus. We show the practicality of the language by
		  implementation of a reversible fast Fourier transform. Our
		  results indicate that the reversible programming paradigm
		  has fundamental properties that are relevant to many
		  different areas of computer science.},
  isbn		= {978-1-60558-077-7}
}

@InProceedings{	  yokoyama12,
  title		= {Towards a {{Reversible Functional Language}}},
  booktitle	= {Reversible {{Computation}}},
  author	= {Yokoyama, Tetsuo and Axelsen, Holger Bock and Gl{\"u}ck,
		  Robert},
  editor	= {De Vos, Alexis and Wille, Robert},
  year		= {2012},
  pages		= {14--29},
  publisher	= {Springer},
  address	= {Berlin, Heidelberg},
  doi		= {10.1007/978-3-642-29517-1_2},
  abstract	= {We identify concepts of reversibility for a functional
		  language by means of a set of semantic rules with specific
		  properties. These properties include injectivity along with
		  local backward determinism, an important operational
		  property for an efficient reversible language. We define a
		  concise reversible first-order functional language in which
		  access to the backward semantics is provided to the
		  programmer by inverse function calls. Reversibility
		  guarantees that in this language a backward run (inverse
		  interpretation) is as fast as the corresponding forward run
		  itself. By adopting a symmetric first-match policy for case
		  expressions, we can write overlapping patterns in case
		  branches, as is customary in ordinary functional languages,
		  and also in leaf expressions, unlike existing inverse
		  interpreter methods, which enables concise programs. In
		  patterns, the use of a duplication/equality operator also
		  simplifies inverse computation and program inversion. We
		  discuss the advantages of a reversible functional language
		  using example programs, including run-length encoding.
		  Program inversion is seen to be as lightweight as for
		  imperative reversible languages and realized by recursive
		  descent. Finally, we show that the proposed language is
		  r-Turing complete.},
  isbn		= {978-3-642-29517-1},
  langid	= {english},
  keywords	= {Functional Language,General Matcher,Inverse
		  Computation,Operational Semantic,Turing Machine}
}

@Article{	  zelkowitz73,
  title		= {Reversible Execution},
  author	= {Zelkowitz, M. V.},
  year		= {1973},
  month		= sep,
  journal	= {Commun. ACM},
  volume	= {16},
  number	= {9},
  pages		= {566},
  issn		= {0001-0782},
  doi		= {10.1145/362342.362360},
  urldate	= {2024-11-10},
  abstract	= {The ability to backtrack, or retrace, the execution of a
		  computer program has gained wider acceptance recently as a
		  desired feature within a programming language. This is
		  particularly useful in two different applications: (1) In
		  debugging systems where the trace output is saved and can
		  be interrogated under programmer control [1, 3]; (2) In
		  artificial intelligence applications where one is trying to
		  prove a certain result. It is frequently necessary to
		  backup the proof and try some alternative path [2].}
}

@Article{	  zhang23,
  title		= {Interval {{Parsing Grammars}} for {{File Format
		  Parsing}}},
  author	= {Zhang, Jialun and Morrisett, Greg and Tan, Gang},
  year		= {2023},
  month		= jun,
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {7},
  number	= {PLDI},
  pages		= {150:1073--150:1095},
  doi		= {10.1145/3591264},
  urldate	= {2023-10-20},
  abstract	= {File formats specify how data is encoded for persistent
		  storage. They cannot be formalized as context-free grammars
		  since their specifications include context-sensitive
		  patterns such as the random access pattern and the
		  type-length-value pattern. We propose a new grammar
		  mechanism called Interval Parsing Grammars IPGs) for file
		  format specifications. An IPG attaches to every
		  nonterminal/terminal an interval, which specifies the range
		  of input the nonterminal/terminal consumes. By connecting
		  intervals and attributes, the context-sensitive patterns in
		  file formats can be well handled. In this paper, we
		  formalize IPGs' syntax as well as its semantics, and its
		  semantics naturally leads to a parser generator that
		  generates a recursive-descent parser from an IPG. In
		  general, IPGs are declarative, modular, and enable
		  termination checking. We have used IPGs to specify a number
		  of file formats including ZIP, ELF, GIF, PE, and part of
		  PDF; we have also evaluated the performance of the
		  generated parsers.},
  keywords	= {Context-sensitive Grammars,File Formats}
}

@InProceedings{	  zhou22,
  title		= {Synthesizing Analytical {{SQL}} Queries from Computation
		  Demonstration},
  booktitle	= {Proceedings of the 43rd {{ACM SIGPLAN International
		  Conference}} on {{Programming Language Design}} and
		  {{Implementation}}},
  author	= {Zhou, Xiangyu and Bodik, Rastislav and Cheung, Alvin and
		  Wang, Chenglong},
  year		= {2022},
  month		= jun,
  series	= {{{PLDI}} 2022},
  pages		= {168--182},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  doi		= {10.1145/3519939.3523712},
  urldate	= {2023-10-20},
  abstract	= {Analytical SQL is widely used in modern database
		  applications and data analysis. However, its partitioning
		  and grouping operators are challenging for novice users.
		  Unfortunately, programming by example, shown effective on
		  standard SQL, are less attractive because examples for
		  analytical queries are more laborious to solve by hand. To
		  make demonstrations easier to author, we designed a new
		  end-user specification, programming by computation
		  demonstration, that allows the user to demonstrate the task
		  using a (possibly incomplete) cell-level computation trace.
		  This specification is exploited in a new abstraction-based
		  synthesis algorithm to prove that a partially formed query
		  cannot be completed to satisfy the specification, allowing
		  us to prune the search tree. We implemented our approach in
		  a tool named Sickle and tested it on 80 real-world
		  analytical SQL tasks. Results show that even from small
		  demonstrations, Sickle can solve 76 tasks, in 12.8 seconds
		  on average, while the prior approaches can solve only 60
		  tasks and are on average 22.5 times slower. Furthermore,
		  our user study with 13 participants reveals that our
		  specification increases user efficiency and confidence on
		  challenging tasks.},
  isbn		= {978-1-4503-9265-5},
  keywords	= {program synthesis,programing languages}
}
